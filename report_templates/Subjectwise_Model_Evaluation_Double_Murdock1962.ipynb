{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b0cd44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:15:12.684754Z",
     "iopub.status.busy": "2022-06-03T19:15:12.683844Z",
     "iopub.status.idle": "2022-06-03T19:15:18.683602Z",
     "shell.execute_reply": "2022-06-03T19:15:18.682180Z"
    },
    "papermill": {
     "duration": 6.049561,
     "end_time": "2022-06-03T19:15:18.686945",
     "exception": false,
     "start_time": "2022-06-03T19:15:12.637384",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# | code-summary: code -- load dependencies and data and select parameters\n",
    "\n",
    "from compmemlearn.fitting import generate_objective_function\n",
    "from compmemlearn.datasets import events_metadata, generate_trial_mask\n",
    "from scipy.optimize import differential_evolution\n",
    "from numba.typed import List, Dict\n",
    "from numba.core import types\n",
    "from numba import njit\n",
    "from psifr import fr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "lb = np.finfo(float).eps\n",
    "ub = 1 - np.finfo(float).eps\n",
    "\n",
    "figure_caption = \"\"\"Distribution of log-likelihood scores of recall sequences exhibited by each subject in dataset under each considered model.\"\"\"\n",
    "\n",
    "section_tag = \"LohnasKahanaCond4\"\n",
    "\n",
    "data_path = \"../data/LohnasKahana2014.csv\"\n",
    "results_path = \"results/\"\n",
    "trial_query = \"condition == 4\"\n",
    "\n",
    "model_paths = [\n",
    "    \"compmemlearn.models.Base_CMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "]\n",
    "\n",
    "model_names = [\"PrototypeCMR\", \"ICMR_2_0_0\", \"ICMR_2_0_1\", \"ICMR_2_1_0\", \"ICMR_2_1_1\"]\n",
    "\n",
    "free_parameters = [\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"choice_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"choice_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"choice_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"context_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"context_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "]\n",
    "bounds = [\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "]\n",
    "fixed_parameters = [\n",
    "    {},\n",
    "    {\"feature_sensitivity\": 1, \"context_sensitivity\": 1, \"learn_first\": False},\n",
    "    {\"feature_sensitivity\": 1, \"context_sensitivity\": 1, \"learn_first\": True},\n",
    "    {\"feature_sensitivity\": 1, \"choice_sensitivity\": 1, \"learn_first\": False},\n",
    "    {\"feature_sensitivity\": 1, \"choice_sensitivity\": 1, \"learn_first\": True},\n",
    "]\n",
    "\n",
    "analysis_paths = ['compmemlearn.analyses.plot_spc', 'compmemlearn.analyses.plot_crp', 'compmemlearn.analyses.plot_pfr']\n",
    "analysis_names = ['spc', 'crp', 'pfr']\n",
    "\n",
    "experiment_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd51b461",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:15:18.744105Z",
     "iopub.status.busy": "2022-06-03T19:15:18.743721Z",
     "iopub.status.idle": "2022-06-03T19:15:18.778888Z",
     "shell.execute_reply": "2022-06-03T19:15:18.777647Z"
    },
    "papermill": {
     "duration": 0.065863,
     "end_time": "2022-06-03T19:15:18.782062",
     "exception": false,
     "start_time": "2022-06-03T19:15:18.716199",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "data_path = \"data/Murdock1962.csv\"\n",
    "trial_query = \"subject > -1\"\n",
    "model_paths = [\n",
    "    \"compmemlearn.models.Base_CMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "]\n",
    "model_names = [\"PrototypeCMR\", \"ICMR_2_0_0\", \"ICMR_2_0_1\", \"ICMR_2_1_0\", \"ICMR_2_1_1\"]\n",
    "free_parameters = [\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"choice_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"choice_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"choice_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"context_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"context_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "]\n",
    "bounds = [\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "]\n",
    "fixed_parameters = [\n",
    "    {},\n",
    "    {\"feature_sensitivity\": 1, \"context_sensitivity\": 1, \"learn_first\": False},\n",
    "    {\"feature_sensitivity\": 1, \"context_sensitivity\": 1, \"learn_first\": True},\n",
    "    {\"feature_sensitivity\": 1, \"choice_sensitivity\": 1, \"learn_first\": False},\n",
    "    {\"feature_sensitivity\": 1, \"choice_sensitivity\": 1, \"learn_first\": True},\n",
    "]\n",
    "section_tag = \"Murdock1962\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c26471d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:15:18.835319Z",
     "iopub.status.busy": "2022-06-03T19:15:18.834867Z",
     "iopub.status.idle": "2022-06-03T19:15:18.841422Z",
     "shell.execute_reply": "2022-06-03T19:15:18.840299Z"
    },
    "papermill": {
     "duration": 0.036619,
     "end_time": "2022-06-03T19:15:18.844050",
     "exception": false,
     "start_time": "2022-06-03T19:15:18.807431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'Howard' in section_tag or ('Lohnas' in section_tag and '1' not in section_tag):\n",
    "    analysis_paths = ['compmemlearn.analyses.plot_flex_spc', 'compmemlearn.analyses.plot_flex_crp', 'compmemlearn.analyses.plot_flex_pfr', 'compmemlearn.analyses.plot_rpl']\n",
    "    analysis_names = ['spc', 'crp', 'pfr', 'rpl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36671552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:15:18.898212Z",
     "iopub.status.busy": "2022-06-03T19:15:18.897749Z",
     "iopub.status.idle": "2022-06-03T19:20:06.398155Z",
     "shell.execute_reply": "2022-06-03T19:20:06.396295Z"
    },
    "papermill": {
     "duration": 287.571829,
     "end_time": "2022-06-03T19:20:06.441964",
     "exception": false,
     "start_time": "2022-06-03T19:15:18.870135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function murdock_objective_function.<locals>.objective_function at 0x2b431671b9d0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14060.115502064733\n",
      "23348.218353032524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function murdock_objective_function.<locals>.objective_function at 0x2b4317e97e50>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14060.115502064733\n",
      "23348.218353032524\n",
      "<function murdock_objective_function.<locals>.objective_function at 0x2b4319636f70>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14060.115502064733\n",
      "23348.218353032524\n",
      "<function murdock_objective_function.<locals>.objective_function at 0x2b431856f040>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14060.115502064733\n",
      "23348.218353032524\n",
      "<function murdock_objective_function.<locals>.objective_function at 0x2b43180d4f70>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14060.115502064733\n",
      "23348.218353032524\n",
      "dependencies and parameters validated\n"
     ]
    }
   ],
   "source": [
    "#| code-summary: code -- test that specified parameters are valid\n",
    "#| output: false\n",
    "\n",
    "events = pd.read_csv(data_path)\n",
    "\n",
    "trials, list_lengths, presentations = events_metadata(events)\n",
    "trial_mask = generate_trial_mask(events, trial_query)\n",
    "\n",
    "# import models from specified source\n",
    "models = []\n",
    "for i in range(len(model_paths)):\n",
    "    module_name, model_name = model_paths[i].rsplit('.',1)\n",
    "    module = importlib.import_module(module_name)\n",
    "    models.append(getattr(module, model_name))\n",
    "\n",
    "# import analyses from specified source\n",
    "analyses = []\n",
    "for i in range(len(analysis_paths)):\n",
    "    module_name, analysis_name = analysis_paths[i].rsplit('.',1)\n",
    "    module = importlib.import_module(module_name)\n",
    "    analyses.append(getattr(module, analysis_name))\n",
    "\n",
    "# make sure model initializes with provided parameters and boundaries\n",
    "for model_index, model_class in enumerate(models):\n",
    "\n",
    "    @njit(fastmath=True, nogil=True)\n",
    "    def init_model(item_count, presentation_count, parameters):\n",
    "        return model_class(item_count, presentation_count, parameters)\n",
    "\n",
    "    subject_specific_trial_mask = np.logical_and(\n",
    "                generate_trial_mask(events, f'subject == {pd.unique(events.subject)[0]}'), trial_mask)\n",
    "\n",
    "    cost_function = generate_objective_function(\n",
    "        [trials[i][subject_specific_trial_mask[i]] for i in range(len(trials))],\n",
    "        [presentations[i][subject_specific_trial_mask[i]] for i in range(len(presentations))],\n",
    "        list_lengths,\n",
    "        init_model,\n",
    "        fixed_parameters[model_index],\n",
    "        free_parameters[model_index],\n",
    "    )\n",
    "    print(cost_function)\n",
    "    \n",
    "    for boundary_index in range(2):\n",
    "        x = np.array([each[boundary_index] for each in bounds[model_index]])\n",
    "        assert(len(x) == len(free_parameters[model_index])) \n",
    "\n",
    "        # parameter configuration\n",
    "        parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n",
    "        for name, value in fixed_parameters[model_index].items():\n",
    "            parameters[name] = value\n",
    "        for i in range(len(free_parameters[model_index])):\n",
    "                parameters[free_parameters[model_index][i]] = x[i]\n",
    "\n",
    "        model = init_model(20, 20, parameters)\n",
    "        model.experience(model.items)\n",
    "        model.free_recall()\n",
    "\n",
    "        print(cost_function(x))\n",
    "\n",
    "print('dependencies and parameters validated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69f8fcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:20:06.508546Z",
     "iopub.status.busy": "2022-06-03T19:20:06.508038Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-06-03T19:20:06.473076",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "individual fits for PrototypeCMR with tag Murdock1962 already exist\n",
      "ICMR_2_0_0, Subject 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4483.293389188407\n",
      "ICMR_2_0_0, Subject 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5633.23706610298\n",
      "ICMR_2_0_0, Subject 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5285.399568325298\n",
      "ICMR_2_0_0, Subject 4\n"
     ]
    }
   ],
   "source": [
    "# | code-summary: code -- 1) fit each model class participant-by-participant\n",
    "# | output: false\n",
    "\n",
    "for model_index, model_class in enumerate(models):\n",
    "\n",
    "    # load individual fits for this model and section tag from csv if they exist\n",
    "    if os.path.isfile(results_path + '{}_{}_individual.csv'.format(section_tag, model_names[model_index])):\n",
    "        pd.read_csv(results_path + '{}_{}_individual.csv'.format(section_tag, model_names[model_index]))\n",
    "        print('individual fits for {} with tag {} already exist'.format(model_names[model_index], section_tag))\n",
    "\n",
    "    # otherwise, fit each participant individually\n",
    "    else:\n",
    "        model_individual_fits = []\n",
    "\n",
    "        @njit(fastmath=True, nogil=True)\n",
    "        def init_model(item_count, presentation_count, parameters):\n",
    "            return model_class(item_count, presentation_count, parameters)\n",
    "\n",
    "        for subject in pd.unique(events.subject):\n",
    "            print(f'{model_names[model_index]}, Subject {subject}')\n",
    "\n",
    "            subject_specific_trial_mask = np.logical_and(\n",
    "                generate_trial_mask(events, f'subject == {subject}'), trial_mask)\n",
    "            \n",
    "            try:\n",
    "                # cost function to be minimized\n",
    "                # ours scales inversely with the probability that the data could have been\n",
    "                # generated using the specified parameters and our model\n",
    "                cost_function = generate_objective_function(\n",
    "                    [trials[i][subject_specific_trial_mask[i]] for i in range(len(trials))],\n",
    "                    [presentations[i][subject_specific_trial_mask[i]] for i in range(len(presentations))],\n",
    "                    list_lengths,\n",
    "                    init_model,\n",
    "                    fixed_parameters[model_index],\n",
    "                    free_parameters[model_index],\n",
    "                )\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            fit_result =  differential_evolution(cost_function, bounds[model_index], disp=False)\n",
    "\n",
    "            fitted_parameters = {\n",
    "                'subject': subject, 'trial_count': np.sum(subject_specific_trial_mask), \n",
    "                'likelihood': fit_result.fun, 'model': model_names[model_index]\n",
    "                }\n",
    "            for i in range(len(fit_result.x)):\n",
    "                fitted_parameters[free_parameters[model_index][i]] = fit_result.x[i]\n",
    "            for key in fixed_parameters[model_index]:\n",
    "                fitted_parameters[key] = fixed_parameters[model_index][key]\n",
    "\n",
    "            model_individual_fits.append(pd.DataFrame.from_dict(fitted_parameters, orient='index').T)\n",
    "            print(model_individual_fits[-1]['likelihood'][0])\n",
    "\n",
    "        model_individual_fits = pd.concat(model_individual_fits, ignore_index=True)\n",
    "        model_individual_fits.to_csv(\n",
    "            results_path + '{}_{}_individual.csv'.format(section_tag, model_names[model_index]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89796b4f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| code-summary: code -- 3) plot distribution of log-likelihoods across individual subjects\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# build individual fits df concatenating results from each model\n",
    "individual_fits = []\n",
    "for model_index, model_class in enumerate(models):\n",
    "    individual_fits.append(\n",
    "        pd.read_csv(results_path + '{}_{}_individual.csv'.format(section_tag, model_names[model_index])))\n",
    "individual_fits = pd.concat(individual_fits, ignore_index=True)\n",
    "\n",
    "# plot distribution of log-likelihoods across individual subjects\n",
    "g = sns.catplot(x='model', y='likelihood', data=individual_fits, kind='violin', inner='stick')\n",
    "sns.swarmplot(x=\"model\", y=\"likelihood\", data=individual_fits, color=\"k\", size=3, ax=g.ax)\n",
    "g.ax.set_ylabel('Individual Log-Likelihood')\n",
    "#plt.savefig(results_path + 'individual_{}.pdf'.format(section_tag), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3cfae3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "individual_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a9a95",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| code-summary: display markdown rendering of summary table\n",
    "#| echo: false\n",
    "#| input: false\n",
    "#| output: asis\n",
    "\n",
    "summary_table = pd.DataFrame(group.describe().rename(columns={'likelihood':name}).squeeze()\n",
    "            for name, group in individual_fits[['model', 'likelihood']].groupby('model')).T.to_markdown()\n",
    "\n",
    "print(\"\"\"::: {{#fig-{section_tag}fits layout-nrow=2 layout-valign=\"center\"}}\n",
    "\n",
    "![]({results_path}individual_{section_tag}.pdf)\n",
    "\n",
    "{summary_table}\n",
    "\n",
    "{individual_fits_caption}\n",
    ":::\"\"\".format(section_tag=section_tag, summary_table=summary_table, individual_fits_caption=figure_caption, results_path=results_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa5be3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| code-summary: perform t-tests on individual-level fits\n",
    "#| output: false\n",
    " \n",
    "from scipy.stats import ttest_rel\n",
    "import itertools\n",
    "\n",
    "for combination in itertools.combinations(pd.unique(individual_fits.model), 2):\n",
    "\n",
    "    print(combination)\n",
    "    print(ttest_rel(individual_fits[individual_fits.model == combination[0]].likelihood, individual_fits[individual_fits.model == combination[1]].likelihood, alternative='two-sided'))\n",
    "    print(ttest_rel(individual_fits[individual_fits.model == combination[0]].likelihood, individual_fits[individual_fits.model == combination[1]].likelihood, alternative='less'))\n",
    "    print(ttest_rel(individual_fits[individual_fits.model == combination[0]].likelihood, individual_fits[individual_fits.model == combination[1]].likelihood, alternative='greater'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7c5c8a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for combination in itertools.combinations(pd.unique(individual_fits.model), 2):\n",
    "\n",
    "    print(combination)\n",
    "    print(np.mean(individual_fits[individual_fits.model == combination[0]].likelihood.values < individual_fits[individual_fits.model == combination[1]].likelihood.values), \n",
    "        np.mean(individual_fits[individual_fits.model == combination[1]].likelihood.values < individual_fits[individual_fits.model == combination[0]].likelihood.values))\n",
    "\n",
    "    print(np.sum(individual_fits[individual_fits.model == combination[0]].likelihood.values < individual_fits[individual_fits.model == combination[1]].likelihood.values), \n",
    "        np.sum(individual_fits[individual_fits.model == combination[1]].likelihood.values < individual_fits[individual_fits.model == combination[0]].likelihood.values))\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fcd9f4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_weights(positive_log_likelihoods, number_parameters, N):\n",
    "    AIC = 2 * positive_log_likelihoods + 2 * number_parameters\n",
    "    AICc = AIC #+ (2*np.power(number_parameters, 2) + 2 * number_parameters) / (N - number_parameters - 2)\n",
    "    AICd = AIC - np.min(AICc)\n",
    "    #return AICd\n",
    "    AICw = np.exp(-.5 * AICd) / np.sum(np.exp(-.5 * AICd))\n",
    "    return AICw\n",
    "\n",
    "aicw = {'Model': [], 'Subject': [], 'AICw': []}\n",
    "\n",
    "total_nlns = np.zeros(len(models))\n",
    "for subject_index, subject in enumerate(pd.unique(events.subject)):\n",
    "\n",
    "    subject_specific_trial_mask = np.logical_and(\n",
    "                    generate_trial_mask(events, f'subject == {subject}'), trial_mask)\n",
    "\n",
    "    nlnLs = []\n",
    "    for model_index, model_class in enumerate(models):\n",
    "        nlnLs.append(\n",
    "            individual_fits[individual_fits.model == model_names[model_index]].likelihood.values[subject_index])\n",
    "    nlnLs = np.array(nlnLs)\n",
    "    total_nlns += nlnLs\n",
    "    \n",
    "    weights = model_weights(nlnLs, len(free_parameters[model_index]), np.sum(subject_specific_trial_mask))\n",
    "    #print(weights)\n",
    "    for model_index, model_class in enumerate(models):\n",
    "        aicw['Model'].append(model_names[model_index])\n",
    "        aicw['Subject'].append(subject)\n",
    "        aicw['AICw'].append(weights[model_index])\n",
    "\n",
    "aicw = pd.DataFrame(data=aicw)\n",
    "total_aicw = model_weights(total_nlns, len(free_parameters[model_index]), np.sum(trial_mask))\n",
    "print(total_aicw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a203e6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "x = sns.pointplot(x=\"Model\", y=\"AICw\", data=aicw, join=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1492a90",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from compmemlearn.datasets import find_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d916c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_df_from_events(model_class, parameters, events, trial_mask, experiment_count, first_recall_item=None):\n",
    "\n",
    "    trials, list_lengths, presentations = events_metadata(events)\n",
    "    chose = [i for i in range(len(trial_mask)) if np.sum(trial_mask[i]) != 0]\n",
    "    assert(len(chose) == 1)\n",
    "    chose = chose[0]\n",
    "    trial_mask = trial_mask[chose]\n",
    "    trials = trials[chose][trial_mask]\n",
    "    presentations = presentations[chose][trial_mask]\n",
    "\n",
    "    default_columns = ['subject', 'list', 'trial_type', 'item', 'input', 'output', 'study', 'recall', 'repeat', 'intrusion', 'first_input']\n",
    "    extra_columns = [each for each in events.columns if each not in default_columns]\n",
    "\n",
    "    labels = {}\n",
    "    for column in extra_columns:\n",
    "        try:\n",
    "            labels[column] = (\n",
    "                events.pivot_table(index=['subject', 'list'], dropna=False)[column].values)\n",
    "\n",
    "            if 'list length' in events.columns:\n",
    "                trial_details = events.pivot_table(index=['subject', 'list'], dropna=False).reset_index()\n",
    "                list_length_mask = trial_details.eval(trial_query).to_numpy(dtype='bool')\n",
    "                labels[column] = labels[column][list_length_mask]\n",
    "            else:\n",
    "                labels[column] = labels[column][trial_mask]\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    data = []\n",
    "    for experiment in range(experiment_count):\n",
    "        for trial_index in range(len(presentations)):\n",
    "        \n",
    "            # retrieve presentation sequence for this trial and measure number of unique items\n",
    "            presentation = presentations[trial_index]\n",
    "            item_count = np.max(presentation)+1\n",
    "\n",
    "            # record presentation events\n",
    "            for presentation_index, presentation_event in enumerate(presentation):\n",
    "                data.append([\n",
    "                    experiment, trial_index, 'study', presentation_index+1, presentation_event, presentation_index+1])\n",
    "                for label in labels:\n",
    "                    data[-1].append(labels[label][trial_index])\n",
    "\n",
    "            # simulate recall and identify first study position of each recalled item\n",
    "            model = model_class(item_count, len(presentation), parameters)\n",
    "            model.experience(model.items[presentation])\n",
    "            if first_recall_item is not None:\n",
    "                model.force_recall(first_recall_item)\n",
    "            recalled = model.free_recall()\n",
    "            trial = [find_first(recalled[i], presentation) + 1 for i in range(len(recalled))]\n",
    "\n",
    "            # record recall events\n",
    "            for recall_index, recall_event in enumerate(trial):\n",
    "                if recall_event != 0:\n",
    "                    data.append([\n",
    "                        experiment, trial_index, 'recall', recall_index+1, \n",
    "                        presentation[recall_event-1], recall_event])\n",
    "                    for label in labels:\n",
    "                        data[-1].append(labels[label][trial_index])\n",
    "\n",
    "    data = pd.DataFrame(data, columns=[\n",
    "        'subject', 'list', 'trial_type', 'position', 'item', 'first_input'] + list(labels.keys()))\n",
    "    merged = fr.merge_free_recall(data, list_keys=['first_input'] + list(labels.keys()))\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b3866",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid')\n",
    "\n",
    "# for each unique list length\n",
    "if not (isinstance(list_lengths, list) or isinstance(list_lengths, List)): \n",
    "    list_lengths = [list_lengths]\n",
    "\n",
    "for ll_index, list_length in enumerate(list_lengths):\n",
    "    \n",
    "    # for each unique model\n",
    "    for model_index, model_class in enumerate(models):\n",
    "\n",
    "        # load sim_df from csv if it exists\n",
    "        sim_df_path = results_path + '{}_{}_ll{}_sim_df.csv'.format(section_tag, model_names[model_index], list_length)\n",
    "        if os.path.isfile(sim_df_path):\n",
    "            sim_df = pd.read_csv(sim_df_path)\n",
    "            print('sim_df for {} with tag {} and list length {} already exists'.format(model_names[model_index], section_tag, list_length))\n",
    "\n",
    "        # otherwise, generate it\n",
    "        else:\n",
    "\n",
    "            @njit(fastmath=True, nogil=True)\n",
    "            def init_model(item_count, presentation_count, parameters):\n",
    "                return model_class(item_count, presentation_count, parameters)\n",
    "\n",
    "            # for each unique matching entry in individual df\n",
    "            sim_dfs = []\n",
    "            for subject in pd.unique(individual_fits.subject):\n",
    "                \n",
    "                fit_result = individual_fits.query(f'subject == {subject} & model == \"{model_names[model_index]}\"')\n",
    "\n",
    "                # configure model based on specified parameters\n",
    "                fitted_parameters = Dict.empty(\n",
    "                    key_type=types.unicode_type, value_type=types.float64\n",
    "                )\n",
    "                for i in range(len(free_parameters[model_index])):\n",
    "                    fitted_parameters[free_parameters[model_index][i]] = fit_result[free_parameters[model_index][i]].values[0]\n",
    "                for key in fixed_parameters[model_index]:\n",
    "                    fitted_parameters[key] = fixed_parameters[model_index][key]\n",
    "\n",
    "                if 'list length' in events.columns:\n",
    "                    ll_specific_trial_query = trial_query + f' & subject == {subject} & `list length` == {list_length}'\n",
    "                else:\n",
    "                    ll_specific_trial_query = trial_query + f' & subject == {subject}'\n",
    "\n",
    "                ll_specific_trial_mask = generate_trial_mask(events, ll_specific_trial_query)\n",
    "\n",
    "                if np.sum(ll_specific_trial_mask) == 0:\n",
    "                    continue\n",
    "\n",
    "                # simulate df based on specified trial_count and experiment_count\n",
    "                sim_dfs.append(simulate_df_from_events(\n",
    "                    init_model, fitted_parameters, events, ll_specific_trial_mask, experiment_count))\n",
    "                sim_dfs[-1].subject = subject\n",
    "\n",
    "            # concatenate simulations into one dataframe\n",
    "            if len(sim_dfs) == 0:\n",
    "                sim_df = None\n",
    "                continue\n",
    "            sim_df = pd.concat(sim_dfs)\n",
    "\n",
    "            # save sim_df to csv\n",
    "            sim_df.to_csv(results_path +'{}_{}_ll{}_sim_df.csv'.format(section_tag, model_names[model_index], list_length), index=False)\n",
    "\n",
    "        if sim_df is None:\n",
    "            continue\n",
    "\n",
    "        # design general filter for analysis df\n",
    "        if len(list_lengths) > 1:\n",
    "            analysis_query = trial_query + f' & `list length` == {list_length}'\n",
    "        else:\n",
    "            analysis_query = trial_query\n",
    "            \n",
    "        # generate plot for each parametrized analysis and model\n",
    "        for analysis_index, analysis_function in enumerate(analyses):\n",
    "            analysis_name = analysis_names[analysis_index]\n",
    "            axis = analysis_function(\n",
    "                [events, sim_df], analysis_query, contrast_name=\"source\", labels=[\"data\", model_names[model_index]])\n",
    "            plt.savefig(results_path+'{}_{}_ll{}_{}.pdf'.format(section_tag, model_names[model_index], list_length, analysis_name), bbox_inches=\"tight\")\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "Subjectwise_Model_Evaluation.ipynb",
   "output_path": "reports/Subjectwise_Model_Evaluation_Double_Murdock1962.ipynb",
   "parameters": {
    "bounds": [
     [
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ]
     ],
     [
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ]
     ],
     [
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ]
     ],
     [
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ]
     ],
     [
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ]
     ]
    ],
    "data_path": "data/Murdock1962.csv",
    "fixed_parameters": [
     {},
     {
      "context_sensitivity": 1,
      "feature_sensitivity": 1,
      "learn_first": false
     },
     {
      "context_sensitivity": 1,
      "feature_sensitivity": 1,
      "learn_first": true
     },
     {
      "choice_sensitivity": 1,
      "feature_sensitivity": 1,
      "learn_first": false
     },
     {
      "choice_sensitivity": 1,
      "feature_sensitivity": 1,
      "learn_first": true
     }
    ],
    "free_parameters": [
     [
      "encoding_drift_rate",
      "start_drift_rate",
      "recall_drift_rate",
      "shared_support",
      "item_support",
      "learning_rate",
      "primacy_scale",
      "primacy_decay",
      "stop_probability_scale",
      "stop_probability_growth",
      "choice_sensitivity",
      "delay_drift_rate"
     ],
     [
      "encoding_drift_rate",
      "start_drift_rate",
      "recall_drift_rate",
      "shared_support",
      "item_support",
      "learning_rate",
      "primacy_scale",
      "primacy_decay",
      "stop_probability_scale",
      "stop_probability_growth",
      "choice_sensitivity",
      "delay_drift_rate"
     ],
     [
      "encoding_drift_rate",
      "start_drift_rate",
      "recall_drift_rate",
      "shared_support",
      "item_support",
      "learning_rate",
      "primacy_scale",
      "primacy_decay",
      "stop_probability_scale",
      "stop_probability_growth",
      "choice_sensitivity",
      "delay_drift_rate"
     ],
     [
      "encoding_drift_rate",
      "start_drift_rate",
      "recall_drift_rate",
      "shared_support",
      "item_support",
      "learning_rate",
      "primacy_scale",
      "primacy_decay",
      "stop_probability_scale",
      "stop_probability_growth",
      "context_sensitivity",
      "delay_drift_rate"
     ],
     [
      "encoding_drift_rate",
      "start_drift_rate",
      "recall_drift_rate",
      "shared_support",
      "item_support",
      "learning_rate",
      "primacy_scale",
      "primacy_decay",
      "stop_probability_scale",
      "stop_probability_growth",
      "context_sensitivity",
      "delay_drift_rate"
     ]
    ],
    "model_names": [
     "PrototypeCMR",
     "ICMR_2_0_0",
     "ICMR_2_0_1",
     "ICMR_2_1_0",
     "ICMR_2_1_1"
    ],
    "model_paths": [
     "compmemlearn.models.Base_CMR",
     "compmemlearn.models.Dual_ICMR",
     "compmemlearn.models.Dual_ICMR",
     "compmemlearn.models.Dual_ICMR",
     "compmemlearn.models.Dual_ICMR"
    ],
    "section_tag": "Murdock1962",
    "trial_query": "subject > -1"
   },
   "start_time": "2022-06-03T19:15:08.908522",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}