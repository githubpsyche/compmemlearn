{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko\n",
    "import os\n",
    "\n",
    "def sbatch(script_path, slurm_path, requirements_path, credentials, data_dir=None, asset_dir=None):\n",
    "\n",
    "    # extract script names from paths\n",
    "    script_name = script_path[script_path.rfind('/'):] if '/' in script_path else script_path\n",
    "    slurm_name = slurm_path[slurm_path.rfind('/'):] if '/' in slurm_path else slurm_path\n",
    "    requirements_name = requirements_path[requirements_path.rfind('/'):] if '/' in requirements_path else requirements_path\n",
    "\n",
    "    # connect to the server\n",
    "    ssh = paramiko.SSHClient()\n",
    "    ssh.load_system_host_keys()\n",
    "    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "\n",
    "    ssh.connect(*credentials)\n",
    "\n",
    "    # load Python and create venv for sbatch job\n",
    "    ssh.exec_command(\"module load GCCcore/.10.2.0\")\n",
    "    ssh.exec_command(\"module load Python/3.8.6\")\n",
    "    ssh.exec_command(f\"python -m venv {script_name[:script_name.find('.')]}\")\n",
    "\n",
    "    # add requirements to venv\n",
    "    sftp = ssh.open_sftp()\n",
    "    remote_path = \"/home/gunnj/\" + script_name[:script_name.find('.')] + \"/\"\n",
    "    print(remote_path)\n",
    "    sftp.put(requirements_path, remote_path + requirements_name)\n",
    "    ssh.exec_command(\"source ${HOME}/\" + script_name[:script_name.find('.')] + \"/bin/activate\")\n",
    "    ssh.exec_command(\"pip install -r ${HOME}/\" + script_name[:script_name.find('.')] + requirements_name)\n",
    "    ssh.exec_command(\"deactivate\")\n",
    "\n",
    "    # add script and slurm files to server \n",
    "    sftp.put(script_path, remote_path + script_name)\n",
    "    sftp.put(slurm_path, remote_path + slurm_name)\n",
    "\n",
    "    # add contents of data_dir to server\n",
    "    if data_dir is not None:\n",
    "        for file in os.listdir(data_dir):\n",
    "\n",
    "            #TODO: properly handle nested directory structure\n",
    "            sftp.put(os.path.join(data_dir, file), remote_path + file)\n",
    "\n",
    "    if asset_dir is not None:\n",
    "        for file in os.listdir(asset_dir):\n",
    "\n",
    "            #TODO: properly handle nested directory structure\n",
    "            sftp.put(os.path.join(asset_dir, file), remote_path + file)\n",
    "\n",
    "    # run the script\n",
    "    ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('sbatch ' + remote_path + slurm_name)\n",
    "\n",
    "    # check for any error messages\n",
    "    print(ssh_stderr.read().decode(\"utf-8\"))\n",
    "\n",
    "    # display the output of the sbatch command and track the job ID\n",
    "    submission_message = ssh_stdout.read().decode(\"utf-8\")\n",
    "    job_id = submission_message.split(' ')[-1]\n",
    "    print(submission_message)\n",
    "\n",
    "    return job_id\n",
    "\n",
    "    # when the job is finished, copy the result back to the local machine manually, i guess?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = '''\n",
    "import papermill as pm\n",
    "import numpy as np\n",
    "\n",
    "section_introduction = \"\"\"\n",
    "## Comparison of Scaling Mechanims in Instance CMR\n",
    "We start by comparing how our echo- and trace-scaling implementations of InstanceCMR account for behavior in a classic experiment where each item is presented just once per study phase. For these simulations, we used the dataset reported by @murdock1970interresponse. Each of 72 undergraduates performed 20 trials with study lists each consisting of 20 unique words visually presented at either 60 or 120 words per minute. Given a particular subject, words were unique both within and across trials, and randomly selected from the Toronto Word Pool [@friendly1982toronto], a widely-used collection of high frequency nouns, adjectives, and verbs. While the major focus of the original report by @murdock1970interresponse was to investigate inter-response times in single-trial free recall, here we focus consideration on the content of recorded recall sequences. \n",
    "\"\"\"\n",
    "\n",
    "individual_fits_statement = \"\"\"\n",
    "First we evaluated each model variant based on their ability to predict the specific sequences of recalls exhibited by each participant. Considering all 20 trials performed by each participant in the dataset, we applied the differential evolution optimization technique to find for each model the parameter configuration that maximized the likelihood of recorded recall sequences. We obtained a unique optimal parameter configuration for each unique participant and each considered model variant. To measure the goodness-of-fit for each parameter configuration and corresponding model, [Figure @fig-{section_tag}Fits] plots the log-likelihood of each participant's recall sequences given each model variant's corresponding optimized parameter configuration.\n",
    "\"\"\"\n",
    "\n",
    "individual_fits_caption = \"\"\"Distribution of log-likelihood scores of recall sequences exhibited by each subject under each considered model across list-lengths [@murdock1970interresponse].\"\"\"\n",
    "\n",
    "benchmark_statistics_statement = \"\"\"\n",
    "As a follow-up, we also compared how readily each model could account for organizational summary statistics in the dataset. We found for each model variant the optimal parameter configuration maximizing the likelihood of the entire dataset rather than participant-by-participant. Using each fitted model variant, we simulated 1000 unique free recall trials and measured summary statistics from the result. [Figure @fig-{section_tag}Summary] plots for each model against the corresponding statistics collected over the dataset how recall probability varies as a function of serial position, how the probability of recalling an item first varies as a function of serial position, and how the conditional recall probabability of an item varies as a function of its serial lag from the previously recalled item.\n",
    "\"\"\"\n",
    "\n",
    "benchmark_statistics_caption = \"\"\"Comparison of summary statistics between each model against observed data [@murdock1970interresponse]\"\"\"\n",
    "\n",
    "section_tag = \"MurdOka_Scaling_Mechanisms\"\n",
    "\n",
    "model_paths = [\"compmemlearn.models.Instance_CMR\", \"compmemlearn.models.Instance_CMR\"]\n",
    "\n",
    "model_names = [\"Trace Scaling\", \"Echo Scaling\"]\n",
    "\n",
    "free_parameters = [\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        #    'choice_sensitivity',\n",
    "        \"context_sensitivity\",\n",
    "        #    'feature_sensitivity'\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"choice_sensitivity\",\n",
    "        #    'context_sensitivity',\n",
    "        #    'feature_sensitivity'\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "lb = np.finfo(float).eps\n",
    "ub = 1 - np.finfo(float).eps\n",
    "bounds = [\n",
    "    [\n",
    "        [lb, ub],\n",
    "        [lb, ub],\n",
    "        [lb, ub],\n",
    "        [lb, ub],\n",
    "        [lb, ub],\n",
    "        [lb, ub],\n",
    "        [lb, 100],\n",
    "        [lb, 100],\n",
    "        [lb, ub],\n",
    "        [lb, 10],\n",
    "        [lb, 10],\n",
    "        [lb, ub],\n",
    "    ],\n",
    "    [\n",
    "        [lb, ub],\n",
    "        [lb, ub],\n",
    "        [lb, ub],\n",
    "        [lb, ub],\n",
    "        [lb, ub],\n",
    "        [lb, ub],\n",
    "        [lb, 100],\n",
    "        [lb, 100],\n",
    "        [lb, ub],\n",
    "        [lb, 10],\n",
    "        [lb, 10],\n",
    "        [lb, ub],\n",
    "    ],\n",
    "]\n",
    "\n",
    "fixed_parameters = [\n",
    "    {\"choice_sensitivity\": 1, \"feature_sensitivity\": 1},\n",
    "    {\"context_sensitivity\": 1, \"feature_sensitivity\": 1},\n",
    "]\n",
    "\n",
    "pm.execute_notebook(\n",
    "    \"Subjectwise_Model_Evaluation.ipynb\",\n",
    "    \"Subjectwise_Model_Evaluation_{section_tag}.ipynb\".format(section_tag=section_tag),\n",
    "    parameters=dict(model_paths=model_paths, model_names=model_names, free_parameters=free_parameters, bounds=bounds, fixed_parameters=fixed_parameters),\n",
    ")\n",
    "'''\n",
    "\n",
    "with open('Scaling_Mechanism_Comparison_dispatch.py', 'w') as f:\n",
    "    f.write(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = {'hostname': \"login.accre.vanderbilt.edu\", 'username': \"gunnj\", 'password': \"\"}\n",
    "\n",
    "sbatch('Scaling_Mechanism_Comparison_dispatch.py', 'dispatch.slurm', 'requirements.txt', credentials, data_dir=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
