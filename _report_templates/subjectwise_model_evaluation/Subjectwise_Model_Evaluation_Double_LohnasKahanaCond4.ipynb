{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1bde0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T18:32:55.455193Z",
     "iopub.status.busy": "2022-06-03T18:32:55.454645Z",
     "iopub.status.idle": "2022-06-03T18:34:05.674117Z",
     "shell.execute_reply": "2022-06-03T18:34:05.672688Z"
    },
    "papermill": {
     "duration": 70.260545,
     "end_time": "2022-06-03T18:34:05.677910",
     "exception": false,
     "start_time": "2022-06-03T18:32:55.417365",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# | code-summary: code -- load dependencies and data and select parameters\n",
    "\n",
    "from compmemlearn.fitting import generate_objective_function\n",
    "from compmemlearn.datasets import events_metadata, generate_trial_mask\n",
    "from scipy.optimize import differential_evolution\n",
    "from numba.typed import List, Dict\n",
    "from numba.core import types\n",
    "from numba import njit\n",
    "from psifr import fr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "lb = np.finfo(float).eps\n",
    "ub = 1 - np.finfo(float).eps\n",
    "\n",
    "figure_caption = \"\"\"Distribution of log-likelihood scores of recall sequences exhibited by each subject in dataset under each considered model.\"\"\"\n",
    "\n",
    "section_tag = \"LohnasKahanaCond4\"\n",
    "\n",
    "data_path = \"../data/LohnasKahana2014.csv\"\n",
    "results_path = \"results/\"\n",
    "trial_query = \"condition == 4\"\n",
    "\n",
    "model_paths = [\n",
    "    \"compmemlearn.models.Base_CMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "]\n",
    "\n",
    "model_names = [\"PrototypeCMR\", \"ICMR_2_0_0\", \"ICMR_2_0_1\", \"ICMR_2_1_0\", \"ICMR_2_1_1\"]\n",
    "\n",
    "free_parameters = [\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"choice_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"choice_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"choice_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"context_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"context_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "]\n",
    "bounds = [\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "]\n",
    "fixed_parameters = [\n",
    "    {},\n",
    "    {\"feature_sensitivity\": 1, \"context_sensitivity\": 1, \"learn_first\": False},\n",
    "    {\"feature_sensitivity\": 1, \"context_sensitivity\": 1, \"learn_first\": True},\n",
    "    {\"feature_sensitivity\": 1, \"choice_sensitivity\": 1, \"learn_first\": False},\n",
    "    {\"feature_sensitivity\": 1, \"choice_sensitivity\": 1, \"learn_first\": True},\n",
    "]\n",
    "\n",
    "analysis_paths = ['compmemlearn.analyses.plot_spc', 'compmemlearn.analyses.plot_crp', 'compmemlearn.analyses.plot_pfr']\n",
    "analysis_names = ['spc', 'crp', 'pfr']\n",
    "\n",
    "experiment_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71c55d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T18:34:05.735455Z",
     "iopub.status.busy": "2022-06-03T18:34:05.735024Z",
     "iopub.status.idle": "2022-06-03T18:34:05.769230Z",
     "shell.execute_reply": "2022-06-03T18:34:05.768415Z"
    },
    "papermill": {
     "duration": 0.060889,
     "end_time": "2022-06-03T18:34:05.771174",
     "exception": false,
     "start_time": "2022-06-03T18:34:05.710285",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "data_path = \"data/LohnasKahana2014.csv\"\n",
    "trial_query = \"condition == 4\"\n",
    "model_paths = [\n",
    "    \"compmemlearn.models.Base_CMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "    \"compmemlearn.models.Dual_ICMR\",\n",
    "]\n",
    "model_names = [\"PrototypeCMR\", \"ICMR_2_0_0\", \"ICMR_2_0_1\", \"ICMR_2_1_0\", \"ICMR_2_1_1\"]\n",
    "free_parameters = [\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"choice_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"choice_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"choice_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"context_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "    [\n",
    "        \"encoding_drift_rate\",\n",
    "        \"start_drift_rate\",\n",
    "        \"recall_drift_rate\",\n",
    "        \"shared_support\",\n",
    "        \"item_support\",\n",
    "        \"learning_rate\",\n",
    "        \"primacy_scale\",\n",
    "        \"primacy_decay\",\n",
    "        \"stop_probability_scale\",\n",
    "        \"stop_probability_growth\",\n",
    "        \"context_sensitivity\",\n",
    "        \"delay_drift_rate\",\n",
    "    ],\n",
    "]\n",
    "bounds = [\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "    [\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 100],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 10],\n",
    "        [2.220446049250313e-16, 0.9999999999999998],\n",
    "    ],\n",
    "]\n",
    "fixed_parameters = [\n",
    "    {},\n",
    "    {\"feature_sensitivity\": 1, \"context_sensitivity\": 1, \"learn_first\": False},\n",
    "    {\"feature_sensitivity\": 1, \"context_sensitivity\": 1, \"learn_first\": True},\n",
    "    {\"feature_sensitivity\": 1, \"choice_sensitivity\": 1, \"learn_first\": False},\n",
    "    {\"feature_sensitivity\": 1, \"choice_sensitivity\": 1, \"learn_first\": True},\n",
    "]\n",
    "section_tag = \"LohnasKahanaCond4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef8b1a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T18:34:05.799860Z",
     "iopub.status.busy": "2022-06-03T18:34:05.799122Z",
     "iopub.status.idle": "2022-06-03T18:34:05.805592Z",
     "shell.execute_reply": "2022-06-03T18:34:05.804785Z"
    },
    "papermill": {
     "duration": 0.022803,
     "end_time": "2022-06-03T18:34:05.807292",
     "exception": false,
     "start_time": "2022-06-03T18:34:05.784489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'Howard' in section_tag or ('Lohnas' in section_tag and '1' not in section_tag):\n",
    "    analysis_paths = ['compmemlearn.analyses.plot_flex_spc', 'compmemlearn.analyses.plot_flex_crp', 'compmemlearn.analyses.plot_flex_pfr', 'compmemlearn.analyses.plot_rpl']\n",
    "    analysis_names = ['spc', 'crp', 'pfr', 'rpl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1753c168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T18:34:05.837675Z",
     "iopub.status.busy": "2022-06-03T18:34:05.837166Z",
     "iopub.status.idle": "2022-06-03T18:36:47.325952Z",
     "shell.execute_reply": "2022-06-03T18:36:47.325265Z"
    },
    "papermill": {
     "duration": 161.508993,
     "end_time": "2022-06-03T18:36:47.331017",
     "exception": false,
     "start_time": "2022-06-03T18:34:05.822024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function lohnas_objective_function.<locals>.objective_function at 0x2b43ad1ea4c0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1142.7285129177264\n",
      "3080.8590394275197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function lohnas_objective_function.<locals>.objective_function at 0x2b43ae353940>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1142.7285129177264\n",
      "3080.8590394275197\n",
      "<function lohnas_objective_function.<locals>.objective_function at 0x2b43b0a3c430>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1142.7285129177264\n",
      "3080.8590394275197\n",
      "<function lohnas_objective_function.<locals>.objective_function at 0x2b43ae92e940>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1143.555731544549\n",
      "3080.8590394275197\n",
      "<function lohnas_objective_function.<locals>.objective_function at 0x2b43b0a3c820>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1143.555731544549\n",
      "3080.8590394275197\n",
      "dependencies and parameters validated\n"
     ]
    }
   ],
   "source": [
    "#| code-summary: code -- test that specified parameters are valid\n",
    "#| output: false\n",
    "\n",
    "events = pd.read_csv(data_path)\n",
    "\n",
    "trials, list_lengths, presentations = events_metadata(events)\n",
    "trial_mask = generate_trial_mask(events, trial_query)\n",
    "\n",
    "# import models from specified source\n",
    "models = []\n",
    "for i in range(len(model_paths)):\n",
    "    module_name, model_name = model_paths[i].rsplit('.',1)\n",
    "    module = importlib.import_module(module_name)\n",
    "    models.append(getattr(module, model_name))\n",
    "\n",
    "# import analyses from specified source\n",
    "analyses = []\n",
    "for i in range(len(analysis_paths)):\n",
    "    module_name, analysis_name = analysis_paths[i].rsplit('.',1)\n",
    "    module = importlib.import_module(module_name)\n",
    "    analyses.append(getattr(module, analysis_name))\n",
    "\n",
    "# make sure model initializes with provided parameters and boundaries\n",
    "for model_index, model_class in enumerate(models):\n",
    "\n",
    "    @njit(fastmath=True, nogil=True)\n",
    "    def init_model(item_count, presentation_count, parameters):\n",
    "        return model_class(item_count, presentation_count, parameters)\n",
    "\n",
    "    subject_specific_trial_mask = np.logical_and(\n",
    "                generate_trial_mask(events, f'subject == {pd.unique(events.subject)[0]}'), trial_mask)\n",
    "\n",
    "    cost_function = generate_objective_function(\n",
    "        [trials[i][subject_specific_trial_mask[i]] for i in range(len(trials))],\n",
    "        [presentations[i][subject_specific_trial_mask[i]] for i in range(len(presentations))],\n",
    "        list_lengths,\n",
    "        init_model,\n",
    "        fixed_parameters[model_index],\n",
    "        free_parameters[model_index],\n",
    "    )\n",
    "    print(cost_function)\n",
    "    \n",
    "    for boundary_index in range(2):\n",
    "        x = np.array([each[boundary_index] for each in bounds[model_index]])\n",
    "        assert(len(x) == len(free_parameters[model_index])) \n",
    "\n",
    "        # parameter configuration\n",
    "        parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n",
    "        for name, value in fixed_parameters[model_index].items():\n",
    "            parameters[name] = value\n",
    "        for i in range(len(free_parameters[model_index])):\n",
    "                parameters[free_parameters[model_index][i]] = x[i]\n",
    "\n",
    "        model = init_model(20, 20, parameters)\n",
    "        model.experience(model.items)\n",
    "        model.free_recall()\n",
    "\n",
    "        print(cost_function(x))\n",
    "\n",
    "print('dependencies and parameters validated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43670e92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T18:36:47.391408Z",
     "iopub.status.busy": "2022-06-03T18:36:47.391026Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-06-03T18:36:47.365099",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrototypeCMR, Subject 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575.1807644260019\n",
      "PrototypeCMR, Subject 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361.3297979369973\n",
      "PrototypeCMR, Subject 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611.2770437545179\n",
      "PrototypeCMR, Subject 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265.78596307025293\n",
      "PrototypeCMR, Subject 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608.1421773978021\n",
      "PrototypeCMR, Subject 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624.5304767262355\n",
      "PrototypeCMR, Subject 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299.8436039152275\n",
      "PrototypeCMR, Subject 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634.0715151913483\n",
      "PrototypeCMR, Subject 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459.5041094652695\n",
      "PrototypeCMR, Subject 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660.6014863604427\n",
      "PrototypeCMR, Subject 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616.0528477599463\n",
      "PrototypeCMR, Subject 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574.2575701009598\n",
      "PrototypeCMR, Subject 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845.8944123355838\n",
      "PrototypeCMR, Subject 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440.6491273917666\n",
      "PrototypeCMR, Subject 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569.7113978954601\n",
      "PrototypeCMR, Subject 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470.90029900046443\n",
      "PrototypeCMR, Subject 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499.975623291099\n",
      "PrototypeCMR, Subject 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457.70867436803417\n",
      "PrototypeCMR, Subject 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304.89849063922406\n",
      "PrototypeCMR, Subject 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603.1012202825082\n",
      "PrototypeCMR, Subject 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219.5097183719241\n",
      "PrototypeCMR, Subject 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365.5789510412364\n",
      "PrototypeCMR, Subject 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438.4304515644096\n",
      "PrototypeCMR, Subject 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496.1582084365312\n",
      "PrototypeCMR, Subject 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249.49537951939345\n",
      "PrototypeCMR, Subject 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296.11476251254186\n",
      "PrototypeCMR, Subject 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460.19183614722533\n",
      "PrototypeCMR, Subject 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334.6865808612224\n",
      "PrototypeCMR, Subject 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366.0502740828172\n",
      "PrototypeCMR, Subject 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607.6155421420532\n",
      "PrototypeCMR, Subject 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450.0268620181923\n",
      "PrototypeCMR, Subject 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519.1390985769635\n",
      "PrototypeCMR, Subject 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510.90074471740076\n",
      "PrototypeCMR, Subject 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481.609090187008\n",
      "PrototypeCMR, Subject 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194.0215244511807\n",
      "ICMR_2_0_0, Subject 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574.8191069856114\n",
      "ICMR_2_0_0, Subject 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361.377242234912\n",
      "ICMR_2_0_0, Subject 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602.5565179294814\n",
      "ICMR_2_0_0, Subject 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265.7325801988403\n",
      "ICMR_2_0_0, Subject 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608.7017802258388\n",
      "ICMR_2_0_0, Subject 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627.6831438959296\n",
      "ICMR_2_0_0, Subject 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298.62644641108955\n",
      "ICMR_2_0_0, Subject 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641.8815313748805\n",
      "ICMR_2_0_0, Subject 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452.7056719565364\n",
      "ICMR_2_0_0, Subject 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655.6101082657622\n",
      "ICMR_2_0_0, Subject 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629.8466943214931\n",
      "ICMR_2_0_0, Subject 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576.0610563086917\n",
      "ICMR_2_0_0, Subject 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838.2684609074802\n",
      "ICMR_2_0_0, Subject 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446.0966588520107\n",
      "ICMR_2_0_0, Subject 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563.0483309916688\n",
      "ICMR_2_0_0, Subject 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473.5104359883527\n",
      "ICMR_2_0_0, Subject 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504.2860360765438\n",
      "ICMR_2_0_0, Subject 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458.2802250036513\n",
      "ICMR_2_0_0, Subject 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308.2348842044984\n",
      "ICMR_2_0_0, Subject 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602.5502049740257\n",
      "ICMR_2_0_0, Subject 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.70427930063266\n",
      "ICMR_2_0_0, Subject 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368.65041723844706\n",
      "ICMR_2_0_0, Subject 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438.37114542156775\n",
      "ICMR_2_0_0, Subject 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496.58165878715204\n",
      "ICMR_2_0_0, Subject 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249.23770348327918\n",
      "ICMR_2_0_0, Subject 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295.7423700807908\n",
      "ICMR_2_0_0, Subject 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453.24809537391116\n",
      "ICMR_2_0_0, Subject 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334.8903855019834\n",
      "ICMR_2_0_0, Subject 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366.1595315959665\n",
      "ICMR_2_0_0, Subject 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608.2222942893383\n",
      "ICMR_2_0_0, Subject 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448.98676947027303\n",
      "ICMR_2_0_0, Subject 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520.3994553104552\n",
      "ICMR_2_0_0, Subject 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511.65315070844423\n",
      "ICMR_2_0_0, Subject 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485.2113051951596\n",
      "ICMR_2_0_0, Subject 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.68925616768271\n",
      "ICMR_2_0_1, Subject 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576.2055233565217\n",
      "ICMR_2_0_1, Subject 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362.92458215546174\n",
      "ICMR_2_0_1, Subject 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603.1274421999683\n",
      "ICMR_2_0_1, Subject 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265.77235844332574\n",
      "ICMR_2_0_1, Subject 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606.9553586059994\n",
      "ICMR_2_0_1, Subject 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628.0101933937391\n",
      "ICMR_2_0_1, Subject 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298.67083183895664\n",
      "ICMR_2_0_1, Subject 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642.2519329263987\n",
      "ICMR_2_0_1, Subject 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458.0522364154336\n",
      "ICMR_2_0_1, Subject 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659.6625987747636\n",
      "ICMR_2_0_1, Subject 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631.65801841478\n",
      "ICMR_2_0_1, Subject 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577.4636862728189\n",
      "ICMR_2_0_1, Subject 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839.2775658352166\n",
      "ICMR_2_0_1, Subject 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445.9564035393719\n",
      "ICMR_2_0_1, Subject 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562.9377396412416\n",
      "ICMR_2_0_1, Subject 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481.0428726134849\n",
      "ICMR_2_0_1, Subject 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.45027720914857\n",
      "ICMR_2_0_1, Subject 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458.78435971300416\n",
      "ICMR_2_0_1, Subject 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305.3149374064375\n",
      "ICMR_2_0_1, Subject 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602.904218496318\n",
      "ICMR_2_0_1, Subject 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224.33726199621756\n",
      "ICMR_2_0_1, Subject 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368.8379498622068\n",
      "ICMR_2_0_1, Subject 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437.8870506754763\n",
      "ICMR_2_0_1, Subject 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496.4813542491515\n",
      "ICMR_2_0_1, Subject 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249.23312865655438\n",
      "ICMR_2_0_1, Subject 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295.7052293434483\n",
      "ICMR_2_0_1, Subject 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453.40330583805195\n",
      "ICMR_2_0_1, Subject 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335.0631720481078\n",
      "ICMR_2_0_1, Subject 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364.44479915955594\n",
      "ICMR_2_0_1, Subject 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609.1959267377091\n",
      "ICMR_2_0_1, Subject 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450.3162420927549\n",
      "ICMR_2_0_1, Subject 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520.9671613431628\n",
      "ICMR_2_0_1, Subject 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510.90655332575\n",
      "ICMR_2_0_1, Subject 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481.5352079003487\n",
      "ICMR_2_0_1, Subject 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.7194615903475\n",
      "ICMR_2_1_0, Subject 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562.2510913268377\n",
      "ICMR_2_1_0, Subject 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364.5170203473761\n",
      "ICMR_2_1_0, Subject 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604.6135697252347\n",
      "ICMR_2_1_0, Subject 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265.78413869757713\n",
      "ICMR_2_1_0, Subject 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606.2067821271568\n",
      "ICMR_2_1_0, Subject 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627.8395689568708\n",
      "ICMR_2_1_0, Subject 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299.3939404091265\n",
      "ICMR_2_1_0, Subject 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641.3365608025562\n",
      "ICMR_2_1_0, Subject 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453.3320196191552\n",
      "ICMR_2_1_0, Subject 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661.4772596531125\n",
      "ICMR_2_1_0, Subject 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606.652987288689\n",
      "ICMR_2_1_0, Subject 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576.5383538714318\n",
      "ICMR_2_1_0, Subject 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847.3163608750015\n",
      "ICMR_2_1_0, Subject 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446.344470213444\n",
      "ICMR_2_1_0, Subject 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563.5114068293894\n",
      "ICMR_2_1_0, Subject 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475.659853586732\n",
      "ICMR_2_1_0, Subject 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507.99680479440013\n",
      "ICMR_2_1_0, Subject 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464.13585646075586\n",
      "ICMR_2_1_0, Subject 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304.8403920897304\n",
      "ICMR_2_1_0, Subject 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609.1466555605057\n",
      "ICMR_2_1_0, Subject 22\n"
     ]
    }
   ],
   "source": [
    "# | code-summary: code -- 1) fit each model class participant-by-participant\n",
    "# | output: false\n",
    "\n",
    "for model_index, model_class in enumerate(models):\n",
    "\n",
    "    # load individual fits for this model and section tag from csv if they exist\n",
    "    if os.path.isfile(results_path + '{}_{}_individual.csv'.format(section_tag, model_names[model_index])):\n",
    "        pd.read_csv(results_path + '{}_{}_individual.csv'.format(section_tag, model_names[model_index]))\n",
    "        print('individual fits for {} with tag {} already exist'.format(model_names[model_index], section_tag))\n",
    "\n",
    "    # otherwise, fit each participant individually\n",
    "    else:\n",
    "        model_individual_fits = []\n",
    "\n",
    "        @njit(fastmath=True, nogil=True)\n",
    "        def init_model(item_count, presentation_count, parameters):\n",
    "            return model_class(item_count, presentation_count, parameters)\n",
    "\n",
    "        for subject in pd.unique(events.subject):\n",
    "            print(f'{model_names[model_index]}, Subject {subject}')\n",
    "\n",
    "            subject_specific_trial_mask = np.logical_and(\n",
    "                generate_trial_mask(events, f'subject == {subject}'), trial_mask)\n",
    "            \n",
    "            try:\n",
    "                # cost function to be minimized\n",
    "                # ours scales inversely with the probability that the data could have been\n",
    "                # generated using the specified parameters and our model\n",
    "                cost_function = generate_objective_function(\n",
    "                    [trials[i][subject_specific_trial_mask[i]] for i in range(len(trials))],\n",
    "                    [presentations[i][subject_specific_trial_mask[i]] for i in range(len(presentations))],\n",
    "                    list_lengths,\n",
    "                    init_model,\n",
    "                    fixed_parameters[model_index],\n",
    "                    free_parameters[model_index],\n",
    "                )\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            fit_result =  differential_evolution(cost_function, bounds[model_index], disp=False)\n",
    "\n",
    "            fitted_parameters = {\n",
    "                'subject': subject, 'trial_count': np.sum(subject_specific_trial_mask), \n",
    "                'likelihood': fit_result.fun, 'model': model_names[model_index]\n",
    "                }\n",
    "            for i in range(len(fit_result.x)):\n",
    "                fitted_parameters[free_parameters[model_index][i]] = fit_result.x[i]\n",
    "            for key in fixed_parameters[model_index]:\n",
    "                fitted_parameters[key] = fixed_parameters[model_index][key]\n",
    "\n",
    "            model_individual_fits.append(pd.DataFrame.from_dict(fitted_parameters, orient='index').T)\n",
    "            print(model_individual_fits[-1]['likelihood'][0])\n",
    "\n",
    "        model_individual_fits = pd.concat(model_individual_fits, ignore_index=True)\n",
    "        model_individual_fits.to_csv(\n",
    "            results_path + '{}_{}_individual.csv'.format(section_tag, model_names[model_index]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630ceeb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| code-summary: code -- 3) plot distribution of log-likelihoods across individual subjects\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# build individual fits df concatenating results from each model\n",
    "individual_fits = []\n",
    "for model_index, model_class in enumerate(models):\n",
    "    individual_fits.append(\n",
    "        pd.read_csv(results_path + '{}_{}_individual.csv'.format(section_tag, model_names[model_index])))\n",
    "individual_fits = pd.concat(individual_fits, ignore_index=True)\n",
    "\n",
    "# plot distribution of log-likelihoods across individual subjects\n",
    "g = sns.catplot(x='model', y='likelihood', data=individual_fits, kind='violin', inner='stick')\n",
    "sns.swarmplot(x=\"model\", y=\"likelihood\", data=individual_fits, color=\"k\", size=3, ax=g.ax)\n",
    "g.ax.set_ylabel('Individual Log-Likelihood')\n",
    "#plt.savefig(results_path + 'individual_{}.pdf'.format(section_tag), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a9571a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "individual_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6b28d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| code-summary: display markdown rendering of summary table\n",
    "#| echo: false\n",
    "#| input: false\n",
    "#| output: asis\n",
    "\n",
    "summary_table = pd.DataFrame(group.describe().rename(columns={'likelihood':name}).squeeze()\n",
    "            for name, group in individual_fits[['model', 'likelihood']].groupby('model')).T.to_markdown()\n",
    "\n",
    "print(\"\"\"::: {{#fig-{section_tag}fits layout-nrow=2 layout-valign=\"center\"}}\n",
    "\n",
    "![]({results_path}individual_{section_tag}.pdf)\n",
    "\n",
    "{summary_table}\n",
    "\n",
    "{individual_fits_caption}\n",
    ":::\"\"\".format(section_tag=section_tag, summary_table=summary_table, individual_fits_caption=figure_caption, results_path=results_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b5dbb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| code-summary: perform t-tests on individual-level fits\n",
    "#| output: false\n",
    " \n",
    "from scipy.stats import ttest_rel\n",
    "import itertools\n",
    "\n",
    "for combination in itertools.combinations(pd.unique(individual_fits.model), 2):\n",
    "\n",
    "    print(combination)\n",
    "    print(ttest_rel(individual_fits[individual_fits.model == combination[0]].likelihood, individual_fits[individual_fits.model == combination[1]].likelihood, alternative='two-sided'))\n",
    "    print(ttest_rel(individual_fits[individual_fits.model == combination[0]].likelihood, individual_fits[individual_fits.model == combination[1]].likelihood, alternative='less'))\n",
    "    print(ttest_rel(individual_fits[individual_fits.model == combination[0]].likelihood, individual_fits[individual_fits.model == combination[1]].likelihood, alternative='greater'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb3343d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for combination in itertools.combinations(pd.unique(individual_fits.model), 2):\n",
    "\n",
    "    print(combination)\n",
    "    print(np.mean(individual_fits[individual_fits.model == combination[0]].likelihood.values < individual_fits[individual_fits.model == combination[1]].likelihood.values), \n",
    "        np.mean(individual_fits[individual_fits.model == combination[1]].likelihood.values < individual_fits[individual_fits.model == combination[0]].likelihood.values))\n",
    "\n",
    "    print(np.sum(individual_fits[individual_fits.model == combination[0]].likelihood.values < individual_fits[individual_fits.model == combination[1]].likelihood.values), \n",
    "        np.sum(individual_fits[individual_fits.model == combination[1]].likelihood.values < individual_fits[individual_fits.model == combination[0]].likelihood.values))\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633b2e9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_weights(positive_log_likelihoods, number_parameters, N):\n",
    "    AIC = 2 * positive_log_likelihoods + 2 * number_parameters\n",
    "    AICc = AIC #+ (2*np.power(number_parameters, 2) + 2 * number_parameters) / (N - number_parameters - 2)\n",
    "    AICd = AIC - np.min(AICc)\n",
    "    #return AICd\n",
    "    AICw = np.exp(-.5 * AICd) / np.sum(np.exp(-.5 * AICd))\n",
    "    return AICw\n",
    "\n",
    "aicw = {'Model': [], 'Subject': [], 'AICw': []}\n",
    "\n",
    "total_nlns = np.zeros(len(models))\n",
    "for subject_index, subject in enumerate(pd.unique(events.subject)):\n",
    "\n",
    "    subject_specific_trial_mask = np.logical_and(\n",
    "                    generate_trial_mask(events, f'subject == {subject}'), trial_mask)\n",
    "\n",
    "    nlnLs = []\n",
    "    for model_index, model_class in enumerate(models):\n",
    "        nlnLs.append(\n",
    "            individual_fits[individual_fits.model == model_names[model_index]].likelihood.values[subject_index])\n",
    "    nlnLs = np.array(nlnLs)\n",
    "    total_nlns += nlnLs\n",
    "    \n",
    "    weights = model_weights(nlnLs, len(free_parameters[model_index]), np.sum(subject_specific_trial_mask))\n",
    "    #print(weights)\n",
    "    for model_index, model_class in enumerate(models):\n",
    "        aicw['Model'].append(model_names[model_index])\n",
    "        aicw['Subject'].append(subject)\n",
    "        aicw['AICw'].append(weights[model_index])\n",
    "\n",
    "aicw = pd.DataFrame(data=aicw)\n",
    "total_aicw = model_weights(total_nlns, len(free_parameters[model_index]), np.sum(trial_mask))\n",
    "print(total_aicw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb24663",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "x = sns.pointplot(x=\"Model\", y=\"AICw\", data=aicw, join=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc8359",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from compmemlearn.datasets import find_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a60a9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_df_from_events(model_class, parameters, events, trial_mask, experiment_count, first_recall_item=None):\n",
    "\n",
    "    trials, list_lengths, presentations = events_metadata(events)\n",
    "    chose = [i for i in range(len(trial_mask)) if np.sum(trial_mask[i]) != 0]\n",
    "    assert(len(chose) == 1)\n",
    "    chose = chose[0]\n",
    "    trial_mask = trial_mask[chose]\n",
    "    trials = trials[chose][trial_mask]\n",
    "    presentations = presentations[chose][trial_mask]\n",
    "\n",
    "    default_columns = ['subject', 'list', 'trial_type', 'item', 'input', 'output', 'study', 'recall', 'repeat', 'intrusion', 'first_input']\n",
    "    extra_columns = [each for each in events.columns if each not in default_columns]\n",
    "\n",
    "    labels = {}\n",
    "    for column in extra_columns:\n",
    "        try:\n",
    "            labels[column] = (\n",
    "                events.pivot_table(index=['subject', 'list'], dropna=False)[column].values)\n",
    "\n",
    "            if 'list length' in events.columns:\n",
    "                trial_details = events.pivot_table(index=['subject', 'list'], dropna=False).reset_index()\n",
    "                list_length_mask = trial_details.eval(trial_query).to_numpy(dtype='bool')\n",
    "                labels[column] = labels[column][list_length_mask]\n",
    "            else:\n",
    "                labels[column] = labels[column][trial_mask]\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    data = []\n",
    "    for experiment in range(experiment_count):\n",
    "        for trial_index in range(len(presentations)):\n",
    "        \n",
    "            # retrieve presentation sequence for this trial and measure number of unique items\n",
    "            presentation = presentations[trial_index]\n",
    "            item_count = np.max(presentation)+1\n",
    "\n",
    "            # record presentation events\n",
    "            for presentation_index, presentation_event in enumerate(presentation):\n",
    "                data.append([\n",
    "                    experiment, trial_index, 'study', presentation_index+1, presentation_event, presentation_index+1])\n",
    "                for label in labels:\n",
    "                    data[-1].append(labels[label][trial_index])\n",
    "\n",
    "            # simulate recall and identify first study position of each recalled item\n",
    "            model = model_class(item_count, len(presentation), parameters)\n",
    "            model.experience(model.items[presentation])\n",
    "            if first_recall_item is not None:\n",
    "                model.force_recall(first_recall_item)\n",
    "            recalled = model.free_recall()\n",
    "            trial = [find_first(recalled[i], presentation) + 1 for i in range(len(recalled))]\n",
    "\n",
    "            # record recall events\n",
    "            for recall_index, recall_event in enumerate(trial):\n",
    "                if recall_event != 0:\n",
    "                    data.append([\n",
    "                        experiment, trial_index, 'recall', recall_index+1, \n",
    "                        presentation[recall_event-1], recall_event])\n",
    "                    for label in labels:\n",
    "                        data[-1].append(labels[label][trial_index])\n",
    "\n",
    "    data = pd.DataFrame(data, columns=[\n",
    "        'subject', 'list', 'trial_type', 'position', 'item', 'first_input'] + list(labels.keys()))\n",
    "    merged = fr.merge_free_recall(data, list_keys=['first_input'] + list(labels.keys()))\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849df25",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid')\n",
    "\n",
    "# for each unique list length\n",
    "if not (isinstance(list_lengths, list) or isinstance(list_lengths, List)): \n",
    "    list_lengths = [list_lengths]\n",
    "\n",
    "for ll_index, list_length in enumerate(list_lengths):\n",
    "    \n",
    "    # for each unique model\n",
    "    for model_index, model_class in enumerate(models):\n",
    "\n",
    "        # load sim_df from csv if it exists\n",
    "        sim_df_path = results_path + '{}_{}_ll{}_sim_df.csv'.format(section_tag, model_names[model_index], list_length)\n",
    "        if os.path.isfile(sim_df_path):\n",
    "            sim_df = pd.read_csv(sim_df_path)\n",
    "            print('sim_df for {} with tag {} and list length {} already exists'.format(model_names[model_index], section_tag, list_length))\n",
    "\n",
    "        # otherwise, generate it\n",
    "        else:\n",
    "\n",
    "            @njit(fastmath=True, nogil=True)\n",
    "            def init_model(item_count, presentation_count, parameters):\n",
    "                return model_class(item_count, presentation_count, parameters)\n",
    "\n",
    "            # for each unique matching entry in individual df\n",
    "            sim_dfs = []\n",
    "            for subject in pd.unique(individual_fits.subject):\n",
    "                \n",
    "                fit_result = individual_fits.query(f'subject == {subject} & model == \"{model_names[model_index]}\"')\n",
    "\n",
    "                # configure model based on specified parameters\n",
    "                fitted_parameters = Dict.empty(\n",
    "                    key_type=types.unicode_type, value_type=types.float64\n",
    "                )\n",
    "                for i in range(len(free_parameters[model_index])):\n",
    "                    fitted_parameters[free_parameters[model_index][i]] = fit_result[free_parameters[model_index][i]].values[0]\n",
    "                for key in fixed_parameters[model_index]:\n",
    "                    fitted_parameters[key] = fixed_parameters[model_index][key]\n",
    "\n",
    "                if 'list length' in events.columns:\n",
    "                    ll_specific_trial_query = trial_query + f' & subject == {subject} & `list length` == {list_length}'\n",
    "                else:\n",
    "                    ll_specific_trial_query = trial_query + f' & subject == {subject}'\n",
    "\n",
    "                ll_specific_trial_mask = generate_trial_mask(events, ll_specific_trial_query)\n",
    "\n",
    "                if np.sum(ll_specific_trial_mask) == 0:\n",
    "                    continue\n",
    "\n",
    "                # simulate df based on specified trial_count and experiment_count\n",
    "                sim_dfs.append(simulate_df_from_events(\n",
    "                    init_model, fitted_parameters, events, ll_specific_trial_mask, experiment_count))\n",
    "                sim_dfs[-1].subject = subject\n",
    "\n",
    "            # concatenate simulations into one dataframe\n",
    "            if len(sim_dfs) == 0:\n",
    "                sim_df = None\n",
    "                continue\n",
    "            sim_df = pd.concat(sim_dfs)\n",
    "\n",
    "            # save sim_df to csv\n",
    "            sim_df.to_csv(results_path +'{}_{}_ll{}_sim_df.csv'.format(section_tag, model_names[model_index], list_length), index=False)\n",
    "\n",
    "        if sim_df is None:\n",
    "            continue\n",
    "\n",
    "        # design general filter for analysis df\n",
    "        if len(list_lengths) > 1:\n",
    "            analysis_query = trial_query + f' & `list length` == {list_length}'\n",
    "        else:\n",
    "            analysis_query = trial_query\n",
    "            \n",
    "        # generate plot for each parametrized analysis and model\n",
    "        for analysis_index, analysis_function in enumerate(analyses):\n",
    "            analysis_name = analysis_names[analysis_index]\n",
    "            axis = analysis_function(\n",
    "                [events, sim_df], analysis_query, contrast_name=\"source\", labels=[\"data\", model_names[model_index]])\n",
    "            plt.savefig(results_path+'{}_{}_ll{}_{}.pdf'.format(section_tag, model_names[model_index], list_length, analysis_name), bbox_inches=\"tight\")\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "Subjectwise_Model_Evaluation.ipynb",
   "output_path": "reports/Subjectwise_Model_Evaluation_Double_LohnasKahanaCond4.ipynb",
   "parameters": {
    "bounds": [
     [
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ]
     ],
     [
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ]
     ],
     [
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ]
     ],
     [
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ]
     ],
     [
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       100
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       10
      ],
      [
       2.220446049250313e-16,
       0.9999999999999998
      ]
     ]
    ],
    "data_path": "data/LohnasKahana2014.csv",
    "fixed_parameters": [
     {},
     {
      "context_sensitivity": 1,
      "feature_sensitivity": 1,
      "learn_first": false
     },
     {
      "context_sensitivity": 1,
      "feature_sensitivity": 1,
      "learn_first": true
     },
     {
      "choice_sensitivity": 1,
      "feature_sensitivity": 1,
      "learn_first": false
     },
     {
      "choice_sensitivity": 1,
      "feature_sensitivity": 1,
      "learn_first": true
     }
    ],
    "free_parameters": [
     [
      "encoding_drift_rate",
      "start_drift_rate",
      "recall_drift_rate",
      "shared_support",
      "item_support",
      "learning_rate",
      "primacy_scale",
      "primacy_decay",
      "stop_probability_scale",
      "stop_probability_growth",
      "choice_sensitivity",
      "delay_drift_rate"
     ],
     [
      "encoding_drift_rate",
      "start_drift_rate",
      "recall_drift_rate",
      "shared_support",
      "item_support",
      "learning_rate",
      "primacy_scale",
      "primacy_decay",
      "stop_probability_scale",
      "stop_probability_growth",
      "choice_sensitivity",
      "delay_drift_rate"
     ],
     [
      "encoding_drift_rate",
      "start_drift_rate",
      "recall_drift_rate",
      "shared_support",
      "item_support",
      "learning_rate",
      "primacy_scale",
      "primacy_decay",
      "stop_probability_scale",
      "stop_probability_growth",
      "choice_sensitivity",
      "delay_drift_rate"
     ],
     [
      "encoding_drift_rate",
      "start_drift_rate",
      "recall_drift_rate",
      "shared_support",
      "item_support",
      "learning_rate",
      "primacy_scale",
      "primacy_decay",
      "stop_probability_scale",
      "stop_probability_growth",
      "context_sensitivity",
      "delay_drift_rate"
     ],
     [
      "encoding_drift_rate",
      "start_drift_rate",
      "recall_drift_rate",
      "shared_support",
      "item_support",
      "learning_rate",
      "primacy_scale",
      "primacy_decay",
      "stop_probability_scale",
      "stop_probability_growth",
      "context_sensitivity",
      "delay_drift_rate"
     ]
    ],
    "model_names": [
     "PrototypeCMR",
     "ICMR_2_0_0",
     "ICMR_2_0_1",
     "ICMR_2_1_0",
     "ICMR_2_1_1"
    ],
    "model_paths": [
     "compmemlearn.models.Base_CMR",
     "compmemlearn.models.Dual_ICMR",
     "compmemlearn.models.Dual_ICMR",
     "compmemlearn.models.Dual_ICMR",
     "compmemlearn.models.Dual_ICMR"
    ],
    "section_tag": "LohnasKahanaCond4",
    "trial_query": "condition == 4"
   },
   "start_time": "2022-06-03T18:32:34.011291",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}