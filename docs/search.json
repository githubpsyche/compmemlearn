[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "compmemlearn",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "library\\analyses\\Alternative_Contiguity.html#data-preparation",
    "href": "library\\analyses\\Alternative_Contiguity.html#data-preparation",
    "title": "compmemlearn",
    "section": "Data Preparation",
    "text": "from compmemlearn.datasets import prepare_lohnas2014_data\nfrom compmemlearn.analyses import recall_by_all_study_positions\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')\n\nevents.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n      condition\n    \n  \n  \n    \n      0\n      1\n      1\n      0\n      1\n      1.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      1\n      1\n      1\n      1\n      2\n      2.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      2\n      1\n      1\n      2\n      3\n      3.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      3\n      1\n      1\n      3\n      4\n      4.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      4\n      1\n      1\n      4\n      5\n      5.0\n      True\n      True\n      0\n      False\n      4"
  },
  {
    "objectID": "library\\analyses\\Alternative_Contiguity.html#analysis",
    "href": "library\\analyses\\Alternative_Contiguity.html#analysis",
    "title": "compmemlearn",
    "section": "Analysis",
    "text": "import pandas as pd\nimport numpy as np\n\ndef indices_of_repeated_items(presentation_sequence):\n\n    values, counts = np.unique(presentation_sequence, return_counts=True)\n    repeated_items = {v: np.where(presentation_sequence == v)[0] for v in values if counts[v] > 1}\n\n    return {key:repeated_items[key] for key in repeated_items}\n\n# lag thresholding doesn't work reliably with this code, overcounting actual transitions\ndef alternative_contiguity_test(mixed_presentations, mixed_recalls, lag_threshold, repetition_count):\n    relevant_lags = list(range(-int(lag_threshold/2), int(lag_threshold/2+1)))\n    del relevant_lags[int(lag_threshold/2)]\n\n    actual_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]\n    possible_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]\n\n    for trial_index in range(len(mixed_presentations)):\n\n        # sequence of item indices ordered as they were studied\n        presentation = mixed_presentations[trial_index]\n\n        # sequence of initial study positions ordered as they were recalled\n        trial_by_study_position = mixed_recalls[trial_index]\n\n        # sequence of item indices ordered as they were recalled\n        trial_by_item_index = presentation[trial_by_study_position-1][:np.size(np.nonzero(trial_by_study_position))]\n\n        # {item_index: [presentation indices]} for each repeated item in presentation sequence spaced by >4 items\n        i_and_j = indices_of_repeated_items(presentation)\n        \n        # then for each unique repeated item in the study list, \n        for repeated_item in i_and_j:\n\n            # search for relevant item(s) in recall sequence and skip if not found \n            look_for = trial_by_item_index == presentation[i_and_j[repeated_item][0]]\n            for k in range(1, repetition_count):\n                look_for = np.logical_or(\n                    look_for, trial_by_item_index == presentation[i_and_j[repeated_item][k]])\n            recall_positions = np.where(look_for)[0]\n\n            if np.size(recall_positions) == 0:\n                continue\n\n            # check each position the item was observed (always just 1 position; we loop for parallelism w control)\n            for recall_position in recall_positions:\n\n                # also skip if no successive recall was made, \n                if np.size(trial_by_item_index) == recall_position + 1:\n                    continue\n\n                # build list of study positions for items recalled up to repeated item\n                prior_lags = [[] for each in range(repetition_count)]\n                for i in range(recall_position):\n\n                    # if considered item is also repeated, we track lags wrt to all presentations\n                    if trial_by_item_index[i] in i_and_j:\n                        for considered in range(len(i_and_j[trial_by_item_index[i]])):\n                            for focal in range(repetition_count):\n                                prior_lags[focal].append(\n                                    int(i_and_j[trial_by_item_index[i]][considered] - i_and_j[repeated_item][focal]))\n                    else:\n                        for k in range(repetition_count):\n                            prior_lags[k].append(int(trial_by_study_position[i] - i_and_j[repeated_item][k]))\n\n                # transition of a given lag is possible if lag not present in prior_lags\n                for lag in relevant_lags:\n                    for k in range(repetition_count):\n                        \n                        # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][-1] < lag_threshold\n                        if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):\n                            continue\n                        \n                        if lag not in prior_lags[k]:\n                            possible_lags[k][relevant_lags.index(lag)] += 1\n\n                # track each serial lag of actually transitioned-to item\n                if trial_by_item_index[recall_position+1] in i_and_j:\n                    positions = i_and_j[trial_by_item_index[recall_position+1]]\n                    for transition_study_position in positions:\n                        for k in range(repetition_count):\n\n                            # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold\n                            if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):\n                                continue\n\n                            lag = int(transition_study_position - i_and_j[repeated_item][k])\n                            if lag in relevant_lags:\n                                actual_lags[k][relevant_lags.index(lag)] += 1\n                else:\n                    transition_study_position = trial_by_study_position[recall_position+1]-1\n                    for k in range(repetition_count):\n\n                        # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold\n                        if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):\n                            continue\n\n                        lag = int(transition_study_position-i_and_j[repeated_item][k])\n                        if lag in relevant_lags:\n                            actual_lags[k][relevant_lags.index(lag)] += 1\n\n    result = []\n    for k in range(repetition_count):\n        \n        for i in range(len(possible_lags[k])):\n            if possible_lags[k][i] == 0:\n                possible_lags[k][i] += 1\n\n        result.append(pd.DataFrame(\n            {'lag': relevant_lags, 'prob': np.divide(actual_lags[k], possible_lags[k]), \n            'actual': actual_lags[k], 'possible': possible_lags[k]}))\n\n    return pd.concat(result, keys=['From Position {}'.format(i+1) for i in range(repetition_count)], names=['locus'])\n# export\n\nfrom numba import njit\nfrom numba import int32\nimport numpy as np\n\n@njit(nogil=True)\ndef alternative_contiguity(trials, presentations, lag_threshold = 3, max_repeats = 2):\n    \n    list_length = len(presentations[0])\n    lag_range = list_length - 1\n    total_actual_lags = np.zeros((max_repeats, lag_range * 2 + 1)) # extended dimension to split by pres positions\n    total_possible_lags = np.zeros((max_repeats, lag_range * 2 + 1))\n    terminus = np.sum(trials != 0, axis=1) # number of recalls per trial\n    recall_by_study_position = recall_by_all_study_positions(trials, presentations, max_repeats)\n    \n    for trial_index in range(len(trials)):\n        previous_item = 0\n        item_count = np.max(presentations[trial_index]) + 1\n        possible_items = np.arange(item_count) # initial pool of possible recalls, 1-indexed\n        possible_positions = np.zeros((item_count, max_repeats), dtype=int32)\n        \n        # we track possible positions using presentations and alt_presentations\n        for item in range(item_count):\n            pos = np.nonzero(presentations[trial_index] == item)[0] + 1\n            possible_positions[item, :len(pos)] = pos\n            \n        for recall_index in range(terminus[trial_index]):\n\n            current_item = presentations[trial_index][trials[trial_index, recall_index]-1]\n            \n            # track possible and actual lags; \n            # focus only on transitions from items with > 1 study positions\n            # and only when those multiple study positions have lag over lag\n            if recall_index > 0 and np.count_nonzero(\n                possible_positions[previous_item]) > 1 and (\n                possible_positions[previous_item][1] - possible_positions[previous_item][0] >= lag_threshold):\n                \n                # item indices don't help track lags anymore\n                # so more complex calculation needed to identify possible lags given previous item\n                current_index = np.nonzero(possible_items==current_item)[0]\n\n                index = 0\n                for x in range(len(recall_by_study_position)):\n                    for y in range(len(recall_by_study_position)):\n                        if possible_positions[previous_item, y] > 0:\n                        \n                            possible_lags = possible_positions[\n                                possible_items, x] - possible_positions[previous_item, y]\n                            \n                            # if tracked position is 0, then we don't actually want to count it in our lags\n                            possible_lags[possible_positions[possible_items, x] == 0] = 0\n                            \n                            # we track actual lag at each iteration\n                            actual_lag = possible_lags[current_index] + lag_range\n                            total_actual_lags[y][actual_lag] += 1\n\n                            # we track possible lag at each iteration\n                            possible_lags += lag_range\n                            total_possible_lags[y][possible_lags] += 1\n                        \n                        index += 1\n\n            # update pool to exclude recalled item (updated to still identify 1-indexed item)\n            previous_item = current_item\n            possible_items = possible_items[possible_items != previous_item]\n\n                                \n    # small correction to avoid nans and commit to excluding multiply-tracked single presentations \n    total_actual_lags[:, lag_range] = 0\n    for i in range(max_repeats):\n        total_possible_lags[i][total_actual_lags[i]==0] += 1\n    \n    return total_actual_lags/total_possible_lags\n\n#selection = list_types == 4\n#alternative_contiguity(trials[selection], presentations[selection], 6, 2)\n\n\nindividual_results = []\n\nfor subject in np.unique(subjects):\n    selection = np.logical_and(list_types == 4, subjects == subject)\n\n    individual_results.append(\n        alternative_contiguity(trials[selection], presentations[selection], 6, 2))\n\nnp.mean(np.array(individual_results), axis=0)\n\narray([[0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.00952381, 0.00714286,\n        0.02357143, 0.00571429, 0.01285714, 0.01428571, 0.03505495,\n        0.00571429, 0.0155102 , 0.04619048, 0.00505495, 0.01569264,\n        0.03380952, 0.02346939, 0.02984127, 0.03125953, 0.02119417,\n        0.03478997, 0.02337276, 0.02438032, 0.04757342, 0.04654344,\n        0.03749433, 0.07345434, 0.06505376, 0.14134409, 0.        ,\n        0.17722157, 0.1074913 , 0.05463955, 0.06811201, 0.0654523 ,\n        0.07416891, 0.07620522, 0.06610723, 0.05367311, 0.05347731,\n        0.04190581, 0.02654247, 0.01420171, 0.02639528, 0.02579365,\n        0.01405699, 0.01496599, 0.01760597, 0.02278912, 0.01939549,\n        0.02042735, 0.01525903, 0.02315018, 0.00952381, 0.01360544,\n        0.02952381, 0.03979592, 0.0152381 , 0.02579365, 0.02380952,\n        0.00714286, 0.03428571, 0.01047619, 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.00952381,\n        0.        , 0.        , 0.03979592, 0.00571429, 0.00571429,\n        0.0152381 , 0.02      , 0.02595238, 0.01598639, 0.04357143,\n        0.0052381 , 0.03107535, 0.00505495, 0.03098639, 0.03386724,\n        0.02527211, 0.03294539, 0.02006803, 0.00626566, 0.04196068,\n        0.03441261, 0.03458128, 0.05680602, 0.05606956, 0.06942044,\n        0.08609565, 0.15021033, 0.17164558, 0.09036054, 0.0704922 ,\n        0.07565847, 0.06124401, 0.07097237, 0.10146722, 0.        ,\n        0.09013582, 0.02819657, 0.04635616, 0.03943094, 0.03044437,\n        0.02622808, 0.01441877, 0.01373234, 0.02223182, 0.02584003,\n        0.01337868, 0.01845456, 0.01053391, 0.02727891, 0.01857928,\n        0.01658312, 0.01587302, 0.00408163, 0.05571429, 0.02142857,\n        0.02238095, 0.01071429, 0.02142857, 0.01666667, 0.        ,\n        0.        , 0.02      , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        ]])"
  },
  {
    "objectID": "library\\analyses\\Alternative_Contiguity.html#plotting",
    "href": "library\\analyses\\Alternative_Contiguity.html#plotting",
    "title": "compmemlearn",
    "section": "Plotting",
    "text": "minimum_lag = 6\nrepetition_count = 2\n\nindividual_results = []\n\nfor subject in np.unique(subjects):\n    selection = np.logical_and(list_types == 4, subjects == subject)\n\n    individual_results.append(\n        alternative_contiguity_test(presentations[selection], trials[selection], minimum_lag, repetition_count))\n\ndf = pd.concat(individual_results, keys=np.unique(subjects), names=['subject']).reset_index()\ndf.drop(['level_2'], axis=1, inplace=True)\ndf\n\n\n\n\n  \n    \n      \n      subject\n      locus\n      lag\n      prob\n      actual\n      possible\n    \n  \n  \n    \n      0\n      1\n      From Position 1\n      -3\n      0.000000\n      0\n      27\n    \n    \n      1\n      1\n      From Position 1\n      -2\n      0.115385\n      3\n      26\n    \n    \n      2\n      1\n      From Position 1\n      -1\n      0.153846\n      4\n      26\n    \n    \n      3\n      1\n      From Position 1\n      1\n      0.200000\n      8\n      40\n    \n    \n      4\n      1\n      From Position 1\n      2\n      0.314286\n      11\n      35\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      415\n      37\n      From Position 2\n      -2\n      0.125000\n      1\n      8\n    \n    \n      416\n      37\n      From Position 2\n      -1\n      0.142857\n      1\n      7\n    \n    \n      417\n      37\n      From Position 2\n      1\n      0.333333\n      2\n      6\n    \n    \n      418\n      37\n      From Position 2\n      2\n      0.000000\n      0\n      9\n    \n    \n      419\n      37\n      From Position 2\n      3\n      0.111111\n      1\n      9\n    \n  \n\n420 rows × 6 columns\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nmax_lag = minimum_lag/2\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\ng = sns.FacetGrid(df, height=4.5)\ng.map_dataframe(\n    lambda data, **kws: sns.lineplot(\n        data=data.query(filt_neg), x='lag', y='prob', hue='locus', err_style='bars', **kws)\n)\n\ng.map_dataframe(\n    lambda data, **kws: sns.lineplot(\n        data=data.query(filt_pos), x='lag', y='prob', hue='locus', err_style='bars', **kws)\n)\n\nplt.legend(['First Presentation', 'Second Presentation'], loc='upper left')\nplt.title('Alternative Contiguity Analysis\\n(Minimum Lag Between Repetitions = {})'.format(minimum_lag))\nplt.tight_layout()\n\n\n\n\n\n%timeit alternative_contiguity(trials[selection], presentations[selection], 6, 2)\n\n4.14 ms ± 69.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)"
  },
  {
    "objectID": "library\\analyses\\Conditional_Stop_Probability.html#data-preparation",
    "href": "library\\analyses\\Conditional_Stop_Probability.html#data-preparation",
    "title": "compmemlearn",
    "section": "Data Preparation",
    "text": "For our demonstrations, we’ll lean on the MurdockOkada1970 dataset. As a reminder, in this dataset each of 72 undergraduates was given 20 test lists with 20-word lists visually presented at either 60 or 120 words/min.\n\nfrom compmemlearn.datasets import prepare_murdock1970_data\n\ntrials, events, list_length = prepare_murdock1970_data('../../data/mo1970.txt')\nevents.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n    \n  \n  \n    \n      0\n      1\n      1\n      1\n      1\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      1\n      1\n      1\n      2\n      2\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      2\n      1\n      1\n      3\n      3\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      3\n      1\n      1\n      4\n      4\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      4\n      1\n      1\n      5\n      5\n      NaN\n      True\n      False\n      0\n      False"
  },
  {
    "objectID": "library\\analyses\\Conditional_Stop_Probability.html#analysis",
    "href": "library\\analyses\\Conditional_Stop_Probability.html#analysis",
    "title": "compmemlearn",
    "section": "Analysis",
    "text": "Fast Array Generation\nDataFrames contain granular subject-by-subject information and are easier to plot using the seaborn library. But sometimes we don’t need this granular information and mainly want to perform our analysis as quickly as possible – perhaps to help with model fitting or analysis. In that case, representing results with numpy arrays and performing just-in-time compilation of our function using numba might be preferred. We include analyses.fast_csp in our library for that purpose here.\n# export\n\nfrom numba import njit\nimport numpy as np\n\n@njit(fastmath=True, nogil=True)\ndef fast_csp(trials, item_count):\n    \n    # numerator is number of trials with zero in current column position\n    numerator = np.zeros(item_count+1)\n\n    # denominator is number of trials without zero in previous column positions\n    denominator = np.zeros(item_count+1)\n\n    stop_positions = trials == 0\n    for i in range(len(trials)):\n\n        # add 1 to index of final recall\n        numerator[np.argmax(stop_positions[i])] += 1\n        \n        # add 1 to each index up through final recall\n        denominator[:np.argmax(stop_positions[i])+1] += 1\n        \n    denominator[denominator==0] += 1\n    return numerator/denominator\n\nfast_csp(trials, list_length)\n\narray([0.        , 0.00138889, 0.01877608, 0.05740609, 0.18195489,\n       0.25919118, 0.33498759, 0.4608209 , 0.50519031, 0.55944056,\n       0.65079365, 0.77272727, 1.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        ])\n\n\n\n\nDataFrame\nThe psifr library doesn’t have a function to generate pandas DataFrames containing conditional stop probability information, so we make our own. For efficiency, it mainly consists of calls to fast_csp.\nimport pandas as pd\n\ndef csp(events, trials):\n    subjects = len(np.unique(events.subject))\n    trial_count = np.max(events.list)\n    list_length = np.max(events.input)\n    \n    result = {'subject': [], 'output': [], 'prob': []}\n    \n    for subject in range(subjects):\n        subject_result = fast_csp(trials[subject*trial_count:(subject+1)*trial_count], list_length)\n        subject_result[np.argmax(subject_result)+1:] = np.nan\n\n        result['subject'] += [subject+1]*(list_length+1)\n        result['output'] += np.arange(list_length+1, dtype=int).tolist()\n        result['prob'] += subject_result.tolist()\n        \n    return pd.DataFrame(result)\n\ncsp(events, trials)\n\n\n\n\n  \n    \n      \n      subject\n      output\n      prob\n    \n  \n  \n    \n      0\n      1\n      0\n      0.0\n    \n    \n      1\n      1\n      1\n      0.0\n    \n    \n      2\n      1\n      2\n      0.0\n    \n    \n      3\n      1\n      3\n      0.0\n    \n    \n      4\n      1\n      4\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1507\n      72\n      16\n      NaN\n    \n    \n      1508\n      72\n      17\n      NaN\n    \n    \n      1509\n      72\n      18\n      NaN\n    \n    \n      1510\n      72\n      19\n      NaN\n    \n    \n      1511\n      72\n      20\n      NaN\n    \n  \n\n1512 rows × 3 columns\n\n\n\nWe can compare the runtimes of our implementations using the %%timeit Jupyter magic:\n\n%%timeit\nfast_csp(trials, list_length)\n\n210 µs ± 10.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n\n\n\n%%timeit\ncsp(events, trials)\n\n2.53 ms ± 156 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\nfast_csp is slower than our serial position effect functions, but faster than our functions analyzing lag-contiguity."
  },
  {
    "objectID": "library\\analyses\\Conditional_Stop_Probability.html#plotting",
    "href": "library\\analyses\\Conditional_Stop_Probability.html#plotting",
    "title": "compmemlearn",
    "section": "Plotting",
    "text": "We’ll define a seaborn-based plotting function that uses our csp function.\n# export\nimport seaborn as sns\nfrom psifr import fr\n\ndef plot_csp(data, **facet_kws):\n    \n    trials = pd.pivot_table(\n        data, index=['subject', 'list'], \n        columns=['output'], values='input', \n        fill_value=0).to_numpy()\n\n    sns.lineplot(\n        data=csp(data, trials), \n        x='output', y='prob', **facet_kws)\n\nsns.set_theme(style=\"darkgrid\")\n\ng = sns.FacetGrid(dropna=False, data=events, height=4, aspect=1.2)\ng.map_dataframe(plot_csp, err_style='bars')\n\ng.set_xlabels('Recall Position')\ng.set_ylabels('Conditional Stop Probability');"
  },
  {
    "objectID": "library\\analyses\\Lag_Contiguity_Effect.html#data-preparation",
    "href": "library\\analyses\\Lag_Contiguity_Effect.html#data-preparation",
    "title": "compmemlearn",
    "section": "Data Preparation",
    "text": "For our demonstrations, we’ll lean on the MurdockOkada1970 dataset. As a reminder, in this dataset each of 72 undergraduates was given 20 test lists with 20-word lists visually presented at either 60 or 120 words/min.\n\nfrom compmemlearn.datasets import prepare_murdock1970_data\n\ntrials, events, list_length = prepare_murdock1970_data('../../data/mo1970.txt')\nevents.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n    \n  \n  \n    \n      0\n      1\n      1\n      1\n      1\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      1\n      1\n      1\n      2\n      2\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      2\n      1\n      1\n      3\n      3\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      3\n      1\n      1\n      4\n      4\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      4\n      1\n      1\n      5\n      5\n      NaN\n      True\n      False\n      0\n      False"
  },
  {
    "objectID": "library\\analyses\\Lag_Contiguity_Effect.html#analysis",
    "href": "library\\analyses\\Lag_Contiguity_Effect.html#analysis",
    "title": "compmemlearn",
    "section": "Analysis",
    "text": "DataFrame\nWe can usually rely on the psifr library to generate pandas DataFrames containing lag-CRP information.\n\nfrom psifr import fr\n\ncrp = fr.lag_crp(events)\ncrp\n\n\n\n\n  \n    \n      \n      \n      prob\n      actual\n      possible\n    \n    \n      subject\n      lag\n      \n      \n      \n    \n  \n  \n    \n      1\n      -19\n      0.166667\n      2\n      12\n    \n    \n      -18\n      0.083333\n      2\n      24\n    \n    \n      -17\n      0.025641\n      1\n      39\n    \n    \n      -16\n      0.019608\n      1\n      51\n    \n    \n      -15\n      0.030303\n      2\n      66\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      72\n      15\n      0.000000\n      0\n      12\n    \n    \n      16\n      0.000000\n      0\n      3\n    \n    \n      17\n      0.000000\n      0\n      4\n    \n    \n      18\n      0.000000\n      0\n      1\n    \n    \n      19\n      NaN\n      0\n      0\n    \n  \n\n2808 rows × 3 columns\n\n\n\n\n\nFast Array-Based Generation\nDataFrames contain granular subject-by-subject information and are easier to plot using the seaborn library. But sometimes we don’t need this granular information and mainly want to perform our analysis as quickly as possible – perhaps to help with model fitting or analysis. In that case, representing results with numpy arrays and performing just-in-time compilation of our function using numba might be preferred. We include analyses.fast_crp in our library for that purpose here.\n# export\n\nfrom numba import njit\nimport numpy as np\n\n@njit(fastmath=True, nogil=True)\ndef fast_crp(trials, item_count):\n    \n    lag_range = item_count - 1\n    total_actual_lags = np.zeros(lag_range * 2 + 1)\n    total_possible_lags = np.zeros(lag_range * 2 + 1)\n    terminus = np.sum(trials != 0, axis=1)\n    \n    # compute actual serial lag b/t recalls\n    actual_lags = trials[:, 1:] - trials[:, :-1]\n    actual_lags += lag_range\n    \n    # tabulate bin totals for actual and possible lags\n    for i in range(len(trials)):\n        possible_items = np.arange(item_count) + 1\n        previous_item = 0\n        \n        for recall_index in range(terminus[i]):\n            \n            # track possible and actual lags\n            if recall_index > 0:\n                total_actual_lags[actual_lags[i, recall_index-1]] += 1\n                \n                # exploit equivalence b/t item index and study position to track possible lags\n                possible_lags = possible_items - previous_item \n                possible_lags += lag_range\n                total_possible_lags[possible_lags] += 1\n                \n            # update pool of possible items to exclude recalled item\n            previous_item = trials[i, recall_index]\n            possible_items = possible_items[possible_items != previous_item]\n    \n    # small correction to avoid nans\n    total_possible_lags[total_actual_lags==0] += 1\n    \n    return total_actual_lags/total_possible_lags\n\nfast_crp(trials, list_length)\n\narray([0.11545802, 0.03865462, 0.03426124, 0.02190876, 0.01986577,\n       0.02267685, 0.02739411, 0.02432077, 0.02417998, 0.02586558,\n       0.02197371, 0.02486135, 0.03163017, 0.03506209, 0.03603604,\n       0.04045307, 0.04037383, 0.06735022, 0.12302405, 0.        ,\n       0.42455483, 0.12300786, 0.0701565 , 0.04939064, 0.04814004,\n       0.04378356, 0.03933364, 0.03939865, 0.03775744, 0.04248573,\n       0.03664553, 0.0403481 , 0.02867384, 0.02528978, 0.03629537,\n       0.03250774, 0.04587156, 0.06060606, 0.02366864])\n\n\nWe can compare the runtimes of compmemlearn’s analyses.fast_crp and psifr’s fr.lag_crp using the %%timeit Jupyter magic:\n\n%%timeit\nfast_crp(trials, 20)\n\n5.65 ms ± 177 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n%%timeit\nfr.lag_crp(events)\n\n470 ms ± 7.77 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\nOur fast implementation is more than 100 times faster!"
  },
  {
    "objectID": "library\\analyses\\Lag_Contiguity_Effect.html#plotting",
    "href": "library\\analyses\\Lag_Contiguity_Effect.html#plotting",
    "title": "compmemlearn",
    "section": "Plotting",
    "text": "psifr’s plotting library creates a separate figure for each plot, when sometimes we want to to include multiple plots in one figure, so we define our own.\n# export\nimport seaborn as sns\nfrom psifr import fr\n\ndef plot_lag_crp(data, max_lag=5, **facet_kws):\n    \n    filt_neg = f'{-max_lag} <= lag < 0'\n    filt_pos = f'0 < lag <= {max_lag}'\n    \n    crp_data = fr.lag_crp(data)\n    \n    sns.lineplot(\n        data=crp_data.query(filt_neg), \n        x='lag', y='prob', **facet_kws)\n    sns.lineplot(\n        data=crp_data.query(filt_pos), \n        x='lag', y='prob', **facet_kws)\n\nsns.set_theme(style=\"darkgrid\")\n\ng = sns.FacetGrid(dropna=False, data=events, height=4, aspect=1.2)\ng.map_dataframe(plot_lag_crp, err_style='bars')\ng.set(ylim=(0, .5))\n\ng.set_xlabels('Item\\'s Lag In Study List From Last Recalled Item')\ng.set_ylabels('Conditional Recall Rate');"
  },
  {
    "objectID": "library\\analyses\\Lag_Contiguity_with_Repetition_Data.html#contrast-with-stochastic-approach-demoed-in-lohnas-kahana-2014",
    "href": "library\\analyses\\Lag_Contiguity_with_Repetition_Data.html#contrast-with-stochastic-approach-demoed-in-lohnas-kahana-2014",
    "title": "compmemlearn",
    "section": "Contrast With Stochastic Approach Demoed in Lohnas & Kahana (2014)",
    "text": "For lists containing repeated spaced items, the lags for such an item is ambiguous. For instance, the transition between an item presented in serial position 5 to an item presented in serial positions 3 and 9 could be considered a lag of −2 or +4.\n\nI kind of disagree with the specifics of this framework. The lags are not ambiguous – we know what they are. Rather, they are numerous, and to account for that we can just track each lag in our analysis.\n\nFor any transition with an ambiguous lag (i.e. a transition including a repeated item), we randomly selected the lag value from the set of possible lags.\n\nThe lag-CRP is a ratio of lag transitions that were made over transitions that could have been made across each output in a dataset. However, for lists containing repeated spaced items, the lags for such an item is numerous. For instance, the transition between an item presented in serial position 5 to an item presented in serial positions 3 and 9 is both a lag of −2 and of +4. In our tally of actual and possible lag transitions, we accordingly count both these values. Relating this approach to the example above, a lag transition of -2 and of +4 is possible (and actual) for the considered output.\nRandomly selecting the lag value from the set of possible lags for each analysis and aggregating over multiple replicates will (probably) converge to this result. However, that approach is imprecise, nondeterministic, and takes longer to run."
  },
  {
    "objectID": "library\\analyses\\Lag_Contiguity_with_Repetition_Data.html#data-preparation",
    "href": "library\\analyses\\Lag_Contiguity_with_Repetition_Data.html#data-preparation",
    "title": "compmemlearn",
    "section": "Data Preparation",
    "text": "from compmemlearn.datasets import prepare_lohnas2014_data\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')\n\nevents.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n      condition\n    \n  \n  \n    \n      0\n      1\n      1\n      0\n      1\n      1.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      1\n      1\n      1\n      1\n      2\n      2.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      2\n      1\n      1\n      2\n      3\n      3.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      3\n      1\n      1\n      3\n      4\n      4.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      4\n      1\n      1\n      4\n      5\n      5.0\n      True\n      True\n      0\n      False\n      4"
  },
  {
    "objectID": "library\\analyses\\Lag_Contiguity_with_Repetition_Data.html#function",
    "href": "library\\analyses\\Lag_Contiguity_with_Repetition_Data.html#function",
    "title": "compmemlearn",
    "section": "Function",
    "text": "That recalled items can have two study positions forces us to complicate the function. Along with the scenario where the current and the previous item have just one relevant serial lag to consider, we must also consider the case where there are two serial lags to consider when either the current item or the previous item had two serial positions. Then there’s one more scenario – when both the the current and the previous item were encountered twice during encoding. This corresponds with four serial lags to consider.\nHow do we weigh these? The approach in the SPC was just to interpret the description of the analysis literally. In the SPC, we tracked the probability of recalling an item given that it was studied at each selected position – even if it was also studied at some other position. Here, we’ll do the same thing, except using lag instead of study position. Extensions of this analysis can exclude items on chosen bases, but this gets us a solid general foundation.\nTo achieve this, we have to change how we track lag lag across trials (in actual) so that lags can occur with multiple lags simultaneously.\nWe must also change how we track changes to the pool of possible lag lags. This probably requires adding some representation of items that have positions as attributes and are looped across to identify relevant lags.\nprevious_recall can identify those items.\nfrom compmemlearn.analyses import recall_by_second_study_position, recall_by_all_study_positions\n# export\n\nfrom numba import njit\nfrom numba import int32\nimport numpy as np\nfrom compmemlearn.datasets import find_first\n\n\n@njit(nogil=True)\ndef fast_mixed_crp(trials, presentations):\n    \n    list_length = len(presentations[0])\n    lag_range = list_length - 1\n    total_actual_lags = np.zeros(lag_range * 2 + 1)\n    total_possible_lags = np.zeros(lag_range * 2 + 1)\n    terminus = np.sum(trials != 0, axis=1) # number of recalls per trial\n    \n    # compute actual serial lag b/t recalls, considering all possible positions\n    alt_presentations = np.fliplr(presentations)\n    alt_trials = recall_by_second_study_position(trials, presentations)\n    actual_lags = np.zeros((4, len(trials), len(trials[0])-1), dtype=int32)\n    actual_lags[0] = trials[:, 1:] - trials[:, :-1]\n    actual_lags[1] = trials[:, 1:] - alt_trials[:, :-1]\n    actual_lags[2] = alt_trials[:, 1:] - trials[:, :-1]\n    actual_lags[3] = alt_trials[:, 1:] - alt_trials[:, :-1]\n    \n    # if actual[0, x, y] == actual[2, x, y] (or 1, 3) then lagged-to item has 1 presentation\n    # if actual[0, x, y] == actual[1, x, y] (or 2, 3 respectively) then lagged-from item has 1 pres\n    # avoid counting single presentations twice by giving those lags a value of 0\n    previous_item_equivalence = actual_lags[0] == actual_lags[2]\n    current_item_equivalence = actual_lags[0] == actual_lags[1]\n    either_item_equivalence = np.logical_or(previous_item_equivalence, current_item_equivalence)\n\n    for i in range(len(actual_lags[0])):\n        actual_lags[1, i][current_item_equivalence[i]] = 0\n        actual_lags[2, i][previous_item_equivalence[i]] = 0\n        actual_lags[3, i][either_item_equivalence[i]] = 0\n        \n    # we add lag_range to have result identify indices in total_ to bin counts\n    actual_lags += lag_range\n    \n    for trial_index in range(len(trials)):\n        \n        previous_item = 0\n        item_count = np.max(presentations[trial_index]) + 1\n        possible_items = np.arange(item_count) # initial pool of possible recalls, 1-indexed\n        possible_positions = np.zeros((item_count, 2))\n        \n        # we track possible positions using presentations and alt_presentations\n        for item in range(item_count):\n            possible_positions[item, 0] = find_first(item, presentations[trial_index])\n            possible_positions[item, 1] = list_length - find_first(item, alt_presentations[trial_index]) -1\n        \n        for recall_index in range(terminus[trial_index]):\n            \n            # track possible and actual lags\n            if recall_index > 0:\n\n                # we add to actual_lags total for each lag transition made for this recall\n                total_actual_lags[actual_lags[:, trial_index, recall_index-1]] += 1\n                \n                # item indices don't help track lags anymore\n                # so more complex calculation needed to identify possible lags given previous item\n                possible_lags = np.zeros((4, len(possible_items)), dtype=int32)\n                possible_lags[0] = possible_positions[possible_items, 0] - possible_positions[previous_item, 0]\n                possible_lags[1] = possible_positions[possible_items, 0] - possible_positions[previous_item, 1]\n                possible_lags[2] = possible_positions[possible_items, 1] - possible_positions[previous_item, 0]\n                possible_lags[3] = possible_positions[possible_items, 1] - possible_positions[previous_item, 1]\n                \n                # avoid redundant counting of single presentations\n                previous_item_equivalence = possible_lags[0] == possible_lags[2]\n                current_item_equivalence = possible_lags[0] == possible_lags[1]\n                either_item_equivalence = np.logical_or(previous_item_equivalence, current_item_equivalence)\n                possible_lags[1][current_item_equivalence] = 0\n                possible_lags[2][previous_item_equivalence] = 0\n                possible_lags[3][either_item_equivalence] = 0\n    \n                possible_lags += lag_range\n                total_possible_lags[possible_lags.flatten()] += 1\n                \n            # update pool to exclude recalled item (updated to still identify 1-indexed item)\n            previous_item = presentations[trial_index][trials[trial_index, recall_index]-1]\n            possible_items = possible_items[possible_items != previous_item]\n    \n    # small correction to avoid nans and commit to excluding multiply-tracked single presentations \n    total_actual_lags[lag_range] = 0\n    total_possible_lags[total_actual_lags==0] += 1\n    \n    return total_actual_lags/total_possible_lags\n# export\n\n@njit(nogil=True)\ndef flex_mixed_crp(trials, presentations, max_repeats=2):\n    \n    list_length = len(presentations[0])\n    lag_range = list_length - 1\n    total_actual_lags = np.zeros(lag_range * 2 + 1)\n    total_possible_lags = np.zeros(lag_range * 2 + 1)\n    terminus = np.sum(trials != 0, axis=1) # number of recalls per trial\n    recall_by_study_position = recall_by_all_study_positions(trials, presentations, max_repeats)\n    \n    for trial_index in range(len(trials)):\n        \n        previous_item = 0\n        item_count = np.max(presentations[trial_index]) + 1\n        possible_items = np.arange(item_count) # initial pool of possible recalls, 1-indexed\n        possible_positions = np.zeros((item_count, max_repeats), dtype=int32)\n        \n        # we track possible positions using presentations and alt_presentations\n        for item in range(item_count):\n            pos = np.nonzero(presentations[trial_index] == item)[0] + 1\n            possible_positions[item, :len(pos)] = pos\n            \n        for recall_index in range(terminus[trial_index]):\n            \n            current_item = presentations[trial_index][trials[trial_index, recall_index]-1]\n            \n            # track possible and actual lags\n            if recall_index > 0:\n                \n                # item indices don't help track lags anymore\n                # so more complex calculation needed to identify possible lags given previous item\n                current_index = np.nonzero(possible_items==current_item)[0]\n                possible_lags = np.zeros((len(recall_by_study_position) ** 2, len(possible_items)), dtype=int32)\n\n                index = 0\n                for x in range(len(recall_by_study_position)):\n                    for y in range(len(recall_by_study_position)):\n                        if possible_positions[previous_item, y] > 0:\n                        \n                            possible_lags[index] = possible_positions[\n                                possible_items, x] - possible_positions[previous_item, y]\n                            \n                            # if tracked position is 0, then we don't actually want to count it in our lags\n                            possible_lags[index][possible_positions[possible_items, x] == 0] = 0\n                        \n                        index += 1\n\n                possible_lags += lag_range\n                total_actual_lags[possible_lags[:, current_index].flatten()] += 1\n                total_possible_lags[possible_lags.flatten()] += 1\n                        \n\n            # update pool to exclude recalled item (updated to still identify 1-indexed item)\n            previous_item = current_item\n            possible_items = possible_items[possible_items != previous_item]\n                    \n    # small correction to avoid nans and commit to excluding multiply-tracked single presentations \n    total_actual_lags[lag_range] = 0\n    total_possible_lags[total_actual_lags==0] += 1\n    \n    return total_actual_lags/total_possible_lags"
  },
  {
    "objectID": "library\\analyses\\Lag_Contiguity_with_Repetition_Data.html#demo",
    "href": "library\\analyses\\Lag_Contiguity_with_Repetition_Data.html#demo",
    "title": "compmemlearn",
    "section": "Demo",
    "text": "Comparison With Regular fast_csp Using Control Lists\n\nfrom compmemlearn.analyses import fast_crp\n\nfast_crp(trials[list_types==1], 40) == fast_mixed_crp(trials[list_types==1], presentations[list_types==1])\n\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True])\n\n\n\n%timeit fast_mixed_crp(trials[list_types==1], presentations[list_types==1])\n\n15.7 ms ± 440 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n%timeit fast_crp(trials[list_types==1], 40)\n\n3.25 ms ± 40.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n%timeit flex_mixed_crp(trials[list_types==1], presentations[list_types==1])\n\n20.9 ms ± 336 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\ncondition = 4\nflex_mixed_crp(trials[list_types==condition], presentations[list_types==condition]) == fast_mixed_crp(trials[list_types==condition], presentations[list_types==condition])\n\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True])\n\n\n\nflex_mixed_crp(trials[list_types==condition], presentations[list_types==condition])\n\narray([0.04545455, 0.07741935, 0.02702703, 0.03448276, 0.01239669,\n       0.01867572, 0.01267606, 0.0255164 , 0.0311493 , 0.02812803,\n       0.02410714, 0.02390767, 0.02356638, 0.01918819, 0.02116041,\n       0.02271252, 0.02799757, 0.02669762, 0.0268757 , 0.0295858 ,\n       0.02862883, 0.02987952, 0.02465116, 0.0199027 , 0.02997859,\n       0.02920609, 0.03033885, 0.03862333, 0.04053552, 0.04422869,\n       0.04406539, 0.05585831, 0.0589584 , 0.05534106, 0.0639848 ,\n       0.06148171, 0.08683975, 0.09879092, 0.17528821, 0.        ,\n       0.28192131, 0.12563791, 0.08370591, 0.06432161, 0.06537967,\n       0.05540897, 0.05018991, 0.04840941, 0.03874644, 0.0437536 ,\n       0.03453365, 0.03611195, 0.0264234 , 0.03119922, 0.0254065 ,\n       0.01907074, 0.02382671, 0.02185995, 0.02243714, 0.01709742,\n       0.01704782, 0.01742919, 0.0191344 , 0.01429933, 0.01544594,\n       0.01411396, 0.02090209, 0.01302546, 0.01519949, 0.01491525,\n       0.01538462, 0.01579779, 0.0123131 , 0.01383399, 0.01030928,\n       0.00693481, 0.01202749, 0.01428571, 0.01298701])\n\n\n\nimport matplotlib.pyplot as plt\n\nfor condition in range(4):\n    test_crp= fast_mixed_crp(trials[list_types==condition+1], presentations[list_types==condition+1])\n    test_crp[len(presentations[0])-1] = np.nan\n    plt.plot(np.arange(len(test_crp)), test_crp, label=str(condition+1))\n    plt.xticks(np.arange(0, len(test_crp), 4), np.arange(0, len(test_crp), 4) - 39)\n    \nplt.legend()\n\n<matplotlib.legend.Legend at 0x1f0e28a8070>"
  },
  {
    "objectID": "library\\analyses\\Measuring_Repetition_Effects.html#controlling-for-serial-position",
    "href": "library\\analyses\\Measuring_Repetition_Effects.html#controlling-for-serial-position",
    "title": "compmemlearn",
    "section": "Controlling for Serial Position",
    "text": "To control for serial position effects of repeated items, analyses are often performed on randomized recall sequences with recall probabilities matched to the serial position curve of controls lists. Recall of each item is then calculated randomly and independently across trials.\n# export\n\nfrom numba import njit, prange\nimport numpy as np\n\n@njit(parallel=True)\ndef randomize_dataset(recall_rate_by_serial_position, sample_size):\n    \"\"\"\n    To control for serial position effects of repeated items, \n    analyses are often performed on randomized recall sequences with recall probabilities \n    matched to the serial position curve of controls lists. Recall of each item is then \n    calculated randomly and independently across trials. \n    \"\"\"\n\n    samples = np.random.rand(sample_size, len(recall_rate_by_serial_position)) < recall_rate_by_serial_position\n    result = np.zeros((sample_size, len(recall_rate_by_serial_position)))\n\n    for i in prange(sample_size):\n        sample = samples[i].nonzero()[0] + 1\n        np.random.shuffle(sample)\n        result[i, :len(sample)] = sample\n\n    return result\nrecall_rates = events.pivot_table(index='input', values='recall').to_numpy().flatten()\n\nrandomize_dataset(recall_rates, 10000000)"
  },
  {
    "objectID": "library\\analyses\\Measuring_Repetition_Effects.html#recall-probability-by-lag",
    "href": "library\\analyses\\Measuring_Repetition_Effects.html#recall-probability-by-lag",
    "title": "compmemlearn",
    "section": "Recall Probability by Lag",
    "text": "NOTE: this version is deprecated and only maintained to aid updating the codebase; see devoted notebook “recall probability by spacing” for the much (>5x) faster replacement\nfrom numba import njit\nimport numpy as np\n\n@njit(fastmath=True, nogil=True)\ndef recall_probability_by_lag(presentations, study_positions_in_recall_order, experiment_count=1):\n\n    presented, retrieved = np.zeros(5), np.zeros(5)\n\n    for trial_index, sequence in enumerate(presentations):\n\n        for experiment in range(experiment_count):\n            \n            # retrieve trial information\n            trial = study_positions_in_recall_order[trial_index*experiment_count + experiment]\n\n            # extract list of recalled items\n            recalled = sequence[trial-1][trial != 0]\n            \n\n            for item in np.unique(sequence):\n                locations = np.where(sequence == item)[0]\n\n                # presented just once\n                if len(locations) == 1:\n                    index = 0\n                else: \n\n                    # no intervening items (massed)\n                    lag = locations[1] - locations[0] - 1\n                    if lag == 0:\n                        index = 1\n\n                    # 1-2 intervening items\n                    elif lag <= 2:\n                        index = 2\n\n                    # 3-5\n                    elif lag <= 5:\n                        index = 3\n\n                    # 6-8\n                    else:\n                        index = 4\n\n                presented[index] += 1\n                retrieved[index] += item in recalled\n        \n    return retrieved, presented, retrieved/presented\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%config InlineBackend.figure_formats = ['svg']\n\nsns.set_theme(style=\"dark\")\ncondition = 4\nsource = 'Lohnas & Kahana (2014)'\n\nresult = recall_probability_by_lag(presentations[list_types>=condition], trials[list_types>=condition])[-1]\nprint(result)\nprint(result[1:] - result[:-1])\nax = sns.barplot(x=['N/A', '0', '1-2', '3-5', '6-8'], \n                 y=result)\nplt.xlabel('Number of Intervening Items Between Repetitions')\nplt.ylabel('Recall Probability')\nplt.title('Condition {}, {}'.format(condition, source))\nplt.show()\n\n[0.37278912 0.43928571 0.47678571 0.55714286 0.57857143]\n[0.0664966  0.0375     0.08035714 0.02142857]\n\n\n\n\n\nfrom compmemlearn.models import Classic_CMR\nfrom numba import int64\n\n@njit(fastmath=True, nogil=True)\ndef sim_recall_probability_by_lag(presentations, experiment_count, model_class, parameters):\n    \"\"\"\n    Apply organizational analyses to visually compare the behavior of the model \n    with these parameters against specified dataset.\n    \"\"\"\n    \n    max_lag = 8\n    total_ratio = np.zeros(max_lag+2)\n    total = 0\n    \n    # generate simulation data from model\n    for experiment in range(experiment_count):\n\n        sim = np.zeros(np.shape(presentations), dtype=int64) # set as int64 when using numba, int otherwise\n        for trial_index in range(len(presentations)):\n            presentation = presentations[trial_index]\n            \n            item_count = np.max(presentation)+1\n            model = model_class(item_count, len(presentation), parameters)\n\n            # simulate study events\n            model.experience(model.items[presentation])\n            \n            # simulate and collect sequence of recalled item indices\n            recalled = model.free_recall()\n            xsorted = np.argsort(presentation)\n            ypos = np.searchsorted(presentation[xsorted], recalled)\n            sim[trial_index, :len(recalled)] = xsorted[ypos]+1\n            \n        total_ratio += recall_probability_by_lag(presentations, sim)\n        total += 1\n        \n    return total_ratio/total"
  },
  {
    "objectID": "library\\analyses\\Measuring_Repetition_Effects.html#or-score",
    "href": "library\\analyses\\Measuring_Repetition_Effects.html#or-score",
    "title": "compmemlearn",
    "section": "OR Score",
    "text": "Given that the probability of recalling an item repeated in positions i and j is equivalent to the probability of recalling either the occurrence of the item in position i or the occurrence of the item in position j, contextual variability predicts that the probability of recalling either of two once-presented items in positions i and j, termed the OR score, should increase with their spacing |i - j|.\nTo control for serial position effects of repeated items, they determined OR scores from randomized recall sequences with recall probabilities matched to the serial position curve of controls lists. They subtracted the OR scores based on these randomized recall sequences from the observed OR scores, and for illustrative purposes added the mean randomized OR score at each lag.\n#TBD"
  },
  {
    "objectID": "library\\analyses\\Measuring_Repetition_Effects.html#rate-of-transition-between-items-that-follow-presentation-of-the-same-item",
    "href": "library\\analyses\\Measuring_Repetition_Effects.html#rate-of-transition-between-items-that-follow-presentation-of-the-same-item",
    "title": "compmemlearn",
    "section": "Rate of transition between items that follow presentation of the same item",
    "text": "They considered transitions between items following a shared repeated item. They calculated the proportion of those items recalled in \\(S_j = {j + 1, j + 2}\\) of which CMR then recalled an item in the set \\(S_i = {i + 1, i + 2}\\). They also calculated the proportion of recalls \\(S_i\\) of which CMR then transitioned to an item in the set \\(S_j\\). They calculated the proportion of transitions for each of lags \\(j - i >= 4\\), and represented the mean percent of transitions across these lags.\nTo estimate the proportion of transitions that CMR would make at these lags in the absence of repeated items, they considered transitions in control lists matched to the same serial positions considered in the mixed lists. They matched these serial positions to 100 random shuffles of the control lists, and took the mean across the reshuffled datasets.\n#TBD"
  },
  {
    "objectID": "library\\analyses\\Measuring_Repetition_Effects.html#how-do-values-of-zeta_s-configure-temporal-contiguity-with-secondary-item-presentations",
    "href": "library\\analyses\\Measuring_Repetition_Effects.html#how-do-values-of-zeta_s-configure-temporal-contiguity-with-secondary-item-presentations",
    "title": "compmemlearn",
    "section": "How Do Values of \\(\\zeta_s\\) Configure Temporal Contiguity With Secondary Item Presentations?",
    "text": "Weights in \\(M^{CF}\\) do not just configure the overall probability of recalling an item. Since the state of context depends on prior items encoded or retrieved and \\(M^{CF}\\) encodes context-to-item associations, differences in \\(M^{CF}\\) learning rates for presentations of an item as enforced by the differential encoding mechanism must also the rate of transition between different items during recall.\nIn particular, weaker learning for the second presentation of a repeated item compared to the first should enforce greater rate of transitions between the repeated item and other items presented near its first presentation.\n# export\n\nimport pandas as pd\nimport numpy as np\n\ndef indices_of_repeated_items(presentation_sequence):\n\n    values, counts = np.unique(presentation_sequence, return_counts=True)\n    repeated_items = {v: np.where(presentation_sequence == v)[0] for v in values if counts[v] > 1}\n\n    return {key:repeated_items[key] for key in repeated_items}\n\n    \ndef alternative_contiguity_test(mixed_presentations, mixed_recalls, lag_threshold, repetition_count):\n    relevant_lags = list(range(-int(lag_threshold/2), int(lag_threshold/2+1)))\n    del relevant_lags[int(lag_threshold/2)]\n\n    actual_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]\n    possible_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]\n\n    for trial_index in range(len(mixed_presentations)):\n\n        # sequence of item indices ordered as they were studied\n        presentation = mixed_presentations[trial_index]\n\n        # sequence of initial study positions ordered as they were recalled\n        trial_by_study_position = mixed_recalls[trial_index]\n\n        # sequence of item indices ordered as they were recalled\n        trial_by_item_index = presentation[trial_by_study_position-1][:np.size(np.nonzero(trial_by_study_position))]\n\n        # {item_index: [presentation indices]} for each repeated item in presentation sequence spaced by >4 items\n        i_and_j = indices_of_repeated_items(presentation)\n        \n        # then for each unique repeated item in the study list, \n        for repeated_item in i_and_j:\n\n            # search for relevant item(s) in recall sequence and skip if not found \n            look_for = trial_by_item_index == presentation[i_and_j[repeated_item][0]]\n            for k in range(1, repetition_count):\n                look_for = np.logical_or(\n                    look_for, trial_by_item_index == presentation[i_and_j[repeated_item][k]])\n            recall_positions = np.where(look_for)[0]\n\n            if np.size(recall_positions) == 0:\n                continue\n\n            # check each position the item was observed (always just 1 position; we loop for parallelism w control)\n            for recall_position in recall_positions:\n\n                # also skip if no successive recall was made, \n                if np.size(trial_by_item_index) == recall_position + 1:\n                    continue\n\n                # build list of study positions for items recalled up to repeated item\n                prior_lags = [[] for each in range(repetition_count)]\n                for i in range(recall_position):\n\n                    # if considered item is also repeated, we track lags wrt to all presentations\n                    if trial_by_item_index[i] in i_and_j:\n                        for considered in range(len(i_and_j[trial_by_item_index[i]])):\n                            for focal in range(repetition_count):\n                                prior_lags[focal].append(\n                                    int(i_and_j[trial_by_item_index[i]][considered] - i_and_j[repeated_item][focal]))\n                    else:\n                        for k in range(repetition_count):\n                            prior_lags[k].append(int(trial_by_study_position[i] - i_and_j[repeated_item][k]))\n\n                # transition of a given lag is possible if lag not present in prior_lags\n                for lag in relevant_lags:\n                    for k in range(repetition_count):\n                        \n                        # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][-1] < lag_threshold\n                        if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):\n                            continue\n                        \n                        if lag not in prior_lags[k]:\n                            possible_lags[k][relevant_lags.index(lag)] += 1\n\n                # track each serial lag of actually transitioned-to item\n                if trial_by_item_index[recall_position+1] in i_and_j:\n                    positions = i_and_j[trial_by_item_index[recall_position+1]]\n                    for transition_study_position in positions:\n                        for k in range(repetition_count):\n\n                            # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold\n                            if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):\n                                continue\n\n                            lag = int(transition_study_position - i_and_j[repeated_item][k])\n                            if lag in relevant_lags:\n                                actual_lags[k][relevant_lags.index(lag)] += 1\n                else:\n                    transition_study_position = trial_by_study_position[recall_position+1]-1\n                    for k in range(repetition_count):\n\n                        # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold\n                        if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):\n                            continue\n\n                        lag = int(transition_study_position-i_and_j[repeated_item][k])\n                        if lag in relevant_lags:\n                            actual_lags[k][relevant_lags.index(lag)] += 1\n\n    result = []\n    for k in range(repetition_count):\n        \n        for i in range(len(possible_lags[k])):\n            if possible_lags[k][i] == 0:\n                possible_lags[k][i] += 1\n\n        result.append(pd.DataFrame(\n            {'lag': relevant_lags, 'prob': np.divide(actual_lags[k], possible_lags[k]), \n            'actual': actual_lags[k], 'possible': possible_lags[k]}))\n\n    return pd.concat(result, keys=['From Position {}'.format(i+1) for i in range(repetition_count)], names=['locus'])\n\n\ndef alternative_contiguity_control(\n    mixed_presentations, control_presentations, control_recalls, lag_threshold, repetition_count):\n    relevant_lags = list(range(-int(lag_threshold/2), int(lag_threshold/2+1)))\n    del relevant_lags[int(lag_threshold/2)]\n\n    actual_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]\n    possible_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]\n\n    for trial_index in range(len(mixed_presentations)):\n\n        # sequence of item indices ordered as they were studied\n        presentation = mixed_presentations[trial_index]\n        control_presentation = control_presentations[trial_index]\n\n        # sequence of initial study positions ordered as they were recalled\n        trial_by_study_position = control_recalls[trial_index]\n\n        # sequence of item indices ordered as they were recalled\n        trial_by_item_index = control_presentation[trial_by_study_position-1][:np.size(np.nonzero(trial_by_study_position))]\n\n        # {item_index: [presentation indices]} for each repeated item in presentation sequence spaced by >4 items\n        i_and_j = indices_of_repeated_items(presentation)\n        \n        # then for each unique repeated item in the study list, \n        for repeated_item in i_and_j:\n\n            # search for relevant item(s) in recall sequence and skip if not found \n            look_for = trial_by_item_index == control_presentation[i_and_j[repeated_item][0]]\n            for k in range(1, repetition_count):\n                look_for = np.logical_or(\n                    look_for, trial_by_item_index == control_presentation[i_and_j[repeated_item][k]])\n            recall_positions = np.where(look_for)[0]\n\n            for recall_position in recall_positions:\n\n                # also skip if no successive recall was made, \n                if np.size(trial_by_item_index) == recall_position + 1:\n                    continue\n\n                # build list of study positions for items recalled up to repeated item\n                prior_lags = [[] for each in range(repetition_count)]\n                for i in range(recall_position):\n                    if trial_by_item_index[i] in i_and_j:\n                        for considered in range(len(i_and_j[trial_by_item_index[i]])):\n                            for focal in range(repetition_count):\n                                prior_lags[focal].append(\n                                    int(i_and_j[trial_by_item_index[i]][considered] - i_and_j[repeated_item][focal]))\n                    else:\n                        for k in range(repetition_count):\n                            prior_lags[k].append(int(trial_by_study_position[i] - i_and_j[repeated_item][k]))\n\n                # transition of a given lag is possible if lag not present in prior_lags\n                for lag in relevant_lags:\n                    for k in range(repetition_count):\n                        if lag not in prior_lags[k]:\n                            possible_lags[k][relevant_lags.index(lag)] += 1\n\n                # track each serial lag of actually transitioned-to item\n                if trial_by_item_index[recall_position+1] in i_and_j:\n                    positions = i_and_j[trial_by_item_index[recall_position+1]]\n                    for transition_study_position in positions:\n                        for k in range(repetition_count):\n                            lag = int(transition_study_position - i_and_j[repeated_item][k])\n                            if lag in relevant_lags:\n                                actual_lags[k][relevant_lags.index(lag)] += 1\n                else:\n                    transition_study_position = trial_by_study_position[recall_position+1]-1\n                    for k in range(repetition_count):\n                        lag = int(transition_study_position-i_and_j[repeated_item][k])\n                        if lag in relevant_lags:\n                            actual_lags[k][relevant_lags.index(lag)] += 1\n\n    result = []\n    for k in range(repetition_count):\n        result.append(pd.DataFrame(\n            {'lag': relevant_lags, 'prob': np.divide(actual_lags[k], possible_lags[k]), \n            'actual': actual_lags[k], 'possible': possible_lags[k]}))\n\n    return pd.concat(result, keys=['From Position {}'.format(i+1) for i in range(repetition_count)], names=['locus'])\n\ndef sim_alternative_contiguity_test(presentations, experiment_count, lag_threshold, repetition_count, encoding_drift_rate,         \n    start_drift_rate, recall_drift_rate, shared_support, item_support, learning_rate, \n    primacy_scale, primacy_decay, stop_probability_scale, \n    stop_probability_growth, choice_sensitivity, delay_drift_rate, \n    drift_familiarity_scale, mfc_familiarity_scale, mcf_familiarity_scale, sampling_rule):\n    \"\"\"\n    Apply organizational analyses to visually compare the behavior of the model \n    with these parameters against specified dataset.\n    \"\"\"\n\n    results = []\n    # generate simulation data from model\n    for experiment in range(experiment_count):\n\n        sim = np.zeros(np.shape(presentations), dtype=int)\n        for trial_index in range(len(presentations)):\n            presentation = presentations[trial_index]\n            \n            item_count = np.max(presentation)+1\n            model = Classic_CMR( item_count, len(presentations),  encoding_drift_rate,         \n                start_drift_rate, recall_drift_rate, shared_support, item_support, learning_rate, \n                primacy_scale, primacy_decay, stop_probability_scale, \n                stop_probability_growth, choice_sensitivity, delay_drift_rate, drift_familiarity_scale, \n                 mfc_familiarity_scale, mcf_familiarity_scale, sampling_rule)\n\n            # simulate study events\n            model.experience(np.eye(model.item_count, model.item_count)[presentation])\n            \n            # simulate and add recall events to trials array\n            recalled = model.free_recall()\n            xsorted = np.argsort(presentation)\n            ypos = np.searchsorted(presentation[xsorted], recalled)\n            sim[trial_index, :len(recalled)] = xsorted[ypos]+1\n\n        # apply contiguity test\n        results.append(alternative_contiguity_test(presentations, sim, lag_threshold, repetition_count))\n\n    return pd.concat(results, keys=list(range(experiment_count)), names=['experiment']).reset_index()\n\nminimum_lag = 6\nrepetition_count = 2\n\nindividual_results = []\n\nfor subject in np.unique(subjects):\n    selection = np.logical_and(list_types > 3, subjects == subject)\n\n    individual_results.append(\n        alternative_contiguity_test(presentations[selection], trials[selection], minimum_lag, repetition_count))\n\ndf = pd.concat(individual_results, keys=np.unique(subjects), names=['subject']).reset_index()\ndf.drop(['level_2'], axis=1, inplace=True)\ndf\n\n\n\n\n  \n    \n      \n      subject\n      locus\n      lag\n      prob\n      actual\n      possible\n    \n  \n  \n    \n      0\n      1\n      From Position 1\n      -3\n      0.000000\n      0\n      27\n    \n    \n      1\n      1\n      From Position 1\n      -2\n      0.115385\n      3\n      26\n    \n    \n      2\n      1\n      From Position 1\n      -1\n      0.153846\n      4\n      26\n    \n    \n      3\n      1\n      From Position 1\n      1\n      0.200000\n      8\n      40\n    \n    \n      4\n      1\n      From Position 1\n      2\n      0.314286\n      11\n      35\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      415\n      37\n      From Position 2\n      -2\n      0.125000\n      1\n      8\n    \n    \n      416\n      37\n      From Position 2\n      -1\n      0.142857\n      1\n      7\n    \n    \n      417\n      37\n      From Position 2\n      1\n      0.333333\n      2\n      6\n    \n    \n      418\n      37\n      From Position 2\n      2\n      0.000000\n      0\n      9\n    \n    \n      419\n      37\n      From Position 2\n      3\n      0.111111\n      1\n      9\n    \n  \n\n420 rows × 6 columns\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nmax_lag = minimum_lag/2\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\ng = sns.FacetGrid(df, height=4.5)\ng.map_dataframe(\n    lambda data, **kws: sns.lineplot(\n        data=data.query(filt_neg), x='lag', y='prob', hue='locus', err_style=None,**kws)\n)\n\ng.map_dataframe(\n    lambda data, **kws: sns.lineplot(\n        data=data.query(filt_pos), x='lag', y='prob', hue='locus', err_style=None, **kws)\n)\n\nplt.legend(['From Position {}'.format(i+1) for i in range(repetition_count)], loc='upper left')\n#plt.title('Stronger Contiguity For First Presentation of an Item\\n(Minimum Lag = {})'.format(minimum_lag))\nplt.tight_layout()\n\n\n\n\n\nControl Version\nHow do we modify this for control lists? - Still use presentation vectors from mixed lists to define i_and_j, but use control list presentations and data for trial_by_study_position and trial_by_item_index and recall_position (except for i_and_j keys and values) - Don’t continue if trial_by_item_index[recall_position+1] in i_and_j\n\nfrom tqdm import tqdm\n\nindividual_results = []\n\nfor iteration in tqdm(range(1000)):\n    for subject in np.unique(subjects):\n        mixed_selection = np.logical_and(list_types == 4, subjects == subject)\n        control_selection = np.logical_and(list_types == 1, subjects == subject)\n        shuffled_trials = trials[control_selection]\n        np.random.shuffle(shuffled_trials)\n\n        individual_results.append(\n            alternative_contiguity_control(presentations[mixed_selection], presentations[control_selection], shuffled_trials, minimum_lag))\n\ndf = pd.concat(individual_results, keys=np.unique(subjects), names=['subject']).reset_index()\ndf.drop(['level_2'], axis=1, inplace=True)\ndf\n\n 77%|███████▋  | 766/1000 [01:58<00:36,  6.37it/s]C:\\Users\\gunnj\\AppData\\Local\\Temp/ipykernel_7552/90211409.py:169: RuntimeWarning: invalid value encountered in true_divide\n  {'lag': relevant_lags, 'prob': np.divide(actual_lagsB, possible_lagsB),\n 87%|████████▋ | 872/1000 [02:14<00:19,  6.63it/s]C:\\Users\\gunnj\\AppData\\Local\\Temp/ipykernel_7552/90211409.py:166: RuntimeWarning: invalid value encountered in true_divide\n  {'lag': relevant_lags, 'prob': np.divide(actual_lagsA, possible_lagsA),\n100%|██████████| 1000/1000 [02:33<00:00,  6.50it/s]\n\n\n\n\n\n  \n    \n      \n      subject\n      locus\n      lag\n      prob\n      actual\n      possible\n    \n  \n  \n    \n      0\n      1\n      From First Position\n      -3\n      0.000000\n      0\n      13\n    \n    \n      1\n      1\n      From First Position\n      -2\n      0.047619\n      1\n      21\n    \n    \n      2\n      1\n      From First Position\n      -1\n      0.050000\n      1\n      20\n    \n    \n      3\n      1\n      From First Position\n      1\n      0.230769\n      6\n      26\n    \n    \n      4\n      1\n      From First Position\n      2\n      0.047619\n      1\n      21\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      415\n      37\n      From Second Position\n      -2\n      0.000000\n      0\n      7\n    \n    \n      416\n      37\n      From Second Position\n      -1\n      0.000000\n      0\n      7\n    \n    \n      417\n      37\n      From Second Position\n      1\n      0.000000\n      0\n      7\n    \n    \n      418\n      37\n      From Second Position\n      2\n      0.000000\n      0\n      6\n    \n    \n      419\n      37\n      From Second Position\n      3\n      0.000000\n      0\n      6\n    \n  \n\n420 rows × 6 columns\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nmax_lag = minimum_lag/2\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\ng = sns.FacetGrid(df, height=4.5)\ng.map_dataframe(\n    lambda data, **kws: sns.lineplot(\n        data=data.query(filt_neg), x='lag', y='prob', hue='locus', err_style='bars', **kws)\n)\n\ng.map_dataframe(\n    lambda data, **kws: sns.lineplot(\n        data=data.query(filt_pos), x='lag', y='prob', hue='locus', err_style='bars', **kws)\n)\n\nplt.legend(['First Presentation', 'Second Presentation'], loc='upper left')\nplt.title('Control Analysis \\n(Minimum Lag = {})'.format(minimum_lag))\nplt.tight_layout()"
  },
  {
    "objectID": "library\\analyses\\Measuring_Repetition_Effects.html#recall-rate-by-lag-from-repetitions",
    "href": "library\\analyses\\Measuring_Repetition_Effects.html#recall-rate-by-lag-from-repetitions",
    "title": "compmemlearn",
    "section": "Recall Rate by Lag From Repetitions",
    "text": "def recall_rate_by_lag(mixed_presentations, mixed_recalls, lag_threshold, lag):\n    \"\"\"\n    Find each item repetition in mixed_presentations and compute the recall rate for items at specified lag from each presentation position. Return the rate relative to the first presentation of each item and relative to the second.\n    \"\"\"\n\n    recalls_A = 0\n    recalls_B = 0\n    total = 0\n\n    for trial_index in range(len(mixed_presentations)):\n\n        # sequence of item indices ordered as they were studied\n        presentation = mixed_presentations[trial_index]\n\n        # sequence of initial study positions ordered as they were recalled\n        trial_by_study_position = mixed_recalls[trial_index]\n\n        # sequence of item indices ordered as they were recalled\n        trial_by_item_index = presentation[trial_by_study_position-1][:np.size(np.nonzero(trial_by_study_position))]\n\n        # {item_index: [presentation indices]} for each repeated item in presentation sequence spaced by >4 items\n        i_and_j = indices_of_repeated_items(presentation, lag_threshold)\n        \n        # then for each unique repeated item in the study list, \n        for repeated_item in i_and_j:\n\n            # get the indices of neighbors to each presentation\n            neighborA = presentation[i_and_j[repeated_item][0] + lag]\n            neighborB = presentation[i_and_j[repeated_item][1] + lag]\n\n            # skip if the neighbor is also a repeatedly presented item\n            if (neighborA in i_and_j) or (neighborB in i_and_j):\n                continue\n\n            # track if they were recalled\n            recalls_A += np.any(neighborA == trial_by_item_index)\n            recalls_B += np.any(neighborB == trial_by_item_index)\n            total += 1\n\n    return recalls_A/total, recalls_B/total, total\n\nindividual_resultsA = []\nindividual_resultsB = []\n\nfor subject in np.unique(subjects):\n    selection = np.logical_and(list_types > 2, subjects == subject)\n\n    result = recall_rate_by_lag(presentations[selection], trials[selection], 4, 1)\n    individual_resultsA.append(result[0])\n    individual_resultsB.append(result[1])\n\nnp.mean(individual_resultsA), np.mean(individual_resultsB)\n\n(0.3857720129269049, 0.382558043145297)"
  },
  {
    "objectID": "library\\analyses\\Probability_of_First_Recall.html#data-preparation",
    "href": "library\\analyses\\Probability_of_First_Recall.html#data-preparation",
    "title": "compmemlearn",
    "section": "Data Preparation",
    "text": "For our demonstrations, we’ll lean on the MurdockOkada1970 dataset. As a reminder, in this dataset each of 72 undergraduates was given 20 test lists with 20-word lists visually presented at either 60 or 120 words/min.\n\nfrom compmemlearn.datasets import prepare_murdock1970_data\n\ntrials, events, list_length = prepare_murdock1970_data(\"../../data/mo1970.txt\")\nevents.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n    \n  \n  \n    \n      0\n      1\n      1\n      1\n      1\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      1\n      1\n      1\n      2\n      2\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      2\n      1\n      1\n      3\n      3\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      3\n      1\n      1\n      4\n      4\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      4\n      1\n      1\n      5\n      5\n      NaN\n      True\n      False\n      0\n      False"
  },
  {
    "objectID": "library\\analyses\\Probability_of_First_Recall.html#analysis",
    "href": "library\\analyses\\Probability_of_First_Recall.html#analysis",
    "title": "compmemlearn",
    "section": "Analysis",
    "text": "DataFrame\nWe can usually rely on the psifr library to generate pandas DataFrames containing PFR information.\n\nfrom psifr import fr\n\npfr = fr.pnr(events).query(\"output <= 1\")\npfr\n\n\n\n\n  \n    \n      \n      \n      \n      prob\n      actual\n      possible\n    \n    \n      subject\n      output\n      input\n      \n      \n      \n    \n  \n  \n    \n      1\n      1\n      1\n      0.00\n      0\n      20\n    \n    \n      2\n      0.00\n      0\n      20\n    \n    \n      3\n      0.00\n      0\n      20\n    \n    \n      4\n      0.00\n      0\n      20\n    \n    \n      5\n      0.00\n      0\n      20\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      72\n      1\n      16\n      0.05\n      1\n      20\n    \n    \n      17\n      0.50\n      10\n      20\n    \n    \n      18\n      0.15\n      3\n      20\n    \n    \n      19\n      0.10\n      2\n      20\n    \n    \n      20\n      0.05\n      1\n      20\n    \n  \n\n1440 rows × 3 columns\n\n\n\n\n\nFast Array Generation\nDataFrames contain granular subject-by-subject information and are easier to plot using the seaborn library. But sometimes we don’t need this granular information and mainly want to perform our analysis as quickly as possible – perhaps to help with model fitting or analysis. In that case, representing results with numpy arrays and performing just-in-time compilation of our function using numba might be preferred. We include analyses.fast_crp in our library for that purpose here.\n# export\n\nfrom numba import njit\nimport numpy as np\n\n\n@njit(fastmath=True, nogil=True)\ndef fast_pfr(trials, item_count):\n    return np.bincount(trials[:, 0], minlength=item_count + 1)[1:] / len(trials)\n\nfast_pfr(trials, list_length)\n\narray([0.06666667, 0.00347222, 0.00208333, 0.00208333, 0.00416667,\n       0.00138889, 0.00694444, 0.00416667, 0.00763889, 0.01458333,\n       0.00902778, 0.01597222, 0.03055556, 0.03472222, 0.05694444,\n       0.09027778, 0.13402778, 0.18611111, 0.15347222, 0.17569444])\n\n\nWe can compare the runtimes of compmemlearn’s and psifr’s functions using the %%timeit Jupyter magic:\n\n%%timeit\nfast_pfr(trials, list_length)\n\n3.88 µs ± 87.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n\n\n\n%%timeit\nfr.pnr(events)\n\n530 ms ± 4.66 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\nOur fast implementation is more than 100,000 times faster!"
  },
  {
    "objectID": "library\\analyses\\Probability_of_First_Recall.html#plotting",
    "href": "library\\analyses\\Probability_of_First_Recall.html#plotting",
    "title": "compmemlearn",
    "section": "Plotting",
    "text": "psifr’s plotting library creates a separate figure for each plot, when sometimes we want to to include multiple plots in one figure, so we define our own.\n# export\nimport seaborn as sns\nfrom psifr import fr\n\n\ndef plot_pfr(data, **facet_kws):\n\n    pfr_data = fr.pnr(data).query(\"output <= 1\")\n\n    sns.lineplot(data=pfr_data, x=\"input\", y=\"prob\", **facet_kws)\n\nsns.set_theme(style=\"darkgrid\")\n\ng = sns.FacetGrid(dropna=False, data=events, height=4, aspect=1.2)\ng.map_dataframe(plot_pfr, err_style=\"bars\")\n\ng.set_xlabels(\"Study Position\")\ng.set_ylabels(\"Probability of First Recall\")"
  },
  {
    "objectID": "library\\analyses\\Probability_of_First_Recall_in_Repetition_Data.html#data-preparation",
    "href": "library\\analyses\\Probability_of_First_Recall_in_Repetition_Data.html#data-preparation",
    "title": "compmemlearn",
    "section": "Data Preparation",
    "text": "from compmemlearn.datasets import prepare_lohnas2014_data\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')\n\nevents.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n      condition\n    \n  \n  \n    \n      0\n      1\n      1\n      0\n      1\n      1.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      1\n      1\n      1\n      1\n      2\n      2.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      2\n      1\n      1\n      2\n      3\n      3.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      3\n      1\n      1\n      3\n      4\n      4.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      4\n      1\n      1\n      4\n      5\n      5.0\n      True\n      True\n      0\n      False\n      4"
  },
  {
    "objectID": "library\\analyses\\Probability_of_First_Recall_in_Repetition_Data.html#function",
    "href": "library\\analyses\\Probability_of_First_Recall_in_Repetition_Data.html#function",
    "title": "compmemlearn",
    "section": "Function",
    "text": "from compmemlearn.analyses import recall_by_second_study_position\nfrom compmemlearn.analyses import recall_by_all_study_positions\n# export\n\nfrom numba import njit\nimport numpy as np\nfrom numba import int32\n\n@njit(nogil=True)\ndef fast_mixed_pfr(trials, presentations):\n    \n    list_length = len(presentations[0])\n    result = np.zeros(list_length, dtype=int32)\n    alt_trials = recall_by_second_study_position(trials, presentations)\n    first_recalls = np.hstack((trials[:, :1], alt_trials[:, :1]))\n    \n    for trial_index in range(len(trials)):\n        for i in range(list_length):\n            result[i] += i+1 in first_recalls[trial_index]\n    \n    return result/len(trials)\n\n@njit(nogil=True)\ndef flex_mixed_pfr(trials, presentations):\n    \n    list_length = len(presentations[0])\n    result = np.zeros(list_length, dtype=int32)\n    all_study_positions = recall_by_all_study_positions(trials, presentations) \n    first_recalls = all_study_positions[:, :, :1]\n    \n    for trial_index in range(len(trials)):\n        for i in range(list_length):\n            result[i] += i+1 in first_recalls[:, trial_index]\n    \n    return result/len(trials)"
  },
  {
    "objectID": "library\\analyses\\Probability_of_First_Recall_in_Repetition_Data.html#demo",
    "href": "library\\analyses\\Probability_of_First_Recall_in_Repetition_Data.html#demo",
    "title": "compmemlearn",
    "section": "Demo",
    "text": "fast_mixed_pfr(trials[list_types==1], presentations[list_types==1])\n\narray([0.21666667, 0.06190476, 0.03333333, 0.04047619, 0.00952381,\n       0.01666667, 0.        , 0.02142857, 0.01190476, 0.01190476,\n       0.01428571, 0.01428571, 0.0047619 , 0.00714286, 0.00952381,\n       0.00238095, 0.00952381, 0.01190476, 0.0047619 , 0.00952381,\n       0.0047619 , 0.01428571, 0.00952381, 0.00714286, 0.01190476,\n       0.01190476, 0.00952381, 0.02142857, 0.01428571, 0.01190476,\n       0.02619048, 0.01190476, 0.01428571, 0.01904762, 0.01190476,\n       0.03571429, 0.05238095, 0.06190476, 0.06428571, 0.07380952])\n\n\n\nflex_mixed_pfr(trials[list_types==1], presentations[list_types==1])\n\narray([0.21666667, 0.06190476, 0.03333333, 0.04047619, 0.00952381,\n       0.01666667, 0.        , 0.02142857, 0.01190476, 0.01190476,\n       0.01428571, 0.01428571, 0.0047619 , 0.00714286, 0.00952381,\n       0.00238095, 0.00952381, 0.01190476, 0.0047619 , 0.00952381,\n       0.0047619 , 0.01428571, 0.00952381, 0.00714286, 0.01190476,\n       0.01190476, 0.00952381, 0.02142857, 0.01428571, 0.01190476,\n       0.02619048, 0.01190476, 0.01428571, 0.01904762, 0.01190476,\n       0.03571429, 0.05238095, 0.06190476, 0.06428571, 0.07380952])\n\n\n\nfast_mixed_pfr(trials[list_types==2], presentations[list_types==2])\n\narray([0.34761905, 0.34761905, 0.06904762, 0.06904762, 0.0452381 ,\n       0.0452381 , 0.03333333, 0.03333333, 0.01666667, 0.01666667,\n       0.01666667, 0.01666667, 0.01428571, 0.01428571, 0.01666667,\n       0.01666667, 0.01190476, 0.01190476, 0.02380952, 0.02380952,\n       0.01666667, 0.01666667, 0.01904762, 0.01904762, 0.02142857,\n       0.02142857, 0.02619048, 0.02619048, 0.03333333, 0.03333333,\n       0.03095238, 0.03095238, 0.04047619, 0.04047619, 0.04285714,\n       0.04285714, 0.06904762, 0.06904762, 0.1       , 0.1       ])\n\n\n\nflex_mixed_pfr(trials[list_types==2], presentations[list_types==2])\n\narray([0.34761905, 0.34761905, 0.06904762, 0.06904762, 0.0452381 ,\n       0.0452381 , 0.03333333, 0.03333333, 0.01666667, 0.01666667,\n       0.01666667, 0.01666667, 0.01428571, 0.01428571, 0.01666667,\n       0.01666667, 0.01190476, 0.01190476, 0.02380952, 0.02380952,\n       0.01666667, 0.01666667, 0.01904762, 0.01904762, 0.02142857,\n       0.02142857, 0.02619048, 0.02619048, 0.03333333, 0.03333333,\n       0.03095238, 0.03095238, 0.04047619, 0.04047619, 0.04285714,\n       0.04285714, 0.06904762, 0.06904762, 0.1       , 0.1       ])\n\n\n\nfast_mixed_pfr(trials[list_types==3], presentations[list_types==3])\n\narray([0.24285714, 0.06428571, 0.05      , 0.06428571, 0.09285714,\n       0.06428571, 0.04047619, 0.04285714, 0.0547619 , 0.05238095,\n       0.03333333, 0.01904762, 0.02380952, 0.01666667, 0.03095238,\n       0.03809524, 0.01428571, 0.00714286, 0.01904762, 0.02857143,\n       0.01428571, 0.02857143, 0.01428571, 0.02619048, 0.02142857,\n       0.01666667, 0.02619048, 0.02142857, 0.0452381 , 0.03809524,\n       0.0452381 , 0.03095238, 0.05      , 0.0547619 , 0.07142857,\n       0.09285714, 0.06666667, 0.11428571, 0.0952381 , 0.09761905])\n\n\n\nfast_mixed_pfr(trials[list_types==4], presentations[list_types==4])\n\narray([0.21190476, 0.04285714, 0.05      , 0.02142857, 0.02857143,\n       0.02857143, 0.01904762, 0.01666667, 0.01666667, 0.02619048,\n       0.01666667, 0.03809524, 0.02380952, 0.02619048, 0.01428571,\n       0.01190476, 0.01190476, 0.01666667, 0.01428571, 0.00952381,\n       0.01666667, 0.02142857, 0.0047619 , 0.00952381, 0.01666667,\n       0.02142857, 0.00952381, 0.03095238, 0.03333333, 0.01428571,\n       0.02142857, 0.02380952, 0.02857143, 0.03571429, 0.02857143,\n       0.04761905, 0.03333333, 0.05714286, 0.04047619, 0.04285714])"
  },
  {
    "objectID": "library\\analyses\\Recall_Probability_by_Spacing.html#data-preparation",
    "href": "library\\analyses\\Recall_Probability_by_Spacing.html#data-preparation",
    "title": "compmemlearn",
    "section": "Data Preparation",
    "text": "from compmemlearn.datasets import prepare_lohnas2014_data\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')\n\nevents.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n      condition\n    \n  \n  \n    \n      0\n      1\n      1\n      0\n      1\n      1.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      1\n      1\n      1\n      1\n      2\n      2.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      2\n      1\n      1\n      2\n      3\n      3.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      3\n      1\n      1\n      3\n      4\n      4.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      4\n      1\n      1\n      4\n      5\n      5.0\n      True\n      True\n      0\n      False\n      4"
  },
  {
    "objectID": "library\\analyses\\Recall_Probability_by_Spacing.html#analysis",
    "href": "library\\analyses\\Recall_Probability_by_Spacing.html#analysis",
    "title": "compmemlearn",
    "section": "Analysis",
    "text": "We optimize this with numba (and some creative Python) to speed up the calculation.\n\nFast Array Generation\nDataFrames contain granular subject-by-subject information and are easier to plot using the seaborn library. But sometimes we don’t need this granular information and mainly want to perform our analysis as quickly as possible – perhaps to help with model fitting or analysis. In that case, representing results with numpy arrays and performing just-in-time compilation of our function using numba might be preferred. We include analyses.fast_rpl in our library for that purpose here.\nThe function assumes items are repeated up to 2 times.\n# export\n\nfrom numba import njit, prange\nimport numpy as np\n\n@njit(nogil=True, parallel=True)\ndef fast_rpl(study_positions_in_recall_order, presentations, max_lag=8):\n    \n    assert(len(presentations) == len(study_positions_in_recall_order))\n\n    total_presented, total_retrieved = np.zeros(max_lag+2), np.zeros(max_lag+2)\n\n    for trial_index in prange(len(presentations)):\n        presented, retrieved = np.zeros(max_lag+2), np.zeros(max_lag+2)\n        trial = study_positions_in_recall_order[trial_index]\n        trial = trial[trial > 0]-1\n        \n        for item in np.unique(presentations[trial_index]):\n            for idx, val in np.ndenumerate(presentations[trial_index]):\n                if val == item:\n                    locationA = idx[0]\n                    break\n\n            lag = 0\n            if locationA < len(presentations[trial_index]):\n                for idx, val in np.ndenumerate(presentations[trial_index][locationA+1:]):\n                    if val == item:\n                        lag = 1 + idx[0]\n                        break\n\n            presented[lag] += 1\n            retrieved[lag] += locationA in trial\n            \n        total_presented += presented\n        total_retrieved += retrieved\n\n    return total_retrieved/total_presented\n\ncondition = 4\n\nresult = fast_rpl(\n    trials[list_types>=condition], presentations[list_types>=condition], max_lag=8)\n\n# lohnas 2014 bins result by N/A, 0, 1-2, 3-5, and 6-8 number of intervening items\nbinned = np.zeros(5)\nbinned[0] = result[0]\nbinned[1] = result[1]\nbinned[2] = (result[2] + result[3])/2\nbinned[3] = (result[4] + result[5] + result[6])/3\nbinned[4] = (result[7] + result[8] + result[9])/3\nprint(binned)\n\n[0.37278912 0.43928571 0.47678571 0.55714286 0.57857143]\n\n\n\n%%timeit\nfast_rpl(presentations, trials, max_lag=8)\n\n2.74 ms ± 253 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n\nDataFrame\nThe psifr library doesn’t have a function to generate pandas DataFrames containing conditional stop probability information, so we make our own. For efficiency, it mainly consists of calls to fast_rpl. Since we normally compare our analyses with the results from Lohnas & Kahana (2014), we’ll automatically bin results between ['N/A', '0', '1-2', '3-5', '6-8'] even though fast_rpl provides more granular information.\n# export\n\nimport pandas as pd\n\ndef rpl(presentations, trials, subjects, trial_count, list_length, max_lag=8):\n    #subjects = len(np.unique(events.subject))\n    #trial_count = np.max(events.list)\n    #list_length = np.max(events.input)\n    #lags = ['N/A'] + list(range(max_lag+1))\n    lags = ['N/A', '0', '1-2', '3-5', '6-8']\n    \n    result = {'subject': [], 'lag': [], 'prob': []}\n    \n    for subject in range(subjects):\n\n        subject_result = fast_rpl(\n            trials[subject*trial_count:(subject+1)*trial_count], presentations[subject*trial_count:(subject+1)*trial_count], max_lag)\n        \n        binned = np.zeros(5)\n        binned[0] = subject_result[0]\n        binned[1] = subject_result[1]\n        binned[2] = (subject_result[2] + subject_result[3])/2\n        binned[3] = (subject_result[4] + subject_result[5] + subject_result[6])/3\n        binned[4] = (subject_result[7] + subject_result[8] + subject_result[9])/3\n\n        result['subject'] += [subject+1]*len(lags)\n        result['lag'] += lags\n        result['prob'] += binned.tolist()\n        \n    return pd.DataFrame(result)"
  },
  {
    "objectID": "library\\analyses\\Recall_Probability_by_Spacing.html#plotting-demo",
    "href": "library\\analyses\\Recall_Probability_by_Spacing.html#plotting-demo",
    "title": "compmemlearn",
    "section": "Plotting Demo",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\n\ncondition = 4\nsource = 'Lohnas & Kahana (2014)'\n\nsubject_count = len(np.unique(events.subject))\ntrial_count = int(np.max(events.list)/4)\n\ndata = rpl(\n    presentations[list_types>=4], trials[list_types>=4], \n    subject_count, trial_count, list_length)\n\nsns.barplot(data=data, x='lag', y='prob')\n\nplt.title('Condition {}, {}'.format(condition, source))\nplt.xlabel('Number of Intervening Items Between Repetitions')\nplt.ylabel('Recall Probability')\n\nText(0, 0.5, 'Recall Probability')"
  },
  {
    "objectID": "library\\analyses\\Serial_Position_Effect.html#data-preparation",
    "href": "library\\analyses\\Serial_Position_Effect.html#data-preparation",
    "title": "compmemlearn",
    "section": "Data Preparation",
    "text": "For our demonstrations, we’ll lean on the MurdockOkada1970 dataset. As a reminder, in this dataset each of 72 undergraduates was given 20 test lists with 20-word lists visually presented at either 60 or 120 words/min.\n\nfrom compmemlearn.datasets import prepare_murdock1970_data\n\ntrials, events, list_length = prepare_murdock1970_data('../../data/mo1970.txt')\nevents.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n    \n  \n  \n    \n      0\n      1\n      1\n      1\n      1\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      1\n      1\n      1\n      2\n      2\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      2\n      1\n      1\n      3\n      3\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      3\n      1\n      1\n      4\n      4\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      4\n      1\n      1\n      5\n      5\n      NaN\n      True\n      False\n      0\n      False"
  },
  {
    "objectID": "library\\analyses\\Serial_Position_Effect.html#analysis",
    "href": "library\\analyses\\Serial_Position_Effect.html#analysis",
    "title": "compmemlearn",
    "section": "Analysis",
    "text": "DataFrame\nWe can usually rely on the psifr library to generate pandas DataFrames containing serial position curve information.\n\nfrom psifr import fr\n\nspc = fr.spc(events)\nspc \n\n\n\n\n  \n    \n      \n      \n      recall\n    \n    \n      subject\n      input\n      \n    \n  \n  \n    \n      1\n      1\n      0.40\n    \n    \n      2\n      0.10\n    \n    \n      3\n      0.25\n    \n    \n      4\n      0.30\n    \n    \n      5\n      0.10\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      72\n      16\n      0.20\n    \n    \n      17\n      0.80\n    \n    \n      18\n      0.85\n    \n    \n      19\n      0.95\n    \n    \n      20\n      1.00\n    \n  \n\n1440 rows × 1 columns\n\n\n\n\n\nFast Array Generation\nDataFrames contain granular subject-by-subject information and are easier to plot using the seaborn library. But sometimes we don’t need this granular information and mainly want to perform our analysis as quickly as possible – perhaps to help with model fitting or analysis. In that case, representing results with numpy arrays and performing just-in-time compilation of our function using numba might be preferred. We include analyses.fast_spc in our library for that purpose here.\n# export\n\nfrom numba import njit\nimport numpy as np\n\n@njit(nogil=True)\ndef fast_spc(trials, item_count):\n    return np.bincount(trials.flatten(), minlength=item_count+1)[1:]/len(trials)\n\nfast_spc(trials, 20)\n\narray([0.44305556, 0.29097222, 0.22222222, 0.18958333, 0.13888889,\n       0.15694444, 0.15486111, 0.14097222, 0.16041667, 0.18958333,\n       0.15347222, 0.1875    , 0.21875   , 0.25347222, 0.27847222,\n       0.3125    , 0.39722222, 0.5875    , 0.68819444, 0.7875    ])\n\n\nWe can compare the runtimes of compmemlearn’s analyses.fast_spc and psifr’s fr.spc using the %%timeit Jupyter magic:\n\n%%timeit\nfast_spc(trials, 20)\n\n34.5 µs ± 1.04 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n\n\n\n%%timeit\nfr.spc(events)\n\n5.14 ms ± 134 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\nOur fast implementation is more than 100 times faster!"
  },
  {
    "objectID": "library\\analyses\\Serial_Position_Effect.html#plotting",
    "href": "library\\analyses\\Serial_Position_Effect.html#plotting",
    "title": "compmemlearn",
    "section": "Plotting",
    "text": "psifr’s plotting library creates a separate figure for each plot, when sometimes we want to to include multiple plots in one figure, so we define our own.\n# export\nfrom psifr import fr\nimport seaborn as sns\n\ndef plot_spc(data, **facet_kws):\n    \n    sns.lineplot(\n        data=fr.spc(data), x='input', y='recall', **facet_kws)\n\nsns.set_theme()\ng = sns.FacetGrid(dropna=False, data=events, aspect=1.5)\ng.map_dataframe(plot_spc, err_style='bars')\ng.set_xlabels('Study Position')\ng.set_ylabels('Recall Rate')\ng.set(ylim=(0, 1));"
  },
  {
    "objectID": "library\\analyses\\Serial_Position_Effect_in_Repetition_Datasets.html#data-preparation",
    "href": "library\\analyses\\Serial_Position_Effect_in_Repetition_Datasets.html#data-preparation",
    "title": "compmemlearn",
    "section": "Data Preparation",
    "text": "from compmemlearn.datasets import prepare_lohnas2014_data\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')\n\nevents.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n      condition\n    \n  \n  \n    \n      0\n      1\n      1\n      0\n      1\n      1.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      1\n      1\n      1\n      1\n      2\n      2.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      2\n      1\n      1\n      2\n      3\n      3.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      3\n      1\n      1\n      3\n      4\n      4.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      4\n      1\n      1\n      4\n      5\n      5.0\n      True\n      True\n      0\n      False\n      4"
  },
  {
    "objectID": "library\\analyses\\Serial_Position_Effect_in_Repetition_Datasets.html#functions",
    "href": "library\\analyses\\Serial_Position_Effect_in_Repetition_Datasets.html#functions",
    "title": "compmemlearn",
    "section": "Functions",
    "text": "Tracking the Study Positions of Repeatedly Presented Items\n# export\n\nfrom numba import njit, prange\nimport numpy as np\nfrom numba import int32\nfrom compmemlearn.datasets import find_first\n\n@njit(nogil=True)\ndef recall_by_second_study_position(trials, presentations):\n    \n    flipped_presentations = np.fliplr(presentations)\n    list_length = len(presentations[0])\n    result = np.zeros(np.shape(trials), dtype=int32)\n    \n    for trial_index in range(len(trials)):\n        \n        trial = trials[trial_index]\n        presentation = presentations[trial_index]\n        flipped_presentation = flipped_presentations[trial_index]\n        \n        for recall_index in range(len(trial)):\n            \n            if trial[recall_index] == 0:\n                continue\n                \n            item_index = presentation[trial[recall_index]-1]\n            result[trial_index, recall_index] = list_length - find_first(\n                item_index, flipped_presentation)\n        \n    return result\n\n@njit(nogil=True)\ndef recall_by_all_study_positions(recall_by_first_study_position, presentations, max_repeats=3):\n    \n    trials_shape = np.shape(recall_by_first_study_position)\n    result = np.zeros(\n            (max_repeats, trials_shape[0], trials_shape[1]), dtype=int32)\n\n    for trial_index in range(len(recall_by_first_study_position)):\n\n        trial = recall_by_first_study_position[trial_index]\n        presentation = presentations[trial_index]\n        \n        for recall_index in range(len(trial)):\n\n            if trial[recall_index] == 0:\n                continue\n\n            presentation_positions = np.nonzero(\n                presentation[trial[recall_index] - 1] == presentation)[0] + 1\n\n            result[:len(presentation_positions), trial_index, recall_index] = presentation_positions\n\n    return result\n\nrecall_by_all_study_positions(trials, presentations, 2)[1, 0]\n\narray([ 0,  0,  0,  0,  0,  0,  0,  0, 19,  0,  0,  0, 13,  0, 31,  0, 34,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0])\n\n\n\n%timeit recall_by_all_study_positions(trials, presentations)\n\n6.55 ms ± 231 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\nrecall_by_second_study_position(trials, presentations)[0]\n\narray([ 1,  2,  3,  4,  5,  6,  7,  9, 19, 11, 17, 14, 13, 15, 31, 20, 34,\n       30, 39, 38, 37, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0])\n\n\n\n%timeit recall_by_second_study_position(trials, presentations)\n\n488 µs ± 3.19 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n\n\n\n\nFast Serial Position Curve\n# export\n\n@njit(nogil=True)\ndef fast_mixed_spc(trials, presentations):\n    \n    list_length = len(presentations[0])\n    result = np.zeros(list_length, dtype=int32)\n    alt_trials = recall_by_second_study_position(trials, presentations)\n    trials = np.hstack((trials, alt_trials))\n    \n    for trial_index in range(len(trials)):\n        for study_position in range(list_length):\n            result[study_position] += study_position+1 in trials[trial_index]\n    \n    return result/len(trials)\n\n\n@njit(nogil=True)\ndef flex_mixed_spc(trials, presentations):\n    \n    list_length = len(presentations[0])\n    result = np.zeros(list_length, dtype=int32)\n    all_study_positions = recall_by_all_study_positions(trials, presentations) \n    \n    for trial_index in range(len(trials)):\n        for study_position in range(list_length):\n            result[study_position] += study_position+1 in all_study_positions[:,trial_index]\n    \n    return result/len(trials)"
  },
  {
    "objectID": "library\\analyses\\Serial_Position_Effect_in_Repetition_Datasets.html#demo",
    "href": "library\\analyses\\Serial_Position_Effect_in_Repetition_Datasets.html#demo",
    "title": "compmemlearn",
    "section": "Demo",
    "text": "fast_mixed_spc(trials[list_types==2], presentations[list_types==2])\n\narray([0.79761905, 0.79761905, 0.72380952, 0.72380952, 0.65      ,\n       0.65      , 0.62857143, 0.62857143, 0.6047619 , 0.6047619 ,\n       0.57857143, 0.57857143, 0.55714286, 0.55714286, 0.56666667,\n       0.56666667, 0.54285714, 0.54285714, 0.56190476, 0.56190476,\n       0.55952381, 0.55952381, 0.55952381, 0.55952381, 0.55238095,\n       0.55238095, 0.54761905, 0.54761905, 0.56904762, 0.56904762,\n       0.56190476, 0.56190476, 0.6047619 , 0.6047619 , 0.59285714,\n       0.59285714, 0.5952381 , 0.5952381 , 0.59285714, 0.59285714])\n\n\n\nflex_mixed_spc(trials[list_types==2], presentations[list_types==2])\n\narray([0.79761905, 0.79761905, 0.72380952, 0.72380952, 0.65      ,\n       0.65      , 0.62857143, 0.62857143, 0.6047619 , 0.6047619 ,\n       0.57857143, 0.57857143, 0.55714286, 0.55714286, 0.56666667,\n       0.56666667, 0.54285714, 0.54285714, 0.56190476, 0.56190476,\n       0.55952381, 0.55952381, 0.55952381, 0.55952381, 0.55238095,\n       0.55238095, 0.54761905, 0.54761905, 0.56904762, 0.56904762,\n       0.56190476, 0.56190476, 0.6047619 , 0.6047619 , 0.59285714,\n       0.59285714, 0.5952381 , 0.5952381 , 0.59285714, 0.59285714])\n\n\n\nfast_mixed_spc(trials[list_types==1], presentations[list_types==1])\n\narray([0.64285714, 0.56904762, 0.5047619 , 0.45238095, 0.40952381,\n       0.38571429, 0.35      , 0.33571429, 0.33571429, 0.3       ,\n       0.32380952, 0.32619048, 0.32619048, 0.32380952, 0.29761905,\n       0.31190476, 0.32380952, 0.29761905, 0.27857143, 0.27142857,\n       0.29047619, 0.28333333, 0.27857143, 0.32857143, 0.28095238,\n       0.33095238, 0.32857143, 0.31666667, 0.32619048, 0.33809524,\n       0.37380952, 0.32380952, 0.36190476, 0.34047619, 0.35952381,\n       0.37619048, 0.39047619, 0.42380952, 0.41428571, 0.3452381 ])\n\n\n\nflex_mixed_spc(trials[list_types==1], presentations[list_types==1])\n\narray([0.64285714, 0.56904762, 0.5047619 , 0.45238095, 0.40952381,\n       0.38571429, 0.35      , 0.33571429, 0.33571429, 0.3       ,\n       0.32380952, 0.32619048, 0.32619048, 0.32380952, 0.29761905,\n       0.31190476, 0.32380952, 0.29761905, 0.27857143, 0.27142857,\n       0.29047619, 0.28333333, 0.27857143, 0.32857143, 0.28095238,\n       0.33095238, 0.32857143, 0.31666667, 0.32619048, 0.33809524,\n       0.37380952, 0.32380952, 0.36190476, 0.34047619, 0.35952381,\n       0.37619048, 0.39047619, 0.42380952, 0.41428571, 0.3452381 ])\n\n\n\nfast_mixed_spc(trials[list_types==3], presentations[list_types==3])\n\narray([0.75714286, 0.70952381, 0.68809524, 0.66666667, 0.66428571,\n       0.6952381 , 0.67380952, 0.67619048, 0.64761905, 0.64761905,\n       0.63809524, 0.59761905, 0.62857143, 0.5952381 , 0.64285714,\n       0.56904762, 0.6047619 , 0.59285714, 0.58571429, 0.6047619 ,\n       0.55238095, 0.56904762, 0.57380952, 0.55238095, 0.61190476,\n       0.56666667, 0.6047619 , 0.61190476, 0.62142857, 0.61666667,\n       0.6452381 , 0.62380952, 0.61666667, 0.65714286, 0.66666667,\n       0.68333333, 0.6952381 , 0.68571429, 0.67142857, 0.67857143])\n\n\n\nfast_mixed_spc(trials[list_types==4], presentations[list_types==4])\n\narray([0.63809524, 0.5452381 , 0.46666667, 0.43333333, 0.4547619 ,\n       0.41666667, 0.42142857, 0.42619048, 0.40714286, 0.4       ,\n       0.40714286, 0.43333333, 0.44285714, 0.43333333, 0.44285714,\n       0.40238095, 0.40238095, 0.43809524, 0.41666667, 0.42857143,\n       0.36190476, 0.38809524, 0.36904762, 0.38333333, 0.42142857,\n       0.40714286, 0.42619048, 0.39761905, 0.42619048, 0.39285714,\n       0.39285714, 0.41666667, 0.42142857, 0.44761905, 0.42619048,\n       0.43095238, 0.40714286, 0.37142857, 0.38333333, 0.30952381])\n\n\n\nfrom compmemlearn.analyses import fast_spc\n\n%timeit fast_spc(trials[list_types==1], list_length)\n\n53.8 µs ± 19.8 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\n%timeit fast_mixed_spc(trials[list_types==1], presentations[list_types==1])\n\n1.13 ms ± 3.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n\n\n\n%timeit flex_mixed_spc(trials[list_types==1], presentations[list_types==1])\n\n4.26 ms ± 134 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)"
  },
  {
    "objectID": "library\\analyses\\Shared_Contiguity.html#data-preparation",
    "href": "library\\analyses\\Shared_Contiguity.html#data-preparation",
    "title": "compmemlearn",
    "section": "Data Preparation",
    "text": "from compmemlearn.datasets import prepare_lohnas2014_data\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')\n\nevents.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n      condition\n    \n  \n  \n    \n      0\n      1\n      1\n      0\n      1\n      1.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      1\n      1\n      1\n      1\n      2\n      2.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      2\n      1\n      1\n      2\n      3\n      3.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      3\n      1\n      1\n      3\n      4\n      4.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      4\n      1\n      1\n      4\n      5\n      5.0\n      True\n      True\n      0\n      False\n      4"
  },
  {
    "objectID": "library\\analyses\\Shared_Contiguity.html#functions",
    "href": "library\\analyses\\Shared_Contiguity.html#functions",
    "title": "compmemlearn",
    "section": "Functions",
    "text": "def shared_contiguity(trials, presentations, max_repeats=2, min_lag=4):\n    \n    list_length = len(presentations[0])\n    total_transitions = 0\n    complementary_transitions = 0\n    terminus = np.sum(trials != 0, axis=1) - 1 # number of recalls per trial\n    \n    for trial_index in range(len(trials)):\n        \n        item_count = np.max(presentations[trial_index]) + 1\n        si = np.zeros((item_count, 2), dtype=int)\n        sj = np.zeros((item_count, 2), dtype=int)\n        \n        # we track possible positions using presentations and alt_presentations\n        for item in range(item_count):\n            pos = np.nonzero(presentations[trial_index] == item)[0]\n            \n            # then we track Si and Sj by identifying repeated items and storing item indices\n            if (len(pos) > 1) and (pos[1] - pos[0] >= min_lag):\n                \n                assert np.all(pos < list_length - 2) # bounds issues don't affect result in this case - might later\n                si[item, :] = presentations[trial_index, pos[0]+1:pos[0]+3] + 1\n                sj[item, :] = presentations[trial_index, pos[1]+1:pos[1]+3] + 1\n            \n        # i can track at each recall index whether si or sj was seen, \n        for recall_index in range(terminus[trial_index]):\n            \n            current_item = presentations[trial_index][trials[trial_index, recall_index]-1] + 1\n            next_item = presentations[trial_index][trials[trial_index, recall_index+1]-1] + 1\n            \n            # then peek at whether the next item was in complementary set, \n            # aggregating totals with each comparison\n            for si_match in np.nonzero(si == current_item)[0]:\n                complementary_transitions += next_item in sj[si_match]\n            for sj_match in np.nonzero(sj == current_item)[0]:\n                complementary_transitions += next_item in si[sj_match]\n \n            total_transitions += 1\n            \n    return complementary_transitions/total_transitions\nIt looks like there are two remaining things to clarify:\nFirst I have to figure out whether and how to track whether it’s possible to make a transition to si or sj.\nNext I have to figure out how often to increment total transitions.\n\nshared_contiguity(trials[list_types == 4], presentations[list_types == 4], 2, 4)\n\n0.0391566265060241"
  },
  {
    "objectID": "library\\datasets\\ClairExpt6.html#data-overview",
    "href": "library\\datasets\\ClairExpt6.html#data-overview",
    "title": "compmemlearn",
    "section": "Data Overview",
    "text": "import numpy as np\nfrom numba import njit, prange\nfrom compmemlearn.models import Classic_CMR\nfrom numba.typed import Dict\nfrom numba.core import types\n\n@njit(fastmath=True, nogil=True, parallel=True)\ndef lohnas_data_likelihood(trials, presentations, model_class, parameters):\n\n    list_length = len(presentations[0])\n    likelihood = np.ones((len(trials), list_length))\n\n    for trial_index in prange(len(trials)):\n\n        item_count = np.max(presentations[trial_index])\n        trial = trials[trial_index]\n        model = model_class(item_count, list_length, parameters)\n        presentation = presentations[trial_index][presentations[trial_index] > 0] -1 ## modify to support odd indexing\n        model.experience(model.items[presentation])\n\n        model.force_recall()\n        for recall_index in range(len(trial) + 1):\n\n            # identify index of item recalled; if zero then recall is over\n            if recall_index == len(trial) and len(trial) < item_count:\n                recall = 0\n            elif trial[recall_index] == 0:\n                recall = 0\n            else:\n                recall = presentation[trial[recall_index]-1] + 1\n\n            # store probability of and simulate recalling item with this index\n            likelihood[trial_index, recall_index] = \\\n                model.outcome_probabilities()[recall] + 10e-7\n\n            if recall == 0:\n                break\n            model.force_recall(recall)\n\n        # reset model to its pre-retrieval (but post-encoding) state\n        model.force_recall(0)\n\n    return -np.sum(np.log(likelihood))\n\ndef lohnas_objective_function(data_to_fit, presentations, model_class, fixed_parameters, free_parameters):\n\n    \"\"\"\n    Generates and returns an objective function for input to support search \n    through parameter space for model fit using an optimization function.\n\n    Returns a function that accepts a vector x specifying arbitrary values for \n    free parameters and returns evaluation of likelihood using the model \n    class, all parameters, and provided data.\n    \"\"\"\n\n    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n    for name, value in fixed_parameters.items():\n        parameters[name] = value\n\n    def objective_function(x):\n        for i in range(len(free_parameters)):\n            parameters[free_parameters[i]] = x[i]\n        return lohnas_data_likelihood(data_to_fit, presentations, model_class, parameters)\n\n    return objective_function"
  },
  {
    "objectID": "library\\datasets\\ClairExpt6.html#condition-wise-fitting",
    "href": "library\\datasets\\ClairExpt6.html#condition-wise-fitting",
    "title": "compmemlearn",
    "section": "Condition-Wise Fitting",
    "text": "cmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ncmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n]\n\nconditions = ['Control', 'RP']\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\ncmr_results = []\nfor condition in [0, 1]:\n    selection = list_types == condition\n    cost_function = lohnas_objective_function(\n        trials[selection], \n        presentations[selection],\n        init_cmr,\n        {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0, 'delay_drift_rate': 0}, \n        cmr_free_parameters)\n\n    cmr_results.append(differential_evolution(cost_function, cmr_bounds, disp=True))\n\ndifferential_evolution step 1: f(x)= 5050.66\ndifferential_evolution step 2: f(x)= 3739.1\ndifferential_evolution step 3: f(x)= 3280.2\ndifferential_evolution step 4: f(x)= 3280.2\ndifferential_evolution step 5: f(x)= 3158.42\ndifferential_evolution step 6: f(x)= 3158.42\ndifferential_evolution step 7: f(x)= 3133.04\ndifferential_evolution step 8: f(x)= 3122.74\ndifferential_evolution step 9: f(x)= 3122.74\ndifferential_evolution step 10: f(x)= 3114.31\ndifferential_evolution step 11: f(x)= 3114.31\ndifferential_evolution step 12: f(x)= 3106.81\ndifferential_evolution step 13: f(x)= 3106.81\ndifferential_evolution step 14: f(x)= 3106.81\ndifferential_evolution step 15: f(x)= 3103.33\ndifferential_evolution step 16: f(x)= 3083.54\ndifferential_evolution step 17: f(x)= 3042.02\ndifferential_evolution step 18: f(x)= 3042.02\ndifferential_evolution step 19: f(x)= 3033.52\ndifferential_evolution step 20: f(x)= 3007.12\ndifferential_evolution step 21: f(x)= 3007.12\ndifferential_evolution step 22: f(x)= 3007.12\ndifferential_evolution step 23: f(x)= 3007.12\ndifferential_evolution step 24: f(x)= 3007.12\ndifferential_evolution step 25: f(x)= 3007.12\ndifferential_evolution step 26: f(x)= 3007.12\ndifferential_evolution step 27: f(x)= 3007.12\ndifferential_evolution step 28: f(x)= 3007.12\ndifferential_evolution step 29: f(x)= 3002.45\ndifferential_evolution step 30: f(x)= 3002.45\ndifferential_evolution step 31: f(x)= 3002.45\ndifferential_evolution step 32: f(x)= 3002.45\ndifferential_evolution step 33: f(x)= 3002.45\ndifferential_evolution step 34: f(x)= 3002.45\ndifferential_evolution step 35: f(x)= 3002.45\ndifferential_evolution step 36: f(x)= 3002.45\ndifferential_evolution step 37: f(x)= 2996.18\ndifferential_evolution step 38: f(x)= 2996.18\ndifferential_evolution step 39: f(x)= 2996.18\ndifferential_evolution step 40: f(x)= 2992.88\ndifferential_evolution step 1: f(x)= 5564.48\ndifferential_evolution step 2: f(x)= 4870.95\ndifferential_evolution step 3: f(x)= 4369.42\ndifferential_evolution step 4: f(x)= 3623.9\ndifferential_evolution step 5: f(x)= 3448.84\ndifferential_evolution step 6: f(x)= 3448.84\ndifferential_evolution step 7: f(x)= 3448.84\ndifferential_evolution step 8: f(x)= 3420.41\ndifferential_evolution step 9: f(x)= 3417.5\ndifferential_evolution step 10: f(x)= 3394.18\ndifferential_evolution step 11: f(x)= 3317.27\ndifferential_evolution step 12: f(x)= 3317.27\ndifferential_evolution step 13: f(x)= 3317.27\ndifferential_evolution step 14: f(x)= 3317.27\ndifferential_evolution step 15: f(x)= 3293.09\ndifferential_evolution step 16: f(x)= 3293.09\ndifferential_evolution step 17: f(x)= 3293.09\ndifferential_evolution step 18: f(x)= 3271.59\ndifferential_evolution step 19: f(x)= 3271.59\ndifferential_evolution step 20: f(x)= 3271.59\ndifferential_evolution step 21: f(x)= 3271.59\ndifferential_evolution step 22: f(x)= 3267.88\ndifferential_evolution step 23: f(x)= 3267.88\ndifferential_evolution step 24: f(x)= 3267.72\ndifferential_evolution step 25: f(x)= 3250.9\ndifferential_evolution step 26: f(x)= 3250.9\ndifferential_evolution step 27: f(x)= 3250.9\ndifferential_evolution step 28: f(x)= 3232.47\ndifferential_evolution step 29: f(x)= 3194.53\ndifferential_evolution step 30: f(x)= 3194.53\ndifferential_evolution step 31: f(x)= 3194.53\n\n\n\ncmr_results\n\n[     fun: 2975.134867581669\n      jac: array([-0.06730261, -0.19517756, -0.01059561,  0.04656613, -0.01514309,\n        -9.09153637,  7.70419319,  0.        ,  0.07862582, -0.03537934,\n        -0.04138201])\n  message: 'Optimization terminated successfully.'\n     nfev: 7377\n      nit: 40\n  success: True\n        x: array([6.94621761e-01, 9.00820304e-01, 8.27694497e-01, 6.29486794e-01,\n        8.02814419e-02, 1.00000000e+00, 2.22044605e-16, 6.19704899e+01,\n        4.03765537e-02, 1.29131693e-01, 5.84921887e+00]),\n      fun: 3160.6782599545445\n      jac: array([ 0.05397851, -0.10190888, -0.00568434,  0.00204636, -0.00422915,\n         0.00104592, -0.00304681,  0.01127773,  0.02678462,  0.01732587,\n        -0.00927685])\n  message: 'Optimization terminated successfully.'\n     nfev: 6900\n      nit: 31\n  success: True\n        x: array([0.77422693, 0.84571273, 0.82856235, 0.13214982, 0.88051187,\n        0.29551315, 4.76381681, 0.31516321, 0.03725594, 0.12108304,\n        1.3268154 ])]\n\n\nfrom numba import int32\n\n@njit(nogil=True)\ndef simulate_array_from_presentations(model_class, parameters, presentations, experiment_count):\n\n    # simulate retrieval for the specified number of times, tracking results in trials array\n    trials = np.zeros((experiment_count * len(presentations), np.max(presentations)), dtype=int32)\n    \n    for experiment in range(experiment_count):\n        for trial_index in range(len(presentations)):\n        \n            # retrieve presentation sequence for this trial and measure number of unique items\n            #presentation = presentations[trial_index]\n            presentation = presentations[trial_index][presentations[trial_index] > 0] -1\n            item_count = np.max(presentation)+1\n            \n            # simulate recall and identify first study position of each recalled item\n            model = model_class(item_count, len(presentation), parameters)\n            model.experience(model.items[presentation])\n            recalled = model.free_recall()\n            \n            for i in range(len(recalled)):\n                trials[experiment*len(presentations) + trial_index, i] = find_first(recalled[i], presentation) + 1\n    \n    return trials\n\n@njit(nogil=True)\ndef find_first(item, vec):\n    \"\"\"return the index of the first occurence of item in vec\"\"\"\n    for i in range(len(vec)):\n        if item == vec[i]:\n            return i\n    return -1\n# simulate data corresponding to each cmr_result\n\nfrom numba.typed import Dict\nfrom numba.core import types\nfrom numpy import matlib\n\nexperiment_count = 1000\n\nsim_trials = []\nsim_presentations = []\nfitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\n\nfor i, cmr_result in enumerate(cmr_results):\n\n    for j in range(len(cmr_result.x)):\n        fitted_parameters[cmr_free_parameters[j]] = cmr_result.x[j]\n        \n    fitted_parameters['sampling_rule'] = 0\n    fitted_parameters['mfc_familiarity_scale'] = 0\n    fitted_parameters['mcf_familiarity_scale'] = 0\n    fitted_parameters['drift_familiarity_scale'] = 0\n    fitted_parameters['delay_drift_rate'] = 0\n\n    sim_trials.append(simulate_array_from_presentations(\n        init_cmr, fitted_parameters, presentations[list_types==i], experiment_count))\n    sim_presentations.append(np.matlib.repmat(presentations[list_types==i], experiment_count, 1))\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(2):\n    \n    test_spc= flex_mixed_spc(trials[list_types==condition], presentations[list_types==condition, :-3])\n    axes[0].plot(np.arange(len(test_spc)), test_spc, label=conditions[condition])\n\n    sim_spc = flex_mixed_spc(sim_trials[condition], sim_presentations[condition][:, :-3])\n    axes[1].plot(np.arange(len(sim_spc)), sim_spc, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='Recall Rate') \nfig.suptitle(\"Serial Position Curve\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nitem_count = 25\nfor condition in range(2):\n\n    test_crp= flex_mixed_crp(trials[list_types==condition], presentations[list_types==condition, :-3])\n    test_crp[item_count-1] = np.nan\n    axes[0].plot(np.arange(len(test_crp)), test_crp, label=conditions[condition])\n\n    sim_crp = flex_mixed_crp(sim_trials[condition], sim_presentations[condition][:, :-3])\n    sim_crp[item_count-1] = np.nan\n    axes[1].plot(np.arange(len(sim_crp)), sim_crp, label=conditions[condition])\n\n#plt.xlabel('Lag')\n#plt.ylabel('Conditional Response Probability')   \naxes[0].set_xticks(np.arange(0, len(test_crp), 4))\naxes[0].set_xticklabels(np.arange(0, len(test_crp), 4) - (item_count - 1))\naxes[1].set_xticks(np.arange(0, len(sim_crp), 4))\naxes[1].set_xticklabels(np.arange(0, len(sim_crp), 4) - (item_count - 1))\nfig.suptitle('Lag-CRP')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(2):\n\n    test_pfr = flex_mixed_pfr(trials[list_types==condition], presentations[list_types==condition, :-3])\n    axes[0].plot(np.arange(len(test_pfr)), test_pfr, label=conditions[condition])\n\n    sim_pfr = flex_mixed_pfr(sim_trials[condition], sim_presentations[condition][:, :-3])\n    axes[1].plot(np.arange(len(sim_pfr)), sim_pfr, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='First Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='First Recall Rate') \nfig.suptitle(\"Probability of First Recall\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(2):\n    test_csp = fast_csp(trials[list_types==condition], list_length)\n    test_csp[test_csp==0] = np.nan\n    axes[0].plot(np.arange(list_length+1), test_csp, label=conditions[condition])\n\n    sim_csp = fast_csp(sim_trials[condition], list_length)\n    sim_csp[sim_csp==0] = np.nan\n    axes[1].plot(np.arange(list_length+1), sim_csp, label=conditions[condition])\n\n#plt.xlabel('Recall Position')\n#plt.ylabel('Conditional Stop Probability')\nfig.suptitle('Conditional Stop Probability')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)"
  },
  {
    "objectID": "library\\datasets\\Data_Simulation.html#demo-dependencies",
    "href": "library\\datasets\\Data_Simulation.html#demo-dependencies",
    "title": "compmemlearn",
    "section": "Demo Dependencies",
    "text": "from compmemlearn.models import Classic_CMR\nfrom compmemlearn.datasets import prepare_murdock1970_data, prepare_lohnas2014_data\nfrom compmemlearn.analyses import fast_rpl, fast_spc\nfrom scipy.optimize import differential_evolution\nfrom numba.typed import List, Dict\nfrom numba.core import types\nfrom psifr import fr\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom numba import njit\nimport numpy.matlib\n\nmurd_trials0, murd_events0, murd_length0 = prepare_murdock1970_data('../../data/mo1970.txt')\n\ncmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate'\n)\n\ncmr_result = np.array(\n    [5.84259066e-01, 4.27375824e-03, 7.21454638e-01, 8.17704509e-01,\n     1.00000000e+00, 9.88623591e-02, 9.31571732e+00, 7.54040329e+01,\n     3.14204629e-02, 3.36598109e-01, 9.99452206e+00, 9.95457387e-01])\n\nfitted_parameters = Dict.empty(\n    key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(cmr_result)):\n    fitted_parameters[cmr_free_parameters[i]] = cmr_result[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\n@njit(nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)"
  },
  {
    "objectID": "library\\datasets\\Data_Simulation.html#functions",
    "href": "library\\datasets\\Data_Simulation.html#functions",
    "title": "compmemlearn",
    "section": "Functions",
    "text": "Pure List Simulation\n# export\nimport pandas as pd\nfrom psifr import fr\nimport numpy as np\nfrom numba import int32\nfrom numba import njit\n\ndef simulate_df(model, experiment_count, first_recall_item=None):\n    \"\"\"\n    Initialize a model with specified parameters and experience sequences and \n    then populate a psifr-formatted dataframe with the outcomes of performing `free recall`. \n    \n    **Required model attributes**:\n    - item_count: specifies number of items encoded into memory\n    - context: vector representing an internal contextual state\n    - experience: adding a new trace to the memory model\n    - free_recall: function that freely recalls a given number of items or until recall stops\n    \"\"\"\n    \n    # encode items\n    model.experience(model.items)\n\n    # simulate retrieval for the specified number of times, tracking results in df\n    data = []\n    for experiment in range(experiment_count):\n        data += [[experiment, 0, 'study', i + 1, i] for i in range(model.item_count)]\n    for experiment in range(experiment_count):\n        if first_recall_item is not None:\n            model.force_recall(first_recall_item)\n        data += [[experiment, 0, 'recall', i + 1, o] for i, o in enumerate(model.free_recall())]\n    data = pd.DataFrame(data, columns=['subject', 'list', 'trial_type', 'position', 'item'])\n    merged = fr.merge_free_recall(data)\n    \n    return merged\n\nsimulate_data = simulate_df\n# export\n\n@njit(fastmath=True, nogil=True)\ndef simulate_array(model, experiment_count, first_recall_item=None):\n    \n    # encode items\n    model.experience(model.items)\n\n    # simulate retrieval for the specified number of times, tracking results in array\n    trials = np.zeros((experiment_count, len(model.items)), dtype=int32)\n    \n    for trial_index in range(len(trials)):\n        \n        recalled = model.free_recall()\n        trials[trial_index, :len(recalled)] = recalled + 1\n        \n    return trials\n\n\nImpure Lists (Possible Repetitions)\n# export\n\n@njit(nogil=True)\ndef simulate_array_from_presentations(model_class, parameters, presentations, experiment_count):\n\n    # simulate retrieval for the specified number of times, tracking results in trials array\n    trials = np.zeros((experiment_count * len(presentations), np.max(presentations)+1), dtype=int32)\n    \n    for experiment in range(experiment_count):\n        for trial_index in range(len(presentations)):\n        \n            # retrieve presentation sequence for this trial and measure number of unique items\n            presentation = presentations[trial_index]\n            item_count = np.max(presentation)+1\n            \n            # simulate recall and identify first study position of each recalled item\n            model = model_class(item_count, len(presentation), parameters)\n            model.experience(model.items[presentation])\n            recalled = model.free_recall()\n            \n            for i in range(len(recalled)):\n                trials[experiment*len(presentations) + trial_index, i] = find_first(recalled[i], presentation) + 1\n    \n    return trials\n\n@njit(nogil=True)\ndef find_first(item, vec):\n    \"\"\"return the index of the first occurence of item in vec\"\"\"\n    for i in range(len(vec)):\n        if item == vec[i]:\n            return i\n    return -1"
  },
  {
    "objectID": "library\\datasets\\Data_Simulation.html#demo",
    "href": "library\\datasets\\Data_Simulation.html#demo",
    "title": "compmemlearn",
    "section": "Demo",
    "text": "Mixed Lists: simulate_array_from_presentations\nMake sure: - presentation array is matched to trial array - mixed list trials are selected - experiment_count doesn’t disrupt alignment\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')\n\nexperiment_count = 1000\n\nfit_sources = ['lohnas_all', 'lohnas_4', 'murdock1962', 'murdock1970']\n\nfit_stats = [\n    np.array([8.65828835e-01, 2.26715503e-01, 9.52028097e-01, 2.63844603e-02,\n       1.47259363e-07, 4.31890546e-01, 2.63745217e+00, 2.98606729e+01,\n       2.51644003e-02, 1.01406301e-01, 1.02305123e+00, 9.80106784e-01]),\n    np.array([8.06135392e-01, 3.07112592e-01, 9.55038268e-01, 1.15022323e-01,\n       1.60855931e-02, 5.07853225e-01, 4.61059897e-01, 7.16087569e+01,\n       2.52322009e-02, 9.37792238e-02, 2.02696856e+00, 9.24630111e-01]),\n    np.array([5.88304182e-01, 3.76144942e-02, 7.51294302e-01, 2.91680115e-01,\n       1.00000000e+00, 1.39633721e-01, 5.62625588e+00, 4.28789782e+01,\n       2.40537436e-02, 2.61824232e-01, 5.32941045e+00, 9.34036191e-01]),\n    np.array([5.79524319e-01, 4.07083020e-03, 7.24717634e-01, 7.47425733e-01,\n       1.00000000e+00, 9.58358158e-02, 9.55947397e+00, 8.71434638e+01,\n       3.13827247e-02, 3.36754300e-01, 9.25336064e+00, 9.95710836e-01])\n]\n\nfor i in range(len(fit_sources)):\n    cmr_result = fit_stats[i]\n\n    fitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\n    for j in range(len(cmr_result)):\n        fitted_parameters[cmr_free_parameters[j]] = cmr_result[j]\n        \n    fitted_parameters['sampling_rule'] = 0\n    fitted_parameters['mfc_familiarity_scale'] = 0\n    fitted_parameters['mcf_familiarity_scale'] = 0\n    fitted_parameters['drift_familiarity_scale'] = 0\n\n    new_sim_array = simulate_array_from_presentations(init_cmr, fitted_parameters, presentations[list_types==4], experiment_count)\n    \n    result = fast_rpl(np.matlib.repmat(presentations[list_types==4], experiment_count, 1), new_sim_array)\n    binned = np.zeros(5)\n    binned[0] = result[0]\n    binned[1] = result[1]\n    binned[2] = (result[2] + result[3])/2\n    binned[3] = (result[4] + result[5] + result[6])/3\n    binned[4] = (result[7] + result[8] + result[9])/3\n    print(fit_sources[i], ':')\n    print(binned)\n    print()\n\nlohnas_all :\n[0.35386862 0.43319286 0.46776964 0.48948095 0.49651786]\n\nlohnas_4 :\n[0.35961046 0.50194643 0.53528214 0.55109286 0.55234048]\n\nmurdock1962 :\n[0.19713656 0.34533214 0.34188036 0.34759405 0.34767381]\n\nmurdock1970 :\n[0.15170502 0.26838214 0.25996429 0.25957381 0.25287619]\n\n\n\n\nfit_sources = ['lohnas_all', 'lohnas_4', 'murdock1962', 'murdock1970']\n\nfit_rpls = [[0.35386862, 0.43319286, 0.46776964, 0.48948095, 0.49651786], \n            [0.35961046, 0.50194643, 0.53528214, 0.55109286, 0.55234048],\n            [0.19713656, 0.34533214, 0.34188036, 0.34759405, 0.34767381],\n            [0.15170502, 0.26838214, 0.25996429, 0.25957381, 0.25287619]]\n\nfor i in range(len(fit_sources)):\n    plt.plot(fit_rpls[i], label=fit_sources[i])\n\nresult = fast_rpl(presentations[list_types==4], trials[list_types==4])\nbinned = np.zeros(5)\nbinned[0] = result[0]\nbinned[1] = result[1]\nbinned[2] = (result[2] + result[3])/2\nbinned[3] = (result[4] + result[5] + result[6])/3\nbinned[4] = (result[7] + result[8] + result[9])/3\nplt.plot(binned, label='data')\nlags = ['N/A', '0', '1-2', '3-5', '6-8']\nplt.xticks(np.arange(len(lags)), lags)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n<matplotlib.legend.Legend at 0x1f757ae98e0>\n\n\n\n\n\n\n\nPure Lists: simulate_df\n\nmodel = Classic_CMR(murd_length0, murd_length0, fitted_parameters)\nsim_df = simulate_df(model, 1000)\n\nsim_df.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n    \n  \n  \n    \n      0\n      0\n      0\n      0\n      1\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      1\n      0\n      0\n      1\n      2\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      2\n      0\n      0\n      2\n      3\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      3\n      0\n      0\n      3\n      4\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      4\n      0\n      0\n      4\n      5\n      2.0\n      True\n      True\n      0\n      False\n    \n  \n\n\n\n\n\n\nPure Lists: simulate_array vs simulate_array_from_presentations\n\n# implementation that assumes pure lists\nmodel = Classic_CMR(murd_length0, murd_length0, fitted_parameters)\noriginal_sim_array = simulate_array(model, len(murd_trials0))#*100)\noriginal_spc = fast_spc(original_sim_array, murd_length0)\n\noriginal_sim_array\n\narray([[18, 14, 19, ...,  0,  0,  0],\n       [17,  0,  0, ...,  0,  0,  0],\n       [18,  1, 19, ...,  0,  0,  0],\n       ...,\n       [ 8, 20, 15, ...,  0,  0,  0],\n       [15, 20, 17, ...,  0,  0,  0],\n       [19, 20,  1, ...,  0,  0,  0]])\n\n\n\n# presentation-based implementation\npresentations = np.zeros((len(murd_trials0), murd_length0), dtype=int)\npresentations[:] = np.arange(murd_length0)\n\nnew_sim_array = simulate_array_from_presentations(init_cmr, fitted_parameters, presentations, 1)\nnew_spc = fast_spc(new_sim_array, murd_length0)\n\nnew_sim_array\n\narray([[18, 20,  5, ...,  0,  0,  0],\n       [13, 12,  8, ...,  0,  0,  0],\n       [19, 20,  3, ...,  0,  0,  0],\n       ...,\n       [20, 19, 15, ...,  0,  0,  0],\n       [17, 18, 14, ...,  0,  0,  0],\n       [19,  1, 20, ...,  0,  0,  0]])\n\n\n\n# comparison\nimport matplotlib.pyplot as plt\n\nplt.plot(fast_spc(original_sim_array, murd_length0), label='original')\nplt.plot(fast_spc(new_sim_array, murd_length0), label='new')\n\nplt.legend()\n\n<matplotlib.legend.Legend at 0x2ddc4396460>"
  },
  {
    "objectID": "library\\datasets\\HowaKaha05.html",
    "href": "library\\datasets\\HowaKaha05.html",
    "title": "compmemlearn",
    "section": "",
    "text": "# default_exp datasets\n\nHowaKaha05 Dataset\n\nKahana, M. J., & Howard, M. W. (2005). Spacing and lag effects in free recall of pure lists. Psychonomic Bulletin & Review, 12(1), 159-164.\n\nSixty-six students studied and attempted free recall of 15 different lists of high-frequency nouns drawn from the Toronto Noun Pool (Friendly, Franklin, Hoffman, & Rubin, 1982). The lists consisted of 30 words, each repeated three times for a total of 90 presentations per list. List presentation was auditory, and the subjects made their responses vocally into a headset microphone. The words were presented at a rate of 1.5 sec. After list presentation, the subjects were given a distractor task involving simple arithmetic problems of the form A B C ?. The subjects had to correctly answer 15 problems in a row before they could proceed to the recall phase.\nThere were three list types: massed, spaced short, and spaced long. In the massed lists, each word was repeated three times successively. In the spaced-short lists, the presentation order was randomized, subject to the constraint that the lag between repetitions was at least 2 and no more than 6. For the spaced-long lists, presentation order was randomized, subject to the constraint that interrepetition lags were at least 6 and not more than 20.\nAs is typical in free recall studies, we took mea-sures to eliminate warm-up effects by excluding the first 2 lists from our data analyses. One of these first 2 practice lists was massed, and the other was randomly chosen to be either spaced short or spaced long. Of the subsequent 12 lists, 4 were massed, 4 were spaced short, and 4 were spaced long, presented in an individually randomized order for each subject.\nimport scipy.io as sio\nimport numpy as np\nimport pandas as pd\nfrom psifr import fr\n# export\ndef prepare_howakaha05_data(path):\n    \"\"\"\n    Prepares data formatted like `../data/HowaKaha05.dat` for fitting.\n    \"\"\"\n    \n    with open(path) as f:\n        howa_data = f.read()\n\n    subject_count = 66\n    trial_count = 15\n    total_lines = 66 * 15 * 5\n    list_length = 90\n\n    lines = [each.split('\\t') for each in howa_data.split('\\n')]\n    trial_info_inds = np.arange(1, total_lines, 5)\n    presentation_info_inds = np.arange(2, total_lines, 5)\n    recall_info_inds = np.arange(4, total_lines, 5)\n\n    # build vectors/matrices tracking list types and presentation item numbers across trials\n    list_types = np.array([int(lines[trial_info_inds[i]-1][2]) for i in range(subject_count * trial_count)])\n    subjects = np.array([int(lines[trial_info_inds[i]-1][0]) for i in range(subject_count * trial_count)])\n    pres_itemnos = np.array([[int(each) for each in lines[presentation_info_inds[i]-1][:-1]] for i in range(\n        subject_count * trial_count)])\n        \n    # convert pres_itemnos into rows of unique indices for easier model encoding\n    presentations = []\n    for i in range(len(pres_itemnos)):\n        seen = []\n        presentations.append([])\n        for p in pres_itemnos[i]:\n            if p not in seen:\n                seen.append(p)\n            presentations[-1].append(seen.index(p))\n    presentations = np.array(presentations)\n\n    # track recalls, discarding intrusions\n    trials = []\n    for i in range(subject_count * trial_count):\n        trials.append([])\n        \n        # if it can be cast as a positive integer and is not yet in the recall sequence, it's not an intrusion\n        trial = lines[recall_info_inds[i]-1][:-1]\n        for t in trial:\n            try:\n                t = int(t)\n                if (t in pres_itemnos[i]):\n                    item = presentations[i][np.where(pres_itemnos[i] == t)[0][0]]+1\n                    if item not in trials[-1]:\n                        trials[-1].append(item)\n            except ValueError:\n                continue\n        \n        # pad with zeros to make sure the list is the right length\n        while len(trials[-1]) < list_length:\n            trials[-1].append(0)\n            \n    trials = np.array(trials)\n\n    # encode dataset into psifr format\n    data = []\n    for trial_index, trial in enumerate(trials):\n        presentation = presentations[trial_index]\n        \n        # every time the subject changes, reset list_index\n        if not data or data[-1][0] != subjects[trial_index]:\n            list_index = 0\n        list_index += 1\n        \n        # add study events\n        for presentation_index, presentation_event in enumerate(presentation):\n            data += [[subjects[trial_index], \n                      list_index, 'study', presentation_index+1, presentation_event,  list_types[trial_index]\n                     ]]\n            \n        # add recall events\n        for recall_index, recall_event in enumerate(trial):\n            if recall_event != 0:\n                data += [[subjects[trial_index], list_index, \n                          'recall', recall_index+1, presentation[recall_event-1], list_types[trial_index]\n                         ]]\n                \n    data = pd.DataFrame(data, columns=[\n        'subject', 'list', 'trial_type', 'position', 'item', 'condition'])\n    merged = fr.merge_free_recall(data, list_keys=['condition'])\n    \n    return trials, merged, list_length, presentations, list_types, data, subjects\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_howakaha05_data(\n    '../../data/HowaKaha05.dat')\n\nevents.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n      condition\n    \n  \n  \n    \n      0\n      118\n      1\n      0\n      1\n      3.0\n      True\n      True\n      0\n      False\n      0\n    \n    \n      1\n      118\n      1\n      0\n      1\n      9.0\n      False\n      True\n      1\n      False\n      0\n    \n    \n      2\n      118\n      1\n      0\n      2\n      3.0\n      True\n      True\n      0\n      False\n      0\n    \n    \n      3\n      118\n      1\n      0\n      2\n      9.0\n      False\n      True\n      1\n      False\n      0\n    \n    \n      4\n      118\n      1\n      0\n      3\n      3.0\n      True\n      True\n      0\n      False\n      0"
  },
  {
    "objectID": "library\\datasets\\Lohnas2014.html",
    "href": "library\\datasets\\Lohnas2014.html",
    "title": "compmemlearn",
    "section": "",
    "text": "# default_exp datasets\n\nLohnas2014 Dataset\n\nSiegel, L. L., & Kahana, M. J. (2014). A retrieved context account of spacing and repetition effects in free recall. Journal of Experimental Psychology: Learning, Memory, and Cognition, 40(3), 755.\n\nAcross 4 sessions, 35 subjects performed delayed free recall of 48 lists. Subjects were University of Pennsylvania undergraduates, graduates and staff, age 18-32. List items were drawn from a pool of 1638 words taken from the University of South Florida free association norms (Nelson, McEvoy, & Schreiber, 2004; Steyvers, Shiffrin, & Nelson, 2004, available at http://memory.psych.upenn.edu/files/wordpools/PEERS_wordpool.zip). Within each session, words were drawn without replacement. Words could repeat across sessions so long as they did not repeat in two successive sessions. Words were also selected to ensure that no strong semantic associates co-occurred in a given list (i.e., the semantic relatedness between any two words on a given list, as determined using WAS (Steyvers et al., 2004), did not exceed a threshold value of 0.55).\nSubjects encountered four different types of lists: 1. Control lists that contained all once-presented items;\n2. pure massed lists containing all twice-presented items; 3. pure spaced lists consisting of items presented twice at lags 1-8, where lag is defined as the number of intervening items between a repeated item’s presentations; 4. mixed lists consisting of once presented, massed and spaced items. Within each session, subjects encountered three lists of each of these four types.\nIn each list there were 40 presentation positions, such that in the control lists each position was occupied by a unique list item, and in the pure massed and pure spaced lists, 20 unique words were presented twice to occupy the 40 positions. In the mixed lists 28 once-presented and six twice-presented words occupied the 40 positions. In the pure spaced lists, spacings of repeated items were chosen so that each of the lags 1-8 occurred with equal probability. In the mixed lists, massed repetitions (lag=0) and spaced repetitions (lags 1-8) were chosen such that each of the 9 lags of 0-8 were used exactly twice within each session. The order of presentation for the different list types was randomized within each session. For the first session, the first four lists were chosen so that each list type was presented exactly once. An experimenter sat in with the subject for these first four lists, though no subject had difficulty understanding the task.\nThe data for this experiment is stored in data/repFR.mat. We define a unique prepare_lohnas2014_data function to build structures from the dataset that works with our existing data analysis and fitting functions.\nLike in prepare_murdock1962_data, we need list lengths, a data frame for visualizations with psifir, and a trials array encoding recall events as sequences of presentation positions. But we’ll also need an additional array tracking presentation order, too.\nimport scipy.io as sio\nimport numpy as np\nimport pandas as pd\nfrom psifr import fr\n# export\n\ndef prepare_lohnas2014_data(path):\n    \"\"\"\n    Prepares data formatted like `data/repFR.mat` for fitting.\n    \"\"\"\n    \n    # load all the data\n    matfile = sio.loadmat(path, squeeze_me=True)['data'].item()\n    subjects = matfile[0]\n    pres_itemnos = matfile[4]\n    recalls = matfile[6]\n    list_types = matfile[7]\n    list_length = matfile[12]\n    \n    # convert pres_itemnos into rows of unique indices for easier model encoding\n    presentations = []\n    for i in range(len(pres_itemnos)):\n        seen = []\n        presentations.append([])\n        for p in pres_itemnos[i]:\n            if p not in seen:\n                seen.append(p)\n            presentations[-1].append(seen.index(p))\n    presentations = np.array(presentations)\n\n    # discard intrusions from recalls\n    trials = []\n    for i in range(len(recalls)):\n        trials.append([])\n        \n        trial = list(recalls[i])\n        for t in trial:\n            if (t > 0) and (t not in trials[-1]):\n                trials[-1].append(t)\n        \n        while len(trials[-1]) < list_length:\n            trials[-1].append(0)\n            \n    trials = np.array(trials)\n    \n    # encode dataset into psifr format\n    data = []\n    for trial_index, trial in enumerate(trials):\n        presentation = presentations[trial_index]\n        \n        # every time the subject changes, reset list_index\n        if not data or data[-1][0] != subjects[trial_index]:\n            list_index = 0\n        list_index += 1\n        \n        # add study events\n        for presentation_index, presentation_event in enumerate(presentation):\n            data += [[subjects[trial_index], \n                      list_index, 'study', presentation_index+1, presentation_event,  list_types[trial_index]\n                     ]]\n            \n        # add recall events\n        for recall_index, recall_event in enumerate(trial):\n            if recall_event != 0:\n                data += [[subjects[trial_index], list_index, \n                          'recall', recall_index+1, presentation[recall_event-1], list_types[trial_index]\n                         ]]\n                \n    data = pd.DataFrame(data, columns=[\n        'subject', 'list', 'trial_type', 'position', 'item', 'condition'])\n    merged = fr.merge_free_recall(data, list_keys=['condition'])\n    \n    return trials, merged, list_length, presentations, list_types, data, subjects\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')\n\nevents.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n      condition\n    \n  \n  \n    \n      0\n      1\n      1\n      0\n      1\n      1.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      1\n      1\n      1\n      1\n      2\n      2.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      2\n      1\n      1\n      2\n      3\n      3.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      3\n      1\n      1\n      3\n      4\n      4.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      4\n      1\n      1\n      4\n      5\n      5.0\n      True\n      True\n      0\n      False\n      4"
  },
  {
    "objectID": "library\\datasets\\Murdock1962.html",
    "href": "library\\datasets\\Murdock1962.html",
    "title": "compmemlearn",
    "section": "",
    "text": "# default_exp datasets\n\nMurdock1962 Dataset\n\nMurdock, B. B., Jr. (1962). The serial position effect of free recall. Journal of Experimental Psychology, 64(5), 482-488. https://doi.org/10.1037/h0045106\n\nOur data structure associated with Murdock (1962) has three LL structures that each seem to correspond to a different data set with different list lengths. Inside each structure is: - recalls with 1200 rows and 50 columns. Each row presumably represents a subject, and each column seems to correspond to a recall position, with -1 coded for intrusions. MurdData_clean.mat probably doesn’t have these intrusions coded at all. - listlength is an integer indicating how long the studied list is. - subject is a 1200x1 vector coding the identities of each subject for each row. Each subject seems to get 80 rows a piece. He really got that much data for each subject? - session similarly codes the index of the session under consideration, and it’s always 1 in this case. - presitemnumbers probably codes the number associated with each item. Is just its presentation index.\nWe’ll enable selection of relevant information from these structures based on which LL structure we’re interested in using a dataset_index parameter.\n# export\n\nimport scipy.io as sio\nimport numpy as np\nimport pandas as pd\nfrom psifr import fr\n\ndef prepare_murdock1962_data(path, dataset_index=0):\n    \"\"\"\n    Prepares data formatted like `data/MurdData_clean.mat` for fitting.\n\n    Loads data from `path` with same format as `data/MurdData_clean.mat` and\n    returns a selected dataset as an array of unique recall trials and a\n    dataframe of unique study and recall events organized according to `psifr`\n    specifications.\n\n    **Arguments**:\n    - path: source of data file\n    - dataset_index: index of the dataset to be extracted from the file\n\n    **Returns**:\n    - trials: int64-array where rows identify a unique trial of responses and\n        columns corresponds to a unique recall index.\n    - merged: as a long format table where each row describes one study or\n        recall event.\n    - list_length: length of lists studied in the considered dataset\n    \"\"\"\n\n    # load all the data\n    matfile = sio.loadmat(path, squeeze_me=True)\n    murd_data = [matfile['data'].item()[0][i].item() for i in range(3)]\n\n    # encode dataset into psifr format\n    trials, list_length, subjects = murd_data[dataset_index][:3]\n    trials = trials.astype('int64')\n\n    data = []\n    for trial_index, trial in enumerate(trials):\n\n        # every time the subject changes, reset list_index\n        if not data or data[-1][0] != subjects[trial_index]:\n            list_index = 0\n        list_index += 1\n\n        # add study events\n        for i in range(list_length):\n            data += [[subjects[trial_index],\n                      list_index, 'study', i+1, i+1]]\n\n        # add recall events\n        for recall_index, recall_event in enumerate(trial):\n            if recall_event != 0:\n                data += [[subjects[trial_index], list_index,\n                          'recall', recall_index+1, recall_event]]\n\n    data = pd.DataFrame(data, columns=[\n        'subject', 'list', 'trial_type', 'position', 'item'])\n    merged = fr.merge_free_recall(data)\n    return trials, merged, list_length\n\nmurd_trials, murd_events, murd_length = prepare_murdock1962_data(\n    '../../data/MurdData_clean.mat', 0)\n\nmurd_events.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n    \n  \n  \n    \n      0\n      1\n      1\n      1\n      1\n      5.0\n      True\n      True\n      0\n      False\n    \n    \n      1\n      1\n      1\n      2\n      2\n      7.0\n      True\n      True\n      0\n      False\n    \n    \n      2\n      1\n      1\n      3\n      3\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      3\n      1\n      1\n      4\n      4\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      4\n      1\n      1\n      5\n      5\n      NaN\n      True\n      False\n      0\n      False"
  },
  {
    "objectID": "library\\datasets\\MurdockOkada1970.html#murdockokada1970-dataset",
    "href": "library\\datasets\\MurdockOkada1970.html#murdockokada1970-dataset",
    "title": "compmemlearn",
    "section": "MurdockOkada1970 Dataset",
    "text": "Murdock, B. B., & Okada, R. (1970). Interresponse times in single-trial free recall. Journal of Experimental Psychology, 86(2), 263.\n\nAuthors investigated interresponse times in single-trial free recall. Each of 72 undergraduates was given 20 test lists with 20-word lists visually presented at either 60 or 120 words/min. The format of the data in these files is as follows:\nRow 1: subject/trial information\nRow 2: serial position as a function of output position.\nRow 3: inter-response time as a function of output position\nThe code 88 means that the subject made an extra-list intrusion.\nimport scipy.io as sio\nimport numpy as np\nimport pandas as pd\nfrom psifr import fr\n# export\n\ndef prepare_murdock1970_data(path):\n    \"\"\"\n    Prepares data formatted like `data/MurdData_clean.mat` for fitting.\n\n    Loads data from `path` with same format as `data/MurdData_clean.mat` and \n    returns a selected dataset as an array of unique recall trials and a \n    dataframe of unique study and recall events organized according to `psifr`\n    specifications.  \n\n    **Arguments**:  \n    - path: source of data file  \n    - dataset_index: index of the dataset to be extracted from the file\n\n    **Returns**:\n    - trials: int64-array where rows identify a unique trial of responses and \n        columns corresponds to a unique recall index.  \n    - merged: as a long format table where each row describes one study or \n        recall event.  \n    - list_length: length of lists studied in the considered dataset\n    \"\"\"\n    \n    with open(path) as f:\n        oka_data = f.read()\n\n    counter = 0\n    trials = []\n    subjects = []\n    list_length = 20\n\n    for line in oka_data.split('\\n'):\n\n        if not line:\n            continue\n\n        # build subjects array\n        if counter == 0:\n            subjects.append(int(line.strip().split('    ')[1]))\n\n        # build trials array\n        if counter == 1:\n\n            trial = [int(each) for each in line.strip().split('    ')]\n            trial = [each for each in trial if each <= 20]\n            already = []\n            for each in trial:\n                if each not in already:\n                    already.append(each)\n            trial = already\n            \n            while len(trial) < 13:\n                trial.append(0)\n\n            trials.append(trial)\n\n        # keep track of which row we are on for the given trial\n        counter += 1\n        if counter == 3:\n            counter = 0\n\n    trials = np.array(trials).astype('int64')\n    \n    data = []\n    for trial_index, trial in enumerate(trials):\n\n        # every time the subject changes, reset list_index\n        if not data or data[-1][0] != subjects[trial_index]:\n            list_index = 0\n        list_index += 1\n\n        # add study events\n        for i in range(list_length):\n            data += [[subjects[trial_index], \n                      list_index, 'study', i+1, i+1]]\n\n        # add recall events\n        for recall_index, recall_event in enumerate(trial):\n            if recall_event != 0:\n                data += [[subjects[trial_index], list_index, \n                          'recall', recall_index+1, recall_event]]\n\n    data = pd.DataFrame(data, columns=[\n        'subject', 'list', 'trial_type', 'position', 'item'])\n    merged = fr.merge_free_recall(data)\n    return trials, merged, list_length\n\nmurd_trials, murd_events, murd_length = prepare_murdock1970_data('../../data/mo1970.txt')\nmurd_events.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n    \n  \n  \n    \n      0\n      1\n      1\n      1\n      1\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      1\n      1\n      1\n      2\n      2\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      2\n      1\n      1\n      3\n      3\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      3\n      1\n      1\n      4\n      4\n      NaN\n      True\n      False\n      0\n      False\n    \n    \n      4\n      1\n      1\n      5\n      5\n      NaN\n      True\n      False\n      0\n      False"
  },
  {
    "objectID": "library\\datasets\\PEERS.html",
    "href": "library\\datasets\\PEERS.html",
    "title": "compmemlearn",
    "section": "",
    "text": "# default_exp datasets\n\nPEERS Dataset\nThe Penn Electrophysiology of Encoding and Retrieval Study (PEERS) is a multi-session experiment looking at scalp EEG during free recall and recognition. It recruits both younger adults (16-30) and older adults (60-90). For now, we exclusively use the free recall trials performed by younger adult participants.\nimport os\nfrom glob import glob\n\n\ndef prepare_peers_data(path):\n    \n    # build list of subject directories that excludes older subjects\n    with open(os.path.join(path, 'PEERS_older_adult_subject_list.txt')) as f:\n        older_subjects = [each for each in f.read().split('\\n')[:-1]]\n        \n    subject_dirs = [each for each in os.listdir(path) \n                    if each[:3] == 'LTP' and each[-3:] not in older_subjects]\n        \n    # loop through subjects\n    for subject_index, subject_dir in enumerate(subject_dirs):\n    \n        # loop through sessions\n        session_dirs = [\n            each for each in os.listdir(os.path.join(path, subject_dir)) \n            if each[:7] == 'session']\n        \n        for session_index, session_dir in enumerate(session_dirs):\n            \n            pass\n            # identify study events in session lag\n            \n            # for each trial, also track recall events\n            \n    return subject_dirs\n\nprepare_peers_data('../../data/ltpFR')\n\n['LTP063',\n 'LTP064',\n 'LTP065',\n 'LTP066',\n 'LTP067',\n 'LTP068',\n 'LTP069',\n 'LTP070',\n 'LTP071',\n 'LTP072',\n 'LTP073',\n 'LTP074',\n 'LTP075',\n 'LTP076',\n 'LTP077',\n 'LTP078',\n 'LTP079',\n 'LTP080',\n 'LTP081',\n 'LTP082',\n 'LTP083',\n 'LTP084',\n 'LTP085',\n 'LTP086',\n 'LTP087',\n 'LTP088',\n 'LTP089',\n 'LTP090',\n 'LTP091',\n 'LTP092',\n 'LTP093',\n 'LTP094',\n 'LTP095',\n 'LTP096',\n 'LTP097',\n 'LTP098',\n 'LTP099',\n 'LTP100',\n 'LTP101',\n 'LTP102',\n 'LTP103',\n 'LTP104',\n 'LTP105',\n 'LTP106',\n 'LTP107',\n 'LTP108',\n 'LTP109',\n 'LTP110',\n 'LTP111',\n 'LTP112',\n 'LTP113',\n 'LTP114',\n 'LTP115',\n 'LTP116',\n 'LTP117',\n 'LTP118',\n 'LTP119',\n 'LTP120',\n 'LTP121',\n 'LTP122',\n 'LTP123',\n 'LTP124',\n 'LTP125',\n 'LTP126',\n 'LTP127',\n 'LTP128',\n 'LTP129',\n 'LTP130',\n 'LTP131',\n 'LTP132',\n 'LTP133',\n 'LTP134',\n 'LTP135',\n 'LTP136',\n 'LTP137',\n 'LTP138',\n 'LTP139',\n 'LTP140',\n 'LTP141',\n 'LTP142',\n 'LTP143',\n 'LTP144',\n 'LTP145',\n 'LTP146',\n 'LTP147',\n 'LTP148',\n 'LTP149',\n 'LTP150',\n 'LTP151',\n 'LTP152',\n 'LTP153',\n 'LTP155',\n 'LTP158',\n 'LTP159',\n 'LTP161',\n 'LTP166',\n 'LTP167',\n 'LTP168',\n 'LTP172',\n 'LTP174',\n 'LTP181',\n 'LTP184',\n 'LTP185',\n 'LTP186',\n 'LTP187',\n 'LTP188',\n 'LTP189',\n 'LTP190',\n 'LTP191',\n 'LTP192',\n 'LTP193',\n 'LTP194',\n 'LTP195',\n 'LTP196',\n 'LTP197',\n 'LTP198',\n 'LTP199',\n 'LTP200',\n 'LTP201',\n 'LTP202',\n 'LTP207',\n 'LTP209',\n 'LTP210',\n 'LTP211',\n 'LTP212',\n 'LTP214',\n 'LTP215',\n 'LTP221',\n 'LTP224',\n 'LTP227',\n 'LTP228',\n 'LTP229',\n 'LTP230',\n 'LTP231',\n 'LTP232',\n 'LTP233',\n 'LTP234',\n 'LTP235',\n 'LTP236',\n 'LTP237',\n 'LTP238',\n 'LTP239',\n 'LTP240',\n 'LTP241',\n 'LTP242',\n 'LTP243',\n 'LTP244',\n 'LTP245',\n 'LTP246',\n 'LTP247',\n 'LTP248',\n 'LTP249',\n 'LTP250',\n 'LTP251',\n 'LTP252',\n 'LTP253',\n 'LTP254',\n 'LTP255',\n 'LTP256',\n 'LTP258',\n 'LTP259',\n 'LTP260',\n 'LTP261',\n 'LTP263',\n 'LTP264',\n 'LTP265',\n 'LTP267',\n 'LTP268',\n 'LTP269',\n 'LTP270',\n 'LTP271',\n 'LTP272',\n 'LTP273',\n 'LTP274',\n 'LTP275',\n 'LTP276',\n 'LTP277',\n 'LTP278',\n 'LTP279',\n 'LTP280',\n 'LTP281',\n 'LTP282',\n 'LTP283',\n 'LTP284',\n 'LTP285',\n 'LTP286',\n 'LTP287',\n 'LTP288',\n 'LTP289',\n 'LTP290',\n 'LTP291',\n 'LTP292',\n 'LTP293',\n 'LTP294',\n 'LTP295',\n 'LTP296',\n 'LTP297',\n 'LTP298',\n 'LTP299',\n 'LTP300']\n\n\ntrials, events, list_length = prepare_peers_data('../../data/ltpFR')\nevents.head()"
  },
  {
    "objectID": "library\\models\\Classic_CMR.html",
    "href": "library\\models\\Classic_CMR.html",
    "title": "compmemlearn",
    "section": "",
    "text": "# default_exp models\n\nClassic CMR\nThe Context Maintenance and Retrieval (CMR) as specified by Morton and Polyn (2016) takes the form of a simplified neural network with two interacting representations, a feature-based representation of the studied item and a contextual representation (the context layer, \\(C\\)). The two layers communicate with one another through two sets of associative connections represented by matrices \\(M^{FC}\\) and \\(M^{CF}\\). Each of these weight matrices contains both pre-experimental associations and new associations learned during the experiment.\n# export\n\nimport numpy as np\nfrom numba import float64, int32, boolean\nfrom numba.experimental import jitclass\nfrom compmemlearn.familiarity import familiarity_weighting\n\ncmr_spec = [\n    ('item_count', int32), \n    ('encoding_drift_rate', float64),\n    ('delay_drift_rate', float64),\n    ('start_drift_rate', float64),\n    ('recall_drift_rate', float64),\n    ('shared_support', float64),\n    ('item_support', float64),\n    ('learning_rate', float64),\n    ('primacy_scale', float64),\n    ('primacy_decay', float64),\n    ('stop_probability_scale', float64),\n    ('stop_probability_growth', float64),\n    ('choice_sensitivity', float64),\n    ('context', float64[::1]),\n    ('start_context_input', float64[::1]),\n    ('delay_context_input', float64[::1]),\n    ('preretrieval_context', float64[::1]),\n    ('recall', int32[::1]),\n    ('retrieving', boolean),\n    ('recall_total', int32),\n    ('primacy_weighting', float64[::1]),\n    ('probabilities', float64[::1]),\n    ('mfc', float64[:,::1]),\n    ('mcf', float64[:,::1]),\n    ('encoding_index', int32),\n    ('items', float64[:,::1]),\n    ('drift_familiarity_scale', float64),\n    ('mfc_familiarity_scale', float64),\n    ('mcf_familiarity_scale', float64),\n    ('sampling_rule', int32)\n]\n# export\n@jitclass(cmr_spec)\nclass Classic_CMR:\n\n    def __init__(self, item_count, presentation_count, parameters):\n\n        # store initial parameters\n        self.item_count = item_count\n        self.encoding_drift_rate = parameters['encoding_drift_rate']\n        self.delay_drift_rate = parameters['delay_drift_rate']\n        self.start_drift_rate = parameters['start_drift_rate']\n        self.recall_drift_rate = parameters['recall_drift_rate']\n        self.shared_support = parameters['shared_support']\n        self.item_support = parameters['item_support']\n        self.learning_rate = parameters['learning_rate']\n        self.primacy_scale = parameters['primacy_scale']\n        self.primacy_decay = parameters['primacy_decay']\n        self.stop_probability_scale = parameters['stop_probability_scale']\n        self.stop_probability_growth = parameters['stop_probability_growth']\n        self.choice_sensitivity = parameters['choice_sensitivity']\n        self.drift_familiarity_scale = parameters['drift_familiarity_scale']\n        self.mfc_familiarity_scale = parameters['mfc_familiarity_scale']\n        self.mcf_familiarity_scale = parameters['mcf_familiarity_scale']\n        self.sampling_rule = parameters['sampling_rule']\n        \n        # at the start of the list context is initialized with a state \n        # orthogonal to the pre-experimental context\n        # associated with the set of items\n        self.context = np.zeros(item_count + 2)\n        self.context[0] = 1\n        self.preretrieval_context = self.context\n        self.recall = np.zeros(item_count, int32) # recalls has at most `item_count` entries\n        self.retrieving = False\n        self.recall_total = 0\n\n        # predefine primacy weighting vectors\n        self.primacy_weighting = parameters['primacy_scale'] * np.exp(\n            -parameters['primacy_decay'] * np.arange(presentation_count)) + 1\n\n        # preallocate for outcome_probabilities\n        self.probabilities = np.zeros((item_count + 1))\n\n        # predefine contextual input vectors relevant for delay_drift_rate and start_drift_rate parameters\n        self.start_context_input = np.zeros((self.item_count+2))\n        self.start_context_input[0] = 1\n        self.delay_context_input = np.zeros((self.item_count+2))\n        self.delay_context_input[-1] = 1\n\n        # The two layers communicate with one another through two sets of \n        # associative connections represented by matrices Mfc and Mcf. \n        # Pre-experimental Mfc is 1-learning_rate and pre-experimental Mcf is\n        # item_support for i=j. For i!=j, Mcf is shared_support.\n        self.mfc = np.eye(item_count, item_count+2, 1) * (1-self.learning_rate)\n        self.mcf = np.ones((item_count, item_count)) * self.shared_support\n        for i in range(item_count):\n            self.mcf[i, i] = self.item_support\n        self.mcf =  np.vstack((np.zeros((1, item_count)), self.mcf, np.zeros((1, item_count))))\n        self.encoding_index = 0\n        self.items = np.eye(item_count, item_count)\n\n    def experience(self, experiences):\n        \n        for i in range(len(experiences)):\n            \n            mfc_familiarity = 1\n            mcf_familiarity = 1\n            if np.any(self.context[1:-1] > 0) and ((self.mfc_familiarity_scale != 0) or (self.mcf_familiarity_scale != 0)):\n                \n                similarity = np.dot(self.context[1:-1], experiences[i]) / (\n                    np.sqrt(np.dot(self.context[1:-1], self.context[1:-1])) * np.sqrt(\n                        np.dot(experiences[i],experiences[i])))\n            \n                mfc_familiarity = familiarity_weighting(self.mfc_familiarity_scale, similarity)\n                mcf_familiarity = familiarity_weighting(self.mcf_familiarity_scale, similarity)\n\n            self.update_context(self.encoding_drift_rate, experiences[i])\n            self.mfc += mfc_familiarity * self.learning_rate * np.outer(self.context, experiences[i]).T\n            self.mcf += mcf_familiarity * self.primacy_weighting[self.encoding_index] * np.outer(\n                self.context, experiences[i])\n            self.encoding_index += 1\n\n    def update_context(self, drift_rate, experience):\n\n        # first pre-experimental or initial context is retrieved\n        familiarity = 1\n        if len(experience) == len(self.mfc):\n            \n            if np.any(self.context[1:-1] > 0) and self.drift_familiarity_scale != 0:\n                \n                similarity = np.dot(self.context[1:-1], experience) / (\n                     np.sqrt(np.dot(self.context[1:-1], self.context[1:-1])) * np.sqrt(\n                          np.dot(experience,experience)))\n                familiarity = familiarity_weighting(self.drift_familiarity_scale, similarity)\n\n            context_input = np.dot(experience, self.mfc)\n            context_input = np.power(context_input, familiarity)\n\n            # if the context is not pre-experimental, the context is retrieved\n            context_input = context_input / np.sqrt(np.sum(np.square(context_input))) # norm to length 1\n            \n        else:\n            context_input = experience\n  \n        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n        rho = np.sqrt(1 + np.square(min(drift_rate, 1.0)) * (\n            np.square(self.context * context_input) - 1)) - (\n                min(drift_rate, 1.0) * (self.context * context_input))\n        self.context = (rho * self.context) + (min(drift_rate, 1.0) * context_input)\n\n    def activations(self, probe, use_mfc=False):\n\n        if use_mfc:\n            return np.dot(probe, self.mfc) + 10e-7\n        else:\n            return np.dot(probe, self.mcf) + 10e-7\n\n    def outcome_probabilities(self):\n\n        self.probabilities[0] = min(self.stop_probability_scale * np.exp(\n            self.recall_total * self.stop_probability_growth), 1.0 - (\n                 (self.item_count-self.recall_total) * 10e-7))\n        self.probabilities[1:] = 10e-7\n\n        if self.probabilities[0] < (1.0 - ((self.item_count-self.recall_total) * 10e-7)):\n\n            # measure the activation for each item\n            activation = self.activations(self.context)\n\n            # already recalled items have zero activation\n            activation[self.recall[:self.recall_total]] = 0\n\n            if np.sum(activation) > 0:\n\n                # power sampling rule vs modified exponential sampling rule\n                if self.sampling_rule == 0:\n                    activation = np.power(activation, self.choice_sensitivity)\n                else:\n                    pre_activation = (2 * activation)/ self.choice_sensitivity\n                    activation = np.exp(pre_activation - np.max(pre_activation))\n                \n                # normalized result downweighted by stop prob is probability of choosing each item\n                self.probabilities[1:] = (1-self.probabilities[0]) * activation / np.sum(activation)\n            \n        return self.probabilities\n\n    def free_recall(self, steps=None):\n\n        # some amount of the pre-list context is reinstated before initiating recall\n        if not self.retrieving:\n            self.recall = np.zeros(self.item_count, int32)\n            self.recall_total = 0\n            self.preretrieval_context = self.context\n            self.update_context(self.delay_drift_rate, self.delay_context_input)\n            self.update_context(self.start_drift_rate, self.start_context_input)\n            self.retrieving = True\n\n        # number of items to retrieve is # of items left to recall if steps is unspecified\n        if steps is None:\n            steps = self.item_count - self.recall_total\n        steps = self.recall_total + steps\n        \n        # at each recall attempt\n        while self.recall_total < steps:\n\n            # the current state of context is used as a retrieval cue to attempt recall of a studied item\n            # compute outcome probabilities and make choice based on distribution\n            outcome_probabilities = self.outcome_probabilities()\n            if np.any(outcome_probabilities[1:]):\n                choice = np.sum(np.cumsum(outcome_probabilities) < np.random.rand(), dtype=int32)\n            else:\n                choice = 0\n\n            # resolve and maybe store outcome\n            # we stop recall if no choice is made (0)\n            if choice == 0:\n                self.retrieving = False\n                self.context = self.preretrieval_context\n                break\n                \n            self.recall[self.recall_total] = choice - 1\n            self.recall_total += 1\n            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n        return self.recall[:self.recall_total]\n\n    def force_recall(self, choice=None):\n\n        if not self.retrieving:\n            self.recall = np.zeros(self.item_count, int32)\n            self.recall_total = 0\n            self.preretrieval_context = self.context\n            self.update_context(self.delay_drift_rate, self.delay_context_input)\n            self.update_context(self.start_drift_rate, self.start_context_input)\n            self.retrieving = True\n\n        if choice is None:\n            pass\n        elif choice > 0:\n            self.recall[self.recall_total] = choice - 1\n            self.recall_total += 1\n            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n        else:\n            self.retrieving = False\n            self.context = self.preretrieval_context\n        return self.recall[:self.recall_total]"
  },
  {
    "objectID": "library\\models\\Instance_CMR.html#context-maintenance-and-retrieval-within-an-instance-based-architecture",
    "href": "library\\models\\Instance_CMR.html#context-maintenance-and-retrieval-within-an-instance-based-architecture",
    "title": "compmemlearn",
    "section": "Context Maintenance and Retrieval within an Instance-Based Architecture",
    "text": "# export \n\nimport numpy as np\nfrom numba import float64, int32, boolean\nfrom numba.experimental import jitclass\n\nicmr_spec = [\n    ('item_count', int32), \n    ('encoding_drift_rate', float64),\n    ('start_drift_rate', float64),\n    ('recall_drift_rate', float64),\n    ('delay_drift_rate', float64),\n    ('shared_support', float64),\n    ('item_support', float64),\n    ('learning_rate', float64),\n    ('primacy_scale', float64),\n    ('primacy_decay', float64),\n    ('stop_probability_scale', float64),\n    ('stop_probability_growth', float64),\n    ('choice_sensitivity', float64),\n    ('context_sensitivity', float64),\n    ('feature_sensitivity', float64),\n    ('context', float64[::1]),\n    ('start_context_input', float64[::1]),\n    ('delay_context_input', float64[::1]),\n    ('preretrieval_context', float64[::1]),\n    ('recall', int32[::1]),\n    ('retrieving', boolean),\n    ('recall_total', int32),\n    ('item_weighting', float64[::1]),\n    ('context_weighting', float64[::1]),\n    ('all_weighting', float64[::1]),\n    ('probabilities', float64[::1]),\n    ('memory', float64[:,::1]),\n    ('encoding_index', int32),\n    ('items', float64[:,::1]),\n    ('norm', float64[::1]),\n]\n# export\n\n\n@jitclass(icmr_spec)\nclass Instance_CMR:\n\n    def __init__(self, item_count, presentation_count, parameters):\n\n        # store initial parameters\n        self.item_count = item_count\n        self.encoding_drift_rate = parameters['encoding_drift_rate']\n        self.delay_drift_rate = parameters['delay_drift_rate']\n        self.start_drift_rate = parameters['start_drift_rate']\n        self.recall_drift_rate = parameters['recall_drift_rate']\n        self.shared_support = parameters['shared_support']\n        self.item_support = parameters['item_support']\n        self.learning_rate = parameters['learning_rate']\n        self.primacy_scale = parameters['primacy_scale']\n        self.primacy_decay = parameters['primacy_decay']\n        self.stop_probability_scale = parameters['stop_probability_scale']\n        self.stop_probability_growth = parameters['stop_probability_growth']\n        self.choice_sensitivity = parameters['choice_sensitivity']\n        self.context_sensitivity = parameters['context_sensitivity']\n        self.feature_sensitivity = parameters['feature_sensitivity']\n        \n        # at the start of the list context is initialized with a state \n        # orthogonal to the pre-experimental context associated with the set of items\n        self.context = np.zeros(item_count + 2)\n        self.context[0] = 1\n        self.preretrieval_context = self.context\n        self.recall = np.zeros(item_count, int32) # recalls has at most `item_count` entries\n        self.retrieving = False\n        self.recall_total = 0\n\n        # predefine activation weighting vectors\n        self.item_weighting = np.ones(item_count+presentation_count)\n        self.context_weighting = np.ones(item_count+presentation_count)\n        self.item_weighting[item_count:] = self.learning_rate\n        self.context_weighting[item_count:] = \\\n            self.primacy_scale * np.exp(-self.primacy_decay * np.arange(presentation_count)) + 1\n        self.all_weighting = self.item_weighting * self.context_weighting\n\n        # preallocate for outcome_probabilities\n        self.probabilities = np.zeros((item_count + 1))\n\n        # predefine contextual input vectors relevant for delay_drift_rate and start_drift_rate parameters\n        self.start_context_input = np.zeros((self.item_count+2))\n        self.start_context_input[0] = 1\n        self.delay_context_input = np.zeros((self.item_count+2))\n        self.delay_context_input[-1] = 1\n\n        # initialize memory\n        # we now conceptualize it as a pairing of two stores Mfc and Mcf respectively\n        # representing feature-to-context and context-to-feature associations\n        mfc = np.eye(item_count, item_count + 2, 1) * (1 - self.learning_rate)\n        mcf = np.ones((item_count, item_count)) * self.shared_support\n        for i in range(item_count):\n            mcf[i, i] = self.item_support\n        mcf = np.hstack((np.zeros((item_count, 1)), mcf,  np.zeros((item_count, 1))))\n        self.memory = np.zeros((item_count + presentation_count, item_count * 2 + 4))\n        self.memory[:item_count,] = np.hstack((mfc, mcf))\n\n        self.norm = np.zeros(item_count + presentation_count)\n        self.norm[:item_count] = np.sqrt(np.sum(np.square(self.memory[0])))\n        self.norm[item_count:] = np.sqrt(2)\n        self.encoding_index = item_count\n        self.items = np.hstack((np.eye(item_count, item_count + 2, 1), np.zeros((item_count, item_count+2))))\n        self.items = self.items.astype(int32)\n\n    def experience(self, experiences):\n\n        for i in range(len(experiences)):\n            self.memory[self.encoding_index] = experiences[i]\n            self.update_context(self.encoding_drift_rate, self.memory[self.encoding_index])\n            self.memory[self.encoding_index, self.item_count+2:] = self.context\n            self.encoding_index += 1\n\n    def update_context(self, drift_rate, experience):\n\n        # first pre-experimental or initial context is retrieved\n        if len(experience) == self.item_count * 2 + 4:\n            context_input = self.echo(experience)[self.item_count + 2:]\n            context_input = context_input / np.sqrt(np.sum(np.square(context_input))) # norm to length 1\n        else:\n            context_input = experience\n\n        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n        rho = np.sqrt(1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)) - (\n                drift_rate * (self.context * context_input))\n        self.context = (rho * self.context) + (drift_rate * context_input)\n        self.context = self.context / np.sqrt(np.sum(np.square(self.context)))\n\n    def echo(self, probe):\n\n        return np.dot(self.activations(probe), self.memory[:self.encoding_index])\n\n    def activations(self, probe, probe_norm=1.0):\n\n        activation = np.dot(self.memory[:self.encoding_index], probe) / (\n             self.norm[:self.encoding_index] * probe_norm)\n\n        # weight activations based on whether probe contains item or contextual features or both\n        if np.any(probe[:self.item_count + 2]): # if probe is an item feature cue as during contextual retrieval\n            if np.any(probe[self.item_count + 2:]): # if probe is (also) a contextual cue as during item retrieval\n                # both mfc and mcf weightings, see below\n                activation *= self.all_weighting[:self.encoding_index]\n            else:\n                # mfc weightings - scale by gamma for each experimental trace\n                activation *= self.item_weighting[:self.encoding_index]\n            activation = np.power(activation, self.context_sensitivity)\n        else:\n            # mcf weightings - scale by primacy/attention function based on experience position\n            activation *= self.context_weighting[:self.encoding_index]\n            if self.feature_sensitivity != 1.0:\n                activation = np.power(activation, self.feature_sensitivity)\n            else:\n                activation = np.power(activation, self.context_sensitivity)\n            \n        return activation\n\n    def outcome_probabilities(self):\n        \n        self.probabilities[0] = min(self.stop_probability_scale * np.exp(\n            self.recall_total * self.stop_probability_growth), 1.0 - (\n                 (self.item_count-self.recall_total) * 10e-7))\n        self.probabilities[1:] = 10e-7\n\n        if self.probabilities[0] < (1.0 - ((self.item_count-self.recall_total) * 10e-7)):\n\n            # measure activation for each item\n            activation_cue = np.hstack((np.zeros(self.item_count + 2), self.context))\n            activation = self.echo(activation_cue)[1:self.item_count+1]\n\n            # already recalled items have zero activation\n            activation[self.recall[:self.recall_total]] = 0\n            \n            # recall probability is a function of activation\n            if np.sum(activation) > 0:\n                activation = np.power(activation, self.choice_sensitivity)\n                self.probabilities[1:] = (1-self.probabilities[0]) * activation / np.sum(activation)\n        \n        return self.probabilities\n\n    def free_recall(self, steps=None):\n\n        # some pre-list context is reinstated before initiating recall\n        if not self.retrieving:\n            self.recall = np.zeros(self.item_count, int32)\n            self.recall_total = 0\n            self.preretrieval_context = self.context\n            self.update_context(self.delay_drift_rate, self.delay_context_input)\n            self.update_context(self.start_drift_rate, self.start_context_input)\n            self.retrieving = True\n            \n        # number of items to retrieve is infinite if steps is unspecified\n        if steps is None:\n            steps = self.item_count - self.recall_total\n        steps = self.recall_total + steps\n\n        # at each recall attempt\n        while self.recall_total < steps:\n\n            # the current state of context is used as a retrieval cue to \n            # attempt recall of a studied item compute outcome probabilities \n            # and make choice based on distribution\n            outcome_probabilities = self.outcome_probabilities()\n            if np.any(outcome_probabilities[1:]):\n                choice = np.sum(\n                    np.cumsum(outcome_probabilities) < np.random.rand(), dtype=int32)\n            else:\n                choice = 0\n\n            # resolve and maybe store outcome\n            # we stop recall if no choice is made (0)\n            if choice == 0:\n                self.retrieving = False\n                self.context = self.preretrieval_context\n                break\n            self.recall[self.recall_total] = choice - 1\n            self.recall_total += 1\n            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n        return self.recall[:self.recall_total]\n    \n    def force_recall(self, choice=None):\n\n        if not self.retrieving:\n            self.recall = np.zeros(self.item_count, int32)\n            self.recall_total = 0\n            self.preretrieval_context = self.context\n            self.update_context(self.delay_drift_rate, self.delay_context_input)\n            self.update_context(self.start_drift_rate, self.start_context_input)\n            self.retrieving = True\n\n        if choice is None:\n            pass\n        elif choice > 0:\n            self.recall[self.recall_total] = choice - 1\n            self.recall_total += 1\n            self.update_context(\n                self.recall_drift_rate, self.items[choice - 1])\n        else:\n            self.retrieving = False\n            self.context = self.preretrieval_context\n        return self.recall[:self.recall_total]"
  },
  {
    "objectID": "library\\models\\Noisy_CMR.html#fitting-murdock-1970-dataset",
    "href": "library\\models\\Noisy_CMR.html#fitting-murdock-1970-dataset",
    "title": "compmemlearn",
    "section": "Fitting Murdock 1970 Dataset",
    "text": "Must update to reflect shift to instance model. But in practice I’ll probably move to a different notebook.\nfrom compmemlearn.datasets import prepare_murdock1970_data\n#from compmemlearn.fitting import murdock_objective_function\nfrom scipy.optimize import differential_evolution\nfrom numba import njit\nimport numpy as np\nfrom compmemlearn.fitting import apply_and_concatenate\nimport seaborn as sns\nfrom numba.typed import Dict\nfrom numba.core import types\nfrom compmemlearn.datasets import simulate_df\nimport matplotlib.pyplot as plt\nfrom psifr import fr\ndef murdock_data_likelihood(data_to_fit, item_counts, model_class, parameters):\n\n    result = 0.0\n    for i in range(len(item_counts)):\n        item_count = item_counts[i]\n        trials = data_to_fit[i]\n        likelihood = np.ones((len(trials), item_count))\n\n        model = model_class(item_count, item_count, parameters)\n        model.experience(model.items)\n\n        for trial_index in range(len(trials)):\n            trial = trials[trial_index]\n\n            model.force_recall()\n            for recall_index in range(len(trial) + 1):\n\n                # identify index of item recalled; if zero then recall is over\n                if recall_index == len(trial) and len(trial) < item_count:\n                    recall = 0\n                else:\n                    recall = trial[recall_index]\n\n                # store probability of and simulate recall of indexed item \n                likelihood[trial_index, recall_index] = \\\n                    model.outcome_probabilities()[recall] + 10e-7\n                \n                if recall == 0:\n                    break\n                model.force_recall(recall)\n\n            # reset model to its pre-retrieval (but post-encoding) state\n            model.force_recall(0)\n        \n        result -= np.sum(np.log(likelihood))\n\n    return result\n\ndef murdock_objective_function(data_to_fit, item_counts, model_class, fixed_parameters, free_parameters):\n    \"\"\"\n    Configures cmr_likelihood for search over specified free/fixed parameters.\n    \"\"\"\n\n    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n    for name, value in fixed_parameters.items():\n        parameters[name] = value\n    \n    def objective_function(x):\n        for i in range(len(free_parameters)):\n            parameters[free_parameters[i]] = x[i]\n        return murdock_data_likelihood(data_to_fit, item_counts, model_class, parameters)\n\n    return objective_function\ntrials, events, list_length = prepare_murdock1970_data('../../data/mo1970.txt')\nfree_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nbounds = (\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n)\n\n#@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Noise_CMR(item_count, presentation_count, parameters)\n    \ncost_function = murdock_objective_function(\n    (trials, ),  \n    (list_length, ),\n    init_cmr,\n    {'sampling_rule': 0}, \n    free_parameters)\n\nmurdock_result = differential_evolution(cost_function, bounds, disp=True)\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(murdock_result.x)):\n    fitted_parameters[free_parameters[i]] = murdock_result.x[i]\nfitted_parameters['sampling_rule'] = 0\n\nmodel0 = Noise_CMR(20, 20, fitted_parameters)\n\nsim_df0 = simulate_df(model0, 5000)\ntrue_df0 = events\n\ncmr_spc0 = apply_and_concatenate(fr.spc, sim_df0, true_df0, contrast_name='source', labels=['ScalarCMR', 'data'])\ncmr_lag_crp0 = apply_and_concatenate(fr.lag_crp, sim_df0, true_df0, 'source', ['ScalarCMR', 'data'])\ncmr_pfr0 = apply_and_concatenate(fr.pnr, sim_df0, true_df0, contrast_name='source', labels=['ScalarCMR', 'data'])\ncmr_pfr0 = cmr_pfr0.query('output <= 1')\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 12/3), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0], data=cmr_spc0, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0].set_xticks(np.arange(1, list_length+1, 3))\naxes[0].set_ylim((0, 1))\n\n# lag CRP\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1].set_xticks(np.arange(-5, 6, 1))\naxes[1].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=cmr_pfr0, x='input', y='prob', err_style='bars', ax=axes[2], hue='source', legend=True)\naxes[2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2].set_xticks(np.arange(1, list_length+1, 3))\naxes[2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=2)"
  },
  {
    "objectID": "library\\models\\Noisy_CMR.html#section",
    "href": "library\\models\\Noisy_CMR.html#section",
    "title": "compmemlearn",
    "section": "",
    "text": ""
  },
  {
    "objectID": "library\\models\\Scalar_CMR.html#fitting-murdock-1970-dataset",
    "href": "library\\models\\Scalar_CMR.html#fitting-murdock-1970-dataset",
    "title": "compmemlearn",
    "section": "Fitting Murdock 1970 Dataset",
    "text": "from compmemlearn.datasets import prepare_murdock1970_data\nfrom compmemlearn.fitting import murdock_objective_function\nfrom scipy.optimize import differential_evolution\nfrom numba import int32\nfrom numba import njit\nimport numpy as np\nfrom compmemlearn.fitting import apply_and_concatenate\nimport seaborn as sns\nfrom numba.typed import Dict\nfrom numba.core import types\nfrom compmemlearn.datasets import simulate_df\nimport matplotlib.pyplot as plt\nfrom psifr import fr\ntrials, events, list_length = prepare_murdock1970_data('../../data/mo1970.txt')\n\nfree_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'increment',\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nbounds = (\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub)\n)\n\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Scalar_CMR(item_count, presentation_count, parameters)\n    \ncost_function = murdock_objective_function(\n    (trials, ),  \n    (list_length, ),\n    init_cmr,\n    {'sampling_rule': 0}, \n    free_parameters)\n\nmurdock_result = differential_evolution(cost_function, bounds, disp=True)\n\ndifferential_evolution step 1: f(x)= 28456.6\ndifferential_evolution step 2: f(x)= 28025.4\ndifferential_evolution step 3: f(x)= 27778\ndifferential_evolution step 4: f(x)= 27474.9\ndifferential_evolution step 5: f(x)= 27474.9\ndifferential_evolution step 6: f(x)= 27474.9\ndifferential_evolution step 7: f(x)= 27189.7\ndifferential_evolution step 8: f(x)= 27189.7\ndifferential_evolution step 9: f(x)= 26938.8\ndifferential_evolution step 10: f(x)= 26938.8\ndifferential_evolution step 11: f(x)= 26681.4\ndifferential_evolution step 12: f(x)= 26510.4\ndifferential_evolution step 13: f(x)= 26083.6\ndifferential_evolution step 14: f(x)= 26083.6\ndifferential_evolution step 15: f(x)= 26083.6\ndifferential_evolution step 16: f(x)= 26083.6\ndifferential_evolution step 17: f(x)= 26019.2\ndifferential_evolution step 18: f(x)= 25866.7\ndifferential_evolution step 19: f(x)= 25866.7\ndifferential_evolution step 20: f(x)= 25866.7\ndifferential_evolution step 21: f(x)= 25866.7\ndifferential_evolution step 22: f(x)= 25866.7\ndifferential_evolution step 23: f(x)= 25866.7\ndifferential_evolution step 24: f(x)= 25866.7\ndifferential_evolution step 25: f(x)= 25866.7\ndifferential_evolution step 26: f(x)= 25866.7\ndifferential_evolution step 27: f(x)= 25866.7\ndifferential_evolution step 28: f(x)= 25866.7\ndifferential_evolution step 29: f(x)= 25866.7\ndifferential_evolution step 30: f(x)= 25866.7\ndifferential_evolution step 31: f(x)= 25866.7\ndifferential_evolution step 32: f(x)= 25866.7\ndifferential_evolution step 33: f(x)= 25221.9\ndifferential_evolution step 34: f(x)= 25221.9\ndifferential_evolution step 35: f(x)= 25221.9\ndifferential_evolution step 36: f(x)= 25221.9\ndifferential_evolution step 37: f(x)= 25221.9\ndifferential_evolution step 38: f(x)= 25221.9\ndifferential_evolution step 39: f(x)= 25221.9\ndifferential_evolution step 40: f(x)= 25221.9\ndifferential_evolution step 41: f(x)= 25221.9\ndifferential_evolution step 42: f(x)= 25221.9\ndifferential_evolution step 43: f(x)= 25221.9\ndifferential_evolution step 44: f(x)= 25205.6\ndifferential_evolution step 45: f(x)= 25205.6\ndifferential_evolution step 46: f(x)= 25157.5\ndifferential_evolution step 47: f(x)= 25157.5\ndifferential_evolution step 48: f(x)= 25157.5\ndifferential_evolution step 49: f(x)= 25057.5\ndifferential_evolution step 50: f(x)= 25057.5\ndifferential_evolution step 51: f(x)= 25057.5\ndifferential_evolution step 52: f(x)= 25057.5\ndifferential_evolution step 53: f(x)= 25057.5\ndifferential_evolution step 54: f(x)= 25057.5\ndifferential_evolution step 55: f(x)= 25057.5\ndifferential_evolution step 56: f(x)= 25057.5\ndifferential_evolution step 57: f(x)= 25057.5\ndifferential_evolution step 58: f(x)= 25057.5\ndifferential_evolution step 59: f(x)= 25044.6\ndifferential_evolution step 60: f(x)= 25033.3\ndifferential_evolution step 61: f(x)= 25033.3\ndifferential_evolution step 62: f(x)= 25033.3\ndifferential_evolution step 63: f(x)= 25033.3\ndifferential_evolution step 64: f(x)= 25033.3\ndifferential_evolution step 65: f(x)= 25033.3\ndifferential_evolution step 66: f(x)= 25033.3\ndifferential_evolution step 67: f(x)= 25033.3\ndifferential_evolution step 68: f(x)= 25033.3\ndifferential_evolution step 69: f(x)= 25016.7\ndifferential_evolution step 70: f(x)= 25016.7\ndifferential_evolution step 71: f(x)= 25010\ndifferential_evolution step 72: f(x)= 24976.5\ndifferential_evolution step 73: f(x)= 24957.2\n\n\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(murdock_result.x)):\n    fitted_parameters[free_parameters[i]] = murdock_result.x[i]\nfitted_parameters['sampling_rule'] = 0\n\nmodel0 = Scalar_CMR(20, 20, fitted_parameters)\n\nsim_df0 = simulate_df(model0, 5000)\ntrue_df0 = events\n\ncmr_spc0 = apply_and_concatenate(fr.spc, sim_df0, true_df0, contrast_name='source', labels=['ScalarCMR', 'data'])\ncmr_lag_crp0 = apply_and_concatenate(fr.lag_crp, sim_df0, true_df0, 'source', ['ScalarCMR', 'data'])\ncmr_pfr0 = apply_and_concatenate(fr.pnr, sim_df0, true_df0, contrast_name='source', labels=['ScalarCMR', 'data'])\ncmr_pfr0 = cmr_pfr0.query('output <= 1')\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 12/3), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0], data=cmr_spc0, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0].set_xticks(np.arange(1, list_length+1, 3))\naxes[0].set_ylim((0, 1))\n\n# lag CRP\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1].set_xticks(np.arange(-5, 6, 1))\naxes[1].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=cmr_pfr0, x='input', y='prob', err_style='bars', ax=axes[2], hue='source', legend=True)\naxes[2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2].set_xticks(np.arange(1, list_length+1, 3))\naxes[2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=2)"
  },
  {
    "objectID": "library\\models\\Trace_Reinstatement_CMR.html#trace-based-reinstatement",
    "href": "library\\models\\Trace_Reinstatement_CMR.html#trace-based-reinstatement",
    "title": "compmemlearn",
    "section": "Trace-Based Reinstatement",
    "text": "A variant of InstanceCMR that slightly breaks PrototypeCMR’s assumption that feature-to-context associations drive the evolution of context across a list-learning experiment. Instead, we’ll suppose that a composite cue containing activation of an item’s item-feature unit AND main contextual unit determines contextual input at each model step.\n# export \n\nimport numpy as np\nfrom numba import float64, int32, boolean\nfrom numba.experimental import jitclass\n\ntrcmr_spec = [\n    ('item_count', int32), \n    ('encoding_drift_rate', float64),\n    ('start_drift_rate', float64),\n    ('recall_drift_rate', float64),\n    ('delay_drift_rate', float64),\n    ('shared_support', float64),\n    ('item_support', float64),\n    ('learning_rate', float64),\n    ('primacy_scale', float64),\n    ('primacy_decay', float64),\n    ('stop_probability_scale', float64),\n    ('stop_probability_growth', float64),\n    ('choice_sensitivity', float64),\n    ('context_sensitivity', float64),\n    ('feature_sensitivity', float64),\n    ('context', float64[::1]),\n    ('start_context_input', float64[::1]),\n    ('delay_context_input', float64[::1]),\n    ('preretrieval_context', float64[::1]),\n    ('recall', int32[::1]),\n    ('retrieving', boolean),\n    ('recall_total', int32),\n    ('item_weighting', float64[::1]),\n    ('context_weighting', float64[::1]),\n    ('all_weighting', float64[::1]),\n    ('probabilities', float64[::1]),\n    ('memory', float64[:,::1]),\n    ('encoding_index', int32),\n    ('items', float64[:,::1]),\n    ('recall_items', float64[:,::1]),\n    ('norm', float64[::1]),\n    ('context_reinstatement', float64),\n    ('feature_drift_rate', float64),\n    ('features', float64[::1]),\n]\n# export\n\n@jitclass(trcmr_spec)\nclass Trace_Reinstatement_CMR:\n\n    def __init__(self, item_count, presentation_count, parameters):\n\n        # store initial parameters\n        self.item_count = item_count\n        self.encoding_drift_rate = parameters['encoding_drift_rate']\n        self.delay_drift_rate = parameters['delay_drift_rate']\n        self.start_drift_rate = parameters['start_drift_rate']\n        self.recall_drift_rate = parameters['recall_drift_rate']\n        self.shared_support = parameters['shared_support']\n        self.item_support = parameters['item_support']\n        self.learning_rate = parameters['learning_rate']\n        self.primacy_scale = parameters['primacy_scale']\n        self.primacy_decay = parameters['primacy_decay']\n        self.stop_probability_scale = parameters['stop_probability_scale']\n        self.stop_probability_growth = parameters['stop_probability_growth']\n        self.choice_sensitivity = parameters['choice_sensitivity']\n        self.context_sensitivity = parameters['context_sensitivity']\n        self.feature_sensitivity = parameters['feature_sensitivity']\n        self.context_reinstatement = parameters['context_reinstatement']\n        self.feature_drift_rate = parameters['feature_drift_rate']\n        \n        # at the start of the list context is initialized with a state \n        # orthogonal to the pre-experimental context associated with the set of items\n        self.context = np.zeros(item_count + 2)\n        self.context[0] = 1\n        self.preretrieval_context = self.context\n        self.recall = np.zeros(item_count, dtype=int32) # recalls has at most `item_count` entries\n        self.retrieving = False\n        self.recall_total = 0\n\n        # predefine activation weighting vectors\n        self.item_weighting = np.ones(item_count+presentation_count)\n        self.context_weighting = np.ones(item_count+presentation_count)\n        self.item_weighting[item_count:] = self.learning_rate\n        self.context_weighting[item_count:] = \\\n            self.primacy_scale * np.exp(-self.primacy_decay * np.arange(presentation_count)) + 1\n        self.all_weighting = self.item_weighting * self.context_weighting\n\n        # preallocate for outcome_probabilities\n        self.probabilities = np.zeros((item_count + 1))\n\n        # predefine contextual input vectors relevant for delay_drift_rate and start_drift_rate parameters\n        self.start_context_input = np.zeros((self.item_count+2))\n        self.start_context_input[0] = 1\n        self.delay_context_input = np.zeros((self.item_count+2))\n        self.delay_context_input[-1] = 1\n\n        # initialize memory\n        # we now conceptualize it as a pairing of two stores Mfc and Mcf respectively\n        # representing feature-to-context and context-to-feature associations\n        mfc = np.eye(item_count, item_count + 2, 1) * (1 - self.learning_rate)\n        mcf = np.ones((item_count, item_count)) * self.shared_support\n        for i in range(item_count):\n            mcf[i, i] = self.item_support\n        mcf = np.hstack((np.zeros((item_count, 1)), mcf,  np.zeros((item_count, 1))))\n        self.memory = np.zeros((item_count + presentation_count, item_count * 2 + 4))\n        self.memory[:item_count,] = np.hstack((mfc, mcf))\n\n        self.norm = np.zeros(item_count + presentation_count)\n        self.norm[:item_count] = np.sqrt(np.sum(np.square(self.memory[0])))\n        self.norm[item_count:] = np.sqrt(2)\n        self.encoding_index = item_count\n\n        # base\n        self.features = np.zeros((self.item_count+2))\n        self.recall_items = np.hstack((np.eye(item_count, item_count + 2, 1), np.zeros((item_count, item_count+2))))\n        \n        # mixed cue\n        self.items = np.hstack((np.eye(item_count, item_count + 2, 1), np.eye(item_count, item_count + 2, 1)))\n        \n        # contextual unit cue\n        #self.items = np.hstack((np.zeros((item_count, item_count+2)), np.eye(item_count, item_count + 2, 1)))\n\n        # parametrized mixed cue\n        #self.items = np.hstack(\n        #    (np.eye(item_count, item_count + 2, 1), self.context_reinstatement*np.eye(item_count,item_count + 2, 1)))\n        \n        #self.items /= np.sqrt(np.sum(np.square(self.items[0])))\n\n    def experience(self, experiences):\n\n        for i in range(len(experiences)):\n\n            # configure contextual representation for trace\n            self.update_context(self.encoding_drift_rate, experiences[i])\n            self.memory[self.encoding_index, self.item_count+2:] = self.context\n\n            # configure feature representation for trace\n            self.update_features(self.feature_drift_rate, experiences[i])\n            self.memory[self.encoding_index, :self.item_count+2] = self.features\n\n            self.encoding_index += 1\n\n    def update_features(self, drift_rate, experience):\n\n        probe = experience.copy() \n        probe[:self.item_count+2] *= 0 #TODO: exclude if I'm including C information in cue\n        feature_input = self.echo(probe)[:self.item_count + 2]\n        feature_input = feature_input / np.sqrt(np.sum(np.square(feature_input))) # norm to length 1\n\n        self.features = experience[:self.item_count+2]\n        rho = np.sqrt(1 + np.square(drift_rate) * (np.square(self.features * feature_input) - 1)) - (\n                drift_rate * (self.features * feature_input))\n        self.features = (rho * self.features) + (drift_rate * feature_input)\n        self.features = self.features / np.sqrt(np.sum(np.square(self.features)))\n\n    def update_context(self, drift_rate, experience):\n\n        # first pre-experimental or initial context is retrieved\n        if len(experience) == self.item_count * 2 + 4:\n            probe = experience.copy() \n            probe[self.item_count+2:] *= self.context_reinstatement\n            context_input = self.echo(probe)[self.item_count + 2:]\n            context_input = context_input / np.sqrt(np.sum(np.square(context_input))) # norm to length 1\n        else:\n            context_input = experience\n\n        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n        rho = np.sqrt(1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)) - (\n                drift_rate * (self.context * context_input))\n        self.context = (rho * self.context) + (drift_rate * context_input)\n        self.context = self.context / np.sqrt(np.sum(np.square(self.context)))\n\n    def echo(self, probe):\n        return np.dot(self.activations(probe), self.memory[:self.encoding_index])\n\n    def activations(self, probe, probe_norm=1.0):\n\n        activation = np.dot(self.memory[:self.encoding_index], probe) / (\n             self.norm[:self.encoding_index] * probe_norm)\n\n        # weight activations based on whether probe contains item or contextual features or both\n        if np.any(probe[:self.item_count + 2]): # if probe is an item feature cue as during contextual retrieval\n            if np.any(probe[self.item_count + 2:]): # if probe is (also) a contextual cue as during item retrieval\n                # both mfc and mcf weightings, see below\n                activation *= self.all_weighting[:self.encoding_index]\n            else:\n                # mfc weightings - scale by gamma for each experimental trace\n                activation *= self.item_weighting[:self.encoding_index]\n            activation = np.power(activation, self.context_sensitivity)\n        else:\n            # mcf weightings - scale by primacy/attention function based on experience position\n            activation *= self.context_weighting[:self.encoding_index]\n            if self.feature_sensitivity != 1.0:\n                activation = np.power(activation, self.feature_sensitivity)\n            else:\n                activation = np.power(activation, self.context_sensitivity)\n            \n        return activation\n\n    def outcome_probabilities(self):\n        \n        self.probabilities[0] = min(self.stop_probability_scale * np.exp(\n            self.recall_total * self.stop_probability_growth), 1.0 - (\n                 (self.item_count-self.recall_total) * 10e-7))\n        self.probabilities[1:] = 10e-7\n\n        if self.probabilities[0] < (1.0 - ((self.item_count-self.recall_total) * 10e-7)):\n\n            # measure activation for each item\n            activation_cue = np.hstack((np.zeros(self.item_count + 2), self.context))\n            activation = self.echo(activation_cue)[1:self.item_count+1]\n\n            # already recalled items have zero activation\n            activation[self.recall[:self.recall_total]] = 0\n            \n            # recall probability is a function of activation\n            if np.sum(activation) > 0:\n                activation = np.power(activation, self.choice_sensitivity)\n                self.probabilities[1:] = (1-self.probabilities[0]) * activation / np.sum(activation)\n        \n        return self.probabilities\n\n    def free_recall(self, steps=None):\n\n        # some pre-list context is reinstated before initiating recall\n        if not self.retrieving:\n            self.recall = np.zeros(self.item_count, dtype=int32)\n            self.recall_total = 0\n            self.preretrieval_context = self.context\n            self.update_context(self.delay_drift_rate, self.delay_context_input)\n            self.update_context(self.start_drift_rate, self.start_context_input)\n            self.retrieving = True\n            \n        # number of items to retrieve is infinite if steps is unspecified\n        if steps is None:\n            steps = self.item_count - self.recall_total\n        steps = self.recall_total + steps\n\n        # at each recall attempt\n        while self.recall_total < steps:\n\n            # the current state of context is used as a retrieval cue to \n            # attempt recall of a studied item compute outcome probabilities \n            # and make choice based on distribution\n            outcome_probabilities = self.outcome_probabilities()\n            if np.any(outcome_probabilities[1:]):\n                choice = np.sum(\n                    np.cumsum(outcome_probabilities) < np.random.rand(), dtype=int32)\n            else:\n                choice = 0\n\n            # resolve and maybe store outcome\n            # we stop recall if no choice is made (0)\n            if choice == 0:\n                self.retrieving = False\n                self.context = self.preretrieval_context\n                break\n            self.recall[self.recall_total] = choice - 1\n            self.recall_total += 1\n            self.update_context(self.recall_drift_rate, self.recall_items[choice - 1])\n        return self.recall[:self.recall_total]\n    \n    def force_recall(self, choice=None):\n\n        if not self.retrieving:\n            self.recall = np.zeros(self.item_count, dtype=int32)\n            self.recall_total = 0\n            self.preretrieval_context = self.context\n            self.update_context(self.delay_drift_rate, self.delay_context_input)\n            self.update_context(self.start_drift_rate, self.start_context_input)\n            self.retrieving = True\n\n        if choice is None:\n            pass\n        elif choice > 0:\n            self.recall[self.recall_total] = choice - 1\n            self.recall_total += 1\n            self.update_context(\n                self.recall_drift_rate, self.recall_items[choice - 1])\n        else:\n            self.retrieving = False\n            self.context = self.preretrieval_context\n        return self.recall[:self.recall_total]"
  },
  {
    "objectID": "library\\model_analysis\\Alternative_Contiguity_Tracing.html#alternative-contiguity-tracing",
    "href": "library\\model_analysis\\Alternative_Contiguity_Tracing.html#alternative-contiguity-tracing",
    "title": "compmemlearn",
    "section": "Alternative Contiguity Tracing",
    "text": "Fit CMR and InstanceCMR models to condition 4 of lohnas dataset and plot key summary statistics, including repetition effects. (We already do this in another pair of notebooks!). Visualize corresponding memory representations in the models, focusing on lag-connectivity under parameter shifting.\nLay out understanding of how item repetition codetermines model representations and behavior in the canonical and presented trials and why that means no accounting for alternative contiguity (and maybe hopefully also poor accounting for spacing effect).\nTo “prove” understanding, implement transformation of model weights that results in simulation of the alternative contiguity effect.\nRelate these results to CMR’s limitations and potential mechanisms for the transformation that might be implemented within a model.\nfrom compmemlearn.analyses import flex_mixed_spc, flex_mixed_crp, flex_mixed_pfr, fast_csp, alternative_contiguity, fast_rpl\nfrom compmemlearn.datasets import prepare_lohnas2014_data, simulate_array_from_presentations\nfrom compmemlearn.fitting import lohnas_objective_function\nfrom compmemlearn.models import Classic_CMR, Instance_CMR, Trace_Reinstatement_CMR\nfrom compmemlearn.model_analysis import matrix_heatmap, icmr_memory_heatmap, latent_mfc_mcf, connectivity_by_lag, mfc_heatmap\n\nimport numpy as np\nfrom numpy import matlib\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import differential_evolution\n\nfrom numba import njit\nfrom numba import int32\nfrom numba.typed import Dict\nfrom numba.core import types\n\n\nconditions = ['Control', 'Massed', 'Spaced', 'Mixed']\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')"
  },
  {
    "objectID": "library\\model_analysis\\Alternative_Contiguity_Tracing.html#initial-fitting",
    "href": "library\\model_analysis\\Alternative_Contiguity_Tracing.html#initial-fitting",
    "title": "compmemlearn",
    "section": "Initial Fitting",
    "text": "PrototypeCMR\n\ncmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate'\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ncmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\ncondition = 4\nselection = list_types == condition\ncost_function = lohnas_objective_function(\n    trials[selection], \n    presentations[selection],\n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    cmr_free_parameters)\n\ncmr_result = differential_evolution(cost_function, cmr_bounds, disp=True)\n\n\ncmr_result\n\n     fun: 17271.488868401062\n     jac: array([ 4.36193657e-01, -2.87764124e-01,  5.14046403e-01, -3.44880391e-01,\n        2.74860213e+01,  5.78802429e-01,  4.72937248e-03,  0.00000000e+00,\n        2.95767677e-01, -6.92671165e-01, -5.31144909e-02, -7.47240843e-01])\n message: 'Optimization terminated successfully.'\n    nfev: 8861\n     nit: 34\n success: True\n       x: array([8.53866588e-01, 9.01233935e-02, 9.64653634e-01, 3.64986965e-02,\n       2.22044605e-16, 4.60969130e-01, 3.38252088e+00, 3.05443417e+01,\n       2.13921114e-02, 1.06822773e-01, 1.17216059e+00, 9.84763294e-01])\n\n\nexperiment_count = 1000\n\ncmr_fitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\nfor j in range(len(cmr_result.x)):\n    cmr_fitted_parameters[cmr_free_parameters[j]] = cmr_result.x[j]\n    \ncmr_fitted_parameters['sampling_rule'] = 0\ncmr_fitted_parameters['mfc_familiarity_scale'] = 0\ncmr_fitted_parameters['mcf_familiarity_scale'] = 0\ncmr_fitted_parameters['drift_familiarity_scale'] = 0\n\ncmr_trials = simulate_array_from_presentations(\n    init_cmr, cmr_fitted_parameters, presentations[list_types==condition], experiment_count)\ncmr_presentations = np.matlib.repmat(presentations[list_types==condition], experiment_count, 1)\n\nmodel_name = 'PrototypeCMR'\n\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(20, 20), sharey='row')\n\n# spc\ndata_spc= flex_mixed_spc(trials[list_types==condition], presentations[list_types==condition])\ncmr_spc = flex_mixed_spc(cmr_trials, cmr_presentations)\naxes[0, 0].plot(np.arange(len(data_spc)), data_spc, label='Data')\naxes[0, 0].plot(np.arange(len(cmr_spc)), cmr_spc, label=model_name)\naxes[0, 0].set_title('SPC')\n\n# pfr\ndata_pfr = flex_mixed_pfr(trials[list_types==condition], presentations[list_types==condition])\ncmr_pfr = flex_mixed_pfr(cmr_trials, cmr_presentations)\naxes[1, 1].plot(np.arange(len(data_pfr)), data_pfr, label='Data')\naxes[1, 1].plot(np.arange(len(cmr_pfr)), cmr_pfr, label=model_name)\naxes[1, 1].set_title('PFR')\n\n# crp\nlag_range = len(presentations[0])-1\ndata_crp= flex_mixed_crp(trials[list_types==condition], presentations[list_types==condition])\ndata_crp[lag_range] = np.nan\ncmr_crp = flex_mixed_crp(cmr_trials, cmr_presentations)\ncmr_crp[lag_range] = np.nan\naxes[1, 0].plot(np.arange(len(data_crp)), data_crp, label='Data')\naxes[1, 0].plot(np.arange(len(cmr_crp)), cmr_crp, label=model_name)\naxes[1, 0].set_xticks(np.arange(0, len(data_crp), 4))\naxes[1, 0].set_xticklabels(np.arange(0, len(data_crp), 4) - lag_range)\naxes[1, 0].set_title('CRP')\n\n# rpl\ndata_rpl = fast_rpl(\n    trials[list_types==condition], presentations[list_types==condition], max_lag=8)\nbinned = np.zeros(5)\nbinned[0] = data_rpl[0]\nbinned[1] = data_rpl[1]\nbinned[2] = (data_rpl[2] + data_rpl[3])/2\nbinned[3] = (data_rpl[4] + data_rpl[5] + data_rpl[6])/3\nbinned[4] = (data_rpl[7] + data_rpl[8] + data_rpl[9])/3\ndata_rpl = binned.copy()\n\ncmr_rpl = fast_rpl(\n    cmr_trials, cmr_presentations, max_lag=8)\nbinned = np.zeros(5)\nbinned[0] = cmr_rpl[0]\nbinned[1] = cmr_rpl[1]\nbinned[2] = (cmr_rpl[2] + cmr_rpl[3])/2\nbinned[3] = (cmr_rpl[4] + cmr_rpl[5] + cmr_rpl[6])/3\nbinned[4] = (cmr_rpl[7] + cmr_rpl[8] + cmr_rpl[9])/3\ncmr_rpl = binned.copy()\n\naxes[0, 1].plot(np.arange(len(data_rpl)), data_rpl, label='Data')\naxes[0, 1].plot(np.arange(len(cmr_rpl)), cmr_rpl, label=model_name)\naxes[0, 1].set_title('Recall Probability by Lag')\n\n# alt contiguity (data)\ndata_altcrp = alternative_contiguity(\n    trials[list_types==condition], presentations[list_types==condition], 6, 2)\ndata_altcrp[:, lag_range] = np.nan\naxes[2, 0].plot(np.arange(7), data_altcrp[0][lag_range-3:lag_range+4], label='First Presentation')\naxes[2, 0].plot(np.arange(7), data_altcrp[1][lag_range-3:lag_range+4], label='Second Presentation')\naxes[2, 0].set_xticks(np.arange(7))\naxes[2, 0].set_xticklabels(np.arange(7) - 3)\naxes[2, 0].set_title('Repetition Contiguity -- Data')\n\ncmr_altcrp = alternative_contiguity(\n    cmr_trials, cmr_presentations, 6, 2)\ncmr_altcrp[:, lag_range] = np.nan\naxes[2, 1].plot(np.arange(7), cmr_altcrp[0][lag_range-3:lag_range+4], label='First Presentation')\naxes[2, 1].plot(np.arange(7), cmr_altcrp[1][lag_range-3:lag_range+4], label='Second Presentation')\naxes[2, 1].set_xticks(np.arange(7))\naxes[2, 1].set_xticklabels(np.arange(7) - 3)\naxes[2, 1].set_title('Repetition Contiguity -- ' + model_name)\n\naxes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\naxes[2, 1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);\n\n\n\n\n\nmodel_name = 'PrototypeCMR'\n\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 10), sharey='row')\n\n# alt contiguity (data)\ndata_altcrp = alternative_contiguity(\n    trials[list_types==condition], presentations[list_types==condition], 6, 2)\ndata_altcrp[:, lag_range] = np.nan\ncmr_altcrp = alternative_contiguity(\n    cmr_trials, cmr_presentations, 6, 2)\ncmr_altcrp[:, lag_range] = np.nan\n\naxes.plot(np.arange(7), data_altcrp[0][lag_range-3:lag_range+4]-data_altcrp[1][lag_range-3:lag_range+4], label='Data')\naxes.plot(np.arange(7), cmr_altcrp[0][lag_range-3:lag_range+4]-cmr_altcrp[1][lag_range-3:lag_range+4], label=model_name)\naxes.set_xticks(np.arange(7))\naxes.set_xticklabels(np.arange(7) - 3)\naxes.set_title('Positional Contiguity Difference')\n\naxes.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n<matplotlib.legend.Legend at 0x21749473ee0>\n\n\n\n\n\n\n\nInstanceCMR\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nicmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n    'context_sensitivity',\n#    'feature_sensitivity'\n    'delay_drift_rate',\n)\n\nicmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n#    (lb, 10),\n#    (lb, 10)\n    (lb, ub),\n]\n\n@njit(fastmath=True, nogil=True)\ndef init_icmr(item_count, presentation_count, parameters):\n    return Instance_CMR(item_count, presentation_count, parameters)\n\ncondition = 4\nselection = list_types == condition\ncost_function = lohnas_objective_function(\n    trials[selection], \n    presentations[selection],\n    init_icmr,\n    {'choice_sensitivity': 1, 'feature_sensitivity': 1}, \n    icmr_free_parameters)\n\nicmr_result = differential_evolution(cost_function, icmr_bounds, disp=True)\n\ndifferential_evolution step 1: f(x)= 46459.2\ndifferential_evolution step 2: f(x)= 28269\ndifferential_evolution step 3: f(x)= 26437.4\ndifferential_evolution step 4: f(x)= 24436.2\ndifferential_evolution step 5: f(x)= 24436.2\ndifferential_evolution step 6: f(x)= 20687.5\ndifferential_evolution step 7: f(x)= 20080.2\ndifferential_evolution step 8: f(x)= 20065.4\ndifferential_evolution step 9: f(x)= 19693.7\ndifferential_evolution step 10: f(x)= 19693.7\ndifferential_evolution step 11: f(x)= 19620.8\ndifferential_evolution step 12: f(x)= 19620.8\ndifferential_evolution step 13: f(x)= 19620.8\ndifferential_evolution step 14: f(x)= 19620.8\ndifferential_evolution step 15: f(x)= 19578.4\ndifferential_evolution step 16: f(x)= 18942.2\ndifferential_evolution step 17: f(x)= 18942.2\ndifferential_evolution step 18: f(x)= 18942.2\ndifferential_evolution step 19: f(x)= 18207\ndifferential_evolution step 20: f(x)= 18207\ndifferential_evolution step 21: f(x)= 18207\ndifferential_evolution step 22: f(x)= 18207\ndifferential_evolution step 23: f(x)= 18207\ndifferential_evolution step 24: f(x)= 18207\ndifferential_evolution step 25: f(x)= 18066.3\ndifferential_evolution step 26: f(x)= 18066.3\ndifferential_evolution step 27: f(x)= 18066.3\ndifferential_evolution step 28: f(x)= 17823.5\ndifferential_evolution step 29: f(x)= 17823.5\ndifferential_evolution step 30: f(x)= 17823.5\ndifferential_evolution step 31: f(x)= 17675.6\ndifferential_evolution step 32: f(x)= 17675.6\ndifferential_evolution step 33: f(x)= 17675.6\ndifferential_evolution step 34: f(x)= 17675.6\ndifferential_evolution step 35: f(x)= 17675.6\ndifferential_evolution step 36: f(x)= 17675.6\ndifferential_evolution step 37: f(x)= 17675.6\ndifferential_evolution step 38: f(x)= 17517.9\ndifferential_evolution step 39: f(x)= 17517.9\ndifferential_evolution step 40: f(x)= 17517.9\ndifferential_evolution step 41: f(x)= 17517.9\ndifferential_evolution step 42: f(x)= 17517.9\ndifferential_evolution step 43: f(x)= 17471.5\ndifferential_evolution step 44: f(x)= 17471.5\ndifferential_evolution step 45: f(x)= 17471.5\ndifferential_evolution step 46: f(x)= 17454.3\ndifferential_evolution step 47: f(x)= 17454.3\ndifferential_evolution step 48: f(x)= 17416\ndifferential_evolution step 49: f(x)= 17369.9\ndifferential_evolution step 50: f(x)= 17369.9\ndifferential_evolution step 51: f(x)= 17369.9\ndifferential_evolution step 52: f(x)= 17361.7\ndifferential_evolution step 53: f(x)= 17361.7\ndifferential_evolution step 54: f(x)= 17330.1\ndifferential_evolution step 55: f(x)= 17330.1\ndifferential_evolution step 56: f(x)= 17280.6\ndifferential_evolution step 57: f(x)= 17280.6\ndifferential_evolution step 58: f(x)= 17280.6\ndifferential_evolution step 59: f(x)= 17280.6\ndifferential_evolution step 60: f(x)= 17280.6\n\n\n\nicmr_result\n\n     fun: 17221.459000970448\n     jac: array([-34.70595385,  15.63421393,  22.91963017, 306.74091249,\n       -33.19582901,   9.75414878, -11.35013015,   0.        ,\n       -16.64921001,  71.7092917 , -10.55632317, -15.95180939])\n message: 'Optimization terminated successfully.'\n    nfev: 12969\n     nit: 60\n success: True\n       x: array([8.32901225e-01, 2.08116235e-01, 9.60915690e-01, 3.05257500e-04,\n       3.18582949e-02, 1.02883666e-01, 2.14975563e+00, 6.66001243e+01,\n       2.05812661e-02, 1.09385203e-01, 1.35697460e+00, 9.42731805e-01])\n\n\nexperiment_count = 1000\n\nicmr_fitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\nfor j in range(len(icmr_result.x)):\n    icmr_fitted_parameters[icmr_free_parameters[j]] = icmr_result.x[j]\n    \nicmr_fitted_parameters['choice_sensitivity'] = 1\nicmr_fitted_parameters['feature_sensitivity'] = 1\n\nicmr_trials = simulate_array_from_presentations(\n    init_icmr, icmr_fitted_parameters, presentations[list_types==condition], experiment_count)\nicmr_presentations = np.matlib.repmat(presentations[list_types==condition], experiment_count, 1)\n\nmodel_name = 'InstanceCMR'\n\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(20, 20), sharey='row')\n\n# spc\ndata_spc= flex_mixed_spc(trials[list_types==condition], presentations[list_types==condition])\nicmr_spc = flex_mixed_spc(icmr_trials, icmr_presentations)\naxes[0, 0].plot(np.arange(len(data_spc)), data_spc, label='Data')\naxes[0, 0].plot(np.arange(len(icmr_spc)), icmr_spc, label=model_name)\naxes[0, 0].set_title('SPC')\n\n# pfr\ndata_pfr = flex_mixed_pfr(trials[list_types==condition], presentations[list_types==condition])\nicmr_pfr = flex_mixed_pfr(icmr_trials, icmr_presentations)\naxes[1, 1].plot(np.arange(len(data_pfr)), data_pfr, label='Data')\naxes[1, 1].plot(np.arange(len(icmr_pfr)), icmr_pfr, label=model_name)\naxes[1, 1].set_title('PFR')\n\n# crp\nlag_range = len(presentations[0])-1\ndata_crp= flex_mixed_crp(trials[list_types==condition], presentations[list_types==condition])\ndata_crp[lag_range] = np.nan\nicmr_crp = flex_mixed_crp(icmr_trials, icmr_presentations)\nicmr_crp[lag_range] = np.nan\naxes[1, 0].plot(np.arange(len(data_crp)), data_crp, label='Data')\naxes[1, 0].plot(np.arange(len(icmr_crp)), icmr_crp, label=model_name)\naxes[1, 0].set_xticks(np.arange(0, len(data_crp), 4))\naxes[1, 0].set_xticklabels(np.arange(0, len(data_crp), 4) - lag_range)\naxes[1, 0].set_title('CRP')\n\n# rpl\ndata_rpl = fast_rpl(\n    trials[list_types==condition], presentations[list_types==condition], max_lag=8)\nbinned = np.zeros(5)\nbinned[0] = data_rpl[0]\nbinned[1] = data_rpl[1]\nbinned[2] = (data_rpl[2] + data_rpl[3])/2\nbinned[3] = (data_rpl[4] + data_rpl[5] + data_rpl[6])/3\nbinned[4] = (data_rpl[7] + data_rpl[8] + data_rpl[9])/3\ndata_rpl = binned.copy()\n\nicmr_rpl = fast_rpl(\n    icmr_trials, icmr_presentations, max_lag=8)\nbinned = np.zeros(5)\nbinned[0] = icmr_rpl[0]\nbinned[1] = icmr_rpl[1]\nbinned[2] = (icmr_rpl[2] + icmr_rpl[3])/2\nbinned[3] = (icmr_rpl[4] + icmr_rpl[5] + icmr_rpl[6])/3\nbinned[4] = (icmr_rpl[7] + icmr_rpl[8] + icmr_rpl[9])/3\nicmr_rpl = binned.copy()\n\naxes[0, 1].plot(np.arange(len(data_rpl)), data_rpl, label='Data')\naxes[0, 1].plot(np.arange(len(icmr_rpl)), icmr_rpl, label=model_name)\naxes[0, 1].set_title('Recall Probability by Lag')\n\n# alt contiguity (data)\ndata_altcrp = alternative_contiguity(\n    trials[list_types==condition], presentations[list_types==condition], 6, 2)\ndata_altcrp[:, lag_range] = np.nan\naxes[2, 0].plot(np.arange(7), data_altcrp[0][lag_range-3:lag_range+4], label='First Presentation')\naxes[2, 0].plot(np.arange(7), data_altcrp[1][lag_range-3:lag_range+4], label='Second Presentation')\naxes[2, 0].set_xticks(np.arange(7))\naxes[2, 0].set_xticklabels(np.arange(7) - 3)\naxes[2, 0].set_title('Repetition Contiguity -- Data')\n\nicmr_altcrp = alternative_contiguity(\n    icmr_trials, icmr_presentations, 6, 2)\nicmr_altcrp[:, lag_range] = np.nan\naxes[2, 1].plot(np.arange(7), icmr_altcrp[0][lag_range-3:lag_range+4], label='First Presentation')\naxes[2, 1].plot(np.arange(7), icmr_altcrp[1][lag_range-3:lag_range+4], label='Second Presentation')\naxes[2, 1].set_xticks(np.arange(7))\naxes[2, 1].set_xticklabels(np.arange(7) - 3)\naxes[2, 1].set_title('Repetition Contiguity -- ' + model_name)\n\naxes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\naxes[2, 1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);\n\n\n\n\n\n\nTrace_Reinstatement_CMR\n# remember to run nbdev_build_lib first! \n\nimport compmemlearn\nimport importlib\nimportlib.reload(compmemlearn.models)\nfrom compmemlearn.models import Trace_Reinstatement_CMR\n\ntrcmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n    'context_sensitivity',\n#    'feature_sensitivity'\n    'delay_drift_rate',\n    'context_reinstatement'\n)\n\ntrcmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n#    (lb, 10),\n#    (lb, 10)\n    (lb, ub),\n    (1, 10)\n]\n\n@njit(fastmath=True, nogil=True)\ndef init_trcmr(item_count, presentation_count, parameters):\n    return Trace_Reinstatement_CMR(item_count, presentation_count, parameters)\n\ncondition = 4\nselection = list_types == condition\ncost_function = lohnas_objective_function(\n    trials[selection], \n    presentations[selection],\n    init_trcmr,\n    {'choice_sensitivity': 1, 'feature_sensitivity': 1}, \n    trcmr_free_parameters)\n\n# will throw error if i haven't already fitted\nprint(init_trcmr(20, 20, trcmr_fitted_parameters).items[0]) # to maybe avoid weird fitting failure -- we'll see if it works\n\n\n[0.         0.02499219 0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.99968765\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.        ]\n\n\n\ntrcmr_result = differential_evolution(cost_function, trcmr_bounds, disp=True)\ntrcmr_result\n\ndifferential_evolution step 1: f(x)= 38770.8\ndifferential_evolution step 2: f(x)= 31970\ndifferential_evolution step 3: f(x)= 28471.3\ndifferential_evolution step 4: f(x)= 20224.9\ndifferential_evolution step 5: f(x)= 20053.9\ndifferential_evolution step 6: f(x)= 19901.2\ndifferential_evolution step 7: f(x)= 19746.1\ndifferential_evolution step 8: f(x)= 19671.3\ndifferential_evolution step 9: f(x)= 19671.3\ndifferential_evolution step 10: f(x)= 19671.3\ndifferential_evolution step 11: f(x)= 19671.3\ndifferential_evolution step 12: f(x)= 19671.3\ndifferential_evolution step 13: f(x)= 19654.2\ndifferential_evolution step 14: f(x)= 19625.7\ndifferential_evolution step 15: f(x)= 19574.9\ndifferential_evolution step 16: f(x)= 19574.9\ndifferential_evolution step 17: f(x)= 19574.9\ndifferential_evolution step 18: f(x)= 19574.9\ndifferential_evolution step 19: f(x)= 19574.9\ndifferential_evolution step 20: f(x)= 19373.8\ndifferential_evolution step 21: f(x)= 19373.8\ndifferential_evolution step 22: f(x)= 19373.8\ndifferential_evolution step 23: f(x)= 19373.8\ndifferential_evolution step 24: f(x)= 19373.8\ndifferential_evolution step 25: f(x)= 19373.8\ndifferential_evolution step 26: f(x)= 19373.8\ndifferential_evolution step 27: f(x)= 19373.8\ndifferential_evolution step 28: f(x)= 19373.8\ndifferential_evolution step 29: f(x)= 19373.8\ndifferential_evolution step 30: f(x)= 18841.3\n\n\n     fun: 17059.651290065947\n     jac: array([-3.95208188e+01, -4.22016456e+01, -1.21831908e+02,  5.78427716e+01,\n       -1.35005394e+00,  1.87246768e+00, -1.51703717e-01,  0.00000000e+00,\n       -8.20444256e+01,  1.97843110e+02,  1.71508874e+01, -6.52773448e+02,\n       -6.14309105e+00])\n message: 'Optimization terminated successfully.'\n    nfev: 12317\n     nit: 30\n success: True\n       x: array([8.32287621e-01, 6.19383237e-03, 9.14802390e-01, 6.03601368e-03,\n       3.49635680e-01, 7.39360206e-01, 2.72092798e+00, 4.64522241e+01,\n       1.91378214e-02, 1.14005522e-01, 2.29533351e+00, 9.99988823e-01,\n       5.73518735e+00])\n\n\n\nWith Maxed Out Context Reinstatement\n\nexperiment_count = 1000\n\ntrcmr_fitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\nfor j in range(len(trcmr_result.x)):\n    trcmr_fitted_parameters[trcmr_free_parameters[j]] = trcmr_result.x[j]\n    \ntrcmr_fitted_parameters['choice_sensitivity'] = 1\ntrcmr_fitted_parameters['feature_sensitivity'] = 1\ntrcmr_fitted_parameters['context_reinstatement'] = 40 # hack to drive alternative contiguity effect\n\n# will throw error if i haven't already fitted\nprint(init_trcmr(20, 20, trcmr_fitted_parameters).items[0]) # to maybe avoid weird fitting failure -- we'll see if it works\n\ntrcmr_trials = simulate_array_from_presentations(\n    init_trcmr, trcmr_fitted_parameters, presentations[list_types==condition], experiment_count)\ntrcmr_presentations = np.matlib.repmat(presentations[list_types==condition], experiment_count, 1)\n\nmodel_name = 'Trace Reinstatement CMR'\n\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(20, 20), sharey='row')\n\n# spc\ndata_spc= flex_mixed_spc(trials[list_types==condition], presentations[list_types==condition])\ntrcmr_spc = flex_mixed_spc(trcmr_trials, trcmr_presentations)\naxes[0, 0].plot(np.arange(len(data_spc)), data_spc, label='Data')\naxes[0, 0].plot(np.arange(len(trcmr_spc)), trcmr_spc, label=model_name)\naxes[0, 0].set_title('SPC')\n\n# pfr\ndata_pfr = flex_mixed_pfr(trials[list_types==condition], presentations[list_types==condition])\ntrcmr_pfr = flex_mixed_pfr(trcmr_trials, trcmr_presentations)\naxes[1, 1].plot(np.arange(len(data_pfr)), data_pfr, label='Data')\naxes[1, 1].plot(np.arange(len(trcmr_pfr)), trcmr_pfr, label=model_name)\naxes[1, 1].set_title('PFR')\n\n# crp\nlag_range = len(presentations[0])-1\ndata_crp= flex_mixed_crp(trials[list_types==condition], presentations[list_types==condition])\ndata_crp[lag_range] = np.nan\ntrcmr_crp = flex_mixed_crp(trcmr_trials, trcmr_presentations)\ntrcmr_crp[lag_range] = np.nan\naxes[1, 0].plot(np.arange(len(data_crp)), data_crp, label='Data')\naxes[1, 0].plot(np.arange(len(trcmr_crp)), trcmr_crp, label=model_name)\naxes[1, 0].set_xticks(np.arange(0, len(data_crp), 4))\naxes[1, 0].set_xticklabels(np.arange(0, len(data_crp), 4) - lag_range)\naxes[1, 0].set_title('CRP')\n\n# rpl\ndata_rpl = fast_rpl(\n    trials[list_types==condition], presentations[list_types==condition], max_lag=8)\nbinned = np.zeros(5)\nbinned[0] = data_rpl[0]\nbinned[1] = data_rpl[1]\nbinned[2] = (data_rpl[2] + data_rpl[3])/2\nbinned[3] = (data_rpl[4] + data_rpl[5] + data_rpl[6])/3\nbinned[4] = (data_rpl[7] + data_rpl[8] + data_rpl[9])/3\ndata_rpl = binned.copy()\n\ntrcmr_rpl = fast_rpl(\n    trcmr_trials, trcmr_presentations, max_lag=8)\nbinned = np.zeros(5)\nbinned[0] = trcmr_rpl[0]\nbinned[1] = trcmr_rpl[1]\nbinned[2] = (trcmr_rpl[2] + trcmr_rpl[3])/2\nbinned[3] = (trcmr_rpl[4] + trcmr_rpl[5] + trcmr_rpl[6])/3\nbinned[4] = (trcmr_rpl[7] + trcmr_rpl[8] + trcmr_rpl[9])/3\ntrcmr_rpl = binned.copy()\n\naxes[0, 1].plot(np.arange(len(data_rpl)), data_rpl, label='Data')\naxes[0, 1].plot(np.arange(len(trcmr_rpl)), trcmr_rpl, label=model_name)\naxes[0, 1].set_title('Recall Probability by Lag')\n\n# alt contiguity (data)\ndata_altcrp = alternative_contiguity(\n    trials[list_types==condition], presentations[list_types==condition], 6, 2)\ndata_altcrp[:, lag_range] = np.nan\naxes[2, 0].plot(np.arange(7), data_altcrp[0][lag_range-3:lag_range+4], label='First Presentation')\naxes[2, 0].plot(np.arange(7), data_altcrp[1][lag_range-3:lag_range+4], label='Second Presentation')\naxes[2, 0].set_xticks(np.arange(7))\naxes[2, 0].set_xticklabels(np.arange(7) - 3)\naxes[2, 0].set_title('Repetition Contiguity -- Data')\n\ntrcmr_altcrp = alternative_contiguity(\n    trcmr_trials, trcmr_presentations, 6, 2)\ntrcmr_altcrp[:, lag_range] = np.nan\naxes[2, 1].plot(np.arange(7), trcmr_altcrp[0][lag_range-3:lag_range+4], label='First Presentation')\naxes[2, 1].plot(np.arange(7), trcmr_altcrp[1][lag_range-3:lag_range+4], label='Second Presentation')\naxes[2, 1].set_xticks(np.arange(7))\naxes[2, 1].set_xticklabels(np.arange(7) - 3)\naxes[2, 1].set_title('Repetition Contiguity -- ' + model_name)\n\naxes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\naxes[2, 1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);\n\n[0.         0.02499219 0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.99968765\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.        ]\n\n\n\n\n\n\n\nWith Parametrized Amount\n\nexperiment_count = 1000\n\ntrcmr_fitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\nfor j in range(len(trcmr_result.x)):\n    trcmr_fitted_parameters[trcmr_free_parameters[j]] = trcmr_result.x[j]\n    \ntrcmr_fitted_parameters['choice_sensitivity'] = 1\ntrcmr_fitted_parameters['feature_sensitivity'] = 1\n\n# will throw error if i haven't already fitted\nprint(init_trcmr(20, 20, trcmr_fitted_parameters).items[0]) # to maybe avoid weird fitting failure -- we'll see if it works\n\ntrcmr_trials = simulate_array_from_presentations(\n    init_trcmr, trcmr_fitted_parameters, presentations[list_types==condition], experiment_count)\ntrcmr_presentations = np.matlib.repmat(presentations[list_types==condition], experiment_count, 1)\n\n[0.         0.17177067 0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.98513696\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.        ]\n\n\n\nmodel_name = 'Trace Reinstatement CMR'\n\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(20, 20), sharey='row')\n\n# spc\ndata_spc= flex_mixed_spc(trials[list_types==condition], presentations[list_types==condition])\ntrcmr_spc = flex_mixed_spc(trcmr_trials, trcmr_presentations)\naxes[0, 0].plot(np.arange(len(data_spc)), data_spc, label='Data')\naxes[0, 0].plot(np.arange(len(trcmr_spc)), trcmr_spc, label=model_name)\naxes[0, 0].set_title('SPC')\n\n# pfr\ndata_pfr = flex_mixed_pfr(trials[list_types==condition], presentations[list_types==condition])\ntrcmr_pfr = flex_mixed_pfr(trcmr_trials, trcmr_presentations)\naxes[1, 1].plot(np.arange(len(data_pfr)), data_pfr, label='Data')\naxes[1, 1].plot(np.arange(len(trcmr_pfr)), trcmr_pfr, label=model_name)\naxes[1, 1].set_title('PFR')\n\n# crp\nlag_range = len(presentations[0])-1\ndata_crp= flex_mixed_crp(trials[list_types==condition], presentations[list_types==condition])\ndata_crp[lag_range] = np.nan\ntrcmr_crp = flex_mixed_crp(trcmr_trials, trcmr_presentations)\ntrcmr_crp[lag_range] = np.nan\naxes[1, 0].plot(np.arange(len(data_crp)), data_crp, label='Data')\naxes[1, 0].plot(np.arange(len(trcmr_crp)), trcmr_crp, label=model_name)\naxes[1, 0].set_xticks(np.arange(0, len(data_crp), 4))\naxes[1, 0].set_xticklabels(np.arange(0, len(data_crp), 4) - lag_range)\naxes[1, 0].set_title('CRP')\n\n# rpl\ndata_rpl = fast_rpl(\n    trials[list_types==condition], presentations[list_types==condition], max_lag=8)\nbinned = np.zeros(5)\nbinned[0] = data_rpl[0]\nbinned[1] = data_rpl[1]\nbinned[2] = (data_rpl[2] + data_rpl[3])/2\nbinned[3] = (data_rpl[4] + data_rpl[5] + data_rpl[6])/3\nbinned[4] = (data_rpl[7] + data_rpl[8] + data_rpl[9])/3\ndata_rpl = binned.copy()\n\ntrcmr_rpl = fast_rpl(\n    trcmr_trials, trcmr_presentations, max_lag=8)\nbinned = np.zeros(5)\nbinned[0] = trcmr_rpl[0]\nbinned[1] = trcmr_rpl[1]\nbinned[2] = (trcmr_rpl[2] + trcmr_rpl[3])/2\nbinned[3] = (trcmr_rpl[4] + trcmr_rpl[5] + trcmr_rpl[6])/3\nbinned[4] = (trcmr_rpl[7] + trcmr_rpl[8] + trcmr_rpl[9])/3\ntrcmr_rpl = binned.copy()\n\naxes[0, 1].plot(np.arange(len(data_rpl)), data_rpl, label='Data')\naxes[0, 1].plot(np.arange(len(trcmr_rpl)), trcmr_rpl, label=model_name)\naxes[0, 1].set_title('Recall Probability by Lag')\n\n# alt contiguity (data)\ndata_altcrp = alternative_contiguity(\n    trials[list_types==condition], presentations[list_types==condition], 6, 2)\ndata_altcrp[:, lag_range] = np.nan\naxes[2, 0].plot(np.arange(7), data_altcrp[0][lag_range-3:lag_range+4], label='First Presentation')\naxes[2, 0].plot(np.arange(7), data_altcrp[1][lag_range-3:lag_range+4], label='Second Presentation')\naxes[2, 0].set_xticks(np.arange(7))\naxes[2, 0].set_xticklabels(np.arange(7) - 3)\naxes[2, 0].set_title('Repetition Contiguity -- Data')\n\ntrcmr_altcrp = alternative_contiguity(\n    trcmr_trials, trcmr_presentations, 6, 2)\ntrcmr_altcrp[:, lag_range] = np.nan\naxes[2, 1].plot(np.arange(7), trcmr_altcrp[0][lag_range-3:lag_range+4], label='First Presentation')\naxes[2, 1].plot(np.arange(7), trcmr_altcrp[1][lag_range-3:lag_range+4], label='Second Presentation')\naxes[2, 1].set_xticks(np.arange(7))\naxes[2, 1].set_xticklabels(np.arange(7) - 3)\naxes[2, 1].set_title('Repetition Contiguity -- ' + model_name)\n\naxes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\naxes[2, 1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);"
  },
  {
    "objectID": "library\\model_analysis\\Alternative_Contiguity_Tracing.html#lag-connectivity",
    "href": "library\\model_analysis\\Alternative_Contiguity_Tracing.html#lag-connectivity",
    "title": "compmemlearn",
    "section": "Lag-Connectivity",
    "text": "To begin our analysis of model representations underlying this effect, we’ll develop an extension of the lag-connectivity analysis that tracks whether our memory representations similarly disfavor the repetition contiguity effect.\nWe’ll simulate each study sequence presented in the study. After each simulation, we’ll identify items that were presented repeatedly with some minimum spacing between repetitions (usually 6). Then we’ll track for lags in range [-3, 3] from each study position the mean connection weight between the focused item and item at the corresponding lag.\n\nFunctions\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef matrix_heatmap(matrix, title='', figsize=(15, 15), savefig=False, axis=None):\n    \"\"\"\n\n    **Arguments**:  \n    - matrix: an array of model states, ideally with columns representing unique feature indices and rows\n        representing unique update indices  \n    - title: a title for the generated plot, ideally conveying what array values represent at each entry  \n    - savefig: boolean deciding whether generated figure is saved (True if Yes)\n    \"\"\"\n    plt.figure(figsize=figsize)\n    sns.heatmap(matrix, annot=True, linewidths=.5, ax=axis)\n    plt.title(title)\n    plt.xlabel('Feature Index')\n    plt.ylabel('Update Index')\n    if savefig:\n        plt.savefig('figures/{}.jpeg'.format(title).replace(' ', '_').lower(), bbox_inches='tight')\n    plt.show()\n\ndef icmr_memory_heatmap(model, just_experimental=False, just_context=False):\n    memory_shape = np.shape(model.memory)\n    fig_size = list(reversed(memory_shape))\n    plotted_memory = model.memory.copy()\n    title = \"Memory Traces\"\n\n    if just_context:\n        fig_size[0] /= 2\n        plotted_memory = plotted_memory[:, int(memory_shape[1]/2):]\n        title = \"Contextual \" + title\n\n    if just_experimental:\n        fig_size[1] -= model.item_count\n        plotted_memory = plotted_memory[model.item_count:]\n        title = \"Experimental \" + title\n\n\n    matrix_heatmap(plotted_memory, title, figsize=fig_size)\n    \ndef mixed_connectivity_by_lag(item_connections, presentation):\n    item_count = np.max(presentation)+1\n    lag_range = len(presentation) - 1\n    total_connectivity = np.zeros(lag_range * 2 + 1)\n    total_possible_lags = np.zeros(lag_range * 2 + 1)\n    item_positions = np.arange(len(presentation), dtype=int)\n\n    for item in range(item_count):\n\n        # only consider items that are repeated\n        current_positions = np.nonzero(presentation == item)[0]\n\n        # we consider each study position of repeated items separately\n        for position_index in range(len(current_positions)):\n\n            # lag of each item from current item is item_positions - current_position, \n            # and will always be in range [-lag_range, lag_range] so we keep position by adding lag_range\n            item_lags = item_positions - current_positions[position_index] + lag_range\n            total_connectivity[item_lags[presentation != item]] += item_connections[item, presentation[presentation != item]]\n            total_possible_lags[item_lags[presentation != item]] += 1\n\n    # divide by possible lags to get average connectivity\n    total_possible_lags[total_connectivity == 0] += 1\n    connectivity = total_connectivity / total_possible_lags\n    return connectivity\n\ndef alternative_connectivity_by_lag(item_connections, presentation, minimum_lag=6, max_repeats=2):\n\n    item_count = np.max(presentation)+1\n    lag_range = len(presentation) - 1\n    total_connectivity = np.zeros((max_repeats, lag_range * 2 + 1))\n    total_possible_lags = np.zeros((max_repeats, lag_range * 2 + 1))\n    item_positions = np.arange(len(presentation), dtype=int)\n\n    for item in range(item_count):\n\n        # only consider items that are repeated\n        current_positions = np.nonzero(presentation == item)[0]\n        if len(current_positions) < max_repeats:\n            continue\n\n        # only consider items with repeats of lag >= minimum_lag\n        assert(current_positions[1] > current_positions[0])\n        if current_positions[1] - current_positions[0] < minimum_lag:\n            continue\n\n        # we consider each study position of repeated items separately\n        for position_index in range(max_repeats):\n\n            # lag of each item from current item is item_positions - current_position, \n            # and will always be in range [-lag_range, lag_range] so we keep position by adding lag_range\n            item_lags = item_positions - current_positions[position_index] + lag_range\n            total_connectivity[position_index, item_lags] += item_connections[item, presentation]\n            total_possible_lags[position_index, item_lags] += 1\n\n    # divide by possible lags to get average connectivity\n    total_possible_lags[total_connectivity == 0] += 1\n    connectivity = total_connectivity / total_possible_lags\n    return connectivity\n\n\nInstanceCMR\n\n# configure parameters\nmodel_class = Instance_CMR\nmodel_parameters = icmr_fitted_parameters\n\n# track results\nglobal_lag_range = 39\n\nfor list_type in [1, 2, 3, 4]:\n    mfc_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mcf_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n\n    # loop through presentations\n    for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n        # simulate list study\n        item_count = np.max(presentation)+1\n        model = model_class(item_count, len(presentation), model_parameters)\n        model.experience(model.items[presentation])\n        lag_range = item_count+1\n\n        # extract item connections\n        if model_class.__name__ == 'Classic_CMR':\n            mfc_connections = model.mfc[:, 1:-1]\n            mcf_connections = model.mcf[1:-1, :]\n        else:\n            latent_mfc, latent_mcf = latent_mfc_mcf(model)\n            mfc_connections = latent_mfc[:, 1:-1]\n            mcf_connections = latent_mcf[:, 1:-1]\n\n        # track alternative connectivity\n        mfc_alternative_connectivities[0] += mixed_connectivity_by_lag(mfc_connections, presentation)\n        mcf_alternative_connectivities[0] += mixed_connectivity_by_lag(mcf_connections, presentation)\n        #mfc_alternative_connectivities += alternative_connectivity_by_lag(mfc_connections, presentation)[:, lag_range-3:lag_range+4]\n        #mcf_alternative_connectivities += alternative_connectivity_by_lag(mcf_connections, presentation)[:, lag_range-3:lag_range+4]\n\n    # reduce sum to mean\n    mfc_alternative_connectivity = mfc_alternative_connectivities / (trial_index+1)\n    mcf_alternative_connectivity = mcf_alternative_connectivities / (trial_index+1)\n    mfc_alternative_connectivity[:, global_lag_range] = np.nan\n    mcf_alternative_connectivity[:, global_lag_range] = np.nan\n\n    # plot results\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 20/2), sharey=True)\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[0])), mcf_alternative_connectivity[0], label='First Presentation')\n    #axes[0].plot(np.arange(len(mcf_alternative_connectivity[1])), mcf_alternative_connectivity[1], label='Second Presentation')\n    axes[0].set_xticks(np.arange(0, global_lag_range * 2 + 1, 2))\n    axes[0].set_xticklabels(np.arange(0, global_lag_range * 2 + 1, 2) - global_lag_range)\n    axes[0].set_title('MCF')\n\n    # same for MFC\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[0])), mfc_alternative_connectivity[0], label='First Presentation')\n    #axes[1].plot(np.arange(len(mfc_alternative_connectivity[1])), mfc_alternative_connectivity[1], label='Second Presentation')\n    axes[1].set_xticks(np.arange(0, global_lag_range * 2 + 1, 2))\n    axes[1].set_xticklabels(np.arange(0, global_lag_range * 2 + 1, 2) - global_lag_range)\n    axes[1].set_title('MFC')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassic CMR\n\n# configure parameters\nmodel_class = Classic_CMR\nmodel_parameters = cmr_fitted_parameters\n\n# track results\nglobal_lag_range = 39\n\nfor list_type in [1, 2, 3, 4]:\n    mfc_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mcf_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n\n    # loop through presentations\n    for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n        # simulate list study\n        item_count = np.max(presentation)+1\n        model = model_class(item_count, len(presentation), model_parameters)\n        model.experience(model.items[presentation])\n        lag_range = item_count+1\n\n        # extract item connections\n        if model_class.__name__ == 'Classic_CMR':\n            mfc_connections = model.mfc[:, 1:-1]\n            mcf_connections = model.mcf[1:-1, :]\n        else:\n            latent_mfc, latent_mcf = latent_mfc_mcf(model)\n            mfc_connections = latent_mfc[:, 1:-1]\n            mcf_connections = latent_mcf[:, 1:-1]\n\n        # track alternative connectivity\n        mfc_alternative_connectivities[0] += mixed_connectivity_by_lag(mfc_connections, presentation)\n        mcf_alternative_connectivities[0] += mixed_connectivity_by_lag(mcf_connections, presentation)\n        #mfc_alternative_connectivities += alternative_connectivity_by_lag(mfc_connections, presentation)[:, lag_range-3:lag_range+4]\n        #mcf_alternative_connectivities += alternative_connectivity_by_lag(mcf_connections, presentation)[:, lag_range-3:lag_range+4]\n\n    # reduce sum to mean\n    mfc_alternative_connectivity = mfc_alternative_connectivities / (trial_index+1)\n    mcf_alternative_connectivity = mcf_alternative_connectivities / (trial_index+1)\n    mfc_alternative_connectivity[:, global_lag_range] = np.nan\n    mcf_alternative_connectivity[:, global_lag_range] = np.nan\n\n    # plot results\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 20/2), sharey=True)\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[0])), mcf_alternative_connectivity[0], label='First Presentation')\n    #axes[0].plot(np.arange(len(mcf_alternative_connectivity[1])), mcf_alternative_connectivity[1], label='Second Presentation')\n    axes[0].set_xticks(np.arange(0, global_lag_range * 2 + 1, 2))\n    axes[0].set_xticklabels(np.arange(0, global_lag_range * 2 + 1, 2) - global_lag_range)\n    axes[0].set_title('MCF')\n\n    # same for MFC\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[0])), mfc_alternative_connectivity[0], label='First Presentation')\n    #axes[1].plot(np.arange(len(mfc_alternative_connectivity[1])), mfc_alternative_connectivity[1], label='Second Presentation')\n    axes[1].set_xticks(np.arange(0, global_lag_range * 2 + 1, 2))\n    axes[1].set_xticklabels(np.arange(0, global_lag_range * 2 + 1, 2) - global_lag_range)\n    axes[1].set_title('MFC')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTR-CMR\n\n# configure parameters\nmodel_class = Trace_Reinstatement_CMR\nmodel_parameters = trcmr_fitted_parameters\n\n# track results\nglobal_lag_range = 39\n\nfor list_type in [1, 2, 3, 4]:\n    mfc_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mcf_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n\n    # loop through presentations\n    for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n        # simulate list study\n        item_count = np.max(presentation)+1\n        model = model_class(item_count, len(presentation), model_parameters)\n        model.experience(model.items[presentation])\n        lag_range = item_count+1\n\n        # extract item connections\n        if model_class.__name__ == 'Classic_CMR':\n            mfc_connections = model.mfc[:, 1:-1]\n            mcf_connections = model.mcf[1:-1, :]\n        else:\n            latent_mfc, latent_mcf = latent_mfc_mcf(model)\n            mfc_connections = latent_mfc[:, 1:-1]\n            mcf_connections = latent_mcf[:, 1:-1]\n\n        # track alternative connectivity\n        mfc_alternative_connectivities[0] += mixed_connectivity_by_lag(mfc_connections, presentation)\n        mcf_alternative_connectivities[0] += mixed_connectivity_by_lag(mcf_connections, presentation)\n        #mfc_alternative_connectivities += alternative_connectivity_by_lag(mfc_connections, presentation)[:, lag_range-3:lag_range+4]\n        #mcf_alternative_connectivities += alternative_connectivity_by_lag(mcf_connections, presentation)[:, lag_range-3:lag_range+4]\n\n    # reduce sum to mean\n    mfc_alternative_connectivity = mfc_alternative_connectivities / (trial_index+1)\n    mcf_alternative_connectivity = mcf_alternative_connectivities / (trial_index+1)\n    mfc_alternative_connectivity[:, global_lag_range] = np.nan\n    mcf_alternative_connectivity[:, global_lag_range] = np.nan\n\n    # plot results\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 20/2), sharey=True)\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[0])), mcf_alternative_connectivity[0], label='First Presentation')\n    #axes[0].plot(np.arange(len(mcf_alternative_connectivity[1])), mcf_alternative_connectivity[1], label='Second Presentation')\n    axes[0].set_xticks(np.arange(0, global_lag_range * 2 + 1, 2))\n    axes[0].set_xticklabels(np.arange(0, global_lag_range * 2 + 1, 2) - global_lag_range)\n    axes[0].set_title('MCF')\n\n    # same for MFC\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[0])), mfc_alternative_connectivity[0], label='First Presentation')\n    #axes[1].plot(np.arange(len(mfc_alternative_connectivity[1])), mfc_alternative_connectivity[1], label='Second Presentation')\n    axes[1].set_xticks(np.arange(0, global_lag_range * 2 + 1, 2))\n    axes[1].set_xticklabels(np.arange(0, global_lag_range * 2 + 1, 2) - global_lag_range)\n    axes[1].set_title('MFC')"
  },
  {
    "objectID": "library\\model_analysis\\Alternative_Contiguity_Tracing.html#alternative-lag-connectivity",
    "href": "library\\model_analysis\\Alternative_Contiguity_Tracing.html#alternative-lag-connectivity",
    "title": "compmemlearn",
    "section": "Alternative Lag-Connectivity",
    "text": "InstanceCMR\n\n# configure parameters\nmodel_class = Instance_CMR\nmodel_parameters = icmr_fitted_parameters\n\n# track results\nglobal_lag_range = 39\n\nfor list_type in [4]:\n    mfc_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mcf_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n\n    # loop through presentations\n    for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n        # simulate list study\n        item_count = np.max(presentation)+1\n        model = model_class(item_count, len(presentation), model_parameters)\n        model.experience(model.items[presentation])\n\n        # extract item connections\n        if model_class.__name__ == 'Classic_CMR':\n            mfc_connections = model.mfc[:, 1:-1]\n            mcf_connections = model.mcf[1:-1, :]\n            if trial_index == 0:\n                mfc_heatmap(model.mfc)\n                mfc_heatmap(model.mcf)\n                print(presentation)\n        else:\n            latent_mfc, latent_mcf = latent_mfc_mcf(model)\n            mfc_connections = latent_mfc[:, 1:-1]\n            mcf_connections = latent_mcf[:, 1:-1]\n            if trial_index == 0:\n                icmr_memory_heatmap(model, just_experimental=True, just_context=True)\n                print(presentation)\n\n        # track alternative connectivity\n        mfc_alternative_connectivities += alternative_connectivity_by_lag(mfc_connections, presentation)\n        mcf_alternative_connectivities += alternative_connectivity_by_lag(mcf_connections, presentation)\n\n    # reduce sum to mean\n    mfc_alternative_connectivity = mfc_alternative_connectivities / (trial_index+1)\n    mcf_alternative_connectivity = mcf_alternative_connectivities / (trial_index+1)\n    mfc_alternative_connectivity[:, global_lag_range] = np.nan\n    mcf_alternative_connectivity[:, global_lag_range] = np.nan\n\n    # focus on +/- 3 lags\n    plotting_lag_range = 5\n    mfc_alternative_connectivity = mfc_alternative_connectivity[:, global_lag_range-plotting_lag_range:global_lag_range+plotting_lag_range+1]\n    mcf_alternative_connectivity = mcf_alternative_connectivity[:, global_lag_range-plotting_lag_range:global_lag_range+plotting_lag_range+1]\n\n    # plot results\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 20/2), sharey=False)\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[0])), mcf_alternative_connectivity[0], label='First Presentation')\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[1])), mcf_alternative_connectivity[1], label='Second Presentation')\n    axes[0].set_xticks(np.arange(0, plotting_lag_range * 2 + 1, 2))\n    axes[0].set_xticklabels(np.arange(0, plotting_lag_range * 2 + 1, 2) - plotting_lag_range)\n    axes[0].set_title('MCF')\n\n    # same for MFC\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[0])), mfc_alternative_connectivity[0], label='First Presentation')\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[1])), mfc_alternative_connectivity[1], label='Second Presentation')\n    axes[1].set_xticks(np.arange(0, plotting_lag_range * 2 + 1, 2))\n    axes[1].set_xticklabels(np.arange(0, plotting_lag_range * 2 + 1, 2) - plotting_lag_range)\n    axes[1].set_title('MFC')\n\n\n\n\n[ 0  1  2  3  4  5  6  7  8  9 10 11 11 12 13 14 15 16  9 17 18 19 18 20\n 21 22 19 23 24 25 21 26 27 23 28 29 30 31 32 33]\n\n\n\n\n\n\n\nClassic CMR\n\n# configure parameters\nmodel_class = Classic_CMR\nmodel_parameters = cmr_fitted_parameters\n\n# track results\nglobal_lag_range = 39\n\nfor list_type in [4]:\n    mfc_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mcf_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n\n    # loop through presentations\n    for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n        # simulate list study\n        item_count = np.max(presentation)+1\n        model = model_class(item_count, len(presentation), model_parameters)\n        model.experience(model.items[presentation])\n\n        # extract item connections\n        if model_class.__name__ == 'Classic_CMR':\n            mfc_connections = model.mfc[:, 1:-1]\n            mcf_connections = model.mcf[1:-1, :]\n            if trial_index == 0:\n                mfc_heatmap(model.mfc)\n                mfc_heatmap(model.mcf)\n                print(presentation)\n        else:\n            latent_mfc, latent_mcf = latent_mfc_mcf(model)\n            mfc_connections = latent_mfc[:, 1:-1]\n            mcf_connections = latent_mcf[:, 1:-1]\n            if trial_index == 0:\n                icmr_memory_heatmap(model, just_experimental=True, just_context=True)\n                print(presentation)\n\n        # track alternative connectivity\n        mfc_alternative_connectivities += alternative_connectivity_by_lag(mfc_connections, presentation)\n        mcf_alternative_connectivities += alternative_connectivity_by_lag(mcf_connections, presentation)\n\n    # reduce sum to mean\n    mfc_alternative_connectivity = mfc_alternative_connectivities / (trial_index+1)\n    mcf_alternative_connectivity = mcf_alternative_connectivities / (trial_index+1)\n    mfc_alternative_connectivity[:, global_lag_range] = np.nan\n    mcf_alternative_connectivity[:, global_lag_range] = np.nan\n\n    # focus on +/- 3 lags\n    plotting_lag_range = 5\n    mfc_alternative_connectivity = mfc_alternative_connectivity[:, global_lag_range-plotting_lag_range:global_lag_range+plotting_lag_range+1]\n    mcf_alternative_connectivity = mcf_alternative_connectivity[:, global_lag_range-plotting_lag_range:global_lag_range+plotting_lag_range+1]\n\n    # plot results\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 20/2), sharey=False)\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[0])), mcf_alternative_connectivity[0], label='First Presentation')\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[1])), mcf_alternative_connectivity[1], label='Second Presentation')\n    axes[0].set_xticks(np.arange(0, plotting_lag_range * 2 + 1, 2))\n    axes[0].set_xticklabels(np.arange(0, plotting_lag_range * 2 + 1, 2) - plotting_lag_range)\n    axes[0].set_title('MCF')\n\n    # same for MFC\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[0])), mfc_alternative_connectivity[0], label='First Presentation')\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[1])), mfc_alternative_connectivity[1], label='Second Presentation')\n    axes[1].set_xticks(np.arange(0, plotting_lag_range * 2 + 1, 2))\n    axes[1].set_xticklabels(np.arange(0, plotting_lag_range * 2 + 1, 2) - plotting_lag_range)\n    axes[1].set_title('MFC')\n\n\n\n\n\n\n\n[ 0  1  2  3  4  5  6  7  8  9 10 11 11 12 13 14 15 16  9 17 18 19 18 20\n 21 22 19 23 24 25 21 26 27 23 28 29 30 31 32 33]\n\n\n\n\n\n\n\nTR-CMR\n\n# configure parameters\nmodel_class = Trace_Reinstatement_CMR\nmodel_parameters = trcmr_fitted_parameters\n\n# track results\nglobal_lag_range = 39\n\nfor list_type in [4]:\n    mfc_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mcf_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n\n    # loop through presentations\n    for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n        # simulate list study\n        item_count = np.max(presentation)+1\n        model = model_class(item_count, len(presentation), model_parameters)\n        model.experience(model.items[presentation])\n\n        # extract item connections\n        if model_class.__name__ == 'Classic_CMR':\n            mfc_connections = model.mfc[:, 1:-1]\n            mcf_connections = model.mcf[1:-1, :]\n            if trial_index == 0:\n                mfc_heatmap(model.mfc)\n                mfc_heatmap(model.mcf)\n                print(presentation)\n        else:\n            latent_mfc, latent_mcf = latent_mfc_mcf(model)\n            mfc_connections = latent_mfc[:, 1:-1]\n            mcf_connections = latent_mcf[:, 1:-1]\n            if trial_index == 0:\n                icmr_memory_heatmap(model, just_experimental=True, just_context=True)\n                print(presentation)\n\n        # track alternative connectivity\n        mfc_alternative_connectivities += alternative_connectivity_by_lag(mfc_connections, presentation)\n        mcf_alternative_connectivities += alternative_connectivity_by_lag(mcf_connections, presentation)\n\n    # reduce sum to mean\n    mfc_alternative_connectivity = mfc_alternative_connectivities / (trial_index+1)\n    mcf_alternative_connectivity = mcf_alternative_connectivities / (trial_index+1)\n    mfc_alternative_connectivity[:, global_lag_range] = np.nan\n    mcf_alternative_connectivity[:, global_lag_range] = np.nan\n\n    # focus on +/- 3 lags\n    plotting_lag_range = 5\n    mfc_alternative_connectivity = mfc_alternative_connectivity[:, global_lag_range-plotting_lag_range:global_lag_range+plotting_lag_range+1]\n    mcf_alternative_connectivity = mcf_alternative_connectivity[:, global_lag_range-plotting_lag_range:global_lag_range+plotting_lag_range+1]\n\n    # plot results\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 20/2), sharey=False)\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[0])), mcf_alternative_connectivity[0], label='First Presentation')\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[1])), mcf_alternative_connectivity[1], label='Second Presentation')\n    axes[0].set_xticks(np.arange(0, plotting_lag_range * 2 + 1, 2))\n    axes[0].set_xticklabels(np.arange(0, plotting_lag_range * 2 + 1, 2) - plotting_lag_range)\n    axes[0].set_title('MCF')\n\n    # same for MFC\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[0])), mfc_alternative_connectivity[0], label='First Presentation')\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[1])), mfc_alternative_connectivity[1], label='Second Presentation')\n    axes[1].set_xticks(np.arange(0, plotting_lag_range * 2 + 1, 2))\n    axes[1].set_xticklabels(np.arange(0, plotting_lag_range * 2 + 1, 2) - plotting_lag_range)\n    axes[1].set_title('MFC')\n\n\n\n\n[ 0  1  2  3  4  5  6  7  8  9 10 11 11 12 13 14 15 16  9 17 18 19 18 20\n 21 22 19 23 24 25 21 26 27 23 28 29 30 31 32 33]"
  },
  {
    "objectID": "library\\model_analysis\\Contiguity_Tracing.html#contiguity-tracing",
    "href": "library\\model_analysis\\Contiguity_Tracing.html#contiguity-tracing",
    "title": "compmemlearn",
    "section": "Contiguity Tracing",
    "text": "Let’s try an analysis where I simulate a regular trial using the model and compute a representational CRP where for each serial position, I tabulate the corresponding item’s connectivity to items with graduating serial lag from the item."
  },
  {
    "objectID": "library\\model_analysis\\Contiguity_Tracing.html#background-of-this-notebook",
    "href": "library\\model_analysis\\Contiguity_Tracing.html#background-of-this-notebook",
    "title": "compmemlearn",
    "section": "Background of This Notebook",
    "text": "from compmemlearn.fitting import murdock_objective_function, apply_and_concatenate\nfrom compmemlearn.datasets import prepare_lohnas2014_data, simulate_array, simulate_df\nfrom compmemlearn.models import Classic_CMR, Instance_CMR\nfrom scipy.optimize import differential_evolution\nfrom numba.typed import List, Dict\nimport seaborn as sns\nimport numpy as np\nfrom numba import njit, types\nimport matplotlib.pyplot as plt\nfrom psifr import fr\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')"
  },
  {
    "objectID": "library\\model_analysis\\Contiguity_Tracing.html#initial-fitting",
    "href": "library\\model_analysis\\Contiguity_Tracing.html#initial-fitting",
    "title": "compmemlearn",
    "section": "Initial Fitting",
    "text": "Instance CMR\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nicmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n    'context_sensitivity',\n#    'feature_sensitivity'\n    'delay_drift_rate',\n)\n\nicmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n#    (lb, 10),\n#    (lb, 10)\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_icmr(item_count, presentation_count, parameters):\n    return Instance_CMR(item_count, presentation_count, parameters)\n    \ncost_function = murdock_objective_function(\n    (trials[list_types == 1], ), \n    (list_length, ), \n    init_icmr,\n    {'choice_sensitivity': 1, 'feature_sensitivity': 1},\n    icmr_free_parameters)\n\n#result = differential_evolution(cost_function, icmr_bounds, disp=True)\n\nicmr_result = np.array([7.66940287e-01, 3.40249111e-01, 9.48122676e-01, 2.14378788e-03,\n       1.42758234e-01, 5.66283526e-01, 2.20949851e+00, 7.60228147e-01,\n       2.40663552e-02, 9.01763767e-02, 1.82284478e+00, 4.93091746e-01])\n\nicmr_fitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(icmr_result)):\n    icmr_fitted_parameters[icmr_free_parameters[i]] = icmr_result[i]\nicmr_fitted_parameters['choice_sensitivity'] = 1\nicmr_fitted_parameters['feature_sensitivity'] = 1\n\nmodel0 = Instance_CMR(list_length, list_length, icmr_fitted_parameters)\n\nsim_df0 = simulate_df(model0, 1000)\ntrue_df0 = events.loc[events.condition==1]\n\nicmr_spc0 = apply_and_concatenate(fr.spc, sim_df0, true_df0, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_lag_crp0 = apply_and_concatenate(fr.lag_crp, sim_df0, true_df0, 'source', ['InstanceCMR', 'data'])\nicmr_pfr0 = apply_and_concatenate(fr.pnr, sim_df0, true_df0, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_pfr0 = icmr_pfr0.query('output <= 1')\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 12/3), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0], data=icmr_spc0, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0].set_xticks(np.arange(1, list_length+1, 3))\naxes[0].set_ylim((0, 1))\n\n# lag CRP\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[1], data=icmr_lag_crp0.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1], data=icmr_lag_crp0.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1].set_xticks(np.arange(-5, 6, 1))\naxes[1].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=icmr_pfr0, x='input', y='prob', err_style='bars', ax=axes[2], hue='source', legend=True)\naxes[2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2].set_xticks(np.arange(1, list_length+1, 3))\naxes[2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=2)\n\n\n\n\n\n\nClassic CMR\n\ncmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate'\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ncmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n]\n\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n    \ncost_function = murdock_objective_function(\n    (trials[list_types == 1], ), \n    (list_length, ), \n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, \n         'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    cmr_free_parameters)\n\nresult = differential_evolution(cost_function, cmr_bounds, disp=True)\n\ndifferential_evolution step 1: f(x)= 38886.5\ndifferential_evolution step 2: f(x)= 28748.4\ndifferential_evolution step 3: f(x)= 25562.1\ndifferential_evolution step 4: f(x)= 25562.1\ndifferential_evolution step 5: f(x)= 19949.3\ndifferential_evolution step 6: f(x)= 19949.3\ndifferential_evolution step 7: f(x)= 19949.3\ndifferential_evolution step 8: f(x)= 19949.3\ndifferential_evolution step 9: f(x)= 19949.3\ndifferential_evolution step 10: f(x)= 19949.3\ndifferential_evolution step 11: f(x)= 19949.3\ndifferential_evolution step 12: f(x)= 19562.1\ndifferential_evolution step 13: f(x)= 19562.1\ndifferential_evolution step 14: f(x)= 19349.4\ndifferential_evolution step 15: f(x)= 19311.6\ndifferential_evolution step 16: f(x)= 19196.3\ndifferential_evolution step 17: f(x)= 19196.3\ndifferential_evolution step 18: f(x)= 19106.7\ndifferential_evolution step 19: f(x)= 19106.7\ndifferential_evolution step 20: f(x)= 19106.7\ndifferential_evolution step 21: f(x)= 19106.7\ndifferential_evolution step 22: f(x)= 19106.7\ndifferential_evolution step 23: f(x)= 19106.7\ndifferential_evolution step 24: f(x)= 19106.7\ndifferential_evolution step 25: f(x)= 18975.8\ndifferential_evolution step 26: f(x)= 18975.8\ndifferential_evolution step 27: f(x)= 18975.8\ndifferential_evolution step 28: f(x)= 18912.9\ndifferential_evolution step 29: f(x)= 18912.9\ndifferential_evolution step 30: f(x)= 18895.5\ndifferential_evolution step 31: f(x)= 18895.5\ndifferential_evolution step 32: f(x)= 18895.5\ndifferential_evolution step 33: f(x)= 18895.5\n\n\nFor some reason, printing result.x and and directly using the array as cmr_result doesn’t work. So whatever.\n\ncmr_result = result.x\n\ncmr_fitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(cmr_result)):\n    cmr_fitted_parameters[cmr_free_parameters[i]] = cmr_result[i]\ncmr_fitted_parameters['sampling_rule'] = 0\ncmr_fitted_parameters['mfc_familiarity_scale'] = 0\ncmr_fitted_parameters['mcf_familiarity_scale'] = 0\ncmr_fitted_parameters['drift_familiarity_scale'] = 0\nmodel0 = Classic_CMR(list_length, list_length, cmr_fitted_parameters)\n\nsim_df0 = simulate_df(model0, 1000)\ntrue_df0 = events.loc[events.condition==1]\n\ncmr_spc0 = apply_and_concatenate(fr.spc, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp0 = apply_and_concatenate(fr.lag_crp, sim_df0, true_df0, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr0 = apply_and_concatenate(fr.pnr, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr0 = cmr_pfr0.query('output <= 1')\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 12/3), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0], data=cmr_spc0, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0].set_xticks(np.arange(1, list_length+1, 3))\naxes[0].set_ylim((0, 1))\n\n# lag CRP\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1].set_xticks(np.arange(-5, 6, 1))\naxes[1].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=cmr_pfr0, x='input', y='prob', err_style='bars', ax=axes[2], hue='source', legend=True)\naxes[2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2].set_xticks(np.arange(1, list_length+1, 3))\naxes[2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=2)\n\n\n\n\n\n\nNoisy_CMR\n# remember to run nbdev_build_lib first! \n\nimport compmemlearn\nimport importlib\nimportlib.reload(compmemlearn.models)\nfrom compmemlearn.models import Noisy_CMR\ndef slow_murdock_data_likelihood(data_to_fit, item_counts, model_class, parameters):\n\n    result = 0.0\n    for i in range(len(item_counts)):\n        item_count = item_counts[i]\n        trials = data_to_fit[i]\n        likelihood = np.ones((len(trials), item_count))\n\n        model = model_class(item_count, item_count, parameters)\n        model.experience(model.items)\n\n        for trial_index in range(len(trials)):\n            trial = trials[trial_index]\n\n            model.force_recall()\n            for recall_index in range(len(trial) + 1):\n\n                # identify index of item recalled; if zero then recall is over\n                if recall_index == len(trial) and len(trial) < item_count:\n                    recall = 0\n                else:\n                    recall = trial[recall_index]\n\n                # store probability of and simulate recall of indexed item \n                likelihood[trial_index, recall_index] = \\\n                    model.outcome_probabilities()[recall] + 10e-7\n                \n                if recall == 0:\n                    break\n                model.force_recall(recall)\n\n            # reset model to its pre-retrieval (but post-encoding) state\n            model.force_recall(0)\n        \n        result -= np.sum(np.log(likelihood))\n\n    return result\n\ndef slow_murdock_objective_function(data_to_fit, item_counts, model_class, fixed_parameters, free_parameters):\n    \"\"\"\n    Configures cmr_likelihood for search over specified free/fixed parameters.\n    \"\"\"\n\n    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n    for name, value in fixed_parameters.items():\n        parameters[name] = value\n    \n    def objective_function(x):\n        for i in range(len(free_parameters)):\n            parameters[free_parameters[i]] = x[i]\n        return slow_murdock_data_likelihood(data_to_fit, item_counts, model_class, parameters)\n\n    return objective_function\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nicmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n    'context_sensitivity',\n#    'feature_sensitivity'\n    'delay_drift_rate',\n)\n\nicmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n#    (lb, 10),\n#    (lb, 10)\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_ncmr(item_count, presentation_count, parameters):\n    return Noisy_CMR(item_count, presentation_count, parameters)\n    \ncost_function = murdock_objective_function(\n    (trials[list_types == 1], ), \n    (list_length, ), \n    init_ncmr,\n    {'choice_sensitivity': 1, 'feature_sensitivity': 1},\n    icmr_free_parameters)\n\nresult = differential_evolution(cost_function, icmr_bounds, disp=True)\nresult\n\ndifferential_evolution step 1: f(x)= 34339.7\ndifferential_evolution step 2: f(x)= 23934.4\ndifferential_evolution step 3: f(x)= 22650.8\ndifferential_evolution step 4: f(x)= 22238.9\ndifferential_evolution step 5: f(x)= 21860.8\ndifferential_evolution step 6: f(x)= 21860.8\ndifferential_evolution step 7: f(x)= 21860.8\ndifferential_evolution step 8: f(x)= 21786.2\ndifferential_evolution step 9: f(x)= 21728.2\ndifferential_evolution step 10: f(x)= 21728.2\ndifferential_evolution step 11: f(x)= 21728.2\ndifferential_evolution step 12: f(x)= 21728.2\ndifferential_evolution step 13: f(x)= 21633.9\ndifferential_evolution step 14: f(x)= 21633.9\ndifferential_evolution step 15: f(x)= 21633.9\ndifferential_evolution step 16: f(x)= 21633.9\ndifferential_evolution step 17: f(x)= 21633.9\ndifferential_evolution step 18: f(x)= 21633.9\ndifferential_evolution step 19: f(x)= 21633.9\ndifferential_evolution step 20: f(x)= 21633.9\ndifferential_evolution step 21: f(x)= 21629.2\ndifferential_evolution step 22: f(x)= 21629.2\ndifferential_evolution step 23: f(x)= 21629\ndifferential_evolution step 24: f(x)= 21595.1\n\n\n\nncmr_result = result.x\n\nncmr_fitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(ncmr_result)):\n    ncmr_fitted_parameters[icmr_free_parameters[i]] = ncmr_result[i]\nncmr_fitted_parameters['choice_sensitivity'] = 1\nncmr_fitted_parameters['feature_sensitivity'] = 1\n\nmodel0 = Noisy_CMR(list_length, list_length, ncmr_fitted_parameters)\n\nsim_df0 = simulate_df(model0, 1000)\ntrue_df0 = events.loc[events.condition==1]\n\nncmr_spc0 = apply_and_concatenate(fr.spc, sim_df0, true_df0, contrast_name='source', labels=['NoisyCMR', 'data'])\nncmr_lag_crp0 = apply_and_concatenate(fr.lag_crp, sim_df0, true_df0, 'source', ['NoisyCMR', 'data'])\nncmr_pfr0 = apply_and_concatenate(fr.pnr, sim_df0, true_df0, contrast_name='source', labels=['NoisyCMR', 'data'])\nncmr_pfr0 = ncmr_pfr0.query('output <= 1')\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 12/3), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0], data=ncmr_spc0, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0].set_xticks(np.arange(1, list_length+1, 3))\naxes[0].set_ylim((0, 1))\n\n# lag CRP\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[1], data=ncmr_lag_crp0.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1], data=ncmr_lag_crp0.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1].set_xticks(np.arange(-5, 6, 1))\naxes[1].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=ncmr_pfr0, x='input', y='prob', err_style='bars', ax=axes[2], hue='source', legend=True)\naxes[2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2].set_xticks(np.arange(1, list_length+1, 3))\naxes[2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=2)"
  },
  {
    "objectID": "library\\model_analysis\\Contiguity_Tracing.html#trace-visualization",
    "href": "library\\model_analysis\\Contiguity_Tracing.html#trace-visualization",
    "title": "compmemlearn",
    "section": "Trace Visualization",
    "text": "# export\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef matrix_heatmap(matrix, title='', figsize=(15, 15), savefig=False, axis=None):\n    \"\"\"\n    Plots an array of model states as a value-annotated heatmap with an arbitrary title.\n\n    **Arguments**:  \n    - matrix: an array of model states, ideally with columns representing unique feature indices and rows\n        representing unique update indices  \n    - title: a title for the generated plot, ideally conveying what array values represent at each entry  \n    - savefig: boolean deciding whether generated figure is saved (True if Yes)\n    \"\"\"\n    plt.figure(figsize=figsize)\n    sns.heatmap(matrix, annot=True, linewidths=.5, ax=axis)\n    plt.title(title)\n    plt.xlabel('Feature Index')\n    plt.ylabel('Update Index')\n    if savefig:\n        plt.savefig('figures/{}.jpeg'.format(title).replace(' ', '_').lower(), bbox_inches='tight')\n    plt.show()\n\ndef icmr_memory_heatmap(model, just_experimental=False, just_context=False):\n    memory_shape = np.shape(model.memory)\n    fig_size = list(reversed(memory_shape))\n    plotted_memory = model.memory.copy()\n    title = \"Memory Traces\"\n\n    if just_context:\n        fig_size[0] /= 2\n        plotted_memory = plotted_memory[:, int(memory_shape[1]/2):]\n        title = \"Contextual \" + title\n\n    if just_experimental:\n        fig_size[1] -= model.item_count\n        plotted_memory = plotted_memory[int(memory_shape[0]/2):]\n        title = \"Experimental \" + title\n\n    matrix_heatmap(plotted_memory, title, figsize=fig_size)\n\nicmr_result = np.array([7.66940287e-01, 3.40249111e-01, 9.48122676e-01, 2.14378788e-03,\n       1.42758234e-01, 5.66283526e-01, 2.20949851e+00, 7.60228147e-01,\n       2.40663552e-02, 9.01763767e-02, 1.82284478e+00, 4.93091746e-01])\n\nicmr_fitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(icmr_result)):\n    icmr_fitted_parameters[icmr_free_parameters[i]] = icmr_result[i]\nicmr_fitted_parameters['choice_sensitivity'] = 1\nicmr_fitted_parameters['feature_sensitivity'] = 1\n\nmodel = Instance_CMR(list_length, list_length, icmr_fitted_parameters)\nsim_df = simulate_df(model, 1)\n\nicmr_memory_heatmap(model, just_experimental=True, just_context=True)\n\n\n\n\n\nmodel = Noisy_CMR(list_length, list_length, ncmr_fitted_parameters)\nsim_df = simulate_df(model, 1)\n\nicmr_memory_heatmap(model, just_experimental=False, just_context=False)"
  },
  {
    "objectID": "library\\model_analysis\\Contiguity_Tracing.html#latent-mfc-and-mcf",
    "href": "library\\model_analysis\\Contiguity_Tracing.html#latent-mfc-and-mcf",
    "title": "compmemlearn",
    "section": "Latent MFC and MCF",
    "text": "# export\n\nimport numpy as np\n\ndef latent_mfc_mcf(model):\n    \n    \"\"\"\n    Generates the latent $M^{FC}$ and $M^{CF}$ in the specified ICMR instance.\n    For exploring and demonstrating model equivalence, we can calculate for any state of ICMR's dual-store memory \n    array $M$ a corresponding $M^{FC}$ (or $M^{CF}$) by computing for each orthogonal $f_i$ (or $c_i$) the model's \n    corresponding echo representation. \n    \"\"\"\n    \n    # start by finding latent mfc: the contextual representation cued when each orthogonal $f_i$ is cued\n    latent_mfc = np.zeros((model.item_count, model.item_count+2))\n    for i in range(model.item_count):\n        latent_mfc[i] = model.echo(model.items[i])[model.item_count + 2:]\n\n    latent_mcf = np.zeros((model.item_count, model.item_count+2))\n    context_units = np.hstack(\n        (np.zeros((model.item_count, model.item_count+2)), \n         np.eye(model.item_count, model.item_count + 2, 1))\n         )\n    for i in range(model.item_count):\n        latent_mcf[i] = model.echo(context_units[i])[:model.item_count+2]\n\n    return latent_mfc, latent_mcf\n\ndef mfc_heatmap(mfc):\n    matrix_heatmap(mfc, title='', figsize=list(reversed(np.shape(mfc))))\n\nicmr_result = np.array([7.66940287e-01, 3.40249111e-01, 9.48122676e-01, 2.14378788e-03,\n       1.42758234e-01, 5.66283526e-01, 2.20949851e+00, 7.60228147e-01,\n       2.40663552e-02, 9.01763767e-02, 1.82284478e+00, 4.93091746e-01])\n\nicmr_fitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(icmr_result)):\n    icmr_fitted_parameters[icmr_free_parameters[i]] = icmr_result[i]\nicmr_fitted_parameters['choice_sensitivity'] = 1\nicmr_fitted_parameters['feature_sensitivity'] = 1\n\nmodel = Instance_CMR(list_length, list_length, icmr_fitted_parameters)\nsim_df = simulate_df(model, 1)\n\nlatent_mfc, latent_mcf = latent_mfc_mcf(model)\n\nmfc_heatmap(latent_mfc)\nmfc_heatmap(latent_mcf)\n\n\n\n\n\n\n\n\nmodel = Noisy_CMR(list_length, list_length, ncmr_fitted_parameters)\nsim_df = simulate_df(model, 1)\n\nnoisy_latent_mfc, noisy_latent_mcf = latent_mfc_mcf(model)\n\nmfc_heatmap(noisy_latent_mfc)\nmfc_heatmap(noisy_latent_mcf)\n\n\n\n\n\n\n\n\ncmr_fitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(cmr_result)):\n    cmr_fitted_parameters[cmr_free_parameters[i]] = cmr_result[i]\ncmr_fitted_parameters['sampling_rule'] = 0\ncmr_fitted_parameters['mfc_familiarity_scale'] = 0\ncmr_fitted_parameters['mcf_familiarity_scale'] = 0\ncmr_fitted_parameters['drift_familiarity_scale'] = 0\ncmr_model = Classic_CMR(list_length, list_length, cmr_fitted_parameters)\nsimulate_df(cmr_model, 1);\n\nmfc_heatmap(cmr_model.mfc)\nmfc_heatmap(cmr_model.mcf)"
  },
  {
    "objectID": "library\\model_analysis\\Contiguity_Tracing.html#memory-connectivity-by-lag",
    "href": "library\\model_analysis\\Contiguity_Tracing.html#memory-connectivity-by-lag",
    "title": "compmemlearn",
    "section": "Memory Connectivity by Lag",
    "text": "Connectivity here refers to “how much an item’s corresponding feature or contextual unit gets activated when another considered item’s corresponding contextual or feature unit is activated. memory argument should always be a 2D matrix mapping item connections, usually a subset of the corresponding memory matrix.\n# export\n\ndef connectivity_by_lag(item_connections, item_count):\n    \n    lag_range = item_count - 1\n    total_connectivity = np.zeros(lag_range * 2 + 1)\n    total_possible_lags = np.zeros(lag_range * 2 + 1)\n    item_positions = np.arange(item_count, dtype=int)\n    \n    # tabulate bin totals for actual and possible lags\n    # this time instead of looping through trials and recall indices, we only loop once through each item index\n    for i in range(item_count):\n\n        # lag of each item from current item is item position - i, \n        # and will always be in range [-lag_range, lag_range] so we keep position by adding lag_range\n        item_lags = item_positions - i + lag_range\n        total_connectivity[item_lags] += item_connections[i]\n        total_possible_lags[item_lags] += 1\n\n    # divide by possible lags to get average connectivity\n    connectivity = total_connectivity / total_possible_lags\n    return connectivity\ndef mixed_connectivity_by_lag(item_connections, presentation):\n    item_count = np.max(presentation)+1\n    lag_range = len(presentation) - 1\n    total_connectivity = np.zeros(lag_range * 2 + 1)\n    total_possible_lags = np.zeros(lag_range * 2 + 1)\n    item_positions = np.arange(len(presentation), dtype=int)\n\n    for item in range(item_count):\n\n        # only consider items that are repeated\n        current_positions = np.nonzero(presentation == item)[0]\n\n        # we consider each study position of repeated items separately\n        for position_index in range(len(current_positions)):\n\n            # lag of each item from current item is item_positions - current_position, \n            # and will always be in range [-lag_range, lag_range] so we keep position by adding lag_range\n            item_lags = item_positions - current_positions[position_index] + lag_range\n            total_connectivity[item_lags] += item_connections[item, presentation]\n            total_possible_lags[item_lags] += 1\n\n    # divide by possible lags to get average connectivity\n    total_possible_lags[total_connectivity == 0] += 1\n    connectivity = total_connectivity / total_possible_lags\n    return connectivity\n\nPrototypeCMR\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n#test_crp = connectivity_by_lag(cmr_model.mcf[1:-1, :], cmr_model.item_count)\ntest_crp = mixed_connectivity_by_lag(cmr_model.mcf[1:-1, :], np.arange(cmr_model.item_count, dtype=int))\ntest_crp[cmr_model.item_count-1] = np.nan\naxes[0].plot(np.arange(len(test_crp)), test_crp)\naxes[0].set_xticks(np.arange(0, len(test_crp), 4))\naxes[0].set_xticklabels(np.arange(0, len(test_crp), 4) - (cmr_model.item_count - 1))\naxes[0].set_title('MCF')\n\n# same for MFC\n#test_crp = connectivity_by_lag(cmr_model.mfc[:, 1:-1], cmr_model.item_count)\ntest_crp = mixed_connectivity_by_lag(cmr_model.mfc[:, 1:-1], np.arange(cmr_model.item_count, dtype=int))\ntest_crp[cmr_model.item_count-1] = np.nan\naxes[1].plot(np.arange(len(test_crp)), test_crp)\naxes[1].set_xticks(np.arange(0, len(test_crp), 4))\naxes[1].set_xticklabels(np.arange(0, len(test_crp), 4) - (cmr_model.item_count - 1))\naxes[1].set_title('MFC')\nfig.suptitle('PrototypeCMR Item Connectivity By Lag')\n\n\nText(0.5, 0.98, 'PrototypeCMR Item Connectivity By Lag')\n\n\n\n\n\n\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 5), sharey=True)\ntest_crp = (connectivity_by_lag(cmr_model.mcf[1:-1, :], cmr_model.item_count) + connectivity_by_lag(cmr_model.mfc[:, 1:-1], cmr_model.item_count))/2\ntest_crp[cmr_model.item_count-1] = np.nan\naxes.plot(np.arange(len(test_crp)), test_crp)\naxes.set_xticks(np.arange(0, len(test_crp), 4))\naxes.set_xticklabels(np.arange(0, len(test_crp), 4) - (cmr_model.item_count - 1))\naxes.set_title('Mean')\n\ntest_crp\n\narray([0.19768762, 0.19768767, 0.19768774, 0.19768784, 0.19768799,\n       0.19768822, 0.19768855, 0.19768903, 0.19768974, 0.1976908 ,\n       0.19769235, 0.19769463, 0.197698  , 0.19770296, 0.19771026,\n       0.19772103, 0.19773689, 0.19776027, 0.19779471, 0.19784545,\n       0.19792021, 0.19803037, 0.19819267, 0.19843182, 0.19878417,\n       0.19930334, 0.20006828, 0.20119534, 0.20285597, 0.20530276,\n       0.20890787, 0.21421967, 0.22204611, 0.23357766, 0.25056832,\n       0.27560249, 0.31248804, 0.36683547, 0.4469114 ,        nan,\n       0.4469114 , 0.36683547, 0.31248804, 0.27560249, 0.25056832,\n       0.23357766, 0.22204611, 0.21421967, 0.20890787, 0.20530276,\n       0.20285597, 0.20119534, 0.20006828, 0.19930334, 0.19878417,\n       0.19843182, 0.19819267, 0.19803037, 0.19792021, 0.19784545,\n       0.19779471, 0.19776027, 0.19773689, 0.19772103, 0.19771026,\n       0.19770296, 0.197698  , 0.19769463, 0.19769235, 0.1976908 ,\n       0.19768974, 0.19768903, 0.19768855, 0.19768822, 0.19768799,\n       0.19768784, 0.19768774, 0.19768767, 0.19768762])\n\n\n\n\n\n\n\nInstanceCMR\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5), sharey=True)\n\ntest_crp = connectivity_by_lag(latent_mcf[:, 1:-1], model.item_count)\ntest_crp[model.item_count-1] = np.nan\naxes[0].plot(np.arange(len(test_crp)), test_crp)\naxes[0].set_xticks(np.arange(0, len(test_crp), 4))\naxes[0].set_xticklabels(np.arange(0, len(test_crp), 4) - (model.item_count - 1))\naxes[0].set_title('Context to Feature Associations (MCF)')\n\n# same for MFC\ntest_crp = connectivity_by_lag(latent_mfc[:, 1:-1], model.item_count)\ntest_crp[model.item_count-1] = np.nan\naxes[1].plot(np.arange(len(test_crp)), test_crp)\naxes[1].set_xticks(np.arange(0, len(test_crp), 4))\naxes[1].set_xticklabels(np.arange(0, len(test_crp), 4) - (model.item_count - 1))\naxes[1].set_title('Feature to Context Associations (MFC)')\nfig.suptitle('InstanceCMR Item Connectivity By Lag')\n\nText(0.5, 0.98, 'InstanceCMR Item Connectivity By Lag')\n\n\n\n\n\n\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 5), sharey=True)\n\ntest_crp = (connectivity_by_lag(latent_mcf[:, 1:-1], model.item_count) + connectivity_by_lag(latent_mfc[:, 1:-1], model.item_count))/2\ntest_crp[model.item_count-1] = np.nan\naxes.plot(np.arange(len(test_crp)), test_crp)\naxes.set_xticks(np.arange(0, len(test_crp), 4))\naxes.set_xticklabels(np.arange(0, len(test_crp), 4) - (model.item_count - 1))\naxes.set_title('InstanceCMR Mean')\ntest_crp\n\narray([0.0044123 , 0.00442927, 0.00439535, 0.00435875, 0.0043293 ,\n       0.00430716, 0.00429065, 0.00427818, 0.00426855, 0.00426094,\n       0.00425479, 0.00424974, 0.00424552, 0.00424197, 0.00423898,\n       0.0042365 , 0.00423451, 0.00423307, 0.0042323 , 0.00423243,\n       0.00423386, 0.00423727, 0.00424375, 0.00425509, 0.00427414,\n       0.00430555, 0.00435678, 0.00443984, 0.00457406, 0.00479056,\n       0.00513945, 0.00570143, 0.00660656, 0.00806467, 0.01041486,\n       0.01420667, 0.0203346 , 0.03026503, 0.04642974,        nan,\n       0.08096561, 0.03590036, 0.01818106, 0.01067097, 0.00731709,\n       0.00574602, 0.00497271, 0.004572  , 0.00435357, 0.00422872,\n       0.00415411, 0.00410753, 0.004077  , 0.00405579, 0.00403998,\n       0.00402722, 0.00401606, 0.00400556, 0.00399511, 0.00398428,\n       0.00397273, 0.00396015, 0.00394627, 0.00393077, 0.00391328,\n       0.00389336, 0.00387047, 0.00384388, 0.00381267, 0.00377558,\n       0.00373095, 0.00367647, 0.00360897, 0.00352402, 0.00341535,\n       0.00327409, 0.00308763, 0.00283816, 0.00250086])\n\n\n\n\n\n\n\nNoisyCMR\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5), sharey=True)\n\ntest_crp = connectivity_by_lag(noisy_latent_mcf[:, 1:-1], model.item_count)\ntest_crp[model.item_count-1] = np.nan\naxes[0].plot(np.arange(len(test_crp)), test_crp)\naxes[0].set_xticks(np.arange(0, len(test_crp), 4))\naxes[0].set_xticklabels(np.arange(0, len(test_crp), 4) - (model.item_count - 1))\naxes[0].set_title('MCF')\n\n# same for MFC\ntest_crp = connectivity_by_lag(noisy_latent_mfc[:, 1:-1], model.item_count)\ntest_crp[model.item_count-1] = np.nan\naxes[1].plot(np.arange(len(test_crp)), test_crp)\naxes[1].set_xticks(np.arange(0, len(test_crp), 4))\naxes[1].set_xticklabels(np.arange(0, len(test_crp), 4) - (model.item_count - 1))\naxes[1].set_title('MFC')\nfig.suptitle('InstanceCMR Item Connectivity By Lag')\n\nText(0.5, 0.98, 'InstanceCMR Item Connectivity By Lag')\n\n\n\n\n\n\n\nNotes\nCMR seems to fit toward stronger MCF weights overall relative to MFC. But when you turn sharey off during plotting, it’s clear that the effect is more of a translation up the y-axis than a meaningful change in the pattern of connectivities (aside from the reflection along y-axis thing).\nInstanceCMR though seems to do no such translation, instead making its latent MCF “steeper” than its latent MFC.\nWhat if I take an average? CMR only gets assymetry if I do a weighted average that downweights MFC importance. InstanceCMR needs no such transformation. Neither of these CRPs exactly match what I see in the data, but that makes some sense. It’s unclear whether these observations imply more fundamental differences between model architectures."
  },
  {
    "objectID": "library\\model_analysis\\Contiguity_Tracing.html#parameter-shifting",
    "href": "library\\model_analysis\\Contiguity_Tracing.html#parameter-shifting",
    "title": "compmemlearn",
    "section": "Parameter Shifting",
    "text": "Add experiments to this notebook tracing how changing relevant model parameters simulataneously shapes CRP structure and memory connections, focusing on learning and drift rates parameter-wise and contiguity and assymetry outcome-wise. I’m done when I know high-level (parametric) ways to control contiguity.\n\nfrom tqdm import tqdm\nfrom compmemlearn.analyses import fast_spc, fast_crp, fast_pfr\nimport pandas as pd\n\nmax_lag = 13\n\nscore_ranges = {\n    'encoding_drift_rate': np.arange(.001, .99, .1),\n    'recall_drift_rate': np.arange(.001, .99, .1),\n    'shared_support': np.arange(.001, .005, .001),\n    'item_support': np.arange(.001, .01, .001),\n    'learning_rate': np.arange(.001, .99, .1),\n    'choice_sensitivity': np.arange(.001, 5, .5),\n}\n\nfor model_class in [Classic_CMR]:\n\n    if model_class.__name__ == 'Classic_CMR':\n        parameters = cmr_fitted_parameters\n    else:\n        parameters = icmr_fitted_parameters\n\n    for varied_parameter in score_ranges.keys():\n        print(varied_parameter, parameters[varied_parameter])\n        crps = []\n        spcs = []\n        pfrs = []\n        mfc_connectivities = []\n        mcf_connectivities = []\n\n        for parameter_value in tqdm(score_ranges[varied_parameter]):\n\n\n            # simulate data with this parameter value modified\n            sub_params = parameters.copy()\n            sub_params[varied_parameter] = parameter_value\n            model = model_class(list_length, list_length, sub_params)\n            simulation = simulate_array(model, 10000)\n\n            # accumulate spcs, crps, pfrs\n            spc = fast_spc(simulation, list_length)\n            spc = pd.DataFrame(\n                {'Study Position': np.arange(len(spc)), 'Recall Rate': spc, varied_parameter: parameter_value})\n            spcs.append(spc)\n\n            crp = fast_crp(simulation, list_length)\n            crp[list_length-1] = np.nan\n            crp = pd.DataFrame(\n                {'Lag': np.arange(max_lag*2 + 1, dtype=int)-max_lag, 'Recall Rate': crp[list_length-max_lag-1:list_length+max_lag], varied_parameter: parameter_value})\n            crps.append(crp)\n\n            pfr = fast_pfr(simulation, list_length)\n            pfr = pd.DataFrame(\n                {'Study Position': np.arange(len(pfr)), 'First Recall Rate': pfr, varied_parameter: parameter_value})\n            pfrs.append(pfr)\n            \n            if model_class.__name__ == 'Classic_CMR':\n                mfc_connectivity = connectivity_by_lag(model.mfc[:, 1:-1], model.item_count)\n                mcf_connectivity = connectivity_by_lag(model.mcf[1:-1, :], model.item_count)\n            else:\n                latent_mfc, latent_mcf = latent_mfc_mcf(model)\n                mfc_connectivity = connectivity_by_lag(latent_mfc[:, 1:-1], model.item_count)\n                mcf_connectivity = connectivity_by_lag(latent_mcf[: , 1:-1], model.item_count)\n\n            mfc_connectivity[model.item_count-1] = np.nan\n            mcf_connectivity[model.item_count-1] = np.nan\n            mfc_connectivity = pd.DataFrame(\n                {'Lag': np.arange(max_lag*2 + 1, dtype=int)-max_lag, 'Recall Rate': mfc_connectivity[model.item_count-max_lag-1:model.item_count+max_lag], varied_parameter: parameter_value}\n            )\n            mcf_connectivity = pd.DataFrame(\n                {'Lag': np.arange(max_lag*2 + 1, dtype=int)-max_lag, 'Recall Rate': mcf_connectivity[model.item_count-max_lag-1:model.item_count+max_lag], varied_parameter: parameter_value}\n            )\n            mfc_connectivities.append(mfc_connectivity)\n            mcf_connectivities.append(mcf_connectivity)\n\n        # concatenate result into a single table\n        spc = pd.concat(spcs).reset_index()\n        crp = pd.concat(crps).reset_index()\n        pfr = pd.concat(pfrs).reset_index()\n        mfc_connectivity = pd.concat(mfc_connectivities).reset_index()\n        mcf_connectivity = pd.concat(mcf_connectivities).reset_index()\n\n        sns.set(style='darkgrid')\n        fig, axes = plt.subplots(5, 1, figsize=(10, 20), sharey=False)\n\n        sns.lineplot(ax=axes[0], data=spc, x='Study Position', y='Recall Rate', hue=varied_parameter, ci=None)\n        #axes[0].set_xlabel('Study Position')\n        #axes[0].set_ylabel('Probability Recall')\n        axes[0].set_title('SPC')\n        axes[0].legend(np.round(score_ranges[varied_parameter], 5), bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n        sns.lineplot(ax=axes[1], data=pfr, x='Study Position', y='First Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[1].set_title('PFR')\n\n        filt_neg = f'{-max_lag} <= Lag < 0'\n        filt_pos = f'0 < Lag <= {max_lag}'\n        sns.lineplot(ax=axes[2], data=crp.query(filt_neg), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        sns.lineplot(ax=axes[2], data=crp.query(filt_pos), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[2].set_title('Lag-CRP')\n\n        sns.lineplot(ax=axes[3], data=mfc_connectivity.query(filt_neg), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        sns.lineplot(ax=axes[3], data=mfc_connectivity.query(filt_pos), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[3].set_title('MFC Lag-Connectivity')\n        \n        sns.lineplot(ax=axes[4], data=mcf_connectivity.query(filt_neg), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        sns.lineplot(ax=axes[4], data=mcf_connectivity.query(filt_pos), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[4].set_title('MCF Lag-Connectivity')\n\n        plt.tight_layout(pad=2)\n\n        fig.suptitle(varied_parameter.replace('_', ' ').upper())\n        #plt.savefig('results/{}_{}.svg'.format(model.__name__, varied_parameter))\n        plt.show()\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nencoding_drift_rate 0.7344167192532168\n\n\n100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nrecall_drift_rate 0.9322928178785643\n\n\n100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\n\n\n\n\n\n  0%|          | 0/4 [00:00<?, ?it/s]\n\n\nshared_support 0.39537504326174394\n\n\n100%|██████████| 4/4 [00:02<00:00,  1.55it/s]\n\n\n\n\n\n  0%|          | 0/9 [00:00<?, ?it/s]\n\n\nitem_support 2.220446049250313e-16\n\n\n100%|██████████| 9/9 [00:06<00:00,  1.46it/s]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nlearning_rate 0.9999999999999998\n\n\n100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nchoice_sensitivity 5.760897798064937\n\n\n100%|██████████| 10/10 [00:07<00:00,  1.42it/s]\n\n\n\n\n\n\nNotes\n\nICMR\n\nEncoding drift rate messes with SPC height at high value for some reason. CRP sharpness grows with drift rate. With sharpness comes greater assymetry. Can I control one without the other?\nRecall drift rate has similar effect as encoding drift rate, except my high encoding drift rate seems protective of contiguity even with low recall drift rate. With low recall drift rate, contiguity is not so assymetric even though it’s there, so that’s a neat differentiation. Still, sharpness and assymetry are tied here.\nshared_support breaks the model unless configured to low value. Must return to this. Oh, as this increases, contiguity is suppressed. Assymetry largely untouched.\nitem support configures initial mfc weights and seems to mainly control sharpness w/o affecting assymetry as much, idk.\nLearning rate specifically controls contiguity. High values balance CRP while low values make assymetry super strong. No direct control of mean CRP “height”, I think. This is maybe really valuable, but I haven’t had much success manipulating it in CMR-DE.\nchoice sensitivity seems to control height of CRP w/o disrupting assymetry much except at very low values.\n\nSo we have a lot of parameters that suppress contiguity in a way that also erases apparent assymetry at different rates. And we have a parameter that directly controls assymetry w/o controlling height. Any of these might prove useful tools for getting me toward the suppressed relative contiguity I’m looking for.\n\n\nCMR\n\nEncoding drift rate behavior is same as ICMR’s. Seems clearer that low values suppress assymetry and overall contiguity.\nRecall drift rate too. Clearer than before that recall drift rate is an avenue to impact assymetry w/o erasing contiguity as quickly as\nRelevant range for shared_support seems wildly different. Must return.\nItem support has a weird experiment I wanna return to but overall seems to drive greater negative assymetry at higher values rather than positive. Must compare with ICMR again. I need to consider a smaller range of values for CMR too since the parameter fits very close to 0. I wonder if I have the model implemented wrong?\nLearning rate works similarly. Fits to as sharp assymetry as possible, suggesting the model wishes it could go further.\nModel very noisy with choice sensitivity values below 1.0 apparently.\n\n\n\nLag_Connectivity\nEncoding drift rate affects both MFC and MCF lag-connectivity. Low values make flat memories. As value increases, memory remains flat but grows in height. Then after some threshold, contiguity sharpness rather than memory strength is modified.\nRecall drift rate doesn’t affect memory, as it shouldn’t.\nShared support especially impacts MFC lag-connecitivity, mainly more distal lags, effectively suppressing lag-contiguity at higher values.\nItem support affects both MFC and MCF lag-connectivity. Opposite transitions is a flat line that translate down as parameter value increases. Main contiguity starts in wrong direction at low values and increases to produce contiguity. Definitely not a parameter to mess with, this shit is weird.\nLearning rate exclusively impacts MFC. Which makes sense because MFC doesn’t affect learning the way MCF does. Wait, that’s not true. Why does higher learning rate suppress forward transitions if it doesn’t affect MCF? Guess because context gets more support for negative transitions, okay.\nChoice sensitivity similarly affects CRP without affecting memory representations.\nSo we get an interesting divide! Recall-based mechanisms can constrain CRP"
  },
  {
    "objectID": "library\\model_analysis\\Data_Likelihood_Under_Model.html#testing-the-likelihood-functions",
    "href": "library\\model_analysis\\Data_Likelihood_Under_Model.html#testing-the-likelihood-functions",
    "title": "compmemlearn",
    "section": "Testing the Likelihood Functions",
    "text": "We’ll make sure the likelihood functions still return expected values depending on pre-fitted parameters from our Murdock, 1962 and Lohnas & Kahana, 2014 dataset analyses.\nfrom compmemlearn.models import Classic_CMR\nfrom numba.typed import List, Dict\nfrom compmemlearn.datasets import prepare_murdock1962_data, prepare_lohnas2014_data\n\nmurdock_data_likelihood\n\nmurd_trials0, murd_events0, murd_length0 = prepare_murdock1962_data('../../data/MurdData_clean.mat', 0)\nmurd_trials1, murd_events1, murd_length1 = prepare_murdock1962_data('../../data/MurdData_clean.mat', 1)\nmurd_trials2, murd_events2, murd_length2 = prepare_murdock1962_data('../../data/MurdData_clean.mat', 2)\n\nfree_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate'\n)\n\nfit_values = np.array([5.88304182e-01, 3.76144942e-02, 7.51294302e-01, 2.91680115e-01,\n       1.00000000e+00, 1.39633721e-01, 5.62625588e+00, 4.28789782e+01,\n       2.40537436e-02, 2.61824232e-01, 5.32941045e+00, 9.34036191e-01])\n\ncmr_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(fit_values)):\n    cmr_parameters[free_parameters[i]] = fit_values[i]\ncmr_parameters['sampling_rule'] = 0\ncmr_parameters['mfc_familiarity_scale'] = 0\ncmr_parameters['mcf_familiarity_scale'] = 0\ncmr_parameters['drift_familiarity_scale'] = 0\n\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\nprint('murdock, 1962 == 80052.6888735279')\nprint(murdock_data_likelihood(\n    (murd_trials0, murd_trials1, murd_trials2), \n    (murd_length0,murd_length1, murd_length2), \n    init_cmr, cmr_parameters))\n\n%timeit murdock_data_likelihood(List([murd_trials0, murd_trials1, murd_trials2]), List([murd_length0,murd_length1, murd_length2]), init_cmr, cmr_parameters)\n\nmurdock, 1962 == 80052.6888735279\n80052.6888735276\n59.4 ms ± 961 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\n\nlohnas_data_likelihood\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')\n\nfit_values = np.array([8.52979921e-01, 9.68207643e-02, 9.64470531e-01, 3.73838044e-02,\n       2.22044605e-16, 4.62850531e-01, 3.18792422e+00, 8.62357681e+01,\n       2.13805131e-02, 1.06861707e-01, 1.18381379e+00, 9.83789369e-01])\n\nfor i in range(len(fit_values)):\n    cmr_parameters[free_parameters[i]] = fit_values[i]\n\nprint('lohnas, 2014 == 17271.524963186363')\nprint(lohnas_data_likelihood(\n    trials[list_types == 4], \n    presentations[list_types == 4], \n    init_cmr, cmr_parameters))\n\n%timeit lohnas_data_likelihood(trials[list_types == 4], presentations[list_types == 4], init_cmr, cmr_parameters)\n\nlohnas, 2014 == 17271.524963186363\n17271.524963184707\n39.4 ms ± 2.65 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)"
  },
  {
    "objectID": "library\\model_analysis\\Data_Likelihood_Under_Model.html#fitting-pure-lists-with-murdock_data_likelihood",
    "href": "library\\model_analysis\\Data_Likelihood_Under_Model.html#fitting-pure-lists-with-murdock_data_likelihood",
    "title": "compmemlearn",
    "section": "Fitting Pure Lists with murdock_data_likelihood",
    "text": "With the runtime of the cost function established, we’ll now use it with scipy’s differential_evolution function to find the best fit parameters for the model to the single subject we’re examining.\n\nLoading and Optimizing Along Cost Function\n\nfrom scipy.optimize import differential_evolution\nimport numpy as np\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nbounds = (\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n)\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\ncost_function = murdock_objective_function(\n    (murd_trials0, murd_trials1, murd_trials2), \n    (murd_length0,murd_length1, murd_length2), \n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    free_parameters)\n\nresult = differential_evolution(cost_function, bounds, disp=True)\nprint(result)\n\ndifferential_evolution step 1: f(x)= 97308.5\ndifferential_evolution step 2: f(x)= 91013.4\ndifferential_evolution step 3: f(x)= 91013.4\ndifferential_evolution step 4: f(x)= 91013.4\ndifferential_evolution step 5: f(x)= 91013.4\ndifferential_evolution step 6: f(x)= 88452\ndifferential_evolution step 7: f(x)= 86792\ndifferential_evolution step 8: f(x)= 84293.4\ndifferential_evolution step 9: f(x)= 84293.4\ndifferential_evolution step 10: f(x)= 84293.4\ndifferential_evolution step 11: f(x)= 82942.1\ndifferential_evolution step 12: f(x)= 82942.1\ndifferential_evolution step 13: f(x)= 82942.1\ndifferential_evolution step 14: f(x)= 82518\ndifferential_evolution step 15: f(x)= 82311.4\ndifferential_evolution step 16: f(x)= 81474.7\ndifferential_evolution step 17: f(x)= 81474.7\ndifferential_evolution step 18: f(x)= 81474.7\ndifferential_evolution step 19: f(x)= 81474.7\ndifferential_evolution step 20: f(x)= 81474.7\ndifferential_evolution step 21: f(x)= 81474.7\ndifferential_evolution step 22: f(x)= 81474.7\ndifferential_evolution step 23: f(x)= 81474.7\ndifferential_evolution step 24: f(x)= 81474.7\ndifferential_evolution step 25: f(x)= 81474.7\ndifferential_evolution step 26: f(x)= 81474.7\ndifferential_evolution step 27: f(x)= 81474.7\ndifferential_evolution step 28: f(x)= 81036.4\ndifferential_evolution step 29: f(x)= 81036.4\ndifferential_evolution step 30: f(x)= 81036.4\ndifferential_evolution step 31: f(x)= 81036.4\ndifferential_evolution step 32: f(x)= 81036.4\ndifferential_evolution step 33: f(x)= 81036.4\ndifferential_evolution step 34: f(x)= 81036.4\ndifferential_evolution step 35: f(x)= 81036.4\ndifferential_evolution step 36: f(x)= 81036.4\ndifferential_evolution step 37: f(x)= 81036.4\ndifferential_evolution step 38: f(x)= 80813.8\ndifferential_evolution step 39: f(x)= 80813.8\ndifferential_evolution step 40: f(x)= 80591.5\ndifferential_evolution step 41: f(x)= 80591.5\n     fun: 80047.41028350465\n     jac: array([-1.34896253e+00,  4.80213202e-01,  1.85682437e+00, -5.99829946e+00,\n       -1.40143674e+02,  3.74129741e+00,  1.29512046e-01,  0.00000000e+00,\n       -1.22934580e+01, -8.96397979e-01,  4.49654183e-01, -2.86818248e+00])\n message: 'Optimization terminated successfully.'\n    nfev: 9419\n     nit: 41\n success: True\n       x: array([6.00473229e-01, 3.32875358e-02, 7.50604203e-01, 2.27164284e-01,\n       1.00000000e+00, 1.30584257e-01, 6.45835896e+00, 6.06522276e+01,\n       2.40310219e-02, 2.61880252e-01, 4.39924093e+00, 9.34438836e-01])\n\n\nWe expect these results:\n     fun: 80052.68887354505\n     jac: array([  10.6170773 ,   17.17708073,   -2.77505022,   -2.50875019,\n       -123.24599022,   17.89885574,   -2.93221094,    0.        ,\n        118.13972376,   26.6605639 ,    7.70960473,    7.07950672])\n message: 'Optimization terminated successfully.'\n    nfev: 7882\n     nit: 36\n success: True\n       x: array([5.88304182e-01, 3.76144942e-02, 7.51294302e-01, 2.91680115e-01,\n       1.00000000e+00, 1.39633721e-01, 5.62625588e+00, 4.28789782e+01,\n       2.40537436e-02, 2.61824232e-01, 5.32941045e+00, 9.34036191e-01])\nThe x attribute of the result object contains the best parameter configuration found, while the fun attribute represents the overall cost of the configuration as computed with our specified cost function.\n\n\nVisualizing Fit\nNext we’ll visualize the fit of the model and its parameters to the data. We’ll do this by simulating a dataset using the models and our parameters found above and plotting its simulated benchmark recall phenomena (serial position curve, lag-CRP, and probability of first recall) against the actual data. A new helper function called apply_and_concatenate helps streamline the process of setting up tables for comparison of an analysis outcome between simulated and real data.\n# export\nimport pandas as pd\n\ndef apply_and_concatenate(function, df1, df2, contrast_name='contrast', labels='AB'):\n    \"\"\"\n    Concatenates the results of a function applied to two dataframes and creates a new column identifying the contrast.\n    \"\"\"\n    return pd.concat([function(df1), function(df2)], keys=labels, names=[contrast_name]).reset_index()\nNow let’s create some simulated data with our model and fitted parameters.\nfrom compmemlearn.datasets import simulate_df\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(result.x)):\n    fitted_parameters[free_parameters[i]] = result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nmodel0 = Classic_CMR(murd_length0, murd_length0, fitted_parameters)\nmodel1 = Classic_CMR(murd_length1, murd_length1, fitted_parameters)\nmodel2 = Classic_CMR(murd_length2, murd_length2, fitted_parameters)\n\nsim_df0 = simulate_df(model0, 1000)\nsim_df1 = simulate_df(model1, 1000)\nsim_df2 = simulate_df(model2, 1000)\ntrue_df0 = murd_events0.copy()\ntrue_df1 = murd_events1.copy()\ntrue_df2 = murd_events2.copy()\nThen extract summary statistics…\ncmr_spc0 = apply_and_concatenate(fr.spc, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp0 = apply_and_concatenate(fr.lag_crp, sim_df0, true_df0, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr0 = apply_and_concatenate(fr.pnr, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr0 = cmr_pfr0.query('output <= 1')\n\ncmr_spc1 = apply_and_concatenate(fr.spc, sim_df1, true_df1, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp1 = apply_and_concatenate(fr.lag_crp, sim_df1, true_df1, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr1 = apply_and_concatenate(fr.pnr, sim_df1, true_df1, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr1 = cmr_pfr1.query('output <= 1')\n\ncmr_spc2 = apply_and_concatenate(fr.spc, sim_df2, true_df2, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp2 = apply_and_concatenate(fr.lag_crp, sim_df2, true_df2, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr2 = apply_and_concatenate(fr.pnr, sim_df2, true_df2, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr2 = cmr_pfr2.query('output <= 1')\nAnd plot the result…\n\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 12/1.5), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0, 0], data=cmr_spc0, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0, 0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0, 0].set_xticks(np.arange(1, murd_length0+1, 2))\naxes[0, 0].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[0, 1], data=cmr_spc1, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0, 1].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0, 1].set_xticks(np.arange(1, murd_length1+1, 3))\naxes[0, 1].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[0, 2], data=cmr_spc2, x='input', y='recall', err_style='bars', hue='source', legend=True)\naxes[0, 2].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0, 2].set_xticks(np.arange(1, murd_length2+1, 4))\naxes[0, 2].set_ylim((0, 1))\n\n# lag CRP\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[1, 0], data=cmr_lag_crp0.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1, 0], data=cmr_lag_crp0.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1, 0].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1, 0].set_xticks(np.arange(-5, 6, 1))\naxes[1, 0].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[1, 1], data=cmr_lag_crp1.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1, 1], data=cmr_lag_crp1.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1, 1].set(xlabel=\"Lag From Last Recalled Item\", ylabel='Conditional Recall Rate')\naxes[1, 1].set_xticks(np.arange(-5, 6, 1))\naxes[1, 1].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[1, 2], data=cmr_lag_crp2.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1, 2], data=cmr_lag_crp2.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1, 2].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1, 2].set_xticks(np.arange(-5, 6, 1))\naxes[1, 2].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=cmr_pfr0, x='input', y='prob', err_style='bars', ax=axes[2, 0], hue='source', legend=False)\naxes[2, 0].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2, 0].set_xticks(np.arange(1, murd_length0+1, 2))\naxes[2, 0].set_ylim((0, 1))\n\nsns.lineplot(data=cmr_pfr1, x='input', y='prob', err_style='bars', ax=axes[2, 1], hue='source', legend=False)\naxes[2, 1].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2, 1].set_xticks(np.arange(1, murd_length1+1, 3))\naxes[2, 1].set_ylim((0, 1))\n\nsns.lineplot(data=cmr_pfr2, x='input', y='prob', err_style='bars', ax=axes[2, 2], hue='source', legend=False)\naxes[2, 2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2, 2].set_xticks(np.arange(1, murd_length2+1, 4))\naxes[2, 2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[0, 2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=2)\n\n\n\n\n\n\nWhy aren’t the fits better?\nThe model doesn’t actually do a good job of capturing some of the quirks in the data – namely the graded probability of first recall curve in that last plot. CMR predicts a much sharper curve than the actual data and its struggle to account for something different results in worse apparent fits to other benchmark recall phenomena visualized here too. At least, that’s our best guess about what’s behind the failure."
  },
  {
    "objectID": "library\\model_analysis\\Data_Likelihood_Under_Model.html#fitting-pure-lists-with-lohnas_data_likelihood",
    "href": "library\\model_analysis\\Data_Likelihood_Under_Model.html#fitting-pure-lists-with-lohnas_data_likelihood",
    "title": "compmemlearn",
    "section": "Fitting Pure Lists with lohnas_data_likelihood",
    "text": "lohnas_data_likelihood is almost always slower than murdock_data_likelihood when it comes to fitting pure lists, but it’s useful to confirm that the functions work similarly in the use cases under which they overlap.\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')\n\nfree_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate'\n)\n\nLoading and Optimizing Along Cost Function\n\nfrom scipy.optimize import differential_evolution\nimport numpy as np\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nbounds = (\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n)\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\ncost_function = lohnas_objective_function(\n    trials[list_types == 1], \n    presentations[list_types == 1], \n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    free_parameters)\n\nlohnas_result = differential_evolution(cost_function, bounds, disp=True)\nprint(lohnas_result)\n\ndifferential_evolution step 1: f(x)= 22456.8\ndifferential_evolution step 2: f(x)= 21794.3\ndifferential_evolution step 3: f(x)= 21794.3\ndifferential_evolution step 4: f(x)= 21794.3\ndifferential_evolution step 5: f(x)= 21794.3\ndifferential_evolution step 6: f(x)= 21794.3\ndifferential_evolution step 7: f(x)= 21794.3\ndifferential_evolution step 8: f(x)= 20789\ndifferential_evolution step 9: f(x)= 20711.1\ndifferential_evolution step 10: f(x)= 20552.2\ndifferential_evolution step 11: f(x)= 20552.2\ndifferential_evolution step 12: f(x)= 19784.7\ndifferential_evolution step 13: f(x)= 19524.3\ndifferential_evolution step 14: f(x)= 19524.3\ndifferential_evolution step 15: f(x)= 19524.3\ndifferential_evolution step 16: f(x)= 19262.8\ndifferential_evolution step 17: f(x)= 19194.9\ndifferential_evolution step 18: f(x)= 19194.9\ndifferential_evolution step 19: f(x)= 19194.9\ndifferential_evolution step 20: f(x)= 19194.9\ndifferential_evolution step 21: f(x)= 19194.9\ndifferential_evolution step 22: f(x)= 19043.8\ndifferential_evolution step 23: f(x)= 19043.8\ndifferential_evolution step 24: f(x)= 19038.3\ndifferential_evolution step 25: f(x)= 19038.3\ndifferential_evolution step 26: f(x)= 19038.3\ndifferential_evolution step 27: f(x)= 19038.3\ndifferential_evolution step 28: f(x)= 18939.9\ndifferential_evolution step 29: f(x)= 18939.9\ndifferential_evolution step 30: f(x)= 18939.9\ndifferential_evolution step 31: f(x)= 18939.9\ndifferential_evolution step 32: f(x)= 18878.9\ndifferential_evolution step 33: f(x)= 18878.9\ndifferential_evolution step 34: f(x)= 18878.9\ndifferential_evolution step 35: f(x)= 18878.9\ndifferential_evolution step 36: f(x)= 18878.9\ndifferential_evolution step 37: f(x)= 18878.9\ndifferential_evolution step 38: f(x)= 18878.9\ndifferential_evolution step 39: f(x)= 18878.9\ndifferential_evolution step 40: f(x)= 18878.9\n     fun: 18810.058985583455\n     jac: array([ 2.22415109e+01, -6.99197695e+01,  2.76399076e+01,  2.91838660e+01,\n        1.67485268e+01, -4.66279741e+01, -1.05916114e+01,  0.00000000e+00,\n        4.38329152e+01, -1.48027539e+02, -2.56040950e+00, -3.63797881e-04])\n message: 'Optimization terminated successfully.'\n    nfev: 8524\n     nit: 40\n success: True\n       x: array([7.33635729e-01, 5.46844102e-01, 9.32757477e-01, 4.54648984e-01,\n       5.28712166e-02, 1.00000000e+00, 5.75890108e-01, 8.17565974e+01,\n       2.52220993e-02, 8.70307405e-02, 6.42673177e+00, 2.22044605e-16])\n\n\n\nfrom compmemlearn.datasets import simulate_df\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(lohnas_result.x)):\n    fitted_parameters[free_parameters[i]] = lohnas_result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nmodel0 = Classic_CMR(40, 40, fitted_parameters)\n\nsim_df0 = simulate_df(model0, 1000)\ntrue_df0 = events.loc[events.condition==1]\n\ncmr_spc0 = apply_and_concatenate(fr.spc, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp0 = apply_and_concatenate(fr.lag_crp, sim_df0, true_df0, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr0 = apply_and_concatenate(fr.pnr, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr0 = cmr_pfr0.query('output <= 1')\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 12/3), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0], data=cmr_spc0, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0].set_xticks(np.arange(1, list_length+1, 3))\naxes[0].set_ylim((0, 1))\n\n# lag CRP\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1].set_xticks(np.arange(-5, 6, 1))\naxes[1].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=cmr_pfr0, x='input', y='prob', err_style='bars', ax=axes[2], hue='source', legend=True)\naxes[2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2].set_xticks(np.arange(1, list_length+1, 3))\naxes[2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=2)\n\n\n\n\n\n\nLet’s compare this result with what we’d obtain if we fit using murdock_data_likelihood.\n\nfrom scipy.optimize import differential_evolution\nimport numpy as np\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nbounds = (\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n)\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\ncost_function = murdock_objective_function(\n    (trials[list_types==1], ), \n    (40, ), \n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    free_parameters)\n\nmurdock_result = differential_evolution(cost_function, bounds, disp=True)\nprint(murdock_result)\n\ndifferential_evolution step 1: f(x)= 25374.1\ndifferential_evolution step 2: f(x)= 22149.1\ndifferential_evolution step 3: f(x)= 22149.1\ndifferential_evolution step 4: f(x)= 22149.1\ndifferential_evolution step 5: f(x)= 22149.1\ndifferential_evolution step 6: f(x)= 21726.2\ndifferential_evolution step 7: f(x)= 21186.5\ndifferential_evolution step 8: f(x)= 20212.4\ndifferential_evolution step 9: f(x)= 20212.4\ndifferential_evolution step 10: f(x)= 20212.4\ndifferential_evolution step 11: f(x)= 20212.4\ndifferential_evolution step 12: f(x)= 19736.4\ndifferential_evolution step 13: f(x)= 19736.4\ndifferential_evolution step 14: f(x)= 19315.3\ndifferential_evolution step 15: f(x)= 19315.3\ndifferential_evolution step 16: f(x)= 19310.9\ndifferential_evolution step 17: f(x)= 19166.4\ndifferential_evolution step 18: f(x)= 19166.4\ndifferential_evolution step 19: f(x)= 19166.4\ndifferential_evolution step 20: f(x)= 19166.4\ndifferential_evolution step 21: f(x)= 19166.4\ndifferential_evolution step 22: f(x)= 19161.6\ndifferential_evolution step 23: f(x)= 19161.6\ndifferential_evolution step 24: f(x)= 19136.2\ndifferential_evolution step 25: f(x)= 19113.5\ndifferential_evolution step 26: f(x)= 18970.4\ndifferential_evolution step 27: f(x)= 18931.5\ndifferential_evolution step 28: f(x)= 18931.5\ndifferential_evolution step 29: f(x)= 18931.5\ndifferential_evolution step 30: f(x)= 18925.5\ndifferential_evolution step 31: f(x)= 18925.5\ndifferential_evolution step 32: f(x)= 18925.5\ndifferential_evolution step 33: f(x)= 18925.5\ndifferential_evolution step 34: f(x)= 18925.5\ndifferential_evolution step 35: f(x)= 18899.1\ndifferential_evolution step 36: f(x)= 18899.1\ndifferential_evolution step 37: f(x)= 18899.1\ndifferential_evolution step 38: f(x)= 18899.1\n     fun: 18807.983211993796\n     jac: array([ 1.09866959e-01, -1.17142917e-01, -9.85892252e-02, -1.12049747e-01,\n        1.20442564e+01, -4.45139447e+01, -2.14640749e-02,  0.00000000e+00,\n        1.42608769e-01, -3.45607987e-02,  9.45874496e-03,  0.00000000e+00])\n message: 'Optimization terminated successfully.'\n    nfev: 8385\n     nit: 38\n success: True\n       x: array([7.34343133e-01, 5.77169827e-01, 9.32322680e-01, 3.95403975e-01,\n       2.22044605e-16, 1.00000000e+00, 5.52537331e-01, 5.21590857e+01,\n       2.36174418e-02, 9.12284879e-02, 5.76055376e+00, 2.22044605e-16])\n\n\n\nfrom compmemlearn.datasets import simulate_df\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(murdock_result.x)):\n    fitted_parameters[free_parameters[i]] = murdock_result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nmodel0 = Classic_CMR(40, 40, fitted_parameters)\n\nsim_df0 = simulate_df(model0, 1000)\ntrue_df0 = events.loc[events.condition==1]\n\ncmr_spc0 = apply_and_concatenate(fr.spc, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp0 = apply_and_concatenate(fr.lag_crp, sim_df0, true_df0, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr0 = apply_and_concatenate(fr.pnr, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr0 = cmr_pfr0.query('output <= 1')\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 12/3), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0], data=cmr_spc0, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0].set_xticks(np.arange(1, list_length+1, 3))\naxes[0].set_ylim((0, 1))\n\n# lag CRP\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1].set_xticks(np.arange(-5, 6, 1))\naxes[1].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=cmr_pfr0, x='input', y='prob', err_style='bars', ax=axes[2], hue='source', legend=True)\naxes[2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2].set_xticks(np.arange(1, list_length+1, 3))\naxes[2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=2)"
  },
  {
    "objectID": "library\\model_analysis\\Data_Likelihood_Under_Model.html#fitting-mixed-lists-with-lohnas_data_likelihood",
    "href": "library\\model_analysis\\Data_Likelihood_Under_Model.html#fitting-mixed-lists-with-lohnas_data_likelihood",
    "title": "compmemlearn",
    "section": "Fitting Mixed Lists with lohnas_data_likelihood",
    "text": "trials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')\n\nfree_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate',\n)\n\nLoading and Optimizing Along Cost Function\n\nfrom scipy.optimize import differential_evolution\nimport numpy as np\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nbounds = (\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n)\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\ncost_function = lohnas_objective_function(\n    trials[list_types == 4], \n    presentations[list_types == 4], \n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    free_parameters)\n\nlohnas_result = differential_evolution(cost_function, bounds, disp=True)\nprint(lohnas_result)\n\ndifferential_evolution step 1: f(x)= 21960.7\ndifferential_evolution step 2: f(x)= 19692\ndifferential_evolution step 3: f(x)= 19692\ndifferential_evolution step 4: f(x)= 19692\ndifferential_evolution step 5: f(x)= 19692\ndifferential_evolution step 6: f(x)= 19692\ndifferential_evolution step 7: f(x)= 19692\ndifferential_evolution step 8: f(x)= 19692\ndifferential_evolution step 9: f(x)= 19106\ndifferential_evolution step 10: f(x)= 19106\ndifferential_evolution step 11: f(x)= 19106\ndifferential_evolution step 12: f(x)= 19012.4\ndifferential_evolution step 13: f(x)= 19012.4\ndifferential_evolution step 14: f(x)= 18122.3\ndifferential_evolution step 15: f(x)= 18122.3\ndifferential_evolution step 16: f(x)= 18122.3\ndifferential_evolution step 17: f(x)= 18122.3\ndifferential_evolution step 18: f(x)= 18035.6\ndifferential_evolution step 19: f(x)= 18035.6\ndifferential_evolution step 20: f(x)= 17991.2\ndifferential_evolution step 21: f(x)= 17770.7\ndifferential_evolution step 22: f(x)= 17711\ndifferential_evolution step 23: f(x)= 17711\ndifferential_evolution step 24: f(x)= 17657.4\ndifferential_evolution step 25: f(x)= 17433.7\ndifferential_evolution step 26: f(x)= 17433.7\ndifferential_evolution step 27: f(x)= 17433.7\ndifferential_evolution step 28: f(x)= 17433.7\ndifferential_evolution step 29: f(x)= 17433.7\ndifferential_evolution step 30: f(x)= 17433.7\ndifferential_evolution step 31: f(x)= 17433.7\ndifferential_evolution step 32: f(x)= 17433.7\ndifferential_evolution step 33: f(x)= 17433.7\ndifferential_evolution step 34: f(x)= 17433.7\ndifferential_evolution step 35: f(x)= 17433.7\ndifferential_evolution step 36: f(x)= 17433.7\ndifferential_evolution step 37: f(x)= 17433.7\ndifferential_evolution step 38: f(x)= 17433.7\ndifferential_evolution step 39: f(x)= 17360\n     fun: 17170.906872565276\n     jac: array([-3.17231750e-01,  4.29281499e-02,  2.78305377e-01, -1.91357685e-01,\n        2.77457730e+01, -2.11002771e-02,  4.72937248e-03,  8.58562999e-02,\n       -4.09636414e+00, -7.53061613e-01,  1.41881174e-02,  0.00000000e+00])\n message: 'Optimization terminated successfully.'\n    nfev: 9553\n     nit: 39\n success: True\n       x: array([8.37481840e-01, 3.33421728e-01, 9.66834627e-01, 5.95371489e-02,\n       2.22044605e-16, 4.45280033e-01, 4.47215803e+00, 4.07037005e-01,\n       2.13742105e-02, 1.06866782e-01, 1.31660740e+00, 8.61694026e-09])\n\n\nfrom compmemlearn.datasets import simulate_array_from_presentations\nfrom compmemlearn.analyses import fast_rpl\n\nfitted_parameters = Dict.empty(\n    key_type=types.unicode_type, value_type=types.float64)\nfor j in range(len(lohnas_result.x)):\n    fitted_parameters[free_parameters[j]] = lohnas_result.x[j]\n\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nexperiment_count = 1000\nnew_sim_array = simulate_array_from_presentations(init_cmr, fitted_parameters, presentations[list_types==4], experiment_count)\n\nimport numpy.matlib\n\nresult = fast_rpl(np.matlib.repmat(presentations[list_types==4], experiment_count, 1), new_sim_array)\nbinned = np.zeros(5)\nbinned[0] = result[0]\nbinned[1] = result[1]\nbinned[2] = (result[2] + result[3])/2\nbinned[3] = (result[4] + result[5] + result[6])/3\nbinned[4] = (result[7] + result[8] + result[9])/3\nprint(binned)\n\n[0.37778061 0.45604643 0.48747679 0.50164762 0.50651667]\n\n\n\nimport matplotlib.pyplot as plt\n\nfit_sources = ['lohnas_4']\nfit_rpls = [binned]\n\nfor i in range(len(fit_sources)):\n    plt.plot(fit_rpls[i], label=fit_sources[i])\n\nresult = fast_rpl(presentations[list_types==4], trials[list_types==4])\nbinned = np.zeros(5)\nbinned[0] = result[0]\nbinned[1] = result[1]\nbinned[2] = (result[2] + result[3])/2\nbinned[3] = (result[4] + result[5] + result[6])/3\nbinned[4] = (result[7] + result[8] + result[9])/3\nplt.plot(binned, label='data')\nlags = ['N/A', '0', '1-2', '3-5', '6-8']\nplt.xticks(np.arange(len(lags)), lags)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n<matplotlib.legend.Legend at 0x125811f0d90>\n\n\n\n\n\n\n\nAll Conditions\n\nfrom scipy.optimize import differential_evolution\nimport numpy as np\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nbounds = (\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n)\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\ncost_function = lohnas_objective_function(\n    trials[list_types >= 1], \n    presentations[list_types >= 1], \n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    free_parameters)\n\nlohnas_result = differential_evolution(cost_function, bounds, disp=True)\nprint(lohnas_result)\n\ndifferential_evolution step 1: f(x)= 94631.7\ndifferential_evolution step 2: f(x)= 79692.9\ndifferential_evolution step 3: f(x)= 70885.6\ndifferential_evolution step 4: f(x)= 69762\ndifferential_evolution step 5: f(x)= 67176.3\ndifferential_evolution step 6: f(x)= 67176.3\ndifferential_evolution step 7: f(x)= 67176.3\ndifferential_evolution step 8: f(x)= 66556.1\ndifferential_evolution step 9: f(x)= 66556.1\ndifferential_evolution step 10: f(x)= 65542\ndifferential_evolution step 11: f(x)= 65542\ndifferential_evolution step 12: f(x)= 64378.7\ndifferential_evolution step 13: f(x)= 64378.7\ndifferential_evolution step 14: f(x)= 63249.4\ndifferential_evolution step 15: f(x)= 62687.4\ndifferential_evolution step 16: f(x)= 62687.4\ndifferential_evolution step 17: f(x)= 62365.9\ndifferential_evolution step 18: f(x)= 62365.9\ndifferential_evolution step 19: f(x)= 62302.4\ndifferential_evolution step 20: f(x)= 62004.3\ndifferential_evolution step 21: f(x)= 62004.3\ndifferential_evolution step 22: f(x)= 62004.3\ndifferential_evolution step 23: f(x)= 62004.3\ndifferential_evolution step 24: f(x)= 61902.9\ndifferential_evolution step 25: f(x)= 61902.9\ndifferential_evolution step 26: f(x)= 61849.5\ndifferential_evolution step 27: f(x)= 61722.5\ndifferential_evolution step 28: f(x)= 61620.5\ndifferential_evolution step 29: f(x)= 61620.5\ndifferential_evolution step 30: f(x)= 61541.9\ndifferential_evolution step 31: f(x)= 61541.9\ndifferential_evolution step 32: f(x)= 61490\ndifferential_evolution step 33: f(x)= 61490\ndifferential_evolution step 34: f(x)= 61490\n     fun: 60797.2210129435\n     jac: array([-2.640445  , -0.65556378,  2.33558238, -2.81143002, -0.37325663,\n        0.38999133, -0.0174623 ,  0.        ,  3.73474904,  5.01822797,\n       -0.2757588 , -3.82788128])\n message: 'Optimization terminated successfully.'\n    nfev: 8913\n     nit: 34\n success: True\n       x: array([8.65844790e-01, 2.26172120e-01, 9.52083253e-01, 2.63516673e-02,\n       5.43072905e-07, 4.31711566e-01, 2.64505857e+00, 4.38402542e+01,\n       2.51585067e-02, 1.01418425e-01, 1.02244712e+00, 9.80136664e-01])\n\n\nfrom compmemlearn.datasets import simulate_array_from_presentations\nfrom compmemlearn.analyses import fast_rpl\n\nfitted_parameters = Dict.empty(\n    key_type=types.unicode_type, value_type=types.float64)\nfor j in range(len(lohnas_result.x)):\n    fitted_parameters[free_parameters[j]] = lohnas_result.x[j]\n\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nexperiment_count = 1000\nnew_sim_array = simulate_array_from_presentations(init_cmr, fitted_parameters, presentations[list_types>=1], experiment_count)\n\nimport numpy.matlib\n\nresult = fast_rpl(np.matlib.repmat(presentations[list_types>=1], experiment_count, 1), new_sim_array)\nbinned = np.zeros(5)\nbinned[0] = result[0]\nbinned[1] = result[1]\nbinned[2] = (result[2] + result[3])/2\nbinned[3] = (result[4] + result[5] + result[6])/3\nbinned[4] = (result[7] + result[8] + result[9])/3\nprint(binned)\n\n[0.3343702  0.60605876 0.58105782 0.58587598 0.58480437]\n\n\n\nimport matplotlib.pyplot as plt\n\nfit_sources = ['fit_to_full_dataset']\nfit_rpls = [binned]\n\nfor i in range(len(fit_sources)):\n    plt.plot(fit_rpls[i], label=fit_sources[i])\n\nresult = fast_rpl(presentations[list_types>=1], trials[list_types>=1])\nbinned = np.zeros(5)\nbinned[0] = result[0]\nbinned[1] = result[1]\nbinned[2] = (result[2] + result[3])/2\nbinned[3] = (result[4] + result[5] + result[6])/3\nbinned[4] = (result[7] + result[8] + result[9])/3\nplt.plot(binned, label='data')\nlags = ['N/A', '0', '1-2', '3-5', '6-8']\nplt.xticks(np.arange(len(lags)), lags)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n<matplotlib.legend.Legend at 0x12580e20ac0>\n\n\n\n\n\n\n\nDifferential Encoding\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../data/repFR.mat')\n\nfree_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate',\n    'mfc_familiarity_scale',\n    'mcf_familiarity_scale',\n    'drift_familiarity_scale',\n)\n\nfrom scipy.optimize import differential_evolution\nimport numpy as np\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nbounds = (\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub)\n)\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\ncost_function = lohnas_objective_function(\n    trials[list_types == 4], \n    presentations[list_types == 4], \n    init_cmr,\n    {'sampling_rule': 0}, \n    free_parameters)\n\nlohnas_result = differential_evolution(cost_function, bounds, disp=True)\nprint(lohnas_result)\n\ndifferential_evolution step 1: f(x)= 22294.2\ndifferential_evolution step 2: f(x)= 22294.2\ndifferential_evolution step 3: f(x)= 19887.7\ndifferential_evolution step 4: f(x)= 19618.8\ndifferential_evolution step 5: f(x)= 19618.8\ndifferential_evolution step 6: f(x)= 19618.8\ndifferential_evolution step 7: f(x)= 19618.8\ndifferential_evolution step 8: f(x)= 19347.4\ndifferential_evolution step 9: f(x)= 18814.7\ndifferential_evolution step 10: f(x)= 18814.7\ndifferential_evolution step 11: f(x)= 18139.3\ndifferential_evolution step 12: f(x)= 18139.3\ndifferential_evolution step 13: f(x)= 18139.3\ndifferential_evolution step 14: f(x)= 18139.3\ndifferential_evolution step 15: f(x)= 17855.5\ndifferential_evolution step 16: f(x)= 17827.9\ndifferential_evolution step 17: f(x)= 17827.9\ndifferential_evolution step 18: f(x)= 17655\ndifferential_evolution step 19: f(x)= 17655\ndifferential_evolution step 20: f(x)= 17655\ndifferential_evolution step 21: f(x)= 17538.4\ndifferential_evolution step 22: f(x)= 17538.4\ndifferential_evolution step 23: f(x)= 17538.4\ndifferential_evolution step 24: f(x)= 17538.4\ndifferential_evolution step 25: f(x)= 17538.4\ndifferential_evolution step 26: f(x)= 17520.4\ndifferential_evolution step 27: f(x)= 17520.4\ndifferential_evolution step 28: f(x)= 17471.6\ndifferential_evolution step 29: f(x)= 17471.6\ndifferential_evolution step 30: f(x)= 17465.5\ndifferential_evolution step 31: f(x)= 17462.6\ndifferential_evolution step 32: f(x)= 17462.6\ndifferential_evolution step 33: f(x)= 17429.5\ndifferential_evolution step 34: f(x)= 17429.5\ndifferential_evolution step 35: f(x)= 17429.5\ndifferential_evolution step 36: f(x)= 17429.5\n     fun: 17152.738785919926\n     jac: array([ 8.36007526e-01,  2.67027645e-01, -1.85973476e+00,  6.17073965e+00,\n        4.68331564e+01, -1.02118065e+00,  2.87400328e-02,  5.11499821e-01,\n        8.13815859e-01, -1.51376298e+00, -1.09866961e-01,  4.61295710e-01,\n       -6.80302037e-01, -7.06495485e-01, -1.57826434e+01])\n message: 'Optimization terminated successfully.'\n    nfev: 14677\n     nit: 36\n success: True\n       x: array([8.45399329e-01, 8.94309837e-02, 9.63793630e-01, 2.43252487e-02,\n       2.22044605e-16, 5.95712778e-01, 3.25658220e+00, 2.53201152e-01,\n       2.14029202e-02, 1.06789857e-01, 1.22711302e+00, 9.29194808e-01,\n       4.90150172e-01, 4.58480657e-01, 1.00000000e+00])\n\n\nfrom compmemlearn.datasets import simulate_array_from_presentations\nfrom compmemlearn.analyses import fast_rpl\n\nfitted_parameters = Dict.empty(\n    key_type=types.unicode_type, value_type=types.float64)\nfor j in range(len(lohnas_result.x)):\n    fitted_parameters[free_parameters[j]] = lohnas_result.x[j]\n\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nexperiment_count = 1000\nnew_sim_array = simulate_array_from_presentations(init_cmr, fitted_parameters, presentations[list_types==4], experiment_count)\n\nimport numpy.matlib\n\nresult = fast_rpl(np.matlib.repmat(presentations[list_types==4], experiment_count, 1), new_sim_array)\nbinned = np.zeros(5)\nbinned[0] = result[0]\nbinned[1] = result[1]\nbinned[2] = (result[2] + result[3])/2\nbinned[3] = (result[4] + result[5] + result[6])/3\nbinned[4] = (result[7] + result[8] + result[9])/3\nprint(binned)\n\n[0.37035927 0.48302143 0.52116429 0.54002976 0.54700595]\n\n\n\nimport matplotlib.pyplot as plt\n\nfit_sources = ['lohnas_4']\nfit_rpls = [binned]\n\nfor i in range(len(fit_sources)):\n    plt.plot(fit_rpls[i], label=fit_sources[i])\n\nresult = fast_rpl(presentations[list_types==4], trials[list_types==4])\nbinned = np.zeros(5)\nbinned[0] = result[0]\nbinned[1] = result[1]\nbinned[2] = (result[2] + result[3])/2\nbinned[3] = (result[4] + result[5] + result[6])/3\nbinned[4] = (result[7] + result[8] + result[9])/3\nplt.plot(binned, label='data')\nlags = ['N/A', '0', '1-2', '3-5', '6-8']\nplt.xticks(np.arange(len(lags)), lags)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n<matplotlib.legend.Legend at 0x1258219d0d0>"
  },
  {
    "objectID": "library\\model_analysis\\Model_Characterization.html#initial-fitting-and-memory-visualization",
    "href": "library\\model_analysis\\Model_Characterization.html#initial-fitting-and-memory-visualization",
    "title": "compmemlearn",
    "section": "Initial Fitting and Memory Visualization",
    "text": "InstanceCMR\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nicmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n    'context_sensitivity',\n#    'feature_sensitivity'\n    'delay_drift_rate',\n)\n\nicmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n#    (lb, 10),\n#    (lb, 10)\n    (lb, ub),\n]\n\n@njit(fastmath=True, nogil=True)\ndef init_icmr(item_count, presentation_count, parameters):\n    return Instance_CMR(item_count, presentation_count, parameters)\n\ncondition = 4\nselection = list_types == condition\ncost_function = lohnas_objective_function(\n    trials[selection], \n    presentations[selection],\n    init_icmr,\n    {'choice_sensitivity': 1, 'feature_sensitivity': 1}, \n    icmr_free_parameters)\n\nicmr_result = differential_evolution(cost_function, icmr_bounds, disp=True)\nicmr_result\n\ndifferential_evolution step 1: f(x)= 33720.1\ndifferential_evolution step 2: f(x)= 30743.7\ndifferential_evolution step 3: f(x)= 30743.7\ndifferential_evolution step 4: f(x)= 23444.6\ndifferential_evolution step 5: f(x)= 19831.3\ndifferential_evolution step 6: f(x)= 19400.9\ndifferential_evolution step 7: f(x)= 19400.9\ndifferential_evolution step 8: f(x)= 18531.7\ndifferential_evolution step 9: f(x)= 18285.1\ndifferential_evolution step 10: f(x)= 18274.3\ndifferential_evolution step 11: f(x)= 18194.7\ndifferential_evolution step 12: f(x)= 18125.7\ndifferential_evolution step 13: f(x)= 18125.7\ndifferential_evolution step 14: f(x)= 17241\ndifferential_evolution step 15: f(x)= 17241\ndifferential_evolution step 16: f(x)= 17241\ndifferential_evolution step 17: f(x)= 17241\ndifferential_evolution step 18: f(x)= 16361\ndifferential_evolution step 19: f(x)= 16361\ndifferential_evolution step 20: f(x)= 16361\ndifferential_evolution step 21: f(x)= 16361\ndifferential_evolution step 22: f(x)= 16361\ndifferential_evolution step 23: f(x)= 16361\ndifferential_evolution step 24: f(x)= 16361\ndifferential_evolution step 25: f(x)= 16361\ndifferential_evolution step 26: f(x)= 16361\ndifferential_evolution step 27: f(x)= 16361\ndifferential_evolution step 28: f(x)= 16200.5\ndifferential_evolution step 29: f(x)= 15919.8\ndifferential_evolution step 30: f(x)= 15919.8\ndifferential_evolution step 31: f(x)= 15919.8\ndifferential_evolution step 32: f(x)= 15919.8\ndifferential_evolution step 33: f(x)= 15919.8\ndifferential_evolution step 34: f(x)= 15919.8\ndifferential_evolution step 35: f(x)= 15919.8\ndifferential_evolution step 36: f(x)= 15919.8\ndifferential_evolution step 37: f(x)= 15906.9\ndifferential_evolution step 38: f(x)= 15906.9\ndifferential_evolution step 39: f(x)= 15873.1\ndifferential_evolution step 40: f(x)= 15873.1\ndifferential_evolution step 41: f(x)= 15873.1\ndifferential_evolution step 42: f(x)= 15855\ndifferential_evolution step 43: f(x)= 15855\ndifferential_evolution step 44: f(x)= 15840\ndifferential_evolution step 45: f(x)= 15840\ndifferential_evolution step 46: f(x)= 15840\ndifferential_evolution step 47: f(x)= 15840\ndifferential_evolution step 48: f(x)= 15840\ndifferential_evolution step 49: f(x)= 15840\ndifferential_evolution step 50: f(x)= 15840\ndifferential_evolution step 51: f(x)= 15790.8\ndifferential_evolution step 52: f(x)= 15790.8\ndifferential_evolution step 53: f(x)= 15790.8\ndifferential_evolution step 54: f(x)= 15790.8\ndifferential_evolution step 55: f(x)= 15790.8\ndifferential_evolution step 56: f(x)= 15790.8\ndifferential_evolution step 57: f(x)= 15790.8\ndifferential_evolution step 58: f(x)= 15790.8\ndifferential_evolution step 59: f(x)= 15790.8\ndifferential_evolution step 60: f(x)= 15790.8\ndifferential_evolution step 61: f(x)= 15789.2\n\n\n     fun: 15639.52630931897\n     jac: array([-4.40741130e-01, -2.41743692e-01, -7.29232848e-01, -5.62577043e+00,\n       -6.25277604e+00,  1.09394022e+00, -5.82076613e-03, -2.20279618e-01,\n       -2.04709067e+00, -3.06499715e-01, -4.07453629e-02, -1.16415321e-02])\n message: 'Optimization terminated successfully.'\n    nfev: 15112\n     nit: 61\n success: True\n       x: array([0.81354362, 0.13186679, 0.92156226, 0.01638355, 1.        ,\n       0.51789751, 2.51054862, 1.07486145, 0.02249255, 0.10414492,\n       2.10982446, 0.96461678])\n\n\n\nexperiment_count = 1000\n\n# static_icmr_fit_result = np.array([8.32809463e-01, 4.85458609e-02, 9.61140398e-01, 1.19908530e-03,\n#        1.31621512e-01, 2.45449928e-01, 3.33484776e+00, 2.09892365e+01,\n#        2.15080187e-02, 1.06720819e-01, 1.32169006e+00, 9.94120769e-01])\n\n# icmr_fitted_parameters = Dict.empty(\n#         key_type=types.unicode_type, value_type=types.float64)\n# for j in range(len(static_icmr_fit_result)):\n#     icmr_fitted_parameters[icmr_free_parameters[j]] =static_icmr_fit_result.x[j]\n\nicmr_fitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\nfor j in range(len(icmr_result.x)):\n    icmr_fitted_parameters[icmr_free_parameters[j]] =icmr_result.x[j]\n    \nicmr_fitted_parameters['choice_sensitivity'] = 1\nicmr_fitted_parameters['feature_sensitivity'] = 1\n\nmodel = Instance_CMR(list_length, list_length, icmr_fitted_parameters)\nsimulate_df(model, 1)\n\nicmr_memory_heatmap(model, just_experimental=True, just_context=False)\n\nitem_count = np.max(presentations[0])+1\nmodel = Instance_CMR(item_count, list_length, icmr_fitted_parameters)\nmodel.experience(model.items[presentations[0]])\nicmr_memory_heatmap(model, just_experimental=True, just_context=False)\nprint(presentations[0])\n\n\n\n\n\n\n\n[ 0  1  2  3  4  5  6  7  8  9 10 11 11 12 13 14 15 16  9 17 18 19 18 20\n 21 22 19 23 24 25 21 26 27 23 28 29 30 31 32 33]\n\n\n\n\nTR-CMR\nA cell to reload the model in case I’ve updated the specification:\n\n# remember to run nbdev_build_lib first! \n\n!nbdev_build_lib\nimport compmemlearn\nimport importlib\nimportlib.reload(compmemlearn.models)\nfrom compmemlearn.models import Trace_Reinstatement_CMR, Instance_CMR\n\nConverted Alternative_Contiguity.ipynb.\nConverted Conditional_Stop_Probability.ipynb.\nConverted Lag_Contiguity_Effect.ipynb.\nConverted Lag_Contiguity_with_Repetition_Data.ipynb.\nConverted Measuring_Repetition_Effects.ipynb.\nConverted Probability_of_First_Recall.ipynb.\nConverted Probability_of_First_Recall_in_Repetition_Data.ipynb.\nConverted Recall_Probability_by_Spacing.ipynb.\nConverted Serial_Position_Effect.ipynb.\nConverted Serial_Position_Effect_in_Repetition_Datasets.ipynb.\nConverted Shared_Contiguity.ipynb.\nConverted ClairExpt6.ipynb.\nConverted Data_Simulation.ipynb.\nConverted HowaKaha05.ipynb.\nConverted Lohnas2014.ipynb.\nConverted Murdock1962.ipynb.\nConverted MurdockOkada1970.ipynb.\nConverted PEERS.ipynb.\nConverted index.ipynb.\nConverted Alternative_Contiguity_Tracing.ipynb.\nConverted Contiguity_Tracing.ipynb.\nConverted Data_Likelihood_Under_Model.ipynb.\nConverted Model_Characterization.ipynb.\nConverted Model_Visualization.ipynb.\nConverted Classic_CMR.ipynb.\nConverted Instance_CMR.ipynb.\nConverted Noisy_CMR.ipynb.\nConverted Scalar_CMR.ipynb.\nConverted Trace_Reinstatement_CMR.ipynb.\n\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ntrcmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n    'context_sensitivity',\n#    'feature_sensitivity'\n    'delay_drift_rate',\n    'feature_drift_rate',\n#    'context_reinstatement'\n)\n\ntrcmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n#    (lb, 10),\n#    (lb, 10)\n    (lb, ub),\n    (lb, ub),\n#    (lb, 10)\n]\n\n@njit(fastmath=True, nogil=True)\ndef init_trcmr(item_count, presentation_count, parameters):\n    return Trace_Reinstatement_CMR(item_count, presentation_count, parameters)\n\ncondition = 4\nselection = list_types == condition\ncost_function = lohnas_objective_function(\n    trials[selection], \n    presentations[selection],\n    init_trcmr,\n    {'choice_sensitivity': 1, 'feature_sensitivity': 1, 'context_reinstatement': 0}, \n    trcmr_free_parameters)\n\n# will throw error if i haven't already fitted\n#print(init_trcmr(20, 20, trcmr_fitted_parameters).items[0])\n\n#TODO: When holding variable constant, 1) comment out the variable in free parameters, 2) comment out its bounds, and 3) add constant variable to the dict argument in cost_function, and 4) make sure initial simulation code also sets constant parameter's value (or you won't get far)\n\ntrcmr_result = differential_evolution(cost_function, trcmr_bounds, disp=True)\ntrcmr_result\n\ndifferential_evolution step 1: f(x)= 20113.2\ndifferential_evolution step 2: f(x)= 20113.2\ndifferential_evolution step 3: f(x)= 18436.3\ndifferential_evolution step 4: f(x)= 18436.3\ndifferential_evolution step 5: f(x)= 18436.3\ndifferential_evolution step 6: f(x)= 18436.3\ndifferential_evolution step 7: f(x)= 18287.8\ndifferential_evolution step 8: f(x)= 18287.8\ndifferential_evolution step 9: f(x)= 18006.6\ndifferential_evolution step 10: f(x)= 18006.6\ndifferential_evolution step 11: f(x)= 18006.6\ndifferential_evolution step 12: f(x)= 17808.6\ndifferential_evolution step 13: f(x)= 17808.6\ndifferential_evolution step 14: f(x)= 17808.6\ndifferential_evolution step 15: f(x)= 17808.6\ndifferential_evolution step 16: f(x)= 16763.6\ndifferential_evolution step 17: f(x)= 16763.6\ndifferential_evolution step 18: f(x)= 16658.6\ndifferential_evolution step 19: f(x)= 16658.6\ndifferential_evolution step 20: f(x)= 16658.6\ndifferential_evolution step 21: f(x)= 16658.6\ndifferential_evolution step 22: f(x)= 16658.6\ndifferential_evolution step 23: f(x)= 16658.6\ndifferential_evolution step 24: f(x)= 16658.6\ndifferential_evolution step 25: f(x)= 16658.6\ndifferential_evolution step 26: f(x)= 16658.6\ndifferential_evolution step 27: f(x)= 16600.2\ndifferential_evolution step 28: f(x)= 16600.2\ndifferential_evolution step 29: f(x)= 16162.4\ndifferential_evolution step 30: f(x)= 16162.4\ndifferential_evolution step 31: f(x)= 16162.4\ndifferential_evolution step 32: f(x)= 16162.4\ndifferential_evolution step 33: f(x)= 16067.9\ndifferential_evolution step 34: f(x)= 15965.1\ndifferential_evolution step 35: f(x)= 15965.1\ndifferential_evolution step 36: f(x)= 15965.1\ndifferential_evolution step 37: f(x)= 15933.2\ndifferential_evolution step 38: f(x)= 15933.2\ndifferential_evolution step 39: f(x)= 15933.2\ndifferential_evolution step 40: f(x)= 15867.8\ndifferential_evolution step 41: f(x)= 15867.8\ndifferential_evolution step 42: f(x)= 15867.8\ndifferential_evolution step 43: f(x)= 15867.8\ndifferential_evolution step 44: f(x)= 15867.8\ndifferential_evolution step 45: f(x)= 15867.8\ndifferential_evolution step 46: f(x)= 15867.8\ndifferential_evolution step 47: f(x)= 15834.9\ndifferential_evolution step 48: f(x)= 15834.9\ndifferential_evolution step 49: f(x)= 15834.9\ndifferential_evolution step 50: f(x)= 15834.9\ndifferential_evolution step 51: f(x)= 15781.9\ndifferential_evolution step 52: f(x)= 15775.5\ndifferential_evolution step 53: f(x)= 15775.5\ndifferential_evolution step 54: f(x)= 15775.5\n\n\n     fun: 15699.843571126987\n     jac: array([-1.44409568,  0.10204531, -0.67611836,  2.73339538, -9.39544402,\n       -0.16279955,  0.14388206,  0.        ,  1.54122972, -0.43346518,\n       -0.0165528 , -0.82709448,  0.79999154])\n message: 'Optimization terminated successfully.'\n    nfev: 15359\n     nit: 54\n success: True\n       x: array([8.39314620e-01, 1.63618629e-01, 9.23936537e-01, 1.55520938e-02,\n       1.00000000e+00, 5.23221127e-01, 2.35838577e+00, 9.93512212e+01,\n       2.25120491e-02, 1.04097390e-01, 2.06938199e+00, 9.93062277e-01,\n       1.54392061e-01])\n\n\n\nexperiment_count = 1000\n\n# static_trcmr_result = np.array([8.38888699e-01, 5.11712122e-04, 9.42814559e-01, 6.43556899e-03, # temporarily set to 0\n#        6.45214269e-01, 4.81647177e-01, 4.00131827e+00, 1.98252428e+00,\n#        2.83758432e-02, 9.60298353e-02, 1.58539149e+00, 9.99999887e-01,\n#        3.61675064e-01])\n\n# trcmr_fitted_parameters = Dict.empty(\n#         key_type=types.unicode_type, value_type=types.float64)\n# for j in range(len(static_trcmr_result)):\n#     trcmr_fitted_parameters[trcmr_free_parameters[j]] = static_trcmr_result[j]\n\ntrcmr_fitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\nfor j in range(len(trcmr_result.x)):\n    trcmr_fitted_parameters[trcmr_free_parameters[j]] = trcmr_result.x[j]\n    \ntrcmr_fitted_parameters['choice_sensitivity'] = 1\ntrcmr_fitted_parameters['feature_sensitivity'] = 1\n# trcmr_fitted_parameters['shared_support'] = 0\ntrcmr_fitted_parameters['context_reinstatement'] = 0\n#trcmr_fitted_parameters['feature_drift_rate'] = 1\n\nprint(Trace_Reinstatement_CMR(20, 20, trcmr_fitted_parameters).items[0]) \n\nitem_count = np.max(presentations[0])+1\nmodel = Trace_Reinstatement_CMR(item_count, list_length, trcmr_fitted_parameters)\nmodel.experience(model.items[presentations[0]])\nicmr_memory_heatmap(model, just_experimental=True, just_context=False)\nprint(presentations[0])\n\nmodel = Trace_Reinstatement_CMR(list_length, list_length, trcmr_fitted_parameters)\nsimulate_df(model, 1)\nicmr_memory_heatmap(model, just_experimental=True, just_context=False)\n\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n\n\n\n\n\n[ 0  1  2  3  4  5  6  7  8  9 10 11 11 12 13 14 15 16  9 17 18 19 18 20\n 21 22 19 23 24 25 21 26 27 23 28 29 30 31 32 33]"
  },
  {
    "objectID": "library\\model_analysis\\Model_Characterization.html#benchmark-evaluation",
    "href": "library\\model_analysis\\Model_Characterization.html#benchmark-evaluation",
    "title": "compmemlearn",
    "section": "Benchmark Evaluation",
    "text": "InstanceCMR\n\nmodel_name = 'InstanceCMR'\n\n# identify first recalled item for each trial\nfirst_recalls = np.zeros(len(presentations), dtype=int)\nfor i in range(len(presentations)):\n    first_recalls[i] = presentations[i][trials[i, 0]-1]+1\n\nicmr_trials = simulate_array_from_presentations(\n    init_icmr, icmr_fitted_parameters, presentations[list_types==condition], experiment_count, first_recalls[list_types==condition])\nicmr_presentations = np.matlib.repmat(presentations[list_types==condition], experiment_count, 1)\n\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(20, 20), sharey='row')\n\n# spc\ndata_spc= flex_mixed_spc(trials[list_types==condition], presentations[list_types==condition])\nicmr_spc = flex_mixed_spc(icmr_trials, icmr_presentations)\naxes[0, 0].plot(np.arange(len(data_spc)), data_spc, label='Data')\naxes[0, 0].plot(np.arange(len(icmr_spc)), icmr_spc, label=model_name)\naxes[0, 0].set_title('SPC')\n\n# pfr\ndata_pfr = flex_mixed_pfr(trials[list_types==condition], presentations[list_types==condition])\nicmr_pfr = flex_mixed_pfr(icmr_trials, icmr_presentations)\naxes[1, 1].plot(np.arange(len(data_pfr)), data_pfr, label='Data')\naxes[1, 1].plot(np.arange(len(icmr_pfr)), icmr_pfr, label=model_name)\naxes[1, 1].set_title('PFR')\n\n# crp\nlag_range = len(presentations[0])-1\ndata_crp= flex_mixed_crp(trials[list_types==condition], presentations[list_types==condition])\ndata_crp[lag_range] = np.nan\nicmr_crp = flex_mixed_crp(icmr_trials, icmr_presentations)\nicmr_crp[lag_range] = np.nan\naxes[1, 0].plot(np.arange(len(data_crp)), data_crp, label='Data')\naxes[1, 0].plot(np.arange(len(icmr_crp)), icmr_crp, label=model_name)\naxes[1, 0].set_xticks(np.arange(0, len(data_crp), 4))\naxes[1, 0].set_xticklabels(np.arange(0, len(data_crp), 4) - lag_range)\naxes[1, 0].set_title('CRP')\n\n# rpl\ndata_rpl = fast_rpl(\n    trials[list_types==condition], presentations[list_types==condition], max_lag=8)\nbinned = np.zeros(5)\nbinned[0] = data_rpl[0]\nbinned[1] = data_rpl[1]\nbinned[2] = (data_rpl[2] + data_rpl[3])/2\nbinned[3] = (data_rpl[4] + data_rpl[5] + data_rpl[6])/3\nbinned[4] = (data_rpl[7] + data_rpl[8] + data_rpl[9])/3\ndata_rpl = binned.copy()\n\nicmr_rpl = fast_rpl(\n    icmr_trials, icmr_presentations, max_lag=8)\nbinned = np.zeros(5)\nbinned[0] = icmr_rpl[0]\nbinned[1] = icmr_rpl[1]\nbinned[2] = (icmr_rpl[2] + icmr_rpl[3])/2\nbinned[3] = (icmr_rpl[4] + icmr_rpl[5] + icmr_rpl[6])/3\nbinned[4] = (icmr_rpl[7] + icmr_rpl[8] + icmr_rpl[9])/3\nicmr_rpl = binned.copy()\n\naxes[0, 1].plot(np.arange(len(data_rpl)), data_rpl, label='Data')\naxes[0, 1].plot(np.arange(len(icmr_rpl)), icmr_rpl, label=model_name)\naxes[0, 1].set_title('Recall Probability by Lag')\n\n# alt contiguity (data)\ndata_altcrp = alternative_contiguity(\n    trials[list_types==condition], presentations[list_types==condition], 6, 2)\ndata_altcrp[:, lag_range] = np.nan\naxes[2, 0].plot(np.arange(7), data_altcrp[0][lag_range-3:lag_range+4], label='First Presentation')\naxes[2, 0].plot(np.arange(7), data_altcrp[1][lag_range-3:lag_range+4], label='Second Presentation')\naxes[2, 0].set_xticks(np.arange(7))\naxes[2, 0].set_xticklabels(np.arange(7) - 3)\naxes[2, 0].set_title('Repetition Contiguity -- Data')\n\nicmr_altcrp = alternative_contiguity(\n    icmr_trials, icmr_presentations, 6, 2)\nicmr_altcrp[:, lag_range] = np.nan\naxes[2, 1].plot(np.arange(7), icmr_altcrp[0][lag_range-3:lag_range+4], label='First Presentation')\naxes[2, 1].plot(np.arange(7), icmr_altcrp[1][lag_range-3:lag_range+4], label='Second Presentation')\naxes[2, 1].set_xticks(np.arange(7))\naxes[2, 1].set_xticklabels(np.arange(7) - 3)\naxes[2, 1].set_title('Repetition Contiguity -- ' + model_name)\n\naxes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\naxes[2, 1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);\n\n\n\n\n\nmodel_name = 'InstanceCMR'\n\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 10), sharey='row')\n\n# alt contiguity (data)\nlag_range = len(presentations[0])-1\ndata_altcrp = alternative_contiguity(\n    trials[list_types==condition], presentations[list_types==condition], 6, 2)\ndata_altcrp[:, lag_range] = np.nan\ncmr_altcrp = alternative_contiguity(\n    icmr_trials, icmr_presentations, 6, 2)\ncmr_altcrp[:, lag_range] = np.nan\n\naxes.plot(np.arange(7), data_altcrp[0][lag_range-3:lag_range+4]-data_altcrp[1][lag_range-3:lag_range+4], label='Data')\naxes.plot(np.arange(7), cmr_altcrp[0][lag_range-3:lag_range+4]-cmr_altcrp[1][lag_range-3:lag_range+4], label=model_name)\naxes.set_xticks(np.arange(7))\naxes.set_xticklabels(np.arange(7) - 3)\naxes.set_title('Positional Contiguity Difference')\n\naxes.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n<matplotlib.legend.Legend at 0x22a9946fa90>\n\n\n\n\n\n\n\nTrace-Reinstatement CMR\n\nmodel_name = 'Trace Reinstatement CMR'\n\nfirst_recalls = np.zeros(len(presentations), dtype=int)\nfor i in range(len(presentations)):\n    first_recalls[i] = presentations[i][trials[i, 0]-1]+1\n    \ntrcmr_trials = simulate_array_from_presentations(\n    init_trcmr, trcmr_fitted_parameters, presentations[list_types==condition], experiment_count, first_recalls[list_types==condition])\ntrcmr_presentations = np.matlib.repmat(presentations[list_types==condition], experiment_count, 1)\n\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(20, 20), sharey='row')\n\n# spc\ndata_spc= flex_mixed_spc(trials[list_types==condition], presentations[list_types==condition])\ntrcmr_spc = flex_mixed_spc(trcmr_trials, trcmr_presentations)\naxes[0, 0].plot(np.arange(len(data_spc)), data_spc, label='Data')\naxes[0, 0].plot(np.arange(len(trcmr_spc)), trcmr_spc, label=model_name)\naxes[0, 0].set_title('SPC')\n\n# pfr\ndata_pfr = flex_mixed_pfr(trials[list_types==condition], presentations[list_types==condition])\ntrcmr_pfr = flex_mixed_pfr(trcmr_trials, trcmr_presentations)\naxes[1, 1].plot(np.arange(len(data_pfr)), data_pfr, label='Data')\naxes[1, 1].plot(np.arange(len(trcmr_pfr)), trcmr_pfr, label=model_name)\naxes[1, 1].set_title('PFR')\n\n# crp\nlag_range = len(presentations[0])-1\ndata_crp= flex_mixed_crp(trials[list_types==condition], presentations[list_types==condition])\ndata_crp[lag_range] = np.nan\ntrcmr_crp = flex_mixed_crp(trcmr_trials, trcmr_presentations)\ntrcmr_crp[lag_range] = np.nan\naxes[1, 0].plot(np.arange(len(data_crp)), data_crp, label='Data')\naxes[1, 0].plot(np.arange(len(trcmr_crp)), trcmr_crp, label=model_name)\naxes[1, 0].set_xticks(np.arange(0, len(data_crp), 4))\naxes[1, 0].set_xticklabels(np.arange(0, len(data_crp), 4) - lag_range)\naxes[1, 0].set_title('CRP')\n\n# rpl\ndata_rpl = fast_rpl(\n    trials[list_types==condition], presentations[list_types==condition], max_lag=8)\nbinned = np.zeros(5)\nbinned[0] = data_rpl[0]\nbinned[1] = data_rpl[1]\nbinned[2] = (data_rpl[2] + data_rpl[3])/2\nbinned[3] = (data_rpl[4] + data_rpl[5] + data_rpl[6])/3\nbinned[4] = (data_rpl[7] + data_rpl[8] + data_rpl[9])/3\ndata_rpl = binned.copy()\n\ntrcmr_rpl = fast_rpl(\n    trcmr_trials, trcmr_presentations, max_lag=8)\nbinned = np.zeros(5)\nbinned[0] = trcmr_rpl[0]\nbinned[1] = trcmr_rpl[1]\nbinned[2] = (trcmr_rpl[2] + trcmr_rpl[3])/2\nbinned[3] = (trcmr_rpl[4] + trcmr_rpl[5] + trcmr_rpl[6])/3\nbinned[4] = (trcmr_rpl[7] + trcmr_rpl[8] + trcmr_rpl[9])/3\ntrcmr_rpl = binned.copy()\n\naxes[0, 1].plot(np.arange(len(data_rpl)), data_rpl, label='Data')\naxes[0, 1].plot(np.arange(len(trcmr_rpl)), trcmr_rpl, label=model_name)\naxes[0, 1].set_title('Recall Probability by Lag')\n\n# alt contiguity (data)\ndata_altcrp = alternative_contiguity(\n    trials[list_types==condition], presentations[list_types==condition], 6, 2)\ndata_altcrp[:, lag_range] = np.nan\naxes[2, 0].plot(np.arange(7), data_altcrp[0][lag_range-3:lag_range+4], label='First Presentation')\naxes[2, 0].plot(np.arange(7), data_altcrp[1][lag_range-3:lag_range+4], label='Second Presentation')\naxes[2, 0].set_xticks(np.arange(7))\naxes[2, 0].set_xticklabels(np.arange(7) - 3)\naxes[2, 0].set_title('Repetition Contiguity -- Data')\n\ntrcmr_altcrp = alternative_contiguity(\n    trcmr_trials, trcmr_presentations, 6, 2)\ntrcmr_altcrp[:, lag_range] = np.nan\naxes[2, 1].plot(np.arange(7), trcmr_altcrp[0][lag_range-3:lag_range+4], label='First Presentation')\naxes[2, 1].plot(np.arange(7), trcmr_altcrp[1][lag_range-3:lag_range+4], label='Second Presentation')\naxes[2, 1].set_xticks(np.arange(7))\naxes[2, 1].set_xticklabels(np.arange(7) - 3)\naxes[2, 1].set_title('Repetition Contiguity -- ' + model_name)\n\naxes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\naxes[2, 1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);\n\n\n\n\n\nmodel_name = 'Trace Reinstatement CMR'\n\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 10), sharey='row')\n\n# alt contiguity (data)\ndata_altcrp = alternative_contiguity(\n    trials[list_types==condition], presentations[list_types==condition], 6, 2)\ndata_altcrp[:, lag_range] = np.nan\ncmr_altcrp = alternative_contiguity(\n    trcmr_trials, trcmr_presentations, 6, 2)\ncmr_altcrp[:, lag_range] = np.nan\n\naxes.plot(np.arange(7), data_altcrp[0][lag_range-3:lag_range+4]-data_altcrp[1][lag_range-3:lag_range+4], label='Data')\naxes.plot(np.arange(7), cmr_altcrp[0][lag_range-3:lag_range+4]-cmr_altcrp[1][lag_range-3:lag_range+4], label=model_name)\naxes.set_xticks(np.arange(7))\naxes.set_xticklabels(np.arange(7) - 3)\naxes.set_title('Positional Contiguity Difference')\n\naxes.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n<matplotlib.legend.Legend at 0x22a9ee6a6d0>\n\n\n\n\n\n\n\nTrace-Reinstatement CMR"
  },
  {
    "objectID": "library\\model_analysis\\Model_Characterization.html#latent-mfc-mcf-mfc---mcf-mff",
    "href": "library\\model_analysis\\Model_Characterization.html#latent-mfc-mcf-mfc---mcf-mff",
    "title": "compmemlearn",
    "section": "Latent MFC, MCF, MFC -> MCF (MFF)",
    "text": "This time, we’ll do extra processing to the model’s internal representations to build a more accurate picture of the proximate input into the next step of model processing. For MFC, this mainly means adding a normalization step to processing. For MCF, we assume stop_probability is 0 and no items have been recalled and compute what would be the corresponding output from model.outcome_probabilities. This means scaling retrieved activations with the exponent model.choice_sensitivity and enforcing the sum of entries in the output vector to the value 1.\nFurthermore, we wish to characterize how MFC and MCF interact to determine transitions during simulated free recall. This is found by passing each relevant item feature representation through MFC to retrieve contextual associations and then further passing these retrieved contextual associations through MCF to obtain correspond item feature associations. Though in practice the extent of the link between MFC and MCF is mediated by the contextual drift rate parameter, this provides insight into the directional effect of recalling an item on the probability distribution for the following one. We’ll call this mapping MFF.\n\nInstanceCMR\n\nmodel = Instance_CMR(list_length, list_length, icmr_fitted_parameters)\nsimulate_df(model, 1)\n\nlatent_mfc, latent_mcf, latent_mff = latent_mfc_mcf_mff(model, model.items)\n\nmfc_heatmap(latent_mfc)\nmfc_heatmap(latent_mcf)\nmfc_heatmap(latent_mff)\n\n\n\n\n\n\n\n\n\n\n\n\nTrace-Reinstatement CMR\n\nmodel = Trace_Reinstatement_CMR(list_length, list_length, trcmr_fitted_parameters)\nsimulate_df(model, 1)\n\nlatent_mfc, latent_mcf, latent_mff = latent_mfc_mcf_mff(model, model.recall_items)\n\nmfc_heatmap(latent_mfc)\nmfc_heatmap(latent_mcf)\nmfc_heatmap(latent_mff)"
  },
  {
    "objectID": "library\\model_analysis\\Model_Characterization.html#memory-connectivity-by-lag",
    "href": "library\\model_analysis\\Model_Characterization.html#memory-connectivity-by-lag",
    "title": "compmemlearn",
    "section": "Memory Connectivity by Lag",
    "text": "InstanceCMR\n\n# configure parameters\nmodel_class = Instance_CMR\nmodel_parameters = icmr_fitted_parameters\n\n# track results\nglobal_lag_range = 39\n\nfor list_type in [1, 2, 3, 4]:\n    mfc_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mcf_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mff_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n\n    # loop through presentations\n    for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n        # simulate list study\n        item_count = np.max(presentation)+1\n        model = model_class(item_count, len(presentation), model_parameters)\n        model.experience(model.items[presentation])\n        lag_range = item_count+1\n\n        # extract item connections\n        if model_class.__name__ == 'Classic_CMR':\n            #TODO: Update for Classic CMR\n            mfc_connections = model.mfc[:, 1:-1]\n            mcf_connections = model.mcf[1:-1, :]\n        else:\n            latent_mfc, mcf_connections, mff_connections = latent_mfc_mcf_mff(model, model.items)\n            mfc_connections = latent_mfc[:, 1:-1]\n\n        # track alternative connectivity\n        mfc_alternative_connectivities[0] += mixed_connectivity_by_lag(mfc_connections, presentation)\n        mcf_alternative_connectivities[0] += mixed_connectivity_by_lag(mcf_connections, presentation)\n        mff_alternative_connectivities[0] += mixed_connectivity_by_lag(mff_connections, presentation)\n\n        #mfc_alternative_connectivities += alternative_connectivity_by_lag(mfc_connections, presentation)[:, lag_range-3:lag_range+4]\n        #mcf_alternative_connectivities += alternative_connectivity_by_lag(mcf_connections, presentation)[:, lag_range-3:lag_range+4]\n\n    # reduce sum to mean\n    mfc_alternative_connectivity = mfc_alternative_connectivities / (trial_index+1)\n    mcf_alternative_connectivity = mcf_alternative_connectivities / (trial_index+1)\n    mff_alternative_connectivity = mff_alternative_connectivities / (trial_index+1)\n    mfc_alternative_connectivity[:, global_lag_range] = np.nan\n    mcf_alternative_connectivity[:, global_lag_range] = np.nan\n    mff_alternative_connectivity[:, global_lag_range] = np.nan\n\n    # plot results\n    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 5), sharey=True)\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[0])), mcf_alternative_connectivity[0], label='First Presentation')\n    #axes[0].plot(np.arange(len(mcf_alternative_connectivity[1])), mcf_alternative_connectivity[1], label='Second Presentation')\n    axes[0].set_xticks(np.arange(0, global_lag_range * 2 + 1, 2))\n    axes[0].set_xticklabels(np.arange(0, global_lag_range * 2 + 1, 2) - global_lag_range)\n    axes[0].set_title('MCF')\n\n    # same for MFC\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[0])), mfc_alternative_connectivity[0], label='First Presentation')\n    #axes[1].plot(np.arange(len(mfc_alternative_connectivity[1])), mfc_alternative_connectivity[1], label='Second Presentation')\n    axes[1].set_xticks(np.arange(0, global_lag_range * 2 + 1, 2))\n    axes[1].set_xticklabels(np.arange(0, global_lag_range * 2 + 1, 2) - global_lag_range)\n    axes[1].set_title('MFC')\n\n    # same for MFF\n    axes[2].plot(np.arange(len(mff_alternative_connectivity[0])), mff_alternative_connectivity[0], label='First Presentation')\n    #axes[2].plot(np.arange(len(mff_alternative_connectivity[1])), mff_alternative_connectivity[1], label='Second Presentation')\n    axes[2].set_xticks(np.arange(0, global_lag_range * 2 + 1, 2))\n    axes[2].set_xticklabels(np.arange(0, global_lag_range * 2 + 1, 2) - global_lag_range)\n    axes[2].set_title('MFF')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrace-Reinstatement CMR\n\n# configure parameters\nmodel_class = Trace_Reinstatement_CMR\nmodel_parameters = trcmr_fitted_parameters\n\n# track results\nglobal_lag_range = 39\n\nfor list_type in [1, 2, 3, 4]:\n    mfc_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mcf_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mff_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n\n    # loop through presentations\n    for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n        # simulate list study\n        item_count = np.max(presentation)+1\n        model = model_class(item_count, len(presentation), model_parameters)\n        model.experience(model.items[presentation])\n        lag_range = item_count+1\n\n        # extract item connections\n        if model_class.__name__ == 'Classic_CMR':\n            #TODO: Update for Classic CMR\n            mfc_connections = model.mfc[:, 1:-1]\n            mcf_connections = model.mcf[1:-1, :]\n        else:\n            latent_mfc, mcf_connections, mff_connections = latent_mfc_mcf_mff(model, model.recall_items)\n            mfc_connections = latent_mfc[:, 1:-1]\n\n        # track alternative connectivity\n        mfc_alternative_connectivities[0] += mixed_connectivity_by_lag(mfc_connections, presentation)\n        mcf_alternative_connectivities[0] += mixed_connectivity_by_lag(mcf_connections, presentation)\n        mff_alternative_connectivities[0] += mixed_connectivity_by_lag(mff_connections, presentation)\n\n        #mfc_alternative_connectivities += alternative_connectivity_by_lag(mfc_connections, presentation)[:, lag_range-3:lag_range+4]\n        #mcf_alternative_connectivities += alternative_connectivity_by_lag(mcf_connections, presentation)[:, lag_range-3:lag_range+4]\n\n    # reduce sum to mean\n    mfc_alternative_connectivity = mfc_alternative_connectivities / (trial_index+1)\n    mcf_alternative_connectivity = mcf_alternative_connectivities / (trial_index+1)\n    mff_alternative_connectivity = mff_alternative_connectivities / (trial_index+1)\n    mfc_alternative_connectivity[:, global_lag_range] = np.nan\n    mcf_alternative_connectivity[:, global_lag_range] = np.nan\n    mff_alternative_connectivity[:, global_lag_range] = np.nan\n\n    # plot results\n    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 5), sharey=True)\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[0])), mcf_alternative_connectivity[0], label='First Presentation')\n    #axes[0].plot(np.arange(len(mcf_alternative_connectivity[1])), mcf_alternative_connectivity[1], label='Second Presentation')\n    axes[0].set_xticks(np.arange(0, global_lag_range * 2 + 1, 2))\n    axes[0].set_xticklabels(np.arange(0, global_lag_range * 2 + 1, 2) - global_lag_range)\n    axes[0].set_title('MCF')\n\n    # same for MFC\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[0])), mfc_alternative_connectivity[0], label='First Presentation')\n    #axes[1].plot(np.arange(len(mfc_alternative_connectivity[1])), mfc_alternative_connectivity[1], label='Second Presentation')\n    axes[1].set_xticks(np.arange(0, global_lag_range * 2 + 1, 2))\n    axes[1].set_xticklabels(np.arange(0, global_lag_range * 2 + 1, 2) - global_lag_range)\n    axes[1].set_title('MFC')\n\n    # same for MFF\n    axes[2].plot(np.arange(len(mff_alternative_connectivity[0])), mff_alternative_connectivity[0], label='First Presentation')\n    #axes[2].plot(np.arange(len(mff_alternative_connectivity[1])), mff_alternative_connectivity[1], label='Second Presentation')\n    axes[2].set_xticks(np.arange(0, global_lag_range * 2 + 1, 2))\n    axes[2].set_xticklabels(np.arange(0, global_lag_range * 2 + 1, 2) - global_lag_range)\n    axes[2].set_title('MFF')"
  },
  {
    "objectID": "library\\model_analysis\\Model_Characterization.html#pure-list-parameter-shifting",
    "href": "library\\model_analysis\\Model_Characterization.html#pure-list-parameter-shifting",
    "title": "compmemlearn",
    "section": "Pure List Parameter Shifting",
    "text": "InstanceCMR\n\nmax_lag = 13\n\nscore_ranges = {\n    'encoding_drift_rate': np.arange(.001, .99, .1),\n    'recall_drift_rate': np.arange(.001, .99, .1),\n    'shared_support': np.arange(.001, .005, .001),\n    'item_support': np.arange(.001, .01, .001),\n    'learning_rate': np.arange(.001, .99, .1),\n    'choice_sensitivity': np.arange(.001, 5, .5),\n}\n\nfor model_class in [Instance_CMR]:\n\n    if model_class.__name__ == 'Classic_CMR':\n        parameters = cmr_fitted_parameters\n    elif model_class.__name__ == 'Instance_CMR':\n        parameters = icmr_fitted_parameters\n    else:\n        parameters = trcmr_fitted_parameters\n\n    for varied_parameter in score_ranges.keys():\n        print(varied_parameter, parameters[varied_parameter])\n        crps = []\n        spcs = []\n        pfrs = []\n        mfc_connectivities = []\n        mcf_connectivities = []\n        mff_connectivities = []\n\n        for parameter_value in tqdm(score_ranges[varied_parameter]):\n\n\n            # simulate data with this parameter value modified\n            sub_params = parameters.copy()\n            sub_params[varied_parameter] = parameter_value\n            model = model_class(list_length, list_length, sub_params)\n            simulation = simulate_array(model, 10000)\n\n            # accumulate spcs, crps, pfrs\n            spc = fast_spc(simulation, list_length)\n            spc = pd.DataFrame(\n                {'Study Position': np.arange(len(spc)), 'Recall Rate': spc, varied_parameter: parameter_value})\n            spcs.append(spc)\n\n            crp = fast_crp(simulation, list_length)\n            crp[list_length-1] = np.nan\n            crp = pd.DataFrame(\n                {'Lag': np.arange(max_lag*2 + 1, dtype=int)-max_lag, 'Recall Rate': crp[list_length-max_lag-1:list_length+max_lag], varied_parameter: parameter_value})\n            crps.append(crp)\n\n            pfr = fast_pfr(simulation, list_length)\n            pfr = pd.DataFrame(\n                {'Study Position': np.arange(len(pfr)), 'First Recall Rate': pfr, varied_parameter: parameter_value})\n            pfrs.append(pfr)\n            \n            if model_class.__name__ == 'Classic_CMR':\n                #TODO: still have to update for CMR\n                mfc_connectivity = connectivity_by_lag(model.mfc[:, 1:-1], model.item_count)\n                mcf_connectivity = connectivity_by_lag(model.mcf[1:-1, :], model.item_count)\n            else:\n                latent_mfc, latent_mcf, latent_mff = latent_mfc_mcf_mff(model, model.items)\n                mfc_connectivity = connectivity_by_lag(latent_mfc[:, 1:-1], model.item_count)\n                mcf_connectivity = connectivity_by_lag(latent_mcf, model.item_count)\n                mff_connectivity = connectivity_by_lag(latent_mff, model.item_count)\n                \n\n            mfc_connectivity[model.item_count-1] = np.nan\n            mcf_connectivity[model.item_count-1] = np.nan\n            mfc_connectivity = pd.DataFrame(\n                {'Lag': np.arange(max_lag*2 + 1, dtype=int)-max_lag, 'Recall Rate': mfc_connectivity[model.item_count-max_lag-1:model.item_count+max_lag], varied_parameter: parameter_value}\n            )\n            mcf_connectivity = pd.DataFrame(\n                {'Lag': np.arange(max_lag*2 + 1, dtype=int)-max_lag, 'Recall Rate': mcf_connectivity[model.item_count-max_lag-1:model.item_count+max_lag], varied_parameter: parameter_value}\n            )\n            mff_connectivity = pd.DataFrame(\n                {'Lag': np.arange(max_lag*2 + 1, dtype=int)-max_lag, 'Recall Rate': mff_connectivity[model.item_count-max_lag-1:model.item_count+max_lag], varied_parameter: parameter_value}\n            )\n            mfc_connectivities.append(mfc_connectivity)\n            mcf_connectivities.append(mcf_connectivity)\n            mff_connectivities.append(mff_connectivity)\n\n        # concatenate result into a single table\n        spc = pd.concat(spcs).reset_index()\n        crp = pd.concat(crps).reset_index()\n        pfr = pd.concat(pfrs).reset_index()\n        mfc_connectivity = pd.concat(mfc_connectivities).reset_index()\n        mcf_connectivity = pd.concat(mcf_connectivities).reset_index()\n        mff_connectivity = pd.concat(mff_connectivities).reset_index()\n\n        sns.set(style='darkgrid')\n        fig, axes = plt.subplots(6, 1, figsize=(10, 20), sharey=False)\n\n        sns.lineplot(ax=axes[0], data=spc, x='Study Position', y='Recall Rate', hue=varied_parameter, ci=None)\n        #axes[0].set_xlabel('Study Position')\n        #axes[0].set_ylabel('Probability Recall')\n        axes[0].set_title('SPC')\n        axes[0].legend(np.round(score_ranges[varied_parameter], 5), bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n        sns.lineplot(ax=axes[1], data=pfr, x='Study Position', y='First Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[1].set_title('PFR')\n\n        filt_neg = f'{-max_lag} <= Lag < 0'\n        filt_pos = f'0 < Lag <= {max_lag}'\n        sns.lineplot(ax=axes[2], data=crp.query(filt_neg), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        sns.lineplot(ax=axes[2], data=crp.query(filt_pos), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[2].set_title('Lag-CRP')\n\n        sns.lineplot(ax=axes[3], data=mfc_connectivity.query(filt_neg), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        sns.lineplot(ax=axes[3], data=mfc_connectivity.query(filt_pos), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[3].set_title('MFC Lag-Connectivity')\n        \n        sns.lineplot(ax=axes[4], data=mcf_connectivity.query(filt_neg), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        sns.lineplot(ax=axes[4], data=mcf_connectivity.query(filt_pos), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[4].set_title('MCF Lag-Connectivity')\n\n        sns.lineplot(ax=axes[5], data=mff_connectivity.query(filt_neg), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        sns.lineplot(ax=axes[5], data=mff_connectivity.query(filt_pos), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[5].set_title('MFF Lag-Connectivity')\n\n        plt.tight_layout(pad=2)\n\n        fig.suptitle(varied_parameter.replace('_', ' ').upper())\n        #plt.savefig('results/{}_{}.svg'.format(model.__name__, varied_parameter))\n        plt.show()\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nencoding_drift_rate 0.8363715433354807\n\n\n100%|██████████| 10/10 [00:15<00:00,  1.59s/it]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nrecall_drift_rate 0.9600175060232444\n\n\n100%|██████████| 10/10 [00:15<00:00,  1.53s/it]\n\n\n\n\n\n  0%|          | 0/4 [00:00<?, ?it/s]\n\n\nshared_support 0.0008229999076557321\n\n\n100%|██████████| 4/4 [00:06<00:00,  1.51s/it]\n\n\n\n\n\n  0%|          | 0/9 [00:00<?, ?it/s]\n\n\nitem_support 0.09131365030360249\n\n\n100%|██████████| 9/9 [00:14<00:00,  1.57s/it]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nlearning_rate 0.1915496572645179\n\n\n100%|██████████| 10/10 [00:16<00:00,  1.62s/it]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nchoice_sensitivity 1.0\n\n\n100%|██████████| 10/10 [00:16<00:00,  1.62s/it]\n\n\n\n\n\n\n\nTrace-Reinstatement CMR\n\nmax_lag = 13\n\nscore_ranges = {\n    'encoding_drift_rate': np.arange(.001, .99, .1),\n    'recall_drift_rate': np.arange(.001, .99, .1),\n    'shared_support': np.arange(.001, .005, .001),\n    'item_support': np.arange(.001, .01, .001),\n    'learning_rate': np.arange(.001, .99, .1),\n    'choice_sensitivity': np.arange(.001, 5, .5),\n}\n\nfor model_class in [Trace_Reinstatement_CMR]:\n\n    if model_class.__name__ == 'Classic_CMR':\n        parameters = cmr_fitted_parameters\n    elif model_class.__name__ == 'Instance_CMR':\n        parameters = icmr_fitted_parameters\n    else:\n        parameters = trcmr_fitted_parameters\n\n    for varied_parameter in score_ranges.keys():\n        print(varied_parameter, parameters[varied_parameter])\n        crps = []\n        spcs = []\n        pfrs = []\n        mfc_connectivities = []\n        mcf_connectivities = []\n        mff_connectivities = []\n\n        for parameter_value in tqdm(score_ranges[varied_parameter]):\n\n\n            # simulate data with this parameter value modified\n            sub_params = parameters.copy()\n            sub_params[varied_parameter] = parameter_value\n            model = model_class(list_length, list_length, sub_params)\n            simulation = simulate_array(model, 10000)\n\n            # accumulate spcs, crps, pfrs\n            spc = fast_spc(simulation, list_length)\n            spc = pd.DataFrame(\n                {'Study Position': np.arange(len(spc)), 'Recall Rate': spc, varied_parameter: parameter_value})\n            spcs.append(spc)\n\n            crp = fast_crp(simulation, list_length)\n            crp[list_length-1] = np.nan\n            crp = pd.DataFrame(\n                {'Lag': np.arange(max_lag*2 + 1, dtype=int)-max_lag, 'Recall Rate': crp[list_length-max_lag-1:list_length+max_lag], varied_parameter: parameter_value})\n            crps.append(crp)\n\n            pfr = fast_pfr(simulation, list_length)\n            pfr = pd.DataFrame(\n                {'Study Position': np.arange(len(pfr)), 'First Recall Rate': pfr, varied_parameter: parameter_value})\n            pfrs.append(pfr)\n            \n            if model_class.__name__ == 'Classic_CMR':\n                #TODO: still have to update for CMR\n                mfc_connectivity = connectivity_by_lag(model.mfc[:, 1:-1], model.item_count)\n                mcf_connectivity = connectivity_by_lag(model.mcf[1:-1, :], model.item_count)\n            else:\n                latent_mfc, latent_mcf, latent_mff = latent_mfc_mcf_mff(model, model.recall_items)\n                mfc_connectivity = connectivity_by_lag(latent_mfc[:, 1:-1], model.item_count)\n                mcf_connectivity = connectivity_by_lag(latent_mcf, model.item_count)\n                mff_connectivity = connectivity_by_lag(latent_mff, model.item_count)\n                \n\n            mfc_connectivity[model.item_count-1] = np.nan\n            mcf_connectivity[model.item_count-1] = np.nan\n            mfc_connectivity = pd.DataFrame(\n                {'Lag': np.arange(max_lag*2 + 1, dtype=int)-max_lag, 'Recall Rate': mfc_connectivity[model.item_count-max_lag-1:model.item_count+max_lag], varied_parameter: parameter_value}\n            )\n            mcf_connectivity = pd.DataFrame(\n                {'Lag': np.arange(max_lag*2 + 1, dtype=int)-max_lag, 'Recall Rate': mcf_connectivity[model.item_count-max_lag-1:model.item_count+max_lag], varied_parameter: parameter_value}\n            )\n            mff_connectivity = pd.DataFrame(\n                {'Lag': np.arange(max_lag*2 + 1, dtype=int)-max_lag, 'Recall Rate': mff_connectivity[model.item_count-max_lag-1:model.item_count+max_lag], varied_parameter: parameter_value}\n            )\n            mfc_connectivities.append(mfc_connectivity)\n            mcf_connectivities.append(mcf_connectivity)\n            mff_connectivities.append(mff_connectivity)\n\n        # concatenate result into a single table\n        spc = pd.concat(spcs).reset_index()\n        crp = pd.concat(crps).reset_index()\n        pfr = pd.concat(pfrs).reset_index()\n        mfc_connectivity = pd.concat(mfc_connectivities).reset_index()\n        mcf_connectivity = pd.concat(mcf_connectivities).reset_index()\n        mff_connectivity = pd.concat(mff_connectivities).reset_index()\n\n        sns.set(style='darkgrid')\n        fig, axes = plt.subplots(6, 1, figsize=(10, 20), sharey=False)\n\n        sns.lineplot(ax=axes[0], data=spc, x='Study Position', y='Recall Rate', hue=varied_parameter, ci=None)\n        #axes[0].set_xlabel('Study Position')\n        #axes[0].set_ylabel('Probability Recall')\n        axes[0].set_title('SPC')\n        axes[0].legend(np.round(score_ranges[varied_parameter], 5), bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n        sns.lineplot(ax=axes[1], data=pfr, x='Study Position', y='First Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[1].set_title('PFR')\n\n        filt_neg = f'{-max_lag} <= Lag < 0'\n        filt_pos = f'0 < Lag <= {max_lag}'\n        sns.lineplot(ax=axes[2], data=crp.query(filt_neg), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        sns.lineplot(ax=axes[2], data=crp.query(filt_pos), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[2].set_title('Lag-CRP')\n\n        sns.lineplot(ax=axes[3], data=mfc_connectivity.query(filt_neg), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        sns.lineplot(ax=axes[3], data=mfc_connectivity.query(filt_pos), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[3].set_title('MFC Lag-Connectivity')\n        \n        sns.lineplot(ax=axes[4], data=mcf_connectivity.query(filt_neg), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        sns.lineplot(ax=axes[4], data=mcf_connectivity.query(filt_pos), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[4].set_title('MCF Lag-Connectivity')\n\n        sns.lineplot(ax=axes[5], data=mff_connectivity.query(filt_neg), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        sns.lineplot(ax=axes[5], data=mff_connectivity.query(filt_pos), x='Lag', y='Recall Rate', hue=varied_parameter, ci=None, legend=False)\n        axes[5].set_title('MFF Lag-Connectivity')\n\n        plt.tight_layout(pad=2)\n\n        fig.suptitle(varied_parameter.replace('_', ' ').upper())\n        #plt.savefig('results/{}_{}.svg'.format(model.__name__, varied_parameter))\n        plt.show()\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nencoding_drift_rate 0.8015623810548206\n\n\n100%|██████████| 10/10 [00:19<00:00,  1.97s/it]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nrecall_drift_rate 0.959155432955042\n\n\n100%|██████████| 10/10 [00:16<00:00,  1.63s/it]\n\n\n\n\n\n  0%|          | 0/4 [00:00<?, ?it/s]\n\n\nshared_support 0.008429792074646641\n\n\n100%|██████████| 4/4 [00:06<00:00,  1.65s/it]\n\n\n\n\n\n  0%|          | 0/9 [00:00<?, ?it/s]\n\n\nitem_support 0.7496270374441739\n\n\n100%|██████████| 9/9 [00:14<00:00,  1.61s/it]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nlearning_rate 0.5079383408154622\n\n\n100%|██████████| 10/10 [00:16<00:00,  1.62s/it]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nchoice_sensitivity 1.0\n\n\n100%|██████████| 10/10 [00:16<00:00,  1.64s/it]"
  },
  {
    "objectID": "library\\model_analysis\\Model_Characterization.html#repetition-lag-connectivity-analysis",
    "href": "library\\model_analysis\\Model_Characterization.html#repetition-lag-connectivity-analysis",
    "title": "compmemlearn",
    "section": "Repetition Lag-Connectivity Analysis",
    "text": "InstanceCMR\n\n# configure parameters\nmodel_class = Instance_CMR\nmodel_parameters = icmr_fitted_parameters\n\n# track results\nglobal_lag_range = 39\n\nfor list_type in [4]:\n    mfc_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mcf_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mff_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n\n    # loop through presentations\n    for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n        # simulate list study\n        item_count = np.max(presentation)+1\n        model = model_class(item_count, len(presentation), model_parameters)\n        model.experience(model.items[presentation])\n\n        # extract item connections\n        if model_class.__name__ == 'Classic_CMR':\n            #TODO: More classic_cmr stuff to update\n            mfc_connections = model.mfc[:, 1:-1]\n            mcf_connections = model.mcf[1:-1, :]\n            if trial_index == 0:\n                mfc_heatmap(model.mfc)\n                mfc_heatmap(model.mcf)\n                print(presentation)\n        else:\n            latent_mfc, mcf_connections, mff_connections = latent_mfc_mcf_mff(model, model.items)\n\n        # track alternative connectivity\n        mfc_alternative_connectivities += alternative_connectivity_by_lag(mfc_connections, presentation)\n        mcf_alternative_connectivities += alternative_connectivity_by_lag(mcf_connections, presentation)\n        mff_alternative_connectivities += alternative_connectivity_by_lag(mff_connections, presentation)\n\n    # reduce sum to mean\n    mfc_alternative_connectivity = mfc_alternative_connectivities / (trial_index+1)\n    mcf_alternative_connectivity = mcf_alternative_connectivities / (trial_index+1)\n    mff_alternative_connectivity = mff_alternative_connectivities / (trial_index+1)\n    mfc_alternative_connectivity[:, global_lag_range] = np.nan\n    mcf_alternative_connectivity[:, global_lag_range] = np.nan\n    mff_alternative_connectivity[:, global_lag_range] = np.nan\n\n    # focus on +/- 3 lags\n    plotting_lag_range = 3\n    mfc_alternative_connectivity = mfc_alternative_connectivity[\n        :, global_lag_range-plotting_lag_range:global_lag_range+plotting_lag_range+1]\n    mcf_alternative_connectivity = mcf_alternative_connectivity[\n        :, global_lag_range-plotting_lag_range:global_lag_range+plotting_lag_range+1]\n    mff_alternative_connectivity = mff_alternative_connectivity[\n        :, global_lag_range-plotting_lag_range:global_lag_range+plotting_lag_range+1]\n\n    # plot results\n    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 5), sharey=False)\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[0])), mcf_alternative_connectivity[0], label='First Presentation')\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[1])), mcf_alternative_connectivity[1], label='Second Presentation')\n    axes[0].set_xticks(np.arange(0, plotting_lag_range * 2 + 1, 2))\n    axes[0].set_xticklabels(np.arange(0, plotting_lag_range * 2 + 1, 2) - plotting_lag_range)\n    axes[0].set_title('MCF')\n\n    # same for MFC\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[0])), mfc_alternative_connectivity[0], label='First Presentation')\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[1])), mfc_alternative_connectivity[1], label='Second Presentation')\n    axes[1].set_xticks(np.arange(0, plotting_lag_range * 2 + 1, 2))\n    axes[1].set_xticklabels(np.arange(0, plotting_lag_range * 2 + 1, 2) - plotting_lag_range)\n    axes[1].set_title('MFC')\n\n    # same for MFF\n    axes[2].plot(np.arange(len(mff_alternative_connectivity[0])), mff_alternative_connectivity[0], label='First Presentation')\n    axes[2].plot(np.arange(len(mff_alternative_connectivity[1])), mff_alternative_connectivity[1], label='Second Presentation')\n    axes[2].set_xticks(np.arange(0, plotting_lag_range * 2 + 1, 2))\n    axes[2].set_xticklabels(np.arange(0, plotting_lag_range * 2 + 1, 2) - plotting_lag_range)\n    axes[2].set_title('MFF')\n\n\n\n\n\n\nTrace-Reinstatement CMR\n\n# configure parameters\nmodel_class = Trace_Reinstatement_CMR\nmodel_parameters = trcmr_fitted_parameters\n\n# track results\nglobal_lag_range = 39\n\nfor list_type in [4]:\n    mfc_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mcf_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n    mff_alternative_connectivities = np.zeros((2, global_lag_range * 2 + 1))\n\n    # loop through presentations\n    for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n        # simulate list study\n        item_count = np.max(presentation)+1\n        model = model_class(item_count, len(presentation), model_parameters)\n        model.experience(model.items[presentation])\n\n        # extract item connections\n        if model_class.__name__ == 'Classic_CMR':\n            #TODO: More classic_cmr stuff to update\n            mfc_connections = model.mfc[:, 1:-1]\n            mcf_connections = model.mcf[1:-1, :]\n            if trial_index == 0:\n                mfc_heatmap(model.mfc)\n                mfc_heatmap(model.mcf)\n                print(presentation)\n        else:\n            latent_mfc, mcf_connections, mff_connections = latent_mfc_mcf_mff(model, model.recall_items)\n            mfc_connections = latent_mfc[:, 1:-1]\n\n        # track alternative connectivity\n        mfc_alternative_connectivities += alternative_connectivity_by_lag(mfc_connections, presentation)\n        mcf_alternative_connectivities += alternative_connectivity_by_lag(mcf_connections, presentation)\n        mff_alternative_connectivities += alternative_connectivity_by_lag(mff_connections, presentation)\n\n    # reduce sum to mean\n    mfc_alternative_connectivity = mfc_alternative_connectivities / (trial_index+1)\n    mcf_alternative_connectivity = mcf_alternative_connectivities / (trial_index+1)\n    mff_alternative_connectivity = mff_alternative_connectivities / (trial_index+1)\n    mfc_alternative_connectivity[:, global_lag_range] = np.nan\n    mcf_alternative_connectivity[:, global_lag_range] = np.nan\n    mff_alternative_connectivity[:, global_lag_range] = np.nan\n\n    # focus on +/- 3 lags\n    plotting_lag_range = 3\n    mfc_alternative_connectivity = mfc_alternative_connectivity[\n        :, global_lag_range-plotting_lag_range:global_lag_range+plotting_lag_range+1]\n    mcf_alternative_connectivity = mcf_alternative_connectivity[\n        :, global_lag_range-plotting_lag_range:global_lag_range+plotting_lag_range+1]\n    mff_alternative_connectivity = mff_alternative_connectivity[\n        :, global_lag_range-plotting_lag_range:global_lag_range+plotting_lag_range+1]\n\n    # plot results\n    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 5), sharey=False)\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[0])), mcf_alternative_connectivity[0], label='First Presentation')\n    axes[0].plot(np.arange(len(mcf_alternative_connectivity[1])), mcf_alternative_connectivity[1], label='Second Presentation')\n    axes[0].set_xticks(np.arange(0, plotting_lag_range * 2 + 1, 2))\n    axes[0].set_xticklabels(np.arange(0, plotting_lag_range * 2 + 1, 2) - plotting_lag_range)\n    axes[0].set_title('MCF')\n\n    # same for MFC\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[0])), mfc_alternative_connectivity[0], label='First Presentation')\n    axes[1].plot(np.arange(len(mfc_alternative_connectivity[1])), mfc_alternative_connectivity[1], label='Second Presentation')\n    axes[1].set_xticks(np.arange(0, plotting_lag_range * 2 + 1, 2))\n    axes[1].set_xticklabels(np.arange(0, plotting_lag_range * 2 + 1, 2) - plotting_lag_range)\n    axes[1].set_title('MFC')\n\n    # same for MFF\n    axes[2].plot(np.arange(len(mff_alternative_connectivity[0])), mff_alternative_connectivity[0], label='First Presentation')\n    axes[2].plot(np.arange(len(mff_alternative_connectivity[1])), mff_alternative_connectivity[1], label='Second Presentation')\n    axes[2].set_xticks(np.arange(0, plotting_lag_range * 2 + 1, 2))\n    axes[2].set_xticklabels(np.arange(0, plotting_lag_range * 2 + 1, 2) - plotting_lag_range)\n    axes[2].set_title('MFF')"
  },
  {
    "objectID": "library\\model_analysis\\Model_Characterization.html#mixed-list-parameter-shifting",
    "href": "library\\model_analysis\\Model_Characterization.html#mixed-list-parameter-shifting",
    "title": "compmemlearn",
    "section": "Mixed List Parameter Shifting",
    "text": "Instance_CMR\n\n# configure parameters\nmodel_class = init_icmr\nmodel_name = 'Instance_CMR'\nparameters = icmr_fitted_parameters\nlist_type = 4\n\n# track results\nglobal_lag_range = list_length-1\ncrp_max_lag = 13\nrep_crp_max_lag = 3\nexperiment_count = 100\n\nscore_ranges = {\n    'encoding_drift_rate': np.arange(.001, .99, .1),\n    'recall_drift_rate': np.arange(.001, .99, .1),\n    'shared_support': np.arange(.001, .005, .001),\n    'item_support': np.arange(.001, .01, .001),\n    'learning_rate': np.arange(.001, .99, .1),\n    'choice_sensitivity': np.arange(.001, 5, .5),\n}\n\nfor varied_parameter in score_ranges.keys():\n\n    print(varied_parameter, parameters[varied_parameter])\n    spcs = []\n    pfrs = []\n    rpls = []\n    crps = []\n    rep_crps = []\n    lag_mcfs = []\n    lag_mfcs = []\n    lag_mffs = []\n    rep_lag_mcfs = []\n    rep_lag_mfcs = []\n    rep_lag_mffs = []\n\n    # loop through parameter values\n    for parameter_value in tqdm(score_ranges[varied_parameter]):\n\n        # simulate data with this parameter value modified\n        model_parameters = parameters.copy()\n        model_parameters[varied_parameter] = parameter_value\n        model_trials = simulate_array_from_presentations(\n            model_class, model_parameters, presentations[list_types==list_type], experiment_count)\n        model_presentations = np.matlib.repmat(presentations[list_types==list_type], experiment_count, 1)\n\n        # spc\n        spc = flex_mixed_spc(model_trials, model_presentations)\n        spc = pd.DataFrame(\n                {'Study Position': np.arange(len(spc)), 'Recall Rate': spc, varied_parameter: parameter_value})\n        spcs.append(spc)\n\n        # pfr\n        pfr = flex_mixed_pfr(model_trials, model_presentations)\n        pfr = pd.DataFrame(\n            {'Study Position': np.arange(len(pfr)), 'First Recall Rate': pfr, varied_parameter: parameter_value})\n        pfrs.append(pfr)\n\n        # rpl\n        rpl = fast_rpl(\n            model_trials, model_presentations, max_lag=8)\n        binned = np.zeros(5)\n        binned[0] = rpl[0]\n        binned[1] = rpl[1]\n        binned[2] = (rpl[2] + rpl[3])/2\n        binned[3] = (rpl[4] + rpl[5] + rpl[6])/3\n        binned[4] = (rpl[7] + rpl[8] + rpl[9])/3\n        rpl = binned.copy()\n        rpl = pd.DataFrame(\n            {'Spacing': ['N/A', '0', '1-2', '3-5', '6-8'], 'Recall Rate': rpl, varied_parameter: parameter_value})\n        rpls.append(rpl)\n\n        # crp\n        crp = flex_mixed_crp(model_trials, model_presentations)\n        crp[global_lag_range] = np.nan\n        crp = pd.DataFrame(\n            {'Lag': np.arange(crp_max_lag*2 + 1, dtype=int)-crp_max_lag, \n            'Recall Rate': crp[list_length-crp_max_lag-1:list_length+crp_max_lag], \n            varied_parameter: parameter_value})\n        crps.append(crp)\n\n        # rep crp\n        rep_crp = alternative_contiguity(\n            model_trials, model_presentations, 6, 2)\n        rep_crp[:, global_lag_range] = np.nan\n        rep_crp = pd.DataFrame({\n                \"Lag\": np.arange(rep_crp_max_lag * 2 + 1, dtype=int) - rep_crp_max_lag,\n                \"Differential Recall Rate\": rep_crp[0, list_length-rep_crp_max_lag-1:list_length + rep_crp_max_lag]\n                    - rep_crp[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag],\n                varied_parameter: parameter_value,\n            })\n        rep_crps.append(rep_crp)\n\n        # lag-connectivity requires more involved computations...\n        total_lag_mfc = np.zeros((global_lag_range * 2 + 1))\n        total_lag_mcf = np.zeros((global_lag_range * 2 + 1))\n        total_lag_mff = np.zeros((global_lag_range * 2 + 1))\n        total_rep_lag_mfc = np.zeros((2, global_lag_range * 2 + 1))\n        total_rep_lag_mcf = np.zeros((2, global_lag_range * 2 + 1))\n        total_rep_lag_mff = np.zeros((2, global_lag_range * 2 + 1))\n\n        # loop through presentations\n        for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n            # simulate list study\n            item_count = np.max(presentation)+1\n            model = model_class(item_count, len(presentation), model_parameters)\n            model.experience(model.items[presentation])\n\n            # extract item connections\n            latent_mfc, mcf_connections, mff_connections = latent_mfc_mcf_mff(model, model.items)\n            mfc_connections = latent_mfc[:, 1:-1]\n\n            # track repetition connectivity\n            total_rep_lag_mfc += alternative_connectivity_by_lag(mfc_connections, presentation)\n            total_rep_lag_mcf += alternative_connectivity_by_lag(mcf_connections, presentation)\n            total_rep_lag_mff += alternative_connectivity_by_lag(mff_connections, presentation)\n\n            # and overall connectivity\n            total_lag_mfc += mixed_connectivity_by_lag(mfc_connections, presentation)\n            total_lag_mcf += mixed_connectivity_by_lag(mcf_connections, presentation)\n            total_lag_mff += mixed_connectivity_by_lag(mff_connections, presentation)\n\n        # reduce sum to mean\n        # repetition connectivity\n        rep_lag_mfc = total_rep_lag_mfc / (trial_index+1)\n        rep_lag_mcf = total_rep_lag_mcf / (trial_index+1)\n        rep_lag_mff = total_rep_lag_mff / (trial_index+1)\n        rep_lag_mfc[:, global_lag_range] = np.nan\n        rep_lag_mcf[:, global_lag_range] = np.nan\n        rep_lag_mff[:, global_lag_range] = np.nan\n\n        # overall connectivity\n        lag_mfc = total_lag_mfc / (trial_index+1)\n        lag_mcf = total_lag_mcf / (trial_index+1)\n        lag_mff = total_lag_mff / (trial_index+1)\n        lag_mfc[global_lag_range] = np.nan\n        lag_mcf[global_lag_range] = np.nan\n        lag_mff[global_lag_range] = np.nan\n\n        # aggregate for dataframe\n        rep_lag_mfc = pd.DataFrame(\n            {'Lag': np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag,\n            'Differential Recall Rate': rep_lag_mfc[0, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag]\n            - rep_lag_mfc[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag],\n            varied_parameter: parameter_value})\n        rep_lag_mcf = pd.DataFrame(\n            {'Lag': np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag,\n            'Differential Recall Rate': rep_lag_mcf[0, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag]\n            - rep_lag_mcf[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag],\n            varied_parameter: parameter_value})\n        rep_lag_mff = pd.DataFrame(\n            {'Lag': np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag,\n            'Differential Recall Rate': rep_lag_mff[0, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag]\n            - rep_lag_mff[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag],\n            varied_parameter: parameter_value})\n\n        lag_mfc = pd.DataFrame(\n            {'Lag': np.arange(crp_max_lag*2+1, dtype=int)-crp_max_lag,\n            'Recall Rate': lag_mfc[list_length-crp_max_lag-1:list_length+crp_max_lag],\n            varied_parameter: parameter_value})\n        lag_mcf = pd.DataFrame(\n            {'Lag': np.arange(crp_max_lag*2+1, dtype=int)-crp_max_lag,\n            'Recall Rate': lag_mcf[list_length-crp_max_lag-1:list_length+crp_max_lag],\n            varied_parameter: parameter_value})\n        lag_mff = pd.DataFrame(\n            {'Lag': np.arange(crp_max_lag*2+1, dtype=int)-crp_max_lag,\n            'Recall Rate': lag_mff[list_length-crp_max_lag-1:list_length+crp_max_lag],\n            varied_parameter: parameter_value})\n\n        rep_lag_mcfs.append(rep_lag_mcf)\n        rep_lag_mffs.append(rep_lag_mff)\n        rep_lag_mfcs.append(rep_lag_mfc)\n        lag_mcfs.append(lag_mcf)\n        lag_mffs.append(lag_mff)\n        lag_mfcs.append(lag_mfc)\n    \n    # aggregate fitting results\n    spc = pd.concat(spcs).reset_index()\n    pfr = pd.concat(pfrs).reset_index()\n    crp = pd.concat(crps).reset_index()\n    rpl = pd.concat(rpls).reset_index()\n    rep_crp = pd.concat(rep_crps).reset_index()\n    lag_mcf = pd.concat(lag_mcfs).reset_index()\n    lag_mff = pd.concat(lag_mffs).reset_index()\n    lag_mfc = pd.concat(lag_mfcs).reset_index()\n    rep_lag_mcf = pd.concat(rep_lag_mcfs).reset_index()\n    rep_lag_mff = pd.concat(rep_lag_mffs).reset_index()\n    rep_lag_mfc = pd.concat(rep_lag_mfcs).reset_index()\n\n    # plot results\n    sns.set(style='darkgrid')\n    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(25, 25), sharey=False)\n\n    # spc\n    sns.lineplot(ax=axes[0, 0], data=spc, x='Study Position', y='Recall Rate', hue=varied_parameter, ci=None)\n    axes[0, 0].set_title('SPC')\n\n    # pfr\n    sns.lineplot(ax=axes[0, 1], data=pfr, x='Study Position', y='First Recall Rate', hue=varied_parameter, ci=None, legend=False)\n    axes[0, 1].set_title('PFR')\n\n    # rpl (should be rps)\n    sns.lineplot(ax=axes[0, 2], data=rpl, x='Spacing', y='Recall Rate', hue=varied_parameter, ci=None)\n    axes[0, 2].set_title('Recall Probability by Spacing')\n\n    # crp\n    filt_neg = f'{-crp_max_lag} <= Lag < 0'\n    filt_pos = f'0 < Lag <= {crp_max_lag}'\n    sns.lineplot(ax=axes[1, 0], data=crp.query(filt_neg), x='Lag', y='Recall Rate', \n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[1, 0], data=crp.query(filt_pos), x='Lag', y='Recall Rate', \n        hue=varied_parameter, ci=None, legend=False)\n    axes[1, 0].set_title('CRP')\n\n    # rep_crp\n    sns.lineplot(ax=axes[1, 1], data=rep_crp.query(filt_neg), x='Lag', y=\"Differential Recall Rate\", \n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[1, 1], data=rep_crp.query(filt_pos), x='Lag', y=\"Differential Recall Rate\", \n        hue=varied_parameter, ci=None, legend=False)\n    axes[1, 1].set_title('Repetition Lag-Contiguity Difference')\n\n    # lag_mcf\n    sns.lineplot(ax=axes[2, 0], data=lag_mcf.query(filt_neg), x='Lag', y='Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[2, 0], data=lag_mcf.query(filt_pos), x='Lag', y='Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n\n    # lag_mfc\n    sns.lineplot(ax=axes[2, 1], data=lag_mfc.query(filt_neg), x='Lag', y='Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[2, 1], data=lag_mfc.query(filt_pos), x='Lag', y='Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n\n    # lag_mff\n    sns.lineplot(ax=axes[2, 2], data=lag_mff.query(filt_neg), x='Lag', y='Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[2, 2], data=lag_mff.query(filt_pos), x='Lag', y='Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n\n    # rep_lag_mcf\n    sns.lineplot(ax=axes[3, 0], data=rep_lag_mcf.query(filt_neg), x='Lag', y='Differential Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[3, 0], data=rep_lag_mcf.query(filt_pos), x='Lag', y='Differential Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n\n    # rep_lag_mfc\n    sns.lineplot(ax=axes[3, 1], data=rep_lag_mfc.query(filt_neg), x='Lag', y='Differential Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[3, 1], data=rep_lag_mfc.query(filt_pos), x='Lag', y='Differential Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n\n    # rep_lag_mff\n    sns.lineplot(ax=axes[3, 2], data=rep_lag_mff.query(filt_neg), x='Lag', y='Differential Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[3, 2], data=rep_lag_mff.query(filt_pos), x='Lag', y='Differential Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n\n    # render result\n    plt.show()\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nencoding_drift_rate 0.832809463\n\n\n100%|██████████| 10/10 [03:15<00:00, 19.51s/it]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nrecall_drift_rate 0.961140398\n\n\n100%|██████████| 10/10 [03:13<00:00, 19.32s/it]\n\n\n\n\n\n  0%|          | 0/4 [00:00<?, ?it/s]\n\n\nshared_support 0.0011990853\n\n\n100%|██████████| 4/4 [01:15<00:00, 18.94s/it]\n\n\n\n\n\n  0%|          | 0/9 [00:00<?, ?it/s]\n\n\nitem_support 0.131621512\n\n\n100%|██████████| 9/9 [02:51<00:00, 19.06s/it]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nlearning_rate 0.245449928\n\n\n100%|██████████| 10/10 [03:20<00:00, 20.04s/it]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nchoice_sensitivity 1.0\n\n\n100%|██████████| 10/10 [03:24<00:00, 20.41s/it]\n\n\n\n\n\n\n\nTrace-Reinstatement CMR\n\n# configure parameters\nmodel_class = init_trcmr\nmodel_name = 'Trace-Reinstatement CMR'\nparameters = trcmr_fitted_parameters\nlist_type = 4\n\n# track results\nglobal_lag_range = list_length-1\ncrp_max_lag = 13\nrep_crp_max_lag = 3\nexperiment_count = 100\n\nscore_ranges = {\n    'feature_drift_rate': np.arange(.001, 1, .1),\n}\n\nfor varied_parameter in score_ranges.keys():\n\n    print(varied_parameter, parameters[varied_parameter])\n    print(score_ranges[varied_parameter])\n    spcs = []\n    pfrs = []\n    rpls = []\n    crps = []\n    rep_crps = []\n    lag_mcfs = []\n    lag_mfcs = []\n    lag_mffs = []\n    rep_lag_mcfs = []\n    rep_lag_mfcs = []\n    rep_lag_mffs = []\n\n    # loop through parameter values\n    for parameter_value in tqdm(score_ranges[varied_parameter]):\n\n        # simulate data with this parameter value modified\n        model_parameters = parameters.copy()\n        model_parameters[varied_parameter] = parameter_value\n        model_trials = simulate_array_from_presentations(\n            model_class, model_parameters, presentations[list_types==list_type], experiment_count)\n        model_presentations = np.matlib.repmat(presentations[list_types==list_type], experiment_count, 1)\n\n        # spc\n        spc = flex_mixed_spc(model_trials, model_presentations)\n        spc = pd.DataFrame(\n                {'Study Position': np.arange(len(spc)), 'Recall Rate': spc, varied_parameter: parameter_value})\n        spcs.append(spc)\n\n        # pfr\n        pfr = flex_mixed_pfr(model_trials, model_presentations)\n        pfr = pd.DataFrame(\n            {'Study Position': np.arange(len(pfr)), 'First Recall Rate': pfr, varied_parameter: parameter_value})\n        pfrs.append(pfr)\n\n        # rpl\n        rpl = fast_rpl(\n            model_trials, model_presentations, max_lag=8)\n        binned = np.zeros(5)\n        binned[0] = rpl[0]\n        binned[1] = rpl[1]\n        binned[2] = (rpl[2] + rpl[3])/2\n        binned[3] = (rpl[4] + rpl[5] + rpl[6])/3\n        binned[4] = (rpl[7] + rpl[8] + rpl[9])/3\n        rpl = binned.copy()\n        rpl = pd.DataFrame(\n            {'Spacing': ['N/A', '0', '1-2', '3-5', '6-8'], 'Recall Rate': rpl, varied_parameter: parameter_value})\n        rpls.append(rpl)\n\n        # crp\n        crp = flex_mixed_crp(model_trials, model_presentations)\n        crp[global_lag_range] = np.nan\n        crp = pd.DataFrame(\n            {'Lag': np.arange(crp_max_lag*2 + 1, dtype=int)-crp_max_lag, \n            'Recall Rate': crp[list_length-crp_max_lag-1:list_length+crp_max_lag], \n            varied_parameter: parameter_value})\n        crps.append(crp)\n\n        # rep crp\n        rep_crp = alternative_contiguity(\n            model_trials, model_presentations, 6, 2)\n        rep_crp[:, global_lag_range] = np.nan\n        rep_crp = pd.DataFrame({\n                \"Lag\": np.arange(rep_crp_max_lag * 2 + 1, dtype=int) - rep_crp_max_lag,\n                \"Differential Recall Rate\": rep_crp[0, list_length-rep_crp_max_lag-1:list_length + rep_crp_max_lag]\n                    - rep_crp[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag],\n                varied_parameter: parameter_value,\n            })\n        rep_crps.append(rep_crp)\n\n        # lag-connectivity requires more involved computations...\n        total_lag_mfc = np.zeros((global_lag_range * 2 + 1))\n        total_lag_mcf = np.zeros((global_lag_range * 2 + 1))\n        total_lag_mff = np.zeros((global_lag_range * 2 + 1))\n        total_rep_lag_mfc = np.zeros((2, global_lag_range * 2 + 1))\n        total_rep_lag_mcf = np.zeros((2, global_lag_range * 2 + 1))\n        total_rep_lag_mff = np.zeros((2, global_lag_range * 2 + 1))\n\n        # loop through presentations\n        for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n            # simulate list study\n            item_count = np.max(presentation)+1\n            model = model_class(item_count, len(presentation), model_parameters)\n            model.experience(model.items[presentation])\n\n            # extract item connections\n            latent_mfc, mcf_connections, mff_connections = latent_mfc_mcf_mff(model, model.recall_items)\n            mfc_connections = latent_mfc[:, 1:-1]\n\n            # track repetition connectivity\n            total_rep_lag_mfc += alternative_connectivity_by_lag(mfc_connections, presentation)\n            total_rep_lag_mcf += alternative_connectivity_by_lag(mcf_connections, presentation)\n            total_rep_lag_mff += alternative_connectivity_by_lag(mff_connections, presentation)\n\n            # and overall connectivity\n            total_lag_mfc += mixed_connectivity_by_lag(mfc_connections, presentation)\n            total_lag_mcf += mixed_connectivity_by_lag(mcf_connections, presentation)\n            total_lag_mff += mixed_connectivity_by_lag(mff_connections, presentation)\n\n        # reduce sum to mean\n        # repetition connectivity\n        rep_lag_mfc = total_rep_lag_mfc / (trial_index+1)\n        rep_lag_mcf = total_rep_lag_mcf / (trial_index+1)\n        rep_lag_mff = total_rep_lag_mff / (trial_index+1)\n        rep_lag_mfc[:, global_lag_range] = np.nan\n        rep_lag_mcf[:, global_lag_range] = np.nan\n        rep_lag_mff[:, global_lag_range] = np.nan\n\n        # overall connectivity\n        lag_mfc = total_lag_mfc / (trial_index+1)\n        lag_mcf = total_lag_mcf / (trial_index+1)\n        lag_mff = total_lag_mff / (trial_index+1)\n        lag_mfc[global_lag_range] = np.nan\n        lag_mcf[global_lag_range] = np.nan\n        lag_mff[global_lag_range] = np.nan\n\n        # aggregate for dataframe\n        rep_lag_mfc = pd.DataFrame(\n            {'Lag': np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag,\n            'Differential Recall Rate': rep_lag_mfc[0, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag]\n            - rep_lag_mfc[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag],\n            varied_parameter: parameter_value})\n        rep_lag_mcf = pd.DataFrame(\n            {'Lag': np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag,\n            'Differential Recall Rate': rep_lag_mcf[0, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag]\n            - rep_lag_mcf[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag],\n            varied_parameter: parameter_value})\n        rep_lag_mff = pd.DataFrame(\n            {'Lag': np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag,\n            'Differential Recall Rate': rep_lag_mff[0, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag]\n            - rep_lag_mff[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag],\n            varied_parameter: parameter_value})\n\n        lag_mfc = pd.DataFrame(\n            {'Lag': np.arange(crp_max_lag*2+1, dtype=int)-crp_max_lag,\n            'Recall Rate': lag_mfc[list_length-crp_max_lag-1:list_length+crp_max_lag],\n            varied_parameter: parameter_value})\n        lag_mcf = pd.DataFrame(\n            {'Lag': np.arange(crp_max_lag*2+1, dtype=int)-crp_max_lag,\n            'Recall Rate': lag_mcf[list_length-crp_max_lag-1:list_length+crp_max_lag],\n            varied_parameter: parameter_value})\n        lag_mff = pd.DataFrame(\n            {'Lag': np.arange(crp_max_lag*2+1, dtype=int)-crp_max_lag,\n            'Recall Rate': lag_mff[list_length-crp_max_lag-1:list_length+crp_max_lag],\n            varied_parameter: parameter_value})\n\n        rep_lag_mcfs.append(rep_lag_mcf)\n        rep_lag_mffs.append(rep_lag_mff)\n        rep_lag_mfcs.append(rep_lag_mfc)\n        lag_mcfs.append(lag_mcf)\n        lag_mffs.append(lag_mff)\n        lag_mfcs.append(lag_mfc)\n    \n    # aggregate fitting results\n    spc = pd.concat(spcs).reset_index()\n    pfr = pd.concat(pfrs).reset_index()\n    crp = pd.concat(crps).reset_index()\n    rpl = pd.concat(rpls).reset_index()\n    rep_crp = pd.concat(rep_crps).reset_index()\n    lag_mcf = pd.concat(lag_mcfs).reset_index()\n    lag_mff = pd.concat(lag_mffs).reset_index()\n    lag_mfc = pd.concat(lag_mfcs).reset_index()\n    rep_lag_mcf = pd.concat(rep_lag_mcfs).reset_index()\n    rep_lag_mff = pd.concat(rep_lag_mffs).reset_index()\n    rep_lag_mfc = pd.concat(rep_lag_mfcs).reset_index()\n\n    # plot results\n    sns.set(style='darkgrid')\n    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(25, 25), sharey=False)\n\n    # spc\n    sns.lineplot(ax=axes[0, 0], data=spc, x='Study Position', y='Recall Rate', hue=varied_parameter, ci=None)\n    axes[0, 0].set_title('SPC')\n\n    # pfr\n    sns.lineplot(ax=axes[0, 1], data=pfr, x='Study Position', y='First Recall Rate', hue=varied_parameter, ci=None, legend=False)\n    axes[0, 1].set_title('PFR')\n\n    # rpl (should be rps)\n    sns.lineplot(ax=axes[0, 2], data=rpl, x='Spacing', y='Recall Rate', hue=varied_parameter, ci=None)\n    axes[0, 2].set_title('Recall Probability by Spacing')\n\n    # crp\n    filt_neg = f'{-crp_max_lag} <= Lag < 0'\n    filt_pos = f'0 < Lag <= {crp_max_lag}'\n    sns.lineplot(ax=axes[1, 0], data=crp.query(filt_neg), x='Lag', y='Recall Rate', \n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[1, 0], data=crp.query(filt_pos), x='Lag', y='Recall Rate', \n        hue=varied_parameter, ci=None, legend=False)\n    axes[1, 0].set_title('CRP')\n\n    # rep_crp\n    sns.lineplot(ax=axes[1, 1], data=rep_crp.query(filt_neg), x='Lag', y=\"Differential Recall Rate\", \n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[1, 1], data=rep_crp.query(filt_pos), x='Lag', y=\"Differential Recall Rate\", \n        hue=varied_parameter, ci=None, legend=False)\n    axes[1, 1].set_title('Repetition Lag-Contiguity Difference')\n\n    # lag_mcf\n    sns.lineplot(ax=axes[2, 0], data=lag_mcf.query(filt_neg), x='Lag', y='Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[2, 0], data=lag_mcf.query(filt_pos), x='Lag', y='Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n\n    # lag_mfc\n    sns.lineplot(ax=axes[2, 1], data=lag_mfc.query(filt_neg), x='Lag', y='Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[2, 1], data=lag_mfc.query(filt_pos), x='Lag', y='Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n\n    # lag_mff\n    sns.lineplot(ax=axes[2, 2], data=lag_mff.query(filt_neg), x='Lag', y='Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[2, 2], data=lag_mff.query(filt_pos), x='Lag', y='Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n\n    # rep_lag_mcf\n    sns.lineplot(ax=axes[3, 0], data=rep_lag_mcf.query(filt_neg), x='Lag', y='Differential Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[3, 0], data=rep_lag_mcf.query(filt_pos), x='Lag', y='Differential Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n\n    # rep_lag_mfc\n    sns.lineplot(ax=axes[3, 1], data=rep_lag_mfc.query(filt_neg), x='Lag', y='Differential Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[3, 1], data=rep_lag_mfc.query(filt_pos), x='Lag', y='Differential Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n\n    # rep_lag_mff\n    sns.lineplot(ax=axes[3, 2], data=rep_lag_mff.query(filt_neg), x='Lag', y='Differential Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[3, 2], data=rep_lag_mff.query(filt_pos), x='Lag', y='Differential Recall Rate',\n        hue=varied_parameter, ci=None, legend=False)\n\n    # render result\n    plt.show()\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nfeature_drift_rate 1.0\n[0.001 0.101 0.201 0.301 0.401 0.501 0.601 0.701 0.801 0.901]\n\n\n100%|██████████| 10/10 [04:29<00:00, 26.98s/it]"
  },
  {
    "objectID": "library\\model_analysis\\Model_Characterization.html#repetition-contiguity-parameter-shifting-experiments",
    "href": "library\\model_analysis\\Model_Characterization.html#repetition-contiguity-parameter-shifting-experiments",
    "title": "compmemlearn",
    "section": "Repetition Contiguity Parameter Shifting Experiments",
    "text": "InstanceCMR\n\n# configure parameters\nmodel_class = init_icmr\nmodel_name = 'Instance_CMR'\nparameters = icmr_fitted_parameters\nlist_type = 4\n\n# track results\nglobal_lag_range = list_length-1\ncrp_max_lag = 13\nrep_crp_max_lag = 3\nexperiment_count = 100\n\nscore_ranges = {\n    'encoding_drift_rate': np.arange(.001, .99, .1),\n    'recall_drift_rate': np.arange(.001, .99, .1),\n    'shared_support': np.arange(.001, .005, .001),\n    'item_support': np.arange(.001, .01, .001),\n    'learning_rate': np.arange(.001, .99, .1),\n    'choice_sensitivity': np.arange(.001, 5, .5),\n}\n\nfor varied_parameter in score_ranges.keys():\n\n    print(varied_parameter, parameters[varied_parameter])\n    rep_crps = []\n    rep_lag_mcfs = []\n    rep_lag_mfcs = []\n    rep_lag_mffs = []\n\n    # loop through parameter values\n    for parameter_value in tqdm(score_ranges[varied_parameter]):\n\n        # simulate data with this parameter value modified\n        model_parameters = parameters.copy()\n        model_parameters[varied_parameter] = parameter_value\n        model_trials = simulate_array_from_presentations(\n            model_class, model_parameters, presentations[list_types==list_type], experiment_count)\n        model_presentations = np.matlib.repmat(presentations[list_types==list_type], experiment_count, 1)\n\n        # rep crp\n        rep_crp = alternative_contiguity(\n            model_trials, model_presentations, 6, 2)\n        rep_crp[:, global_lag_range] = np.nan\n        rep_crp = pd.DataFrame({\n                \"Lag\": (np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag).tolist() * 2,\n                \"Recall Rate\": rep_crp[0, list_length-rep_crp_max_lag-1:list_length + rep_crp_max_lag].tolist()\n                    + rep_crp[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist(),\n                varied_parameter: parameter_value,\n                \"Position\": ['First'] * (rep_crp_max_lag*2+1) + ['Second'] * (rep_crp_max_lag*2+1)\n            })\n        rep_crps.append(rep_crp)\n\n        # lag-connectivity requires more involved computations...\n        total_rep_lag_mfc = np.zeros((2, global_lag_range * 2 + 1))\n        total_rep_lag_mcf = np.zeros((2, global_lag_range * 2 + 1))\n        total_rep_lag_mff = np.zeros((2, global_lag_range * 2 + 1))\n\n        # loop through presentations\n        for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n            # simulate list study\n            item_count = np.max(presentation)+1\n            model = model_class(item_count, len(presentation), model_parameters)\n            model.experience(model.items[presentation])\n\n            # extract item connections\n            latent_mfc, mcf_connections, mff_connections = latent_mfc_mcf_mff(model, model.items)\n            mfc_connections = latent_mfc[:, 1:-1]\n\n            # track repetition connectivity\n            total_rep_lag_mfc += alternative_connectivity_by_lag(mfc_connections, presentation)\n            total_rep_lag_mcf += alternative_connectivity_by_lag(mcf_connections, presentation)\n            total_rep_lag_mff += alternative_connectivity_by_lag(mff_connections, presentation)\n\n        # reduce sum to mean\n        # repetition connectivity\n        rep_lag_mfc = total_rep_lag_mfc / (trial_index+1)\n        rep_lag_mcf = total_rep_lag_mcf / (trial_index+1)\n        rep_lag_mff = total_rep_lag_mff / (trial_index+1)\n        rep_lag_mfc[:, global_lag_range] = np.nan\n        rep_lag_mcf[:, global_lag_range] = np.nan\n        rep_lag_mff[:, global_lag_range] = np.nan\n\n        # aggregate for dataframe\n        rep_lag_mfc = pd.DataFrame(\n            {'Lag': (np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag).tolist() * 2,\n            'Recall Rate': rep_lag_mfc[0, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist()\n            + rep_lag_mfc[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist(),\n            varied_parameter: parameter_value,\n            \"Position\": ['First'] * (rep_crp_max_lag*2+1) + ['Second'] * (rep_crp_max_lag*2+1)})\n        rep_lag_mcf = pd.DataFrame(\n            {'Lag': (np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag).tolist() * 2,\n            'Recall Rate': rep_lag_mcf[0, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist()\n            + rep_lag_mcf[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist(),\n            varied_parameter: parameter_value,\n            \"Position\": ['First'] * (rep_crp_max_lag*2+1) + ['Second'] * (rep_crp_max_lag*2+1)})\n        rep_lag_mff = pd.DataFrame(\n            {'Lag': (np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag).tolist() * 2,\n            'Recall Rate': rep_lag_mff[0, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist()\n            + rep_lag_mff[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist(),\n            varied_parameter: parameter_value,\n            \"Position\": ['First'] * (rep_crp_max_lag*2+1) + ['Second'] * (rep_crp_max_lag*2+1)})\n\n        rep_lag_mcfs.append(rep_lag_mcf)\n        rep_lag_mffs.append(rep_lag_mff)\n        rep_lag_mfcs.append(rep_lag_mfc)\n\n    # aggregate fitting results\n    rep_crp = pd.concat(rep_crps).reset_index()\n    rep_lag_mcf = pd.concat(rep_lag_mcfs).reset_index()\n    rep_lag_mff = pd.concat(rep_lag_mffs).reset_index()\n    rep_lag_mfc = pd.concat(rep_lag_mfcs).reset_index()\n\n    # plot results\n    sns.set(style='darkgrid')\n    fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(25, 25), sharey=True)\n\n    # rep_crp\n    sns.lineplot(ax=axes[0, 0], data=rep_crp[rep_crp['Position']=='First'].query(filt_neg), x='Lag', y=\"Recall Rate\", \n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[0, 0], data=rep_crp[rep_crp['Position']=='First'].query(filt_pos), x='Lag', y=\"Recall Rate\", \n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[0, 1], data=rep_crp[rep_crp['Position']=='Second'].query(filt_neg), x='Lag', y=\"Recall Rate\", \n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[0, 1], data=rep_crp[rep_crp['Position']=='Second'].query(filt_pos), x='Lag', y=\"Recall Rate\", \n        hue=varied_parameter, ci=None, legend=False)\n    axes[0, 0].set_title('First Repetition Lag-Contiguity')\n    axes[0, 1].set_title('Second Repetition Lag-Contiguity')\n    \n    # rep_lag_mcf\n    sns.lineplot(\n        ax=axes[1, 0], data=rep_lag_mcf[rep_lag_mcf['Position']=='First'].query(filt_neg), \n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[1, 0], data=rep_lag_mcf[rep_lag_mcf['Position']=='First'].query(filt_pos),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[1, 1], data=rep_lag_mcf[rep_lag_mcf['Position']=='Second'].query(filt_neg),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[1, 1], data=rep_lag_mcf[rep_lag_mcf['Position']=='Second'].query(filt_pos),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    axes[1, 0].set_title('MCF First Repetition Lag-Contiguity')\n    axes[1, 1].set_title('MCF Second Repetition Lag-Contiguity')\n\n    # rep_lag_mfc\n    sns.lineplot(\n        ax=axes[2, 0], data=rep_lag_mfc[rep_lag_mfc['Position']=='First'].query(filt_neg),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[2, 0], data=rep_lag_mfc[rep_lag_mfc['Position']=='First'].query(filt_pos),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[2, 1], data=rep_lag_mfc[rep_lag_mfc['Position']=='Second'].query(filt_neg),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[2, 1], data=rep_lag_mfc[rep_lag_mfc['Position']=='Second'].query(filt_pos),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    axes[2, 0].set_title('MFC First Repetition Lag-Contiguity')\n    axes[2, 1].set_title('MFC Second Repetition Lag-Contiguity')\n\n    # rep_lag_mff\n    sns.lineplot(\n        ax=axes[3, 0], data=rep_lag_mff[rep_lag_mff['Position']=='First'].query(filt_neg),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[3, 0], data=rep_lag_mff[rep_lag_mff['Position']=='First'].query(filt_pos),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[3, 1], data=rep_lag_mff[rep_lag_mff['Position']=='Second'].query(filt_neg),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[3, 1], data=rep_lag_mff[rep_lag_mff['Position']=='Second'].query(filt_pos),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    axes[3, 0].set_title('MFF First Repetition Lag-Contiguity')\n    axes[3, 1].set_title('MFF Second Repetition Lag-Contiguity')\n\n    # render result\n    plt.show()\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nencoding_drift_rate 0.832809463\n\n\n100%|██████████| 10/10 [02:42<00:00, 16.25s/it]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nrecall_drift_rate 0.961140398\n\n\n100%|██████████| 10/10 [02:30<00:00, 15.09s/it]\n\n\n\n\n\n  0%|          | 0/4 [00:00<?, ?it/s]\n\n\nshared_support 0.0011990853\n\n\n100%|██████████| 4/4 [01:00<00:00, 15.11s/it]\n\n\n\n\n\n  0%|          | 0/9 [00:00<?, ?it/s]\n\n\nitem_support 0.131621512\n\n\n100%|██████████| 9/9 [02:15<00:00, 15.10s/it]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nlearning_rate 0.245449928\n\n\n100%|██████████| 10/10 [02:34<00:00, 15.40s/it]\n\n\n\n\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nchoice_sensitivity 1.0\n\n\n100%|██████████| 10/10 [02:36<00:00, 15.65s/it]\n\n\n\n\n\n\n\nTrace-Reinstatement CMR\n\n# configure parameters\nmodel_class = init_trcmr\nmodel_name = 'Trace-Reinstatement CMR'\nparameters = trcmr_fitted_parameters\nlist_type = 4\n\n# track results\nglobal_lag_range = list_length-1\ncrp_max_lag = 13\nrep_crp_max_lag = 3\nexperiment_count = 100\n\nscore_ranges = {\n    'feature_drift_rate': np.arange(.001, 1, .1),\n}\n\nfor varied_parameter in score_ranges.keys():\n\n    print(varied_parameter, parameters[varied_parameter])\n    rep_crps = []\n    rep_lag_mcfs = []\n    rep_lag_mfcs = []\n    rep_lag_mffs = []\n\n    # loop through parameter values\n    for parameter_value in tqdm(score_ranges[varied_parameter]):\n\n        # simulate data with this parameter value modified\n        model_parameters = parameters.copy()\n        model_parameters[varied_parameter] = parameter_value\n        model_trials = simulate_array_from_presentations(\n            model_class, model_parameters, presentations[list_types==list_type], experiment_count)\n        model_presentations = np.matlib.repmat(presentations[list_types==list_type], experiment_count, 1)\n\n        # rep crp\n        rep_crp = alternative_contiguity(\n            model_trials, model_presentations, 6, 2)\n        rep_crp[:, global_lag_range] = np.nan\n        rep_crp = pd.DataFrame({\n                \"Lag\": (np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag).tolist() * 2,\n                \"Recall Rate\": rep_crp[0, list_length-rep_crp_max_lag-1:list_length + rep_crp_max_lag].tolist()\n                    + rep_crp[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist(),\n                varied_parameter: parameter_value,\n                \"Position\": ['First'] * (rep_crp_max_lag*2+1) + ['Second'] * (rep_crp_max_lag*2+1)\n            })\n        rep_crps.append(rep_crp)\n\n        # lag-connectivity requires more involved computations...\n        total_rep_lag_mfc = np.zeros((2, global_lag_range * 2 + 1))\n        total_rep_lag_mcf = np.zeros((2, global_lag_range * 2 + 1))\n        total_rep_lag_mff = np.zeros((2, global_lag_range * 2 + 1))\n\n        # loop through presentations\n        for trial_index, presentation in enumerate(presentations[list_types==list_type]):\n\n            # simulate list study\n            item_count = np.max(presentation)+1\n            model = model_class(item_count, len(presentation), model_parameters)\n            model.experience(model.items[presentation])\n\n            # extract item connections\n            latent_mfc, mcf_connections, mff_connections = latent_mfc_mcf_mff(model, model.recall_items)\n            mfc_connections = latent_mfc[:, 1:-1]\n\n            # track repetition connectivity\n            total_rep_lag_mfc += alternative_connectivity_by_lag(mfc_connections, presentation)\n            total_rep_lag_mcf += alternative_connectivity_by_lag(mcf_connections, presentation)\n            total_rep_lag_mff += alternative_connectivity_by_lag(mff_connections, presentation)\n\n        # reduce sum to mean\n        # repetition connectivity\n        rep_lag_mfc = total_rep_lag_mfc / (trial_index+1)\n        rep_lag_mcf = total_rep_lag_mcf / (trial_index+1)\n        rep_lag_mff = total_rep_lag_mff / (trial_index+1)\n        rep_lag_mfc[:, global_lag_range] = np.nan\n        rep_lag_mcf[:, global_lag_range] = np.nan\n        rep_lag_mff[:, global_lag_range] = np.nan\n\n        # aggregate for dataframe\n        rep_lag_mfc = pd.DataFrame(\n            {'Lag': (np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag).tolist() * 2,\n            'Recall Rate': rep_lag_mfc[0, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist()\n            + rep_lag_mfc[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist(),\n            varied_parameter: parameter_value,\n            \"Position\": ['First'] * (rep_crp_max_lag*2+1) + ['Second'] * (rep_crp_max_lag*2+1)})\n        rep_lag_mcf = pd.DataFrame(\n            {'Lag': (np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag).tolist() * 2,\n            'Recall Rate': rep_lag_mcf[0, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist()\n            + rep_lag_mcf[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist(),\n            varied_parameter: parameter_value,\n            \"Position\": ['First'] * (rep_crp_max_lag*2+1) + ['Second'] * (rep_crp_max_lag*2+1)})\n        rep_lag_mff = pd.DataFrame(\n            {'Lag': (np.arange(rep_crp_max_lag*2+1, dtype=int)-rep_crp_max_lag).tolist() * 2,\n            'Recall Rate': rep_lag_mff[0, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist()\n            + rep_lag_mff[1, list_length-rep_crp_max_lag-1:list_length+rep_crp_max_lag].tolist(),\n            varied_parameter: parameter_value,\n            \"Position\": ['First'] * (rep_crp_max_lag*2+1) + ['Second'] * (rep_crp_max_lag*2+1)})\n\n        rep_lag_mcfs.append(rep_lag_mcf)\n        rep_lag_mffs.append(rep_lag_mff)\n        rep_lag_mfcs.append(rep_lag_mfc)\n\n    # aggregate fitting results\n    rep_crp = pd.concat(rep_crps).reset_index()\n    rep_lag_mcf = pd.concat(rep_lag_mcfs).reset_index()\n    rep_lag_mff = pd.concat(rep_lag_mffs).reset_index()\n    rep_lag_mfc = pd.concat(rep_lag_mfcs).reset_index()\n\n    # plot results\n    sns.set(style='darkgrid')\n    fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(15, 25), sharey=True)\n\n    # rep_crp\n    sns.lineplot(ax=axes[0, 0], data=rep_crp[rep_crp['Position']=='First'].query(filt_neg), x='Lag', y=\"Recall Rate\", \n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[0, 0], data=rep_crp[rep_crp['Position']=='First'].query(filt_pos), x='Lag', y=\"Recall Rate\", \n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[0, 1], data=rep_crp[rep_crp['Position']=='Second'].query(filt_neg), x='Lag', y=\"Recall Rate\", \n        hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(ax=axes[0, 1], data=rep_crp[rep_crp['Position']=='Second'].query(filt_pos), x='Lag', y=\"Recall Rate\", \n        hue=varied_parameter, ci=None, legend=False)\n    axes[0, 0].set_title('First Repetition Lag-Contiguity')\n    axes[0, 1].set_title('Second Repetition Lag-Contiguity')\n    \n    # rep_lag_mcf\n    sns.lineplot(\n        ax=axes[1, 0], data=rep_lag_mcf[rep_lag_mcf['Position']=='First'].query(filt_neg), \n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[1, 0], data=rep_lag_mcf[rep_lag_mcf['Position']=='First'].query(filt_pos),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[1, 1], data=rep_lag_mcf[rep_lag_mcf['Position']=='Second'].query(filt_neg),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[1, 1], data=rep_lag_mcf[rep_lag_mcf['Position']=='Second'].query(filt_pos),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    axes[1, 0].set_title('MCF First Repetition Lag-Contiguity')\n    axes[1, 1].set_title('MCF Second Repetition Lag-Contiguity')\n\n    # rep_lag_mfc\n    sns.lineplot(\n        ax=axes[2, 0], data=rep_lag_mfc[rep_lag_mfc['Position']=='First'].query(filt_neg),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[2, 0], data=rep_lag_mfc[rep_lag_mfc['Position']=='First'].query(filt_pos),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[2, 1], data=rep_lag_mfc[rep_lag_mfc['Position']=='Second'].query(filt_neg),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[2, 1], data=rep_lag_mfc[rep_lag_mfc['Position']=='Second'].query(filt_pos),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    axes[2, 0].set_title('MFC First Repetition Lag-Contiguity')\n    axes[2, 1].set_title('MFC Second Repetition Lag-Contiguity')\n\n    # rep_lag_mff\n    sns.lineplot(\n        ax=axes[3, 0], data=rep_lag_mff[rep_lag_mff['Position']=='First'].query(filt_neg),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[3, 0], data=rep_lag_mff[rep_lag_mff['Position']=='First'].query(filt_pos),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[3, 1], data=rep_lag_mff[rep_lag_mff['Position']=='Second'].query(filt_neg),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    sns.lineplot(\n        ax=axes[3, 1], data=rep_lag_mff[rep_lag_mff['Position']=='Second'].query(filt_pos),\n        x='Lag', y=\"Recall Rate\", hue=varied_parameter, ci=None, legend=False)\n    axes[3, 0].set_title('MFF First Repetition Lag-Contiguity')\n    axes[3, 1].set_title('MFF Second Repetition Lag-Contiguity')\n\n    # render result\n    plt.show()\n\n  0%|          | 0/10 [00:00<?, ?it/s]\n\n\nfeature_drift_rate 1.0\n\n\n100%|██████████| 10/10 [03:52<00:00, 23.28s/it]"
  },
  {
    "objectID": "library\\model_analysis\\Model_Visualization.html#parameter-configuration",
    "href": "library\\model_analysis\\Model_Visualization.html#parameter-configuration",
    "title": "compmemlearn",
    "section": "Parameter Configuration",
    "text": "Pick some parameters for Instance_CMR and CMR to organize comparisons."
  },
  {
    "objectID": "library\\model_analysis\\Model_Visualization.html#encoding",
    "href": "library\\model_analysis\\Model_Visualization.html#encoding",
    "title": "compmemlearn",
    "section": "Encoding",
    "text": "First we create simulations and visualizations to track model state throughout encoding of new memories. To do this, we produce two parallel functions, encoding_states and plot_states that collect and visualize encoding states, respectively. An additional wrapper function called encoding_visualizations plots these states in addition to the final overall state of model memory.\nicmr_parameters = {\n}\n\ncmr_parameters = {\n}\n#hide \n\nimport numpy as np\n\ndef encoding_states(model):\n    \"\"\"\n    Tracks state of context, and item supports across encoding. Model is also advanced to a state of fully encoded\n    memories.\n\n    **Required model attributes**:  \n    - item_count: specifies number of items encoded into memory  \n    - context: vector representing an internal contextual state  \n    - experience: adding a new trace to the memory model  \n    - activations: function returning item activations given a vector probe  \n    - outcome_probabilities: function returning item supports given a set of activations\n\n    **Returns** array representations of context and support for retrieval of each item at each increment of item\n    encoding. Each has shape model.item_count by model.item_count + 1.\n    \"\"\"\n    \n    experiences = np.eye(model.item_count, model.item_count + 1, 1)\n    cmr_experiences = np.eye(model.item_count, model.item_count)\n    encoding_contexts, encoding_supports = model.context, []\n\n    # track model state across experiences\n    for i in range(len(experiences)):\n        try:\n            model.experience(experiences[i].reshape((1, -1)))\n        except ValueError:\n            # special case for CMR\n            model.experience(cmr_experiences[i].reshape((1, -1)))\n\n        # track model contexts and item supports\n        encoding_contexts = np.vstack((encoding_contexts, model.context))\n\n        if model.__class__.__name__ == 'CMR':\n            activation_cue = lambda model: model.context\n        else:\n            activation_cue = lambda model: np.hstack((np.zeros(model.item_count + 1), model.context))\n\n        if len(encoding_supports) > 0:\n            encoding_supports = np.vstack((encoding_supports, model.outcome_probabilities(activation_cue(model))))\n        else:\n            encoding_supports = model.outcome_probabilities(activation_cue(model))\n    \n    return encoding_contexts, encoding_supports\nshow_doc(encoding_states, title_level=3)\n# hide\n\n# collapse_input\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef plot_states(matrix, title, figsize=(15, 15), savefig=False):\n    \"\"\"\n    Plots an array of model states as a value-annotated heatmap with an arbitrary title.\n\n    **Arguments**:  \n    - matrix: an array of model states, ideally with columns representing unique feature indices and rows\n        representing unique update indices  \n    - title: a title for the generated plot, ideally conveying what array values represent at each entry  \n    - savefig: boolean deciding whether generated figure is saved (True if Yes)\n    \"\"\"\n    plt.figure(figsize=figsize)\n    sns.heatmap(matrix, annot=True, linewidths=.5)\n    plt.title(title)\n    plt.xlabel('Feature Index')\n    plt.ylabel('Update Index')\n    if savefig:\n        plt.savefig('figures/{}.jpeg'.format(title).replace(' ', '_').lower(), bbox_inches='tight')\n    plt.show()\nshow_doc(plot_states, title_level=3)\n\ndef encoding_visualizations(model, savefig=True):\n    \"\"\"\n    Plots encoding contexts, encoding supports as heatmaps.\n\n    **Required model attributes**:  \n    - item_count: specifies number of items encoded into memory  \n    - context: vector representing an internal contextual state  \n    - experience: adding a new trace to the memory model  \n    - activations: function returning item activations given a vector probe  \n    - outcome_probabilities: function returning item supports given a set of activations\n    - memory: a unitary representation of the current state of memory\n\n    **Also** requires savefig:  boolean deciding if generated figure is saved\n    \"\"\"\n    \n    encoding_contexts, encoding_supports = encoding_states(model)\n    plot_states(encoding_contexts, 'Encoding Contexts', savefig=savefig)\n    plot_states(encoding_supports, 'Supports For Each Item At Each Increment of Encoding', savefig=savefig)\ntry:\n    show_doc(encoding_visualizations, title_level=3)\nexcept:\n    pass\n\nDemo\n\nICMR\nfrom instance_cmr.models import InstanceCMR\n\nmodel = InstanceCMR(**icmr_parameters)\nencoding_visualizations(model)\n \n\n\nCMR\nfrom instance_cmr.models import CMR\n\nmodel = CMR(**cmr_parameters)\nencoding_visualizations(model)"
  },
  {
    "objectID": "library\\model_analysis\\Model_Visualization.html#latent-mfcmcf",
    "href": "library\\model_analysis\\Model_Visualization.html#latent-mfcmcf",
    "title": "compmemlearn",
    "section": "Latent Mfc/Mcf",
    "text": "def latent_mfc_mcf(model):\n    \n    \"\"\"\n    Generates the latent $M^{FC}$ and $M^{CF}$ in the specified ICMR instance.\n    For exploring and demonstrating model equivalence, we can calculate for any state of ICMR's dual-store memory \n    array $M$ a corresponding $M^{FC}$ (or $M^{CF}$) by computing for each orthogonal $f_i$ (or $c_i$) the model's \n    corresponding echo representation. \n    \"\"\"\n\n    encoding_states(model)\n    \n    # start by finding latent mfc: the contextual representation cued when each orthogonal $f_i$ is cued\n    latent_mfc = np.zeros((model.item_count, model.item_count+1))\n    cue = np.zeros(model.item_count*2 + 2)\n    for i in range(model.item_count):\n        cue *= 0\n        cue[i+1] = 1\n        latent_mfc[i] = model.echo(cue)[model.item_count + 1:]\n\n    # now the latent mcf\n    latent_mcf = np.zeros((model.item_count+1, model.item_count))\n    for i in range(model.item_count+1):\n        cue *= 0\n        cue[model.item_count+1+i] = 1\n        latent_mcf[i] = model.echo(cue)[1:model.item_count + 1] # start at 1 due to dummy column in F\n\n    # plotting\n    return latent_mfc, latent_mcf\nif True:\n    # ICMR\n    model = InstanceCMR(**parameters)\n    latent_mfc, latent_mcf = latent_mfc_mcf(model)\n    print(model.__class__.__name__)\n    plot_states(model.memory, 'ICMR Memory')\n    plot_states(latent_mfc, 'ICMR Latent Mfc')\n    plot_states(latent_mcf, 'ICMR Latent Mcf')\n\n    # CMR\n    model = CMR(**parameters)\n    encoding_states(model)\n    print(model.__class__.__name__)\n    plot_states(model.mfc, 'CMR Mfc')\n    plot_states(model.mcf, 'CMR Mcf')"
  },
  {
    "objectID": "library\\model_analysis\\Model_Visualization.html#retrieval",
    "href": "library\\model_analysis\\Model_Visualization.html#retrieval",
    "title": "compmemlearn",
    "section": "Retrieval",
    "text": "Tracking model state across each step of retrieval. Since it’s stochastic, these values change with each random seed. An additional optional parameter first_recall_item can control which item is recalled first by the model (0 denotes termination of recall while actual items are 1-indexed); it is useful for testing hypotheses about model dynamics during recall. We leave the parameter set at None, for now, indicating no controlled first recall.\n\nimport numpy as np\n\ndef retrieval_states(model, first_recall_item=None):\n    \"\"\"\n    Tracks state of context, and item supports across retrieval. Model is also advanced into a state of\n    completed free recall.\n\n    **Required model attributes**:\n    - item_count: specifies number of items encoded into memory\n    - context: vector representing an internal contextual state\n    - experience: adding a new trace to the memory model\n    - activations: function returning item activations given a vector probe\n    - outcome_probabilities: function returning item supports given a set of activations\n    - free_recall: function that freely recalls a given number of items or until recall stops\n    - state: indicates whether model is encoding or engaged in recall with a string\n\n    **Also** optionally uses first_recall_item: can specify an item for first recall\n\n    **Returns** array representations of context and support for retrieval of each item at each increment of item\n    retrieval. Also returns recall train associated with simulation.\n    \"\"\"\n\n    if model.__class__.__name__ == 'CMR':\n        activation_cue = lambda model: model.context\n    else:\n        activation_cue = lambda model: np.hstack((np.zeros(model.item_count + 1), model.context))\n\n    # encoding items, presuming model is freshly initialized\n    encoding_states(model)\n    retrieval_contexts, retrieval_supports = model.context, model.outcome_probabilities(activation_cue(model))\n\n    # pre-retrieval distraction\n    model.free_recall(0)\n    retrieval_contexts = np.vstack((retrieval_contexts, model.context))\n    retrieval_supports = np.vstack((retrieval_supports, model.outcome_probabilities(activation_cue(model))))\n\n    # optional forced first item recall\n    if first_recall_item is not None:\n        model.force_recall(first_recall_item)\n        retrieval_contexts = np.vstack((retrieval_contexts, model.context))\n        retrieval_supports = np.vstack((retrieval_supports, model.outcome_probabilities(activation_cue(model))))\n\n    # actual recall\n    while model.retrieving:\n        model.free_recall(1)\n        retrieval_contexts = np.vstack((retrieval_contexts, model.context))\n        retrieval_supports = np.vstack((retrieval_supports, model.outcome_probabilities(activation_cue(model))))\n\n    return retrieval_contexts, retrieval_supports, model.recall[:model.recall_total]\ntry:\n    show_doc(retrieval_states, title_level=3)\nexcept:\n    pass\n\ndef outcome_probs_at_index(model, support_index_to_plot=1, savefig=True):\n    \"\"\"\n    Plots outcome probability distribution at a specific index of free recall.\n\n    **Required model attributes**:\n    - item_count: specifies number of items encoded into memory  \n    - context: vector representing an internal contextual state  \n    - experience: adding a new trace to the memory model  \n    - activations: function returning item activations given a vector probe  \n    - outcome_probabilities: function returning item supports given a set of activations  \n    - free_recall: function that freely recalls a given number of items or until recall stops  \n    - state: indicates whether model is encoding or engaged in recall with a string\n\n    **Other arguments**:  \n    - support_index_to_plot: index of retrieval to plot  \n    - savefig: whether to save or display the figure of interest\n\n    **Generates** a plot of outcome probabilities as a line graph. Also returns vector representation of the\n    generated probabilities.\n    \"\"\"\n\n    retrieval_supports = retrieval_states(model)[1]\n    plt.plot(np.arange(model.item_count + 1), retrieval_supports[support_index_to_plot])\n    plt.xlabel('Choice Index')\n    plt.ylabel('Outcome Probability')\n    plt.title('Outcome Probabilities At Recall Index {}'.format(support_index_to_plot))\n    plt.show()\n    return retrieval_supports[support_index_to_plot]\ntry:\n    show_doc(outcome_probs_at_index, title_level=3)\nexcept:\n    pass\n\ndef retrieval_visualizations(model, savefig=True):\n    \"\"\"\n    Plots incremental retrieval contexts and supports, as heatmaps, and prints recalled items.\n\n    **Required model attributes**:\n    - item_count: specifies number of items encoded into memory\n    - context: vector representing an internal contextual state\n    - experience: adding a new trace to the memory model\n    - activations: function returning item activations given a vector probe\n    - outcome_probabilities: function returning item supports given a set of activations\n\n    **Also** uses savefig: boolean deciding whether figures are saved (True) or displayed\n    \"\"\"\n    \n    retrieval_contexts, retrieval_supports, recall = retrieval_states(model)\n    plot_states(retrieval_contexts, 'Retrieval Contexts', savefig=savefig)\n    plot_states(retrieval_supports, 'Supports For Each Item At Each Increment of Retrieval', \n                savefig=savefig)\n    return recall\ntry:\n    show_doc(retrieval_visualizations, title_level=3)\nexcept:\n    pass\n\nDemo\n\nICMR\nmodel = InstanceCMR(**icmr_parameters)\nretrieval_visualizations(model)\nOutputs can look like…\n \n\n\nCMR\nmodel = CMR(**cmr_parameters)\nretrieval_visualizations(model)"
  },
  {
    "objectID": "library\\model_analysis\\Model_Visualization.html#organizational-analyses",
    "href": "library\\model_analysis\\Model_Visualization.html#organizational-analyses",
    "title": "compmemlearn",
    "section": "Organizational Analyses",
    "text": "Upon completion, the psifr toolbox is used to generate three plots corresponding to the contents of Figure 4 in Morton & Polyn, 2016: 1. Recall probability as a function of serial position 2. Probability of starting recall with each serial position 3. Conditional response probability as a function of lag\nWhereas previous visualizations were based on an arbitrary model simulation, the current figures are based on averages over a simulation of the model some specified amount of times.\n\nimport pandas as pd\nfrom psifr import fr\n\ndef temporal_organization_analyses(model, experiment_count, savefig=False, figsize=(15, 15), first_recall_item=None):\n    \"\"\"\n    Visualization of the outcomes of a trio of organizational analyses of model performance on a free recall\n    task.\n\n    **Required model attributes**:\n    - item_count: specifies number of items encoded into memory  \n    - context: vector representing an internal contextual state  \n    - experience: adding a new trace to the memory model  \n    - free_recall: function that freely recalls a given number of items or until recall stops  \n\n    **Other arguments**:  \n    - experiment_count: number of simulations to compute curves over  \n    - savefig: whether to save or display the figure of interest\n\n    **Returns** three plots corresponding to the contents of Figure 4 in Morton & Polyn, 2016:  \n    1. Recall probability as a function of serial position  \n    2. Probability of starting recall with each serial position  \n    3. Conditional response probability as a function of lag  \n    \"\"\"\n    \n    # encode items\n    try:\n        model.experience(np.eye(model.item_count, model.item_count + 1, 1))\n    except ValueError:\n        # so we can apply to CMR\n        model.experience(np.eye(model.item_count, model.item_count))\n    \n    # simulate retrieval for the specified number of times, tracking results in df\n    data = []\n    for experiment in range(experiment_count):\n        data += [[experiment, 0, 'study', i + 1, i] for i in range(model.item_count)]\n    for experiment in range(experiment_count):\n        if first_recall_item is not None:\n            model.force_recall(first_recall_item)\n        data += [[experiment, 0, 'recall', i + 1, o] for i, o in enumerate(model.free_recall())]\n    data = pd.DataFrame(data, columns=['subject', 'list', 'trial_type', 'position', 'item'])\n    merged = fr.merge_free_recall(data)\n    \n    # visualizations\n    # spc\n    recall = fr.spc(merged)\n    g = fr.plot_spc(recall)\n    plt.title('Serial Position Curve')\n    if savefig:\n        plt.savefig('figures/spc.jpeg', bbox_inches='tight')\n    else:\n        plt.show()\n\n    # P(Start Recall) For Each Serial Position\n    prob = fr.pnr(merged)\n    pfr = prob.query('output <= 1')\n    g = fr.plot_spc(pfr).add_legend()\n    plt.title('Probability of Starting Recall With Each Serial Position')\n    if savefig:\n        plt.savefig('figures/pfr.jpeg', bbox_inches='tight')\n    else:\n        plt.show()\n\n    # Conditional response probability as a function of lag\n    crp = fr.lag_crp(merged)\n    g = fr.plot_lag_crp(crp)\n    plt.title('Conditional Response Probability')\n    if savefig:\n        plt.savefig('figures/crp.jpeg', bbox_inches='tight')\n    else:\n        plt.show()\ntry:\n    show_doc(temporal_organization_analyses, title_level=3)\nexcept:\n    pass\n\nDemo\nfrom instance_cmr.models import InstanceCMR\n\nmodel = InstanceCMR(**icmr_parameters)\ntemporal_organization_analyses(model, 100, True)\nfrom instance_cmr.models import CMR\n\nmodel = CMR(**cmr_parameters)\ntemporal_organization_analyses(model, 100, True)"
  },
  {
    "objectID": "projects\\Instance_CMR\\00_MINERVA_2.html#demonstration",
    "href": "projects\\Instance_CMR\\00_MINERVA_2.html#demonstration",
    "title": "compmemlearn",
    "section": "Demonstration",
    "text": "We can apply this implementation of the classic model to reproduce some results from Experiment 1: Homonyms in an Artificial Language of Jamieson et al (2018). The paper MINERVA 2 as a model of semantic memory called ITS (Instance Theory of Semantics Memory), and considers whether it can track contextual differences in word sense. For example, in some contexts “break” can have a similar meaning to the word “report” (e.g. “break the news”) while in other contexts “break” can have a similar meaning to the word “smash” (e.g. “broke the toy”). ITS records a neutral record of word use in the corpus and develops a representation of word meaning on-the-fly by parallel and probe-driven retrieval. This enables it to create unique representations of the meaning of even same-spelled words that occur in different kinds of contexts.\nWe start by building an artificial language corpus enforcing meaningful statistical regularities for our model to infer.\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef artificial_language_corpus():\n    \"\"\"\n    Generate a corpus of experiences to serve examination of ExemplarModel\n\n    `words` are represented as a unique vector where each dimension takes a randomly sampled value from a\n    normal distribution with mean zero and variance 1/n. Experiences are encoded as the sum of the word vectors\n    occurring in a given context.\n\n    A simple artificial language is constructed to generate a corpus of experiences (specified in Table 1 of\n    paper), consisting of 12 words sorted between 7 lexical categories and 3 sentence frames grammatically\n    specifying how triplets of words from different categories can be associated within a verbal context.\n\n    To explore whether an exemplar model can predict human judgements even in the case of homonyms - words with\n    the same spelling/pronunciation but different meanings - 20,000 grammatical sentences are sampled from the\n    artificial language and encoded as experiences for an ExemplarModel instance.\n    \"\"\"\n\n    # random vectors for each word\n    word_list = ['man', 'woman', 'car', 'truck', 'plate', 'glass', 'story',\n                'news', 'stop', 'smash', 'report', 'break']\n    word_vectors = {word: np.random.normal(0, np.sqrt(1 / 20000), 20000) for word in word_list}\n\n    # categories of lexical items\n    lexical_items = {\n        'NOUN_HUMAN': ['man', 'woman'],\n        'NOUN_VEHICLE': ['car', 'truck'],\n        'NOUN_DINNERWARE': ['plate', 'glass'],\n        'NOUN_NEWS': ['story', 'news'],\n        'VERB_VEHICLE': ['stop', 'break'],\n        'VERB_DINNERWARE': ['smash', 'break'],\n        'VERB_NEWS': ['report', 'break'],\n    }\n\n    # sample sentences and experiences\n    sentences, experiences = [], []\n    frames = np.random.choice([1, 2, 3], 20000)\n    for i in range(20000):\n        if frames[i] == 1:\n            sentence = [np.random.choice(lexical_items['NOUN_HUMAN']),\n                        np.random.choice(lexical_items['VERB_VEHICLE']),\n                        np.random.choice(lexical_items['NOUN_VEHICLE'])]\n        elif frames[i] == 2:\n            sentence = [np.random.choice(lexical_items['NOUN_HUMAN']),\n                        np.random.choice(lexical_items['VERB_DINNERWARE']),\n                        np.random.choice(lexical_items['NOUN_DINNERWARE'])]\n        else:\n            sentence = [np.random.choice(lexical_items['NOUN_HUMAN']),\n                        np.random.choice(lexical_items['VERB_NEWS']),\n                        np.random.choice(lexical_items['NOUN_NEWS'])]\n\n        sentences.append(sentence)\n        experiences.append(np.sum([word_vectors[word] for word in sentence], axis=0))\n\n    return {'word_list': word_list, 'word_vectors': word_vectors, 'lexical_items': lexical_items,\n            'sentences': sentences, 'experiences': experiences}\nUsing a model encoding this corpus, we confirm that words that occur in similar contexts have similar meanings by comparing their echoes against their co-occurrence frequencies in a contextual similarity experiment.\ndef contextual_similarity_experiment(model):\n    \"\"\"\n    Generates similarity matrix visualization testing if words in similar contexts have similar echoes.\n\n    We compute and visualize a pairwise similarity matrix comparing echoes associated with each unique word to\n    one another. Items in the same lexical categories (e.g. 'story' and 'news') occur in similar contexts and\n    so should have similar echoes. Items in opposing lexical categories (e.g. 'story' and 'smash') should be\n    found dissimilar. Items that occur equally often in every context ('break') should be somewhere in the\n    middle.\n    \"\"\"\n\n    # initiate model with corpus of word contexts as experiences\n    corpus = artificial_language_corpus()\n    model = model(corpus['experiences'])\n\n    # compute pairwise similarities for each word in list\n    similarities = np.full((len(corpus['word_list']), len(corpus['word_list'])), np.nan)\n    for x in tqdm(range(len(corpus['word_list']))):\n        for y in range(len(corpus['word_list'])):\n            if x == y:\n                continue\n            word, other_word = corpus['word_list'][x], corpus['word_list'][y]\n            similarities[x, y] = model.compare_probes(\n                corpus['word_vectors'][word], corpus['word_vectors'][other_word])\n    sns.heatmap(similarities, xticklabels=corpus['word_list'], yticklabels=corpus['word_list'],\n                annot=True, linewidths=.5, cmap=\"YlGnBu\")\n    plt.savefig('results/contextual_similarity_experiment.svg')\n    return corpus, similarities\nWith these functions, we apply the simulation to our implementation of the classic exemplar model. If the simulation has worked out, the monogamous words from the vehicle topic are clustered together (i.e., stop, car, truck), the monogamous words from the dinnerware topic are clustered together (i.e., plate, glass, smash), the monogamous words from the news topic are clustered together (i.e., story, news, report), and the promiscuous nouns (i.e., man, woman) are not so clustered with one another but highly clustered with other terms while the promiscuous verb (break) is highly associated with every noun but not with other verbs.\nThese would correspond with the outcomes reported in the literature, and confirm that we can treat this implementation of the MINERVA 2 model as a basis for further work.\n\ncorpus, similarities = contextual_similarity_experiment(ExemplarModel)\n\n100%|██████████| 12/12 [16:51<00:00, 84.32s/it]"
  },
  {
    "objectID": "projects\\Instance_CMR\\paper\\00_Introduction.html#instance-and-prototype-accounts-of-abstraction",
    "href": "projects\\Instance_CMR\\paper\\00_Introduction.html#instance-and-prototype-accounts-of-abstraction",
    "title": "compmemlearn",
    "section": "Instance and Prototype Accounts of Abstraction",
    "text": "A central task of memory is to relate features of current experience with relevant and useful information from past experience; however, stored information relevant to a probe is often distributed across multiple learning episodes. To account for our ability to retrieve this information, models of memory search often specify some mechanism for abstraction – selective generalization across recurrent features of past experience [@yee2019abstraction]. Abstraction involves identifying and highlighting features common across experiential episodes while disregarding or suppressing reinstatement more idiosyncratic properties. Since this capacity is central to how memory systems retrieve relevant information from stored experience, much work has explored how humans carry it out.\nDepending on how they characterize the process of abstraction, memory models can often be categorized as prototype- or instance-based. Prototype-based models conceptualize abstraction as a process enacted during encoding; new experiences are conceived as updating memory representations to reflect prototypical features that are common across past experiences. Connectionist models such as the multilayer perceptron are typically examples of prototype-based models [@jamieson2018instance]. Instead of being stored as separate records in memory, learning examples presented to a connectionist model each update a prototypical pattern of weights that eventually map memory probes to responses.\nInstance-based models do store learning exampls as separate records in memory. The model architecture was originally identified to help understand how category learning might be possible without explicit storage of so-called abstract ideas [@hintzman1984minerva; @hintzman1986schema; @hintzman1988judgments]. Instance-based models posit that memory encoding primarily involves accumulating a record of every experience as separate traces in memory. Abstraction over stored instances later occurs at retrieval rather than during encoding, and unfolds through comparison of a memory cue with each instance stored in memory. The abstractive representation finally retrieved is a blend of the content in each stored instance, weighted such that information in the instances most similar to the probe is substantially more prominent than information in instances that are dissimilar to the probe. Because instance-based models preserve a discrete record of all relevant events in memory, they can often selectively retrieve information about even rare past events with high flexibility. \nInstance-based accounts of memory have faced scrutiny for implying that the number of stored instances in memory can increase without limit and are all contacted upon retrieval, respectively placing extraordinary capacity and processing demands on the human nervous system [e.g., @kahana2020computational]. However, at the same time as instance-based models have been critiqued for their architectural lack of data compression at storage, the way abstractive representations exclude idiosyncratic features of individual learning episodes to reflect a center of tendency across them is similarly recurrently cited as a limitation of prototype-based models. In research on categorization for example, ‘exemplar-similarity’ models [@nosofsky2002exemplar; @stanton2002comparisons] outperform comparable prototype-based models by representing categories as sets of stored instances paired with a process for comparison against probes. A related analysis extends these findings to also critique prototype-based accounts of semantic memory. @jamieson2018instance found that because prototype-based distributional semantic models such as latent semantic analysis [@dumais2004latent] and Word2Vec [@church2017word2vec] “collapse the many contexts in which a word occurs to a single best-fitting representation”, they lose the ability to represent rare senses of homonymous and polymsemous words. Consequently, prototype-based models exhibited measureably worse performance accounting for word similarity patterns in various natural language simulations compared to an instance-based account of semantic memory based on the MINERVA 2 multiple traces memory model [@hintzman1984minerva]. In the context of successes like these across diverse research conditions, instance-based accounts of memory have become increasingly prominent.\n\nModels of Free Recall are Traditionally Prototype-Based\nWhile instance-based models have organized formal work in a variety of research subfields, models of memory search primarily focused on accounting for performance on the free recall task largely countervail this pattern. In the free recall task paradigm, research participants are presented a sequence of items — usually a word list — to memorize during a study phase. Later, after a delay or perhaps some distraction task, participants are prompted to recall as many items from the list as possible, in whatever order they come to mind. Since participants largely organize the course of retrieval themselves in the response phase of a free recall task, work by researchers to characterize the organization of responses measured under the paradigm [@postman1971organization; @puff1979memory] have provided important constraints on accounts of the representations and mechanisms underlying search through memory to retrieve information.\nIn particular, three consistent regularities across experiments have received especial emphasis in accounts of performance on the free recall task [@kahana2020computational]. The serial position effect identifies a nonlinear, U-shaped relationship between the position of an item within a study list — its serial position — and its probability of retrieval after encoding [@murdock1962serial]. Researchers typically distinguish between the enhanced retrieval probabilities for early and terminal items; the advantage for the initially presented items is called the primacy effect, while the normally larger advantage for the few presented items is called the recency effect.\nA similar but distinct pattern constraining accounts of memory search is found in analyses relating an item’s serial position with the probability that it will be recalled first in the retrieval phase of experiments. Pivotally, in list-based free recall tasks, participants tend to initiate recall with the most recently studied items from the list; however, in a serial recall task where participants are instructed to recall items in the order in which they were presented rather than freely, participants tend to successfully recall the earliest presented items first [for example in @golomb2008effects]. This difference implies that while participants maintain and can access memories of item positions to perform a serial recall task, memory search and retrieval is organized by other features of experience.\nPrimacy and recency effects demonstrate that the temporal structure of the list affects the memorability of the items within it. This temporal structure can also be seen in the organization of responses throughout the response sequence, not just for initial and terminal items or recall positions. Free recall task data exhibits a pattern called temporal contiguity where items studied at nearby serial positions tend to be recalled near one another at the retrieval phase of an experiment. To quantify this pattern, researchers measure across trials the conditional probability of retrieving items given increasing inter-item lags between the serial positions of considered items and the serial position of the item last recalled. These lag-based condition response probability (lag-CRP) analyses find that subjects reliably tend to make transitions between temporally contiguous items (that is, items presented near one another) during free recall. Furthermore, they exhibit a forward bias, recalling contiguous items presented after the last recalled item more frequently than items presented before [@kahana1996associative].\nTo account for these phenomena, the formal literature has largely converged on retrieved context theories of memory search [for example, @howard2002distributed; @polyn2009context; @morton2016predictive]. Generally, according to these theories, as items are encoded into a memory system, an internal representational of temporal context is also maintained that dynamically updates itself to reflect a weighted summary of recent experience. As each item is studied, a Hebbian learning mechanism associates the item’s features to the current state of the context representation. Once associated, item features can cue retrieval of associated contextual features, and vice versa. When the retrieval phase comes, the current contextual representation can drive memory search by activating a blend of associated item features. This prompts a retrieval competition in which a particular item is selected and retrieved. Correspondingly, retrieving an item reactivates its associated contextual features, updating context before the next recall attempt. The retrieved context supports the neighbors of the just-recalled item, which gives rise to temporal organization.\nWith these basic mechanisms, retrieved-context models have been used to explain many phenomena, including serial and temporal organizational effects in list-learning tasks [@polyn2009context; @siegel2014retrieved; @schwartz2005shadows], and broader domains such as financial decision making [@wachter2019retrieved], emotion regulation [@talmi2019retrieved], and neural signal dynamics within the medial temporal lobe [@kragel2015neural]. Further model development has integrated retrieved context accounts of memory search with theories of semantic knowledge [@morton2016predictive] and changes related to healthy aging [@healey2016four].\nThe framework used to implement most retrieved context models of memory search acts like a prototype model. These models typically encode memories associating contextual states and item features by updating connection weights within a simplified neural network. Through Hebbian learning, where co-activation of item and contextual features increase weights associating those features, the network accumulates a collapsed average representation reflecting the history of context and item interactions across experience. During retrieval, the network can be probed with a contextual cue to retrieve an item feature representation (or vice versa) based on a linear function of the cue’s content and stored context-to-item weights.\nIn contrast, an instance-based alternative would track this history by storing a discrete record of each experience with its unique temporal context in memory to perform abstraction over only at the point of retrieval. Previous instance-based accounts of performance on various tasks have emphasized a role of some sort of temporal contextual representation in organizing performance. Indeed, the original presentation of MINERVA 2, the first major instance-based memory modeling architecture, included a representation of list context as a feature in stored memory instances to model source-specific frequency judgments from memory [@hintzman1984minerva]. [@lehman2013buffer] proposed an instance-based buffer model that accounts for patterns like recency and the position position effect in terms of storage and retrieval of traces containing information about item and contextual co-occurrences. Most recently, @logan2021serial introduced the Context Retrieval and Updating (CRU) model, which extends retrieved context theories’ conceptualization of context as a recency-weighted history of previously presented items to account for performance on whole report, serial recall, and copy typing tasks. Nonetheless, it remains unclear whether differences reported in related memory literatures between the performance of prototype- and instance-based memory models might similarly distinguish models of memory search.\n\n\nResearch Approach\nIn this paper, I show that the mechanisms proposed by the influential Context Maintanence and Retrieval (CMR) model of memory search [@morton2016predictive] can be realized within either a prototypical or instance-based model architecture without substantially impacting performance across various experimental conditions. This instance-based CMR (InstanceCMR) extends the established MINERVA 2 multiple traces model [@hintzman1984minerva; @hintzman1986schema; @hintzman1988judgments] to support context-based memory search and simulate performance on the free recall task. I fit InstanceCMR and its original prototype-based counterpart (prototypeCMR) to the sequences of individual responses made by participants in three distinct free recall task datasets.I find that the models account for retrieval performance with similar effectiveness despite architectural differences, including over data manipulating the lengths of study lists between trials and other data manipulating the number of times particular items are studied within trials.\nAnalyses of the two specifications for CMR suggest that these outcomes can be largely explained by the model’s assumption that feature representations corresponding to studied items in free recall experiments are orthogonal — activation of each unit on an item feature layer corresponds to one item. This ensures that context-to-feature associations built via experience of one item do not overlap with associations built through experience of some other distinct item. Correspondingly, the influence of relevant experiences on the content of abstractive representations retrieved via these associations can be selectively enhanced while simultaneously suppressing the influence of less relevant experiences, without any interference. This capacity to nonlinearly modulate the influence of selected learning episodes on recall based on the content of a probe approximates trace-based activation functions realized within instance-based models, sidestepping issues reported about prototype-based memory models in other literatures."
  },
  {
    "objectID": "projects\\Instance_CMR\\paper\\01_Classic_CMR.html#the-prototype-based-account-of-context-maintenance-and-retrieval",
    "href": "projects\\Instance_CMR\\paper\\01_Classic_CMR.html#the-prototype-based-account-of-context-maintenance-and-retrieval",
    "title": "compmemlearn",
    "section": "The Prototype-Based Account of Context Maintenance and Retrieval",
    "text": "from compmemlearn.models import Classic_CMR\nRetrieved context theories explain memory search in terms of interactions between between two representations across experience: one of temporal context (a context layer, \\(C\\)) and another of features of studied items (an item layer, \\(F\\)). While this paper introduces an instance-based account of these interactions, we here specify a variant of the original prototype-based context maintenance and retrieval (CMR) model [@polyn2009context] to support comparison against this account. The instance-based model we emphasize tracks the history of interactions between context and item features by storing a discrete record of each experience in memory for later inspection. In contrast, PrototypeCMR maintains a simplified neural network whose connection weights accumulate a center of tendency representation reflecting context and item interactions across experience.\n\nParameters and structures specifying CMR\n\n\n\n\n\n\n\n\nStructure Type\nSymbol\nName\nDescription\n\n\n\n\nArchitecture\n\n\n\n\n\n\n\\(C\\)\ntemporal context\nA recency-weighted average of encoded items\n\n\n\n\\(F\\)\nitem features\nCurrent pattern of item feature unit activations\n\n\n\n\\(M^{FC}\\)\n\nencoded feature-to-context associations\n\n\n\n\\(M^{CF}\\)\n\nencoded context-to-feature associations\n\n\nContext Updating\n\n\n\n\n\n\n\\({\\beta}_{enc}\\)\nencoding drift rate\nRate of context drift during item encoding\n\n\n\n\\({\\beta}_{start}\\)\nstart drift rate\nAmount of start-list context retrieved at start of recall\n\n\n\n\\({\\beta}_{rec}\\)\nrecall drift rate\nRate of context drift during recall\n\n\nAssociative Structure\n\n\n\n\n\n\n\\({\\alpha}\\)\nshared support\nAmount of support items initially have for one another\n\n\n\n\\({\\delta}\\)\nitem support\nInitial pre-experimental contextual self-associations\n\n\n\n\\({\\gamma}\\)\nlearning rate\nAmount of experimental context retrieved by a recalled item\n\n\n\n\\({\\phi}_{s}\\)\nprimacy scale\nScaling of primacy gradient on trace activations\n\n\n\n\\({\\phi}_{d}\\)\nprimacy decay\nRate of decay of primacy gradient\n\n\nRetrieval Dynamics\n\n\n\n\n\n\n\\({\\tau}\\)\nchoice sensitivity\nExponential weighting of similarity-driven activation\n\n\n\n\\({\\theta}_{s}\\)\nstop probability scale\nScaling of the stop probability over output position\n\n\n\n\\({\\theta}_{r}\\)\nstop probability growth\nRate of increase in stop probability over output position\n\n\n\n\nInitial State\nAssociative connections built within prototypeCMR are represented by matrices \\(M^{FC}\\) and \\(M^{CF}\\).\nTo summarize pre-experimental associations built between relevant item features and possible contextual states, we initialize \\(M^{FC}\\) according to:\n\\[\nM^{FC}_{pre(ij)} = \\begin{cases} \\begin{alignedat}{2} 1 - \\gamma \\text{, if } i=j \\\\\\\n          0 \\text{, if } i \\neq j\n   \\end{alignedat} \\end{cases}\n \\qquad(1)\\]\nThis connects each unit on \\(F\\) to a unique unit on \\(C\\). Used this way, \\(\\gamma\\) controls the relative contribution of pre-experimentally acquired associations to the course of retrieval compared to experimentally acquired associations. Correspondingly, context-to-feature associations tracked by \\(M^{CF}\\) are set according to:\n\\[\nM^{CF}_{pre(ij)} = \\begin{cases} \\begin{alignedat}{2} 1 - \\delta \\text{, if } i=j \\\\\\\n          \\alpha \\text{, if } i \\neq j\n       \\end{alignedat} \\end{cases}\n \\qquad(2)\\]\nLike \\(\\gamma\\) with respect to \\(M^{FC}\\), the \\(\\delta\\) parameter controls the contribution of pre-experimental context-to-feature associations relative to experimentally acquired ones. Since context-to-feature associations organizes the competition of items for retrieval, the \\(\\alpha\\) parameter specifies a uniform baseline extent to which items support one another in that competition.\nContext is initialized with a state orthogonal to any of those pre-experimentally associated with an relevant item feature. Feature representations corresponding to items are also assumed to be orthonormal with respect to one another such that each unit on \\(F\\) corresponds to one item.\n\n\nEncoding Phase\nWhenever an item \\(i\\) is presented for study, its corresponding feature representation \\(f_i\\) is activated on \\(F\\) and its contextual associations encoded into \\(M^{FC}\\) are retrieved, altering the current state of context \\(C\\).\nThe input to context is determined by:\n\\[\nc^{IN}_{i} = M^{FC}f_{i}\n \\qquad(3)\\]\nand normalized to have length 1. Context is updated based on this input according to:\n\\[ \nc_i = \\rho_ic_{i-1} + \\beta_{enc} c_{i}^{IN}\n \\qquad(4)\\]\nwith \\(\\beta\\) (for encoding we use \\(\\beta_{enc}\\)) shaping the rate of contextual drift with each new experience, and \\(\\rho\\) enforces the length of \\(c_i\\) to 1 according to:\n\\[ \n\\rho_i = \\sqrt{1 + \\beta^2\\left[\\left(c_{i-1} \\cdot c^{IN}_i\\right)^2 - 1\\right]} - \\beta\\left(c_{i-1} \\cdot\nc^{IN}_i\\right)\n \\qquad(5)\\]\nAssociations between each \\(c_i\\) and \\(f_i\\) are built through Hebbian learning:\n\\[\n\\Delta M^{FC}_{exp} = \\gamma c_i f^{'}_i\n \\qquad(6)\\]\nand\n\\[\n\\Delta M^{CF}_{exp} = \\phi_i f_i c^{'}_i\n \\qquad(7)\\]\nwhere \\(\\phi_i\\) enforces a primacy effect, scales the amount of learning based on the serial position of the studied item according to\n\\[ \n\\phi_i = \\phi_se^{-\\phi_d(i-1)} + 1\n \\qquad(8)\\]\nThis function decays over time, such that \\(\\phi_{s}\\) modulates the strength of primacy while \\(\\phi_{d}\\) modulates the rate of decay.\nThis extended Hebbian learning process characterizes how PrototypeCMR performs abstraction. When each item is encoded with a particular temporal context, representations are updated to aggregate a prototypical summary of the item’s temporal contextual associations in \\(M^{FC}\\) and vice versa in \\(M^{CF}\\).\n\n\nRetrieval Phase\nTo help the model account for the primacy effect, we assume that between the encoding and retrieval phase of a task, the content of \\(C\\) has drifted some amoung back toward its pre-experimental state and set the state of context at the start of retrieval according to following, with \\(\\rho\\) calculated as specified above:\n\\[ \nc_{start} = \\rho_{N+1}c_N + \\beta_{start}c_0\n \\qquad(9)\\]\nAt each recall attempt, the current state of context is used as a cue to attempt retrieval of some studied item. An activation \\(a\\) is solicited for each item according to:\n\\[ \na = M^{CF}c\n \\qquad(10)\\]\nEach item gets a minimum activation of \\(10^{-7}\\). To determine the probability of a given recall event, we first calculate the probability of stopping recall - returning no item and ending memory search. This probability varies as a function of output position \\(j\\):\n\\[\nP(stop, j) = \\theta_se^{j\\theta_r}\n \\qquad(11)\\]\nIn this way, \\(\\theta_s\\) and \\(\\theta_r\\) control the scaling and rate of increase of this exponential function. Given that recall is not stopped, the probability \\(P(i)\\) of recalling a given item depends mainly on its activation strength according\n\\[\nP(i) = (1-P(stop))\\frac{a^{\\tau}_i}{\\sum_{k}^{N}a^{\\tau}_k}\n \\qquad(12)\\]\n\\(\\tau\\) here shapes the contrast between well-supported and poorly supported items: exponentiating a large activation and a small activation by a large value of \\(\\tau\\) widens the difference between those activations, making recall of the most activated item even more likely. Small values of \\(\\tau\\) can alternatively driven recall likelihoods of differentially activated items toward one another.\nIf an item is recalled, then that item is reactivated on \\(F\\), and its contextual associations retrieved for integration into context again according to:\n\\[\nc^{IN}_{i} = M^{FC}f_{i}\n \\qquad(13)\\]\nContext is updated again based on this input (using \\(\\beta_{rec}\\) instead of \\(\\beta_{enc}\\)) and used to cue a successive recall attempt. This process continues until recall stops."
  },
  {
    "objectID": "projects\\Instance_CMR\\paper\\02_Instance_CMR.html#context-maintenance-and-retrieval-within-an-instance-based-architecture",
    "href": "projects\\Instance_CMR\\paper\\02_Instance_CMR.html#context-maintenance-and-retrieval-within-an-instance-based-architecture",
    "title": "compmemlearn",
    "section": "Context Maintenance and Retrieval within an Instance-Based Architecture",
    "text": "from compmemlearn.models import Instance_CMR\nPrototype-based implementations of the retrieved context account of memory search generally suppose that learned item and contextual associations are encoded into abstractive prototype representations according to a Hebbian learning process and then retrieved based on activation from a cue. The memory architecture investigated in this paper alternatively supposes that learning episodes are stored as discrete instances in memory and only abstracted over at retrieval. Within previous examples of this architecture [e.g., @hintzman1984minerva; @jamieson2018instance], stored instances are represented as vectors stacked within a \\(m\\) by \\(n\\) memory matrix \\(M\\). In model variations where vectors are not composed of binary values, at retrieval each trace is activated in parallel based on a positively accelerated transformation of its cosine similarity to a probe \\(p\\):\n\\[\na(p)_i = \\left({\\frac {\\sum^{j=n}_{j=1}{p_j \\times M_{ij}}} {\\sqrt{\\sum^{j=n}_{j=1}{p^2_j}}\n        \\sqrt{\\sum^{j=n}_{j=1}{M^2_{ij}}}}}\\right)^{\\tau}\n \\qquad(1)\\]\nWithin this architecture, the parameter \\(\\tau\\) exponentially scales this acceleration, effectively controlling the selectivity of retrieval by modulating the difference in activations between highly and less relevant traces. A sum of stored traces weighted by these nonlinearly scaled activations – called an echo, \\(E(p)\\), is taken to build an abstractive representation for retrieval:\n\\[\nE(p) = \\sum^{i=m}_{i=1}\\sum^{j=n}_{j=1}a(p)_i \\times M_{ij}\n \\qquad(2)\\]\nOur instance-based implementation of the context maintenance and retrieval model (InstanceCMR) realizes the retrieved context account of memory search [as articulated by @morton2016predictive] by extending this instance-based architecture to capture how retrieved context theory avers that item and temporal contextual associations evolve and organize retrieval. To make comparison of architectures as straightforward as possible, mechanisms were deliberately specified to be as similar to those of the original prototypical specification as possible except where required by the constraints of the instance-based architecture.\n\nParameters and structures specifying InstanceCMR\n\n\n\n\n\n\n\n\nStructure Type\nSymbol\nName\nDescription\n\n\n\n\nArchitecture\n\n\n\n\n\n\n\\(M\\)\nmemory\nArray of accumulated memory traces\n\n\n\n\\(C\\)\ntemporal context\nA recency-weighted average of encoded items\n\n\n\n\\(F\\)\nitem features\nCurrent pattern of item feature unit activations\n\n\nContext Updating\n\n\n\n\n\n\n\\({\\beta}_{enc}\\)\nencoding drift rate\nRate of context drift during item encoding\n\n\n\n\\({\\beta}_{start}\\)\nstart drift rate\nAmount of start-list context retrieved at start of recall\n\n\n\n\\({\\beta}_{rec}\\)\nrecall drift rate\nRate of context drift during recall\n\n\nAssociative Structure\n\n\n\n\n\n\n\\({\\alpha}\\)\nshared support\nAmount of support items initially have for one another\n\n\n\n\\({\\delta}\\)\nitem support\nInitial pre-experimental contextual self-associations\n\n\n\n\\({\\gamma}\\)\nlearning rate\nAmount of experimental context retrieved by a recalled item\n\n\n\n\\({\\phi}_{s}\\)\nprimacy scale\nScaling of primacy gradient on trace activations\n\n\n\n\\({\\phi}_{d}\\)\nprimacy decay\nRate of decay of primacy gradient\n\n\nRetrieval Dynamics\n\n\n\n\n\n\n\\({\\tau}\\)\nchoice sensitivity\nExponential weighting of similarity-driven activation\n\n\n\n\\({\\theta}_{s}\\)\nstop probability scale\nScaling of the stop probability over output position\n\n\n\n\\({\\theta}_{r}\\)\nstop probability growth\nRate of increase in stop probability over output position\n\n\n\n\nModel Architecture\nPrototypical CMR stores associations between item feature representations (represented a pattern of weights in an item layer \\(F\\)) and temporal context (represented in a contextual layer \\(C\\)) by integrating prototypical mappings between the representations via Hebbian learning over the course of encoding. In contrast, InstanceCMR tracks the history of interactions between context and item features by storing a discrete record of each experience, even repeated ones, as separate traces within in a memory store for later inspection. Memory for each experience is encoded as a separate row in an \\(m\\) by \\(n\\) memory matrix \\(M\\) where rows correspond to memory traces and columns correspond to features. Each trace representing a pairing \\(i\\) of a presented item’s features \\(f_i\\) and the temporal context of its presentation \\(c_i\\) is encoded as a concatenated vector:\n\\[\nM_i = (f_i, c_i)\n \\qquad(3)\\]\n\n\nInitial State\nStructuring \\(M\\) as a stack of concatenated item and contextual feature vectors \\((f_i, c_i)\\) makes it possible to define pre-experimental associations between items and contextual states similarly to the pattern by which PrototypeCMR’s pre-experimental associations are specified in equations ?@eq-1 and ?@eq-2. To set pre-experimental associations, a trace is encoded into memory \\(M\\) for each relevant item. Each entry \\(j\\) for each item feature component of pre-experimental memory traces trace \\(f_{pre}(i)\\) is set according to\n\\[\nf_{pre(i, j)} = \\begin{cases} \\begin{alignedat}{2} 1 - \\gamma \\text{, if } i=j \\\\\\\n          0 \\text{, if } i \\neq j\n       \\end{alignedat} \\end{cases}\n \\qquad(4)\\]\nThis has the effect of relating each unit on \\(F\\) to a unique unit on \\(C\\) during retrieval. As within prototypical CMR, the \\(\\gamma\\) parameter controls the strength of these pre-experimental associations relative to experimental associations.\nSimilarly to control pre-experimental context-to-item associations, the content of each entry \\(j\\) for the contextual component of each pre-experimental trace \\(c_{pre(i,j)}\\) is set by:\n\\[\nc_{pre(i,j)} = \\begin{cases} \\begin{alignedat}{2} \\delta \\text{, if } i=j \\\\\\\n          \\alpha \\text{, if } i \\neq j\n       \\end{alignedat} \\end{cases}\n \\qquad(5)\\]\nHere, \\(\\delta\\) works similarly to \\(\\gamma\\) to connect indices on \\(C\\) to the corresponding index on \\(F\\) during retrieval from a partial or mixed cue. The \\(\\alpha\\) parameter additionally allows all the items to support one another in the recall competition in a uniform manner.\nBefore list-learning, context \\(C\\) is initialized with a state orthogonal to the pre-experimental context associated with the set of items via the extra index that the representation vector has relative to items’ feature vectors. Following the convention established for prototypical specifications of CMR, item features are further assumed to be orthonormal with respect to one another such that each unique unit on \\(F\\) corresponds to one item."
  },
  {
    "objectID": "projects\\Instance_CMR\\paper\\02_Instance_CMR.html#encoding-phase",
    "href": "projects\\Instance_CMR\\paper\\02_Instance_CMR.html#encoding-phase",
    "title": "compmemlearn",
    "section": "Encoding Phase",
    "text": "In a broad sense, the initial steps of item encoding within InstanceCMR proceed similarly to the process in PrototypeCMR. Just as with PrototypeCMR, when an item \\(i\\) is presented during the study period, its corresponding feature representation \\(f_i\\) is activated on \\(F\\) and its contextual associations encoded into \\(M^{FC}\\) are retrieved by presenting \\(f_i\\) as a probe to memory. InstanceCMR, however, performs retrieval by applying an extension of the basic two-step echo \\(E\\) mechanism outlined in equations 1 and 2.\nThe extension of the original mechanism differentiates between item- and context-based retrieval. When probes include item feature information (\\(p_f \\neq 0\\)), activation for traces encoded during the experiment are modulated by \\(\\gamma\\) to control the contribution of experimentally-accumulated associations to retrieved representations relative to pre-experimental associations:\n\\[\n(, c^{IN}) = E(f_i, 0) = \\sum^{j=m}_{j=1}\\sum^{k=n}_{k=1} {\\gamma} \\times a(f_i, 0)_j \\times M_{jk}\n \\qquad(6)\\]\nThe contextual features of the retrieved echo determine contextual input; this retrieved pre-experimental context is normalized to have length 1. Upon retrieval of \\(c^{IN}\\), the current state of context is updated the same way as it is under the prototype-based framework, applying equations ?@eq-4 and ?@eq-5 to drift \\(c\\) toward \\(c^{IN}\\) and enforce its length to 1, respectively.\nAfter context is updated, the current item \\(f_i\\) and the current state of context \\(c_i\\) become associated in memory \\(M\\) by storing a concatenation of the two vectors as a new trace \\((f_i, c_i)\\). This mechanism reserves abstraction over learning episodes for cue-based retrieval rather than at the point of encoding as in PrototypeCMR.\n\nRetrieval Phase\nFollowing the lead of the classic prototype-based implementation of CMR, before retrieval InstanceCMR reinstates some pre-list context according to ?@eq-9. Similarly, at each recall attempt \\(i\\), we calculate the probability of stopping recall (where no item is recalled and search is terminated) based on output position according to ?@eq-11.\nTo determine the probability of recalling an item given that recall does not terminate, first the current state of context is applied as a retrieval cue to retrieve an item feature presentation \\(f_{rec}\\), again applying a modification of the echo-based retrieval mechanism characteristic of instance-based models that modulates trace activations before aggregation into an echo representation:\n\\[\n(f_{rec},) = E(0, c_i) = \\sum^{j=m}_{j=1}\\sum^{k=n}_{k=1} {\\phi}_j \\times a(0, c_i)_j \\times M_{jk}\n \\qquad(7)\\]\nwhere \\({\\phi}_i\\) scales the amount of learning, simulating increased attention to initial items in a list that has been proposed to explain the primacy effect. \\({\\phi}_i\\) depends on the serial position \\(i\\) of the studied item the same as it does in PrototypeCMR (equation ?@eq-8), with the free parameters \\({\\phi}_s\\) and \\({\\phi}_d\\) respectively controlling the magnitude and decay of the corresponding learning-rate gradient.\nSince item feature representations are presumed to be orthogonal for the purposes of the model, the content of \\(f_{rec}\\) can be interpreted as a measure of the relative support in memory for retrieval of each item \\(i\\), setting the probability distribution of item recalls \\(P(i)\\) to\n\\[\nP(i) = (1-P(stop))\\frac{f_{rec}}{\\sum_{k}^{N}f_{rec}}\n \\qquad(8)\\]\nIf an item is recalled, then that item is reactivated on \\(F\\), and its contextual associations retrieved for integration into context again according to Eq. 6. Context is updated again based on this input (using \\(\\beta_{rec}\\) instead of \\(\\beta_{enc}\\)) and used to cue a successive recall attempt. This process continues until recall stops.\nAn important difference between equation 8 and that applied in our specification of PrototypeCMR to compute \\(P(i)\\) (equation ?@eq-12) is that \\(\\tau\\) is not applied as an exponent to retrieval supports to shape the contrast between well-supported and poorly supported items. Instead, instance-based models apply this transformation to discrete trace activations before aggregation of an echo representation. This difference still achieves the effect of ultimately either widening or shrinking the difference between item supports driving retrieval, but is not trivial. Its consequences are explored in later sections."
  },
  {
    "objectID": "projects\\Instance_CMR\\paper\\03_Methods.html#analysis-approach",
    "href": "projects\\Instance_CMR\\paper\\03_Methods.html#analysis-approach",
    "title": "compmemlearn",
    "section": "Analysis Approach",
    "text": "Our simulation analyses were designed to determine whether instance-based and prototype-based instantiations of CMR can similarly account for behavioral performance in the free recall task. This includes key benchmark phenomena such as the temporal contiguity and serial position effects, as well as for the overall sequence of responses generated by participants. We used a likelihood-based model comparison technique introduced by @kragel2015neural that assesses model variants based on how accurately they can predict the specific sequence in which items were recalled. For each model, we related this technique with an optimization technique called differential evolution [@storn1997differential] to search for the parameter configuration that maximize the likelihood of the considered data. Likelihoods assigned to datasets by models and their respective optimized parameters in turn support comparison of their effectiveness accounting for the recall sequences exhibited by participants in the data. Visualization of datasets compared to those of simulation outputs given these models with these parameters similarly help compare how well models realize temporal contiguity and serial position effects.\n\nLikelihood-based model comparison\nTo evaluate how effectively each model accounts for the responses in our datasets, we applied a likelihood-based model comparison technique introduced by @kragel2015neural that assesses model variants based on how accurately they can predict the specific sequence in which items are recalled. According to this method, repeated items and intrusions (responses naming items not presented in the list) are included from participants’ recall sequences. Given an arbitrary parameter configuration and a sequences of recalls to predict, a model simulates encoding of each item presented in the corresponding study list in its respective order. Then, beginning with the first item the participant recalled in the trial, the probability assigned by the model to the recall event is recorded. Next, the model simulates retrieval of that item, and given its updated state is used to similarly predict the next event in the recall sequence - either retrieval of another item, or termination of recall - and so on until retrieval terminates. The probability that the model assigns to each event in the recall sequence conditional on previous trial events are thus all recorded. These recorded probabilities are then log-transformed and summed to obtain the log-likelihood of the entire sequence. Across an entire dataset containing multiple trials, sequence log-likelihoods can be summed to obtain a log-likelihood of the entire dataset given the model and its parameters. Higher log-likelihoods assigned to datasets by a model correspond to better effectiveness accounting for those datasets.\n\n\nParameter Optimization\nTo find the parameter configuration for each model that maximizes its predicted likelihood of observed data, we applied the optimization technique called differential evolution [@storn1997differential] as implemented in the Python library scipy. Differential evolution maintains a population of possible parameter configurations; at each update, the algorithm mutates each population member by stochastically mixing them with other members of the population. If the new configuration of a member is an improvement over its previous configuration, then it becomes part of the updated population. Otherwise, the new parameter configuration is discarded. Through repetition of this process, gradually driving the population toward configurations that maximize the log-likelihood of the observed data assigned by the considered model. This maximal log-likelihood and its corresponding parameter configurations form the basis of comparison between models.\nWhen exploring how effectively the model accounts for qualitative benchmark phenomena in free recall performance such as the temporal contiguity and serial position effects, we optimized parameter configurations and evaluated performance across all subjects in the considered dataset, except where otherwise noted. For direct comparison of the log-likelihoods of recall sequences, however, we search for optimal parameters and perform comparison at the subject level, considering distributions of log-likelihood values calculated between subjects when contrasting model versions.\n\n\nSummary Statistics\nIn each comparison, we use and visualize a set of summary statistics to characterize the the recall performance of both participants and of each considered model version. To make calculation of these summary statistics with respect to a model possible, we first had to simulate recall sequences using each model. We simulated 1000 unique trials for each unique study list in a considered dataset. For each trial, we simulated encoding of each list item into memory. Next, we simulated free recall according to model specifications outlined above, proceeding stochastically in ecah trial based on the probability distribution computed for each recall attempt until termination. Summary statistics characterizing a model were computed across all relevant simulations.\nOur main analyses focus on the three consistent regularities across experiments reviewed above that have received especial emphasis in accounts of performance on the free recall task. To examine the extent to which datasets and model versions realize the serial position effect, we measured and visualized for each study (serial) position in study lists the rate at which items were retrieved across recall sequences. Relative retrieval rates for early-presented items reflect the magnitude of any primacy effect, while those for items in more terminal study positions measure the recency effect. To measure items retrieved at the initiation of recall across trials, we similarly measured and visualized for each serial position in study lists the rate at which items were retrieved first across each recall sequence.\nWe were similarly interested in the extent to which temporal contiguity where items studied at nearby serial positions tend to be recalled near one another at the retrieval phase of an experiment – was exhibited across recall sequences in our considered datasets and models. To quantify this pattern, we followed the tradition of applying lag-based condition response probability (lag-CRP) analyses. Here, “lag” refers to the number of positions between two item presentations in a study list. Lag-CRP analyses measure the probability of making a recall transition of a particular positive or negative lag, conditional on transition to recall at that lag being possible. Under high temporal contiguity, recall transitions are largely to items with low lag from the last retrieved item and more rarely to items with high lag. Examining conditional response probabilities as a function of lag thus helps characterize the temporal organization of recall across trials."
  },
  {
    "objectID": "projects\\Instance_CMR\\paper\\04_Baseline_Comparison.html#simulation-of-murdock-and-okada-1970",
    "href": "projects\\Instance_CMR\\paper\\04_Baseline_Comparison.html#simulation-of-murdock-and-okada-1970",
    "title": "compmemlearn",
    "section": "Simulation of Murdock and Okada (1970)",
    "text": "We start by comparing how our prototype- and instance-based implementations of CMR account for behavior in a classic experiment where each item is presented just once per study phase. For these simulations, we used the dataset reported by @murdock1970interresponse. Each of 72 undergraduates performed 20 trials with study lists each consisting of 20 unique words visually presented at either 60 or 120 words per minute. Given a particular subject, words were unique both within and across trials, and randomly selected from the Toronto Word Pool [@friendly1982toronto], a widely-used collection of high frequency nouns, adjectives, and verbs.\nWhile the major focus of the original report by @murdock1970interresponse was to investigate inter-response times in single-trial free recall, here we focus consideration on the content of recorded recall sequences. Because it excludes within-list repetitions of studied items, this dataset presents the opportunity to compare model performance under simplified conditions. Since items’ feature representations are assumed orthogonal under considered variants of CMR, retrieving a pattern of contextual associations given an item-based cue only requires abstraction over the cued item’s pre-experimental and single experimental contextual associations. Interpretation of apparent differences in performance across model variants thus focus primarily on mechanisms for context-based item representation retrieval.\nfrom compmemlearn.fitting import murdock_objective_function, apply_and_concatenate\nfrom compmemlearn.models import Classic_CMR, Instance_CMR\nfrom compmemlearn.datasets import prepare_murdock1970_data, simulate_data\nfrom scipy.optimize import differential_evolution\nfrom numba.typed import List, Dict\nfrom numba.core import types\nfrom numba import njit\nfrom psifr import fr\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nmurd_trials0, murd_events0, murd_length0 = prepare_murdock1970_data('../../data/mo1970.txt')\nWe compared the original prototype-based implementation of CMR against our novel instance-based implementation. First we evaluated each model variant based on their ability to predict the specific sequences of recalls exhibited by each participant. Considering all 20 trials performed by each participant in the dataset, we applied the differential evolution optimization technique to find for each model the parameter configuration that maximized the likelihood of recorded recall sequences. We obtained a unique optimal parameter configuration for each unique participant and each considered model variant. To measure the goodness-of-fit for each parameter configuration and corresponding model, Figure 1 plots the log-likelihood of each participant’s recall sequences given each model variant’s corresponding optimized parameter configuration. The distribution of log-likelihood scores between participants for the PrototypeCMR and InstanceCMR model variants only marginally differ, suggesting little meaningful difference between variants in their effectiveness accounting for participant recall performance across the dataset.\n\ncmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate'\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ncmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\nsubject_trial_count = 20 # Each subject gets 20 trials/lists a piece.\ncmr_results = []\n\nfor subject, start_index in enumerate(range(0, len(murd_trials0), subject_trial_count)):\n    print(subject, start_index)\n\n    # cost function to be minimized\n    # ours scales inversely with the probability that the data could have been \n    # generated using the specified parameters and our model\n    cost_function = murdock_objective_function(\n        List([murd_trials0[start_index:start_index+subject_trial_count]]), \n        List([murd_length0]),\n        init_cmr,\n        {'sampling_rule': 0, 'mfc_familiarity_scale': 0, \n         'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n        cmr_free_parameters)\n\n    cmr_results.append(differential_evolution(cost_function, cmr_bounds, disp=False))\n    print(cmr_results[-1].fun)\n\n\nicmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n    'context_sensitivity',\n#    'feature_sensitivity'\n    'delay_drift_rate',\n)\n\nicmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n#    (lb, 10),\n#    (lb, 10)\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_icmr(item_count, presentation_count, parameters):\n    return Instance_CMR(item_count, presentation_count, parameters)\n\nsubject_trial_count = 20 # Each subject gets 20 trials/lists a piece.\nicmr_results = []\n\nfor subject, start_index in enumerate(range(0, len(murd_trials0), subject_trial_count)):\n    print(subject, start_index)\n\n    # cost function to be minimized\n    # ours scales inversely with the probability that the data could have been \n    # generated using the specified parameters and our model\n    cost_function = murdock_objective_function(\n    List([murd_trials0[start_index:start_index+subject_trial_count]]),  \n    List([murd_length0]),\n    init_icmr,\n    {'choice_sensitivity': 1, 'feature_sensitivity': 1}, \n    icmr_free_parameters)\n\n    icmr_results.append(differential_evolution(cost_function, icmr_bounds, disp=False))\n    print(icmr_results[-1].fun)\n\n\nplt.style.use('default')\n\nindividual_fits = [result.fun for result in cmr_results] + [result.fun for result in icmr_results]\nlabels = ['PrototypeCMR'] * len(cmr_results) + ['InstanceCMR'] * len(icmr_results)\nindividual_df = pd.DataFrame(individual_fits, index=labels, columns=['Fit']).reset_index()\nindividual_df.columns = ['Model', 'Fit']\n\nsns.set(style=\"darkgrid\")\n\ng = sns.catplot(x='Model', y='Fit', data=individual_df, kind='violin', inner='stick')\nsns.swarmplot(x=\"Model\", y=\"Fit\", color=\"k\", size=3, data=individual_df, ax=g.ax)\ng.ax.set_ylabel('Individual-Level Fitted Model Log-Likelihoods');\nplt.savefig('individual_murdock1970.pdf', bbox_inches=\"tight\")\n\nsummary_table = pd.DataFrame(group.describe().rename(columns={'Fit':name}).squeeze()\n            for name, group in individual_df.groupby('Model')).T.to_markdown()\n\n\n\n\n\nprint(summary_table)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstanceCMR\nPrototypeCMR\n\n\n\n\ncount\n72\n72\n\n\nmean\n297.128\n296.249\n\n\nstd\n52.7989\n52.8859\n\n\nmin\n156.753\n150.988\n\n\n25%\n258.206\n260.956\n\n\n50%\n299.741\n299.763\n\n\n75%\n331.797\n331.946\n\n\nmax\n387.742\n390.806\n\n\n\n\n\nFigure 1: Distribution of log-likelihood scores of recall sequences exhibited by each subject under each considered model across list-lengths [@murdock1970interresponse]\n\n\nAs a follow-up, we also compared how readily each model could account for organizational summary statistics in the dataset. We found for each model variant the optimal parameter configuration maximizing the likelihood of the entire dataset rather than participant-by-participant. Using each fitted model variant, we simulated 1000 unique free recall trials and measured summary statistics from the result. Figure 2 plots for each model against the corresponding statistics collected over the dataset how recall probability varies as a function of serial position, how the probability of recalling an item first varies as a function of serial position, and how the conditional recall probabability of an item varies as a function of its serial lag from the previously recalled item. Recapitulating our comparison of log-likelihood distributions fitted over discrete participants, we found that both our prototype-based and instance-based CMR implementations account for these benchmark organizational summary statistics across the full dataset to similar extents. To build on this finding of broad model equivalence with respect to the results reported by @murdock1970interresponse, we consider the model variants under broader experimental conditions.\n\ncost_function = murdock_objective_function(\n    List([murd_trials0]),  \n    List([murd_length0]),\n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, \n     'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    cmr_free_parameters)\n\ncmr_result = differential_evolution(cost_function, cmr_bounds, disp=True)\n\n\ncost_function = murdock_objective_function(\n    List([murd_trials0]),  \n    List([murd_length0]),\n    init_icmr,\n    {'choice_sensitivity': 1, 'feature_sensitivity': 1}, \n    icmr_free_parameters)\n\nicmr_result = differential_evolution(cost_function, icmr_bounds, disp=True)\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(cmr_result.x)):\n    fitted_parameters[cmr_free_parameters[i]] = cmr_result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nmodel = Classic_CMR(murd_length0, murd_length0, fitted_parameters)\n\nsim_df = simulate_data(model, 1000)\ntrue_df = murd_events0.copy()\n\ncmr_spc = apply_and_concatenate(fr.spc, sim_df, true_df, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp = apply_and_concatenate(fr.lag_crp, sim_df, true_df, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr = apply_and_concatenate(fr.pnr, sim_df, true_df, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr = cmr_pfr.query('output <= 1')\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(icmr_result.x)):\n    fitted_parameters[icmr_free_parameters[i]] = icmr_result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['choice_sensitivity'] = 1\nfitted_parameters['feature_sensitivity'] = 1\n\nmodel = Instance_CMR(murd_length0, murd_length0, fitted_parameters)\n\nsim_df = simulate_data(model, 1000)\nicmr_spc = apply_and_concatenate(fr.spc, sim_df, true_df, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_lag_crp = apply_and_concatenate(fr.lag_crp, sim_df, true_df, 'source', ['InstanceCMR', 'data'])\nicmr_pfr = apply_and_concatenate(fr.pnr, sim_df, true_df, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_pfr = icmr_pfr.query('output <= 1')\n\nimport matplotlib.pyplot as plt\n\nsns.set(style='darkgrid')\n\nfig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 15/2), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0, 0], data=icmr_spc, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0, 0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0, 0].set_xticks(np.arange(1, 21, 2))\naxes[0, 0].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[1, 0], data=cmr_spc, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[1, 0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[1, 0].set_xticks(np.arange(1, 21, 2))\naxes[1, 0].set_ylim((0, 1))\n\n# lag crp curve\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[0, 1], data=icmr_lag_crp.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[0, 1], data=icmr_lag_crp.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[0, 1].set(xlabel='Item\\'s Lag In Study List From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[0, 1].set_xticks(np.arange(-5, 6, 1))\naxes[0, 1].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[1, 1], data=cmr_lag_crp.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1, 1], data=cmr_lag_crp.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1, 1].set(xlabel='Item\\'s Lag In Study List From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1, 1].set_xticks(np.arange(-5, 6, 1))\naxes[1, 1].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=icmr_pfr, x='input', y='prob', err_style='bars', ax=axes[0, 2], hue='source')\naxes[0, 2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[0, 2].set_xticks(np.arange(1, 21, 2))\naxes[0, 2].set_ylim((0, 1))\n\nsns.lineplot(data=cmr_pfr, x='input', y='prob', err_style='bars', ax=axes[1, 2], hue='source')\naxes[1, 2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[1, 2].set_xticks(np.arange(1, 21, 2))\naxes[1, 2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[0, 2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\naxes[1, 2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\nplt.tight_layout(pad=3)\nplt.savefig('overall_murdock1970.pdf', bbox_inches='tight')\n\n\n\n\n\n\n\nFigure 2: Comparison of summary statistics between each model against observed data [@murdock1970interresponse]"
  },
  {
    "objectID": "projects\\Instance_CMR\\paper\\05_Variable_List_Lengths.html#simulation-of-murdock-jr-1962",
    "href": "projects\\Instance_CMR\\paper\\05_Variable_List_Lengths.html#simulation-of-murdock-jr-1962",
    "title": "compmemlearn",
    "section": "Simulation of Murdock Jr (1962)",
    "text": "A significant feature of the context maintenance and retrieval (CMR) model is its capacity to account for the relative scale-invariance of serial position effects with respect to list length. @murdock1962serial found that changing list lengths across trials in a free recall experiment impacted neither the shape of observed primacy effects during recall nor on the slope of apparent recency effects, though other features of recall sequences did change, such as the overall retrieval probability for initially encoded items as well as the list-list asymptote. Building on these observations, @polyn2009context found that the CMR model could account for these effects of list length on the shape of the serial position curve in free recall using a single parameter configuration.\nHere we investigate whether our prototype- and instance-based implementations of CMR can similarly account for recall performance across different list lengths when fitted to predict the sequences of items recalled in our considered dataset. For these comparisons, we leverage a subset of the original behavioral data reported by @murdock1962serial. In the considered subset, 15 subjects performed 240 trials with study lists each consisting of either 20, 30, or 40 unique words presented sequentially – 80 trials per list length.\nfrom compmemlearn.fitting import murdock_objective_function, apply_and_concatenate\nfrom compmemlearn.datasets import prepare_murdock1962_data, simulate_data\nfrom compmemlearn.models import Classic_CMR, Instance_CMR\nfrom scipy.optimize import differential_evolution\nfrom numba.typed import List, Dict\nimport matplotlib.pyplot as plt\nfrom numba.core import types\nfrom numba import njit\nimport seaborn as sns\nfrom psifr import fr\nimport pandas as pd\nimport numpy as np\n\nmurd_trials0, murd_events0, murd_length0 = prepare_murdock1962_data(\n    '../../data/MurdData_clean.mat', 0)\nmurd_trials1, murd_events1, murd_length1 = prepare_murdock1962_data(\n    '../../data/MurdData_clean.mat', 1)\nmurd_trials2, murd_events2, murd_length2 = prepare_murdock1962_data(\n    '../../data/MurdData_clean.mat', 2)\nFor each model variant and each participant, we found through differential evolution optimization the parameter configuration maximizing the likelihood assigned by the model to each recall sequence in all relevant trials, whether with list length of 20 or 30 or 40. The log-likelihoods of the data corresponding to each participant and model variant are plotted in Figure 1, with a table providing summary statistics. The distribution of log-likelihood scores between participants for the PrototypeCMR and InstanceCMR model variants only marginally differ, suggesting little meaningful difference between variants in their effectiveness predicting recall sequences, even when using a single parameter configuration per participant to account for performance across variable list lengths.\n\ncmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate'\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ncmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\nsubject_trial_count = 80 # Each subject gets 80 trials/lists a piece.\nindividual_cmr_results = []\n\nfor subject, start_index in enumerate(range(0, len(murd_trials0), subject_trial_count)):\n    print(subject, start_index)\n\n    # cost function to be minimized\n    # ours scales inversely with the probability that the data could have been \n    # generated using the specified parameters and our model\n    cost_function = murdock_objective_function(\n        List([murd_trials0[start_index:start_index+subject_trial_count], \n              murd_trials1[start_index:start_index+subject_trial_count], \n              murd_trials2[start_index:start_index+subject_trial_count]]), \n        List([murd_length0, murd_length1, murd_length2]),\n        init_cmr,\n        {'sampling_rule': 0, 'mfc_familiarity_scale': 0, \n         'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n        cmr_free_parameters)\n\n    individual_cmr_results.append(differential_evolution(cost_function, cmr_bounds, disp=False))\n    print(individual_cmr_results[-1].fun)\n\n\nicmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n#    'feature_sensitivity',\n    'context_sensitivity',\n    'delay_drift_rate',\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nicmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n#    (lb, 10),\n#    (lb, 10)\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_icmr(item_count, presentation_count, parameters):\n    return Instance_CMR(item_count, presentation_count, parameters)\n\nsubject_trial_count = 80 # Each subject gets 20 trials/lists a piece.\nindividual_icmr_results = []\n\nfor subject, start_index in enumerate(range(0, len(murd_trials0), subject_trial_count)):\n    print(subject, start_index)\n\n    # cost function to be minimized\n    # ours scales inversely with the probability that the data could have been \n    # generated using the specified parameters and our model\n    cost_function = murdock_objective_function(\n    List([murd_trials0[start_index:start_index+subject_trial_count], \n        murd_trials1[start_index:start_index+subject_trial_count], \n        murd_trials2[start_index:start_index+subject_trial_count]]),  \n    List([murd_length0, murd_length1, murd_length2]),\n    init_icmr,\n    {'choice_sensitivity':1, 'feature_sensitivity': 1}, \n    icmr_free_parameters)\n\n    individual_icmr_results.append(differential_evolution(\n        cost_function, icmr_bounds, disp=False))\n    print(individual_icmr_results[-1].fun)\n\n\nplt.style.use('default')\n\nindividual_fits = [result.fun for result in individual_icmr_results] + [result.fun for result in individual_cmr_results]\nlabels = ['InstanceCMR'] * len(individual_icmr_results) + ['PrototypeCMR'] * len(individual_cmr_results)\nindividual_df = pd.DataFrame(individual_fits, index=labels, columns=['Fit']).reset_index()\nindividual_df.columns = ['Model', 'Fit']\n\nsns.set(style=\"darkgrid\")\n\ng = sns.catplot(x='Model', y='Fit', data=individual_df, kind='violin', inner='stick')\nsns.swarmplot(x=\"Model\", y=\"Fit\", color=\"k\", size=3, data=individual_df, ax=g.ax)\ng.ax.set_ylabel('Individual-Level Fitted Model Log-Likelihoods');\nplt.savefig('individual_murdock1962.pdf', bbox_inches=\"tight\")\nplt.show()\n\nsummary_table = pd.DataFrame(group.describe().rename(columns={'Fit':name}).squeeze()\n            for name, group in individual_df.groupby('Model')).T.to_markdown()\n\n\n\n\nfrom IPython.display import display, Markdown\n\ndisplay(Markdown(\"\"\"\n::: {{#fig-murd62fits layout-ncol=2 layout-valign=\"center\"}}\n\n![](individual_murdock1962.pdf)\n\n{}\n\nDistribution of log-likelihood scores of recall sequences exhibited by each subject under each considered model across list-lengths [@murdock1962serial]\n:::\n\"\"\".format(summary_table)))\n\n\n\n\n\n\n\n\n\n\n\nInstanceCMR\nPrototypeCMR\n\n\n\n\ncount\n15\n15\n\n\nmean\n5295.34\n5280.07\n\n\nstd\n547.19\n553.484\n\n\nmin\n4464.46\n4387.61\n\n\n25%\n4863.55\n4865.08\n\n\n50%\n5285.28\n5280.25\n\n\n75%\n5619.48\n5592.88\n\n\nmax\n6358.67\n6352.11\n\n\n\n\n\nFigure 1: Distribution of log-likelihood scores of recall sequences exhibited by each subject under each considered model across list-lengths [@murdock1962serial]\n\n\nConsidering log-likelihoods alone though leaves ambiguous whether the influence of list length on serial position and related organizational effects are effectively accounted for by both models. To find out, we again focused scrutiny on the prototype-based and instance-based implementations of CMR. We fit each model based on the likelihood assigned to all recall sequences across the dataset rather than by subject or list length. Summary statistics including recall probability as a function of serial position, probability of first recall as a function of serial position, and conditional recall probability as a function of serial lag from the previously recalled item were computed based on simulation of free recall data using the model variants with their fitted parameters. Separate analyses simulated trials with study list lengths of 20 and of 30 items, with summary statistics tracked separately. Figure 2 plots the results of these simulations against statistics from corresponding subsets of the behavioral data from [@murdock1962serial], with unique sets of plots for both model variants and list lengths. As with previous analyses, we found that both our prototype-based and instance-based CMR implementations account for these benchmark organizational summary statistics across the considered data to similar extents.\n\ncost_function = murdock_objective_function(\n    List([murd_trials0, murd_trials1, murd_trials2]),  \n    List([murd_length0, murd_length1, murd_length2]),\n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, \n     'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    cmr_free_parameters)\n\ncmr_result = differential_evolution(cost_function, cmr_bounds, disp=True)\n\n\ncost_function = murdock_objective_function(\n    List([murd_trials0, murd_trials1, murd_trials2]),  \n    List([murd_length0, murd_length1, murd_length2]),\n    init_icmr,\n    {'feature_sensitivity': 1, 'choice_sensitivity': 1}, \n    icmr_free_parameters)\n\nicmr_result = differential_evolution(cost_function, icmr_bounds, disp=True)\nprint(icmr_result)\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(cmr_result.x)):\n    fitted_parameters[cmr_free_parameters[i]] = cmr_result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nmodel0 = Classic_CMR(murd_length0, murd_length0, fitted_parameters)\nmodel1 = Classic_CMR(murd_length1, murd_length1, fitted_parameters)\nmodel2 = Classic_CMR(murd_length2, murd_length2, fitted_parameters)\n\nsim_df0 = simulate_data(model0, 1000)\nsim_df1 = simulate_data(model1, 1000)\nsim_df2 = simulate_data(model2, 1000)\ntrue_df0 = murd_events0.copy()\ntrue_df1 = murd_events1.copy()\ntrue_df2 = murd_events2.copy()\n\ncmr_spc0 = apply_and_concatenate(fr.spc, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp0 = apply_and_concatenate(fr.lag_crp, sim_df0, true_df0, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr0 = apply_and_concatenate(fr.pnr, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr0 = cmr_pfr0.query('output <= 1')\n\ncmr_spc1 = apply_and_concatenate(fr.spc, sim_df1, true_df1, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp1 = apply_and_concatenate(fr.lag_crp, sim_df1, true_df1, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr1 = apply_and_concatenate(fr.pnr, sim_df1, true_df1, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr1 = cmr_pfr1.query('output <= 1')\n\ncmr_spc2 = apply_and_concatenate(fr.spc, sim_df2, true_df2, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp2 = apply_and_concatenate(fr.lag_crp, sim_df2, true_df2, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr2 = apply_and_concatenate(fr.pnr, sim_df2, true_df2, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr2 = cmr_pfr2.query('output <= 1')\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(icmr_result.x)):\n    fitted_parameters[icmr_free_parameters[i]] = icmr_result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['choice_sensitivity'] = 1\nfitted_parameters['feature_sensitivity'] = 1\n\nmodel0 = Instance_CMR(murd_length0, murd_length0, fitted_parameters)\nmodel1 = Instance_CMR(murd_length1, murd_length1, fitted_parameters)\nmodel2 = Instance_CMR(murd_length2, murd_length2, fitted_parameters)\n\nsim_df0 = simulate_data(model0, 1000)\nsim_df1 = simulate_data(model1, 1000)\nsim_df2 = simulate_data(model2, 1000)\ntrue_df0 = murd_events0.copy()\ntrue_df1 = murd_events1.copy()\ntrue_df2 = murd_events2.copy()\n\nicmr_spc0 = apply_and_concatenate(fr.spc, sim_df0, true_df0, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_lag_crp0 = apply_and_concatenate(fr.lag_crp, sim_df0, true_df0, 'source', ['InstanceCMR', 'data'])\nicmr_pfr0 = apply_and_concatenate(fr.pnr, sim_df0, true_df0, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_pfr0 = icmr_pfr0.query('output <= 1')\n\nicmr_spc1 = apply_and_concatenate(fr.spc, sim_df1, true_df1, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_lag_crp1 = apply_and_concatenate(fr.lag_crp, sim_df1, true_df1, 'source', ['InstanceCMR', 'data'])\nicmr_pfr1 = apply_and_concatenate(fr.pnr, sim_df1, true_df1, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_pfr1 = icmr_pfr1.query('output <= 1')\n\nicmr_spc2 = apply_and_concatenate(fr.spc, sim_df2, true_df2, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_lag_crp2 = apply_and_concatenate(fr.lag_crp, sim_df2, true_df2, 'source', ['InstanceCMR', 'data'])\nicmr_pfr2 = apply_and_concatenate(fr.pnr, sim_df2, true_df2, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_pfr2 = icmr_pfr2.query('output <= 1')\n\nsns.set(style='darkgrid')\n\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 12/1.5), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0, 0], data=icmr_spc0, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0, 0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0, 0].set_xticks(np.arange(1, murd_length0+1, 2))\naxes[0, 0].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[0, 1], data=icmr_spc1, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0, 1].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0, 1].set_xticks(np.arange(1, murd_length1+1, 3))\naxes[0, 1].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[0, 2], data=icmr_spc2, x='input', y='recall', err_style='bars', hue='source', legend=True)\naxes[0, 2].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0, 2].set_xticks(np.arange(1, murd_length2+1, 4))\naxes[0, 2].set_ylim((0, 1))\n\n# lag CRP\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[1, 0], data=icmr_lag_crp0.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1, 0], data=icmr_lag_crp0.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1, 0].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1, 0].set_xticks(np.arange(-5, 6, 1))\naxes[1, 0].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[1, 1], data=icmr_lag_crp1.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1, 1], data=icmr_lag_crp1.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1, 1].set(xlabel=\"Lag From Last Recalled Item\", ylabel='Conditional Recall Rate')\naxes[1, 1].set_xticks(np.arange(-5, 6, 1))\naxes[1, 1].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[1, 2], data=icmr_lag_crp2.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1, 2], data=icmr_lag_crp2.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1, 2].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1, 2].set_xticks(np.arange(-5, 6, 1))\naxes[1, 2].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=icmr_pfr0, x='input', y='prob', err_style='bars', ax=axes[2, 0], hue='source', legend=False)\naxes[2, 0].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2, 0].set_xticks(np.arange(1, murd_length0+1, 2))\naxes[2, 0].set_ylim((0, 1))\n\nsns.lineplot(data=icmr_pfr1, x='input', y='prob', err_style='bars', ax=axes[2, 1], hue='source', legend=False)\naxes[2, 1].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2, 1].set_xticks(np.arange(1, murd_length1+1, 3))\naxes[2, 1].set_ylim((0, 1))\n\nsns.lineplot(data=icmr_pfr2, x='input', y='prob', err_style='bars', ax=axes[2, 2], hue='source', legend=False)\naxes[2, 2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2, 2].set_xticks(np.arange(1, murd_length2+1, 4))\naxes[2, 2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[0, 2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=2)\nplt.savefig('icmr_summary_murdock1962.pdf', bbox_inches=\"tight\")\nplt.show()\n\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 12/1.5), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0, 0], data=cmr_spc0, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0, 0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0, 0].set_xticks(np.arange(1, murd_length0+1, 2))\naxes[0, 0].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[0, 1], data=cmr_spc1, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0, 1].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0, 1].set_xticks(np.arange(1, murd_length1+1, 3))\naxes[0, 1].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[0, 2], data=cmr_spc2, x='input', y='recall', err_style='bars', hue='source', legend=True)\naxes[0, 2].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0, 2].set_xticks(np.arange(1, murd_length2+1, 4))\naxes[0, 2].set_ylim((0, 1))\n\n# lag CRP\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[1, 0], data=cmr_lag_crp0.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1, 0], data=cmr_lag_crp0.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1, 0].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1, 0].set_xticks(np.arange(-5, 6, 1))\naxes[1, 0].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[1, 1], data=cmr_lag_crp1.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1, 1], data=cmr_lag_crp1.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1, 1].set(xlabel=\"Lag From Last Recalled Item\", ylabel='Conditional Recall Rate')\naxes[1, 1].set_xticks(np.arange(-5, 6, 1))\naxes[1, 1].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[1, 2], data=cmr_lag_crp2.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1, 2], data=cmr_lag_crp2.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1, 2].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1, 2].set_xticks(np.arange(-5, 6, 1))\naxes[1, 2].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=cmr_pfr0, x='input', y='prob', err_style='bars', ax=axes[2, 0], hue='source', legend=False)\naxes[2, 0].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2, 0].set_xticks(np.arange(1, murd_length0+1, 2))\naxes[2, 0].set_ylim((0, 1))\n\nsns.lineplot(data=cmr_pfr1, x='input', y='prob', err_style='bars', ax=axes[2, 1], hue='source', legend=False)\naxes[2, 1].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2, 1].set_xticks(np.arange(1, murd_length1+1, 3))\naxes[2, 1].set_ylim((0, 1))\n\nsns.lineplot(data=cmr_pfr2, x='input', y='prob', err_style='bars', ax=axes[2, 2], hue='source', legend=False)\naxes[2, 2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2, 2].set_xticks(np.arange(1, murd_length2+1, 4))\naxes[2, 2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[0, 2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=2)\nplt.savefig('cmr_summary_murdock1962.pdf', bbox_inches=\"tight\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) PrototypeCMR\n\n\n\n\n\n\n\n\n\n(b) InstanceCMR\n\n\n\n\nFigure 2: Comparison of summary statistics between each model against observed data [@murdock1962serial]"
  },
  {
    "objectID": "projects\\Instance_CMR\\paper\\06_Item_Repetitions.html#repetition-effects",
    "href": "projects\\Instance_CMR\\paper\\06_Item_Repetitions.html#repetition-effects",
    "title": "compmemlearn",
    "section": "Repetition Effects",
    "text": "While previous analyses evince that our prototype-based and instance-based implementations of CMR equivalently account for free recall performance when each unique item is presented just once during study, there is reason to suspect that the models might diverge when it comes to accounting for the effect of item repetition on later free recall.\nPrevious work [@siegel2014retrieved] has related CMR to two broad accounts of how item repetition influences memory and in particular drives the spacing effect, a monotonic relationship between recall probability and the size of the lag between item repetitions in a study list. Under the contextual-variability account [@anderson1972recognition], each time an item is studied, it’s associated in memory with the current state of a slowly drifting contextual representation. Depending on how spaced apart two presentations of an item might be, the contextual states they are associated with might either be very similar or very distinct. Later, participants use the current state of their contextual representation to probe their memories and retrieve items during free recall. When an item has been associated with diverse contextual states, it can correspondingly be retrieved using diverse possible cues. In this way, the improvements in recall we gain from spacing presentations of an item are explained in terms of variation in the range of possible cues that can trigger recall of that item. A study-phase retrieval account of the spacing effect alternatively emphasizes the consequences of studying a successively presented item. According to the account, when this happens we retrieve memories of the repeated item’s earlier occurrences and their associated contexts. When this happens, it’s proposed that retrieved information is memorally associated with information corresponding to the current presentation context.\nAnalyses of our instance-based implementation of CMR so far suggest it realizes these mechanisms similarly to the original prototype-based CMR. A potentially more relevant distinction between the models might instead turn on differences in how records of past experience are integrated for retrieval. InstanceCMR, like MINERVA 2, has the option to apply its nonlinear activation scaling parameter \\(\\tau\\) to activations of individual traces - that is, before integration into a unitary vector tracking retrieval support. However, CMR does not access trace activations and applies \\(\\tau\\) to the integrated echo representation result.\nThis distinction between instance-based and prototype-based architectures has been marshalled to explain model differences in other research contexts [e.g., @jamieson2018instance]. In this context, however, the different between applying \\(\\tau\\) to trace activations or echo content is between enforcing quasi-linear or quasi-exponential effect of item repetition on subsequent recall probability. Suppose a constant sensitivity parameter \\(\\tau\\) and that two distinct experiences each contributed a support of \\(c\\) for a given feature unit in the current recall. Under trace-based sensitivity scaling, the retrieval support for that feature unit would be \\(c^{\\tau} + c^{\\tau}\\). But under echo-based sensitivity scaling, support would be \\({(c + c)}^{\\tau}\\), a much larger quantity.\nAnother way to illustrate this architectural difference is by simulation. We can have our prototype-based and each variant of our instance-based implementation of CMR simulate a traditional list-learning experiment with study of 20 unique items in order. Then, we can simulate repeated study of an arbitrary item in that list and measure the effect on the probability of retrieving that item for each successive repetition given a static retrieval cue. Figure 1 plots the result of of this simulation over 1000 experiments for 50 item repetitions using PrototypeCMR and InstanceCMRand model parameters fitted using data from @murdock1970interresponse and corresponds with our predictions. Model fitting over a different dataset might obviate these observed differences; however these simulations raise the possibility that with increasing item repetitions, prototype-based and instance-based implementations of CMR might support different predictions about the influence of item repetition on later recall probability, motivating further investigation.\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom numba.typed import Dict\nfrom numba.core import types\nfrom compmemlearn.models import Classic_CMR, Instance_CMR\nimport seaborn as sns\nsns.set(style='darkgrid')\n\nexperiment_count = 1000\nitem_count = 20\npresentation_count = 70\n\ncmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate'\n)\n\ncmr_fit_values = np.array([5.79524319e-01, 4.07083020e-03, 7.24717634e-01, 7.47425733e-01,\n       1.00000000e+00, 9.58358158e-02, 9.55947397e+00, 8.71434638e+01,\n       3.13827247e-02, 3.36754300e-01, 9.25336064e+00, 9.95710836e-01])\n\nparameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor index, name in enumerate(cmr_free_parameters):\n    parameters[name] = cmr_fit_values[index]\n    \nparameters['sampling_rule'] = 0\nparameters['mfc_familiarity_scale'] = 0\nparameters['mcf_familiarity_scale'] = 0\nparameters['drift_familiarity_scale'] = 0\n\nresults = np.zeros((experiment_count, 1+presentation_count-item_count))\n\nfor experiment in range(experiment_count):\n    # arbitrary item and contextual cue\n    repeated_item = 0\n    \n    # initialize model\n    model = Classic_CMR(item_count, presentation_count, parameters)\n    cue = model.context\n    model.experience(model.items)\n    results[experiment, 0] = np.nan \n    \n     # track outcome probability of selected item as it is repeatedly encoded\n    for i in range(presentation_count - item_count):\n        \n        model.experience(model.items[repeated_item:repeated_item+1])\n        \n        if i == 0:\n            cue = model.context\n        \n        pre_cue_context = model.context.copy()\n        model.context = cue\n        results[experiment, i+1] = model.outcome_probabilities()[repeated_item+1]\n        model.context = pre_cue_context\n        \nplt.plot(np.mean(results, axis=0))\nplt.xlabel('Number of Successive Repetitions After 20-Item Trial')\nplt.ylabel('Recall Probability for Repeated Item')\nplt.savefig('cmr_repeffect.pdf', bbox_inches=\"tight\")\nplt.show()\n\n\n\n\n\nicmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n#    'feature_sensitivity',\n    'context_sensitivity',\n    'delay_drift_rate',\n)\n\nicmr_fit_values = np.array([7.25274023e-01, 5.49552946e-03, 7.76637231e-01, 6.81235304e-03,\n       1.00000000e+00, 2.88780665e-01, 6.21718894e+00, 2.83467864e+01,\n       2.40239395e-02, 2.61909193e-01, 1.63472597e+00, 9.45953503e-01])\n\nparameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor index, name in enumerate(icmr_free_parameters):\n    parameters[name] = icmr_fit_values[index]\n    \nparameters['sampling_rule'] = 0\nparameters['choice_sensitivity'] = 1\nparameters['feature_sensitivity'] = 1\n\nresults = np.zeros((experiment_count, 1+presentation_count-item_count))\n\nfor experiment in range(experiment_count):\n    # arbitrary item and contextual cue\n    repeated_item = 0\n    \n    # initialize model\n    model = Instance_CMR(item_count, presentation_count, parameters)\n    cue = model.context\n    model.experience(model.items)\n    results[experiment, 0] = np.nan \n    \n     # track outcome probability of selected item as it is repeatedly encoded\n    for i in range(presentation_count - item_count):\n        \n        model.experience(model.items[repeated_item:repeated_item+1])\n        \n        if i == 0:\n            cue = model.context\n        \n        #cue = model.context # for when i want context to be the cue\n        pre_cue_context = model.context.copy()\n        model.context = cue\n        results[experiment, i+1] = model.outcome_probabilities()[repeated_item+1]\n        model.context = pre_cue_context\n        \nplt.plot(np.mean(results, axis=0))\nplt.xlabel('Number of Successive Repetitions After 20-Item Trial')\nplt.ylabel('Recall Probability for Repeated Item')\nplt.savefig('icmr_repeffect.pdf', bbox_inches=\"tight\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n(a) PrototypeCMR\n\n\n\n\n\n\n\n(b) InstanceCMR\n\n\n\n\nFigure 1: Course of effect of successive item repetitions on recall probability, by model, using parameters fitted over @murdock1970interresponse dataset and a static contextual cue after simulation of a pure 20-item list.\n\n\nThough initial simulations suggest a way to distinguish between instance- and prototype-based accounts of context maintenance and retrieval, free recall datasets with high amounts of repetition to the extent simulated in the above example do not yet exist. However, to support an initial comparison of how models account for item repetition effects, we use data associated with @siegel2014retrieved. Within the dataset, 35 subjects performed delayed free recall of 48 lists over four sessions. Except for deliberate item repetitions, words were unique within each session and did not repeat in successive sessions. The semantic relatedness of words was also controlled below a value of .55 according to WAS [@steyvers2005word]. Across trials, lists were structured in four different ways:\n\nIn control lists, all items were only presented once.\nIn pure massed lists, items were presented twice, always in succession (e.g. 1, 1, 2, 2)\nIn pure spaced lists, items were presented twice with spacing of repetitions from 1 to 8 positions, with each spacing amount equiprobable.\nFinally, mixed lists feature once-presented, massed, and spaced items, with each spacing amount equiprobable\n\nfrom compmemlearn.fitting import lohnas_objective_function, apply_and_concatenate\nfrom compmemlearn.datasets import prepare_lohnas2014_data, simulate_data\nfrom compmemlearn.models import Classic_CMR, Instance_CMR\nfrom scipy.optimize import differential_evolution\nfrom numba.typed import List, Dict\nimport matplotlib.pyplot as plt\nfrom numba.core import types\nfrom numba import njit\nimport seaborn as sns\nfrom psifr import fr\nimport pandas as pd\nimport numpy as np\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../../data/repFR.mat')\nAs with previous analyses, each model variant was fit once for each participant to identify the parameter configuration maximizing the likelihood of observed recall sequences given the considered model, considering all conditions of the dataset. The distribution of data log-likelihoods given each fitted model and participant are plotted in Figure 2, with median values for each model variant highlighted. Similarly to previous analyses, these value distributions were found largely similar. The distribution of log-likelihood scores between participants for the PrototypeCMR and InstanceCMR model variants only marginally differ, suggesting that all considered model variants can predict recall sequences even when item repetitions occur during study with similar degrees of success.\n\ncmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate'\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ncmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\nindividual_cmr_results = []\n\nfor subject in np.unique(subjects):\n    \n    print(subject)\n\n    selection = subjects == subject\n\n    cost_function = lohnas_objective_function(\n        trials[selection], \n        presentations[selection],\n        init_cmr,\n        {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n        cmr_free_parameters)\n\n    individual_cmr_results.append(differential_evolution(\n        cost_function, cmr_bounds, disp=False))\n    print(individual_cmr_results[-1].fun)\n\n\nicmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n#    'feature_sensitivity',\n    'context_sensitivity',\n    'delay_drift_rate',\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nicmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n#    (lb, 10),\n#    (lb, 10)\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_icmr(item_count, presentation_count, parameters):\n    return Instance_CMR(item_count, presentation_count, parameters)\n\nindividual_icmr_results = []\n\nfor subject in np.unique(subjects):\n    \n    print(subject)\n\n    selection = subjects == subject\n\n    cost_function = lohnas_objective_function(\n        trials[selection], \n        presentations[selection],\n        init_icmr,\n        {'choice_sensitivity': 1, 'feature_sensitivity': 1}, \n        icmr_free_parameters)\n\n    individual_icmr_results.append(differential_evolution(\n        cost_function, icmr_bounds, disp=False))\n    print(individual_icmr_results[-1].fun)\n\n\nplt.style.use('default')\n\nindividual_fits = [result.fun for result in individual_icmr_results] + [result.fun for result in individual_cmr_results]\nlabels = ['InstanceCMR'] * len(individual_icmr_results) + ['PrototypeCMR'] * len(individual_cmr_results)\nindividual_df = pd.DataFrame(individual_fits, index=labels, columns=['Fit']).reset_index()\nindividual_df.columns = ['Model', 'Fit']\n\nsns.set(style=\"darkgrid\")\n\ng = sns.catplot(x='Model', y='Fit', data=individual_df, kind='violin', inner='stick')\nsns.swarmplot(x=\"Model\", y=\"Fit\", color=\"k\", size=3, data=individual_df, ax=g.ax)\ng.ax.set_ylabel('Individual-Level Fitted Model Log-Likelihoods');\nplt.savefig('individual_lohnas2014.pdf', bbox_inches=\"tight\")\nplt.show()\n\nsummary_table = pd.DataFrame(group.describe().rename(columns={'Fit':name}).squeeze()\n            for name, group in individual_df.groupby('Model')).T.to_markdown()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstanceCMR\nPrototypeCMR\n\n\n\n\ncount\n35\n35\n\n\nmean\n1676.3\n1668.35\n\n\nstd\n434.819\n429.581\n\n\nmin\n914.375\n856.293\n\n\n25%\n1367.75\n1378.27\n\n\n50%\n1686.97\n1698.98\n\n\n75%\n1955.37\n1957.65\n\n\nmax\n2752.36\n2751.88\n\n\n\n\n\nFigure 2: Log-likelihood score distributions for each subject under each considered model [@siegel2014retrieved]\n\n\nWhile follow-up analysis of summary statistics in previous analyses focused on benchmark phenomena such as serial position effects, inclusion of item repetitions in study designs complicates associated visualizations. Instead, we focused comparison on summary statistics measuring classical item repetition effects. In Figure 3, we measure how effectively our prototype- and instance-based CMR implementations account for the spacing effect. Main model variants were fit to the mixed list (fourth) condition of the entire dataset across subjects to optimize the likelihood of observed recall sequences. Then with each configured model, study phases of each trial in the mixed condition of the dataset were simulated and then followed with simulation of free recall. We then plot for both the behavioral data and simulated datasets, the rate at which items were recalled, binned based on the number of intervening items between repetitions. On the one hand, we observe that both models poorly account for the pattern of recall rates observed as a function of presentation spacing in the mixed condition of the @siegel2014retrieved dataset, exaggerating the mnemonic benefit of item repetition in general while understating the mnemonic effect of increased spacing between repetitions. On the other hand, recapitulating all previous analyses, we again found that both our prototype-based and main instance-based implementations of CMR predicted similar patterns of effects of repetition spacing on later item recall.\n\n\nselection = list_types == 4\ncost_function = lohnas_objective_function(\n    trials[selection], \n    presentations[selection],\n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    cmr_free_parameters)\n\ncmr_result = differential_evolution(cost_function, cmr_bounds, disp=True)\n\n\nicmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n#    'feature_sensitivity',\n    'context_sensitivity',\n    'delay_drift_rate',\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nicmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n#    (lb, 10),\n#    (lb, 10)\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_icmr(item_count, presentation_count, parameters):\n    return Instance_CMR(item_count, presentation_count, parameters)\n\nselection = list_types == 4\ncost_function = lohnas_objective_function(\n    trials[selection], \n    presentations[selection],\n    init_icmr,\n    {'choice_sensitivity': 1, 'feature_sensitivity': 1}, \n    icmr_free_parameters)\n\nicmr_result = differential_evolution(cost_function, icmr_bounds, disp=True)\n\n\nfrom compmemlearn.analyses import sim_recall_probability_by_lag\n\n\nparameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor index, name in enumerate(cmr_free_parameters):\n    parameters[name] = cmr_result.x[index]\n    \nparameters['sampling_rule'] = 0\nparameters['mfc_familiarity_scale'] = 0\nparameters['mcf_familiarity_scale'] = 0\nparameters['drift_familiarity_scale'] = 0\n\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\nselection = list_types == 4\nresult = sim_recall_probability_by_lag(presentations[selection], 10, init_cmr, parameters)\nbinned = np.zeros(5)\nbinned[0] = result[0]\nbinned[1] = result[1]\nbinned[2] = (result[2] + result[3])/2\nbinned[3] = (result[4] + result[5] + result[6])/3\nbinned[4] = (result[7] + result[8] + result[9])/3\n\nax = sns.barplot(x=['N/A', '0', '1-2', '3-5', '6-8'], \n                 y=binned)\nplt.xlabel('Number of Intervening Items Between Repetitions')\nplt.ylabel('Recall Probability')\nplt.show()\n\n\nparameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor index, name in enumerate(icmr_free_parameters):\n    parameters[name] = icmr_result.x[index]\n    \nparameters['sampling_rule'] = 0\nparameters['choice_sensitivity'] = 1\nparameters['feature_sensitivity'] = 1\n@njit(fastmath=True, nogil=True)\ndef init_icmr(item_count, presentation_count, parameters):\n    return Instance_CMR(item_count, presentation_count, parameters)\n\nresult = sim_recall_probability_by_lag(presentations[selection], 10, init_icmr, parameters)\n\nbinned = np.zeros(5)\nbinned[0] = result[0]\nbinned[1] = result[1]\nbinned[2] = (result[2] + result[3])/2\nbinned[3] = (result[4] + result[5] + result[6])/3\nbinned[4] = (result[7] + result[8] + result[9])/3\nprint(binned)\n\nax = sns.barplot(x=['N/A', '0', '1-2', '3-5', '6-8'], \n                 y=binned)\nplt.xlabel('Number of Intervening Items Between Repetitions')\nplt.ylabel('Recall Probability')\nplt.show()\n\n\n\n\n\n\n\n\n(a) PrototypeCMR\n\n\n\n\n\n\n\n(b) InstanceCMR\n\n\n\n\n\n\n\n(c) Data\n\n\n\n\nFigure 3: Comparison of predicted recall probability as function of item repetition spacing between each model and the observed data [@siegel2014retrieved]."
  },
  {
    "objectID": "projects\\Instance_CMR\\paper\\07_Discussion.html#discussion",
    "href": "projects\\Instance_CMR\\paper\\07_Discussion.html#discussion",
    "title": "compmemlearn",
    "section": "Discussion",
    "text": "In light of a collection of results across task domains distinguishing between the performance of prototype- and instance-based models of memory-based behavior, we searched for evidence of a similar distinction with respect to the free recall task paradigm. To do this, we specified and compared the original prototype-based implementation of an established model of task performance based in retrieved context theory (PrototypeCMR) against a parallel instance-based variant (CMR) across diverse experimental conditions, including a dataset featuring variable study list lengths across trials and a dataset featuring item repetitions within trials and variable item repetition spacing between trials. While our simulation analyses focused on the effect of item repetition on recall rates identified some hypothetical distinctions between model predictions, the model variants accounted for human performance on the free recall task with similar effectiveness in each dataset considered.\nOne clear conclusion we can draw from these analyses is that the success of the theoretical commitments made by the Context Maintenance and Retrieval model and models like it are likely not especially dependent on the architectures in which they are implemented. Instead, the main insights of retrieved context theories (at least as formalized by CMR) are highly portable, and can likely be esconced within any reasonable model architecture where memory search via temporal contextual representations might prove valuable. Establishing the portability of these successful theoretical principles across modeling approaches helps advance the historical effort in cognitive science to develop “a general account of memory and its processes in a working computational system to produce a common explanation of behavior rather than a set of lab-specific and domain-specific theories for different behaviors” [@newell1973you; @jamieson2018instance].\nThis finding has been increasingly validated lately in other work. @logan2021serial for example similarly embeds mechanisms for maintaining and organizing retrieval using temporal contextual representations within an instance-based architecture to simultaneously account for performance on substantively distinct variations of a task requiring participants to encode and report random strings in left-to-right order by typing them on a computer keyboard, including whole report, serial recall, and copy typing. Other projects more motivated by neuroscientific data (e.g. [@ketz2013theta]; [@schapiro2017complementary]) embed mechanisms for context-based retrieval within detailed formal accounts of hippocampus functionality more complex than either the instance-based or hebbian associative network architectures considered in this work. Our head-to-head comparison of this instance-based account of context maintenance and retrieval against its more standard prototype-based counterpart and observation that both competitively explain free recall performance under varied conditions further evinces the architectural independence of the retrieved context account of memory search.\nHow do these results fit into the context of other work identifying substantive contrasts between instance- and prototype-based models? Research by @jamieson2018instance comparing the model architectures’ capacity to account for semantic memory emphasizes that the main limitation of prototype-based models is the information that they discard or distort toward some center-of-tendency at encoding - idiosyncratic item or contextual features that do not reflect generalities across experience. With this information discarded or suppressed, memory cues selective for those idiosyncratic features cannot result in retrieval of relevant information. Instance-based models on the other hand are able to select information across learning episodes to include in an abstractive representation based on the content of a cue, enabling flexible retrieval of idiosyncratic features while suppressing more common but irrelevant features.\nThe trace-based application of instance models’ \\(\\tau\\) parameter is described as fundamental to the unique flexibility of instance-based models outlined by @jamieson2018instance, as it enables instance-based models to modulate the influence of particular memory traces in a retrieved echo representation nonlinearly based on the traces’ similarity to a probe. However, while the prototype-based semantic memory models examined by @jamieson2018instance exclude a similar response scaling mechanism, the standard prototype-based specification of CMR does include one. Research on category learning [@nosofsky2002exemplar; @stanton2002comparisons] also contrasting prototype- and instance-based models of the behavior also identifies instance models’ characteristic response-scaling mechanism as crucial for accounting for deterministic patterns in memory performance under various research conditions. However, they also evaluate prototype-based models that, like CMR, do include response-scaling mechanisms – though by definition only instance-based models apply the mechanism to similarities computed between traces and probe representations. To compare the instance-based Exemplar-Generalization model against a prototype-based model with a similar response scaling mechanism, @nosofsky2002exemplar focused on how the models differentially characterize generalization, in this case the category assignment of novel items excluded from initial training. Finding that participants mroe often classify items in the the same categories based on their similarity to one another rather than based on similarity to hypothetical prototype-representations, the instance-based Exemplar-Generalization model came out ahead.\nEven the research above drawing distinctions between the explanatory performance of instance-based and prototype-based models report experimental conditions where the two architectures perform similarly. We can conclude that either the considered research conditions or the model specifications themselves also sidestep any of their more substantive differences. Two assumptions enforced in both the prototype- and instance-based frameworks compared here as well as in corresponding datasets were that list item were effectively representationally orthogonal, and encountered just once or twice before retrieval. Furthermore, contextual states as characterized by CMR differ a consistent amount from item to item during study in a traditional list learning experiment. The assumptions together may prevent a distinction from emerging between highly common and highly idiosyncratic item or contextual features under traditional research conditions as emphasized in architectural comparisons drawn by @jamieson2018instance. Similarly, the uniform similarity structure of list items studied and recalled across evaluated datasets here potentially sidesteps issues raised by @nosofsky2002exemplar with prototype-based models.\nHigher rates of item repetition or enforced distortions of contextual variation (such as by dividing an encoding phase into distinct trials or sessions) might be enough to more clearly distinguish architecture performance. Simulations of high rates of item repetitions reported in ?@fig-repeffect identify one potentially relevant difference between InstanceCMR and PrototypeCMR – an exponential rate of increase of recall rates for repeated items in the former, but not the latter – but the distinction seems independent from contrasts drawn between the architectures drawn by other researchers such as @jamieson2018instance and @nosofsky2002exemplar. By contrast, research conditions where items are repeated rarely in some contexts but frequently in others or nonorthogonal item features influence and are factored into model performance would further explore the relevance of prior exploration of prototype- and instance-based architectures to our understanding of free recall and similar tasks. At the same time, our current results establish that architectural distinctions relevant in other tasks domains may be not particularly critical for accounting for performance across the more traditional research conditions explored here.\nWhile these results suggest some level of equivalance between instance-based and prototype-based models with respect to accounting for free recall performance, their generality is as limited to the simple architectures evaluated as to the datasets explored. More complex or just different models that might be classed in one of these categories may not exhibit the same patterns. For example, the examinations here only consider a constrained conceptualization of instance-based models styled after the MINERVA 2 simulation model of human memory [@hintzman1984minerva]. @lehman2013buffer produced a dual store model of performance on various recall tasks and can be classed as an instance-based model despite excluding some traditional features of models inspired by @hintzman1984minerva, such as reliance on a single trace store and application of a nonlinear response scaling mechanism during retrieval. Its main assumption is that a limited-capacity buffer tracks both information about items and about associations between items and between items and their encoding context; at the same time, it supposes that a secondary, unlimited-capacity store is, with some probability, populated with traces from this buffer. For the free recall task, the model integrates concepts from retrieved context theory, including initiation of recall based on the content of a context cue. With these mechanisms, the model is able to account for serial position and temporal contiguity effects using novel mechanisms not directly instantiated in the variants of CMR explored here. Similarities in predictions offered by the different models indicate that they include analogous features, but important explanatory differences may just as well exist between them and MINERVA-based instance models under certain research conditions as exist between prototype-based and instance-based models in others. Deeper clarification of the distinctions and homologies between different models characterizing performance on memory tasks such as free recall is critical for driving further modeling innovation."
  },
  {
    "objectID": "projects\\Instance_CMR\\paper\\references.html#references",
    "href": "projects\\Instance_CMR\\paper\\references.html#references",
    "title": "compmemlearn",
    "section": "References",
    "text": ""
  },
  {
    "objectID": "projects\\Instance_CMR\\slides\\committee.html#whats-at-stake-when-you-choose-a-model-architecture",
    "href": "projects\\Instance_CMR\\slides\\committee.html#whats-at-stake-when-you-choose-a-model-architecture",
    "title": "compmemlearn",
    "section": "What’s At Stake When You Choose a Model Architecture?",
    "text": "What’s at stake when you’re choosing between instance- and prototype-based architectures to model how humans do memory search? To help find out, I developed an instance-based variant of an established prototype-based account of memory search called the context maintenance and retrieval model. I compared the variant and the original’s capacity to account for human performance across various datasets using prediction-based model fitting and simulation of benchmark behavioral phenomena. Both variants performed similarly in my comparisons, demonstrating the architectural independence of the models’ theoretical commitments and laying the groundwork for deeper integration or crossover between instance- and prototype-based modeling practices."
  },
  {
    "objectID": "projects\\Instance_CMR\\slides\\committee.html#memory-associates-information-based-on-a-history-of-experiences",
    "href": "projects\\Instance_CMR\\slides\\committee.html#memory-associates-information-based-on-a-history-of-experiences",
    "title": "compmemlearn",
    "section": "Memory associates information based on a history of experiences",
    "text": "To get into what I’m talking about, we can start with a simplified idea of memory as a system that associates cues with responses based on co-occurence of features over some history of experiences. Seeing a flower can remind you of details from other times you’ve seen that flower, such as in a vase or while walking outside. Being in this meeting might remind you of similar meetings you’ve had, and so on.\nIn the cognitive modeling literature, research often distinguishes between two basic frameworks summarizing how human memory systems pull this off – between instance and prototype theories."
  },
  {
    "objectID": "projects\\Instance_CMR\\slides\\committee.html#instance-based-models",
    "href": "projects\\Instance_CMR\\slides\\committee.html#instance-based-models",
    "title": "compmemlearn",
    "section": "Instance-Based Models",
    "text": "Instance-based accounts of memory conceptualize learning as growing a collection of distinct memory traces, each a record of a unique event or experience. A reminder retrieves associations by activating each stored instance in parallel based on similarity. Traces highly similar to your reminder are especially activated, while very dissimilar traces see their activations suppressed, thereby prioritizing relevant information. The weighted sum of representations retrieved from all these traces shouting at the same time is an “echo” your memory system replies with.\nThe way I’m describing instance models here closely coheres with the architecture established in the 80s by Hintzman to account for performance like tasks like item recognition and frequency judgments without explicit storage of prototypes. But instance-based models are diverse and have been applied to account for a ambitious range of phenomena. Works such as the Generalized Context and Exemplar-Based Random Walk models pervade accounts of category learning and are about as paradigmatic. A line of integrative works like Gordon’s instance theory of attention and memory and more recent CRU model has even pushed the deceptively simple architecture to account for patterns and processes across many research domains at once, subsuming normally distinguished cognitive processes under a single umbrella."
  },
  {
    "objectID": "projects\\Instance_CMR\\slides\\committee.html#prototype-based-models",
    "href": "projects\\Instance_CMR\\slides\\committee.html#prototype-based-models",
    "title": "compmemlearn",
    "section": "Prototype-based models",
    "text": "Rather than assuming we store each experience separately, prototype-based models assume experience updates memory representations to reflect prototypical features that are common across past experience. A simple and frequent example of what I’m talking about are the weights in linear associator network. In a linear associator, experiences activate units in an input layer to represent an array of features. These in turn pass activation to units in an output layer to form the memory system’s responses - which we’ll keep calling echoes for consistency. Weighted connections control the extent to which activation in an input unit drives activation in a given output unit, and get updated through some learning process with each new experience. For example, through the Hebbian learning rule, units that fire together, wire together, strengthening the connection between input and output units coactivated in a learning episode, thereby preserving a record of their correspondence during experience.\nBeginning the rise of connectionist modeling beginning with work on perceptrons and parallel distributed processing theory by researchers like Rosenblott and McClelland, prototype-based models have become super pervasive, though the domain distribution seems to me to differ from that of instance-based models. Prototype-based accounts of categorization such as the Additive-Prototype model have been proposed, but leading accounts are mostly exemplar-based, and for good reasons. Models of free recall along the tradition I’m familiar with though are largely though certainly not exclusively prototype-based, primarily representing encoded associations within accumulatory representations. Like instance-based models, they’ve also been applied to account for a range of behaviors, like recognition, emotional modulation, and financial decision-making, and undergone extensive iterative refinement."
  },
  {
    "objectID": "projects\\Instance_CMR\\slides\\committee.html#model-architectures-trade-between-compression-and-flexibility",
    "href": "projects\\Instance_CMR\\slides\\committee.html#model-architectures-trade-between-compression-and-flexibility",
    "title": "compmemlearn",
    "section": "Model Architectures Trade Between Compression and Flexibility",
    "text": "However, some fundamental differences between the frameworks though have brought them into conflict. For example, instance-based models have faced criticism from theorists like the memory search scientist Mike Kahana for their lack of data compression. The multitrace account implies that the number of traces can increase without bound, and that they are all contacted simultaneously, and both ideas are difficult to accept given the biological constraints that face cognition.\nOn the other hand and of more central focus for this project, this compressive aspect of prototype-based models has been criticized for collapsing the many contexts in which a item occurs to a single best-fitting representation. Researchers like Jamieson and Jones in 2018 have argued that this can constrain the models from accounting for the full flexibility humans exhibit in domains like semantic memory and categorization.\nAn example by those researchers compared the architectures’ capacity to retrieve homonyms – words that carry multiple meanings, like the way “break” can describe stopping a car, reporting a story in the news, or smashing a plate, depending on the context you use it in. They took a few popular prototype-based models of semantic meaning including LSA - or latent semantic analysis - and compared them against an instance-based model of semantic memory. They encoded homonyms with other words in an artificial language, weighting the distribution of co-occurrence frequencies so that a word like “break” more frequently corresponds with the “stop”-based meaning of the word instead of the “smash” or “news-report”-based meanings. Then they compound-cued retrieval of different senses of the homonym and compared the retrieved representations to synonyms to each relevant word sense. These comparisons and others found that prototype-based models like LSA could not flexibly retrieve the distinct senses of homonyms as well as the instance model, and observation the authors explained in terms of compression and related to similar debates in the category learning literature."
  },
  {
    "objectID": "projects\\Instance_CMR\\slides\\committee.html#current-focus-memory-search",
    "href": "projects\\Instance_CMR\\slides\\committee.html#current-focus-memory-search",
    "title": "compmemlearn",
    "section": "Current Focus: Memory Search",
    "text": "The significance of these differences have been examined in a few domains, but not our present focus – memory SEARCH, a concept that extends our initial conceptualization of memory to include an iterative process where you might remember a piece of information using a probe, and then use the retrieved information to update your probe so you can access more information in memory.\nMuch of what we know about memory search is based on performance on the free recall task, where participants are presented a sequence of items (usually words) and then prompted to recall as many list items as possible in whatever order they want.\nIn the recall phase of this task, participants tend to exhibit a pattern called the temporal contiguity effect, where participants tend to transition between temporally contiguous items on the study list. Analyses like the lag-CRP plot in the bottom right of this slide are applied to showcase this pattern. This is a paradigmatic example, not tied to any particular dataset. For each successive recall a subject makes, there’s a serial “lag” between that recall and the previous recall. The current item may have been studied at position 4 while the previous item may have been studied at position 5, making their “lag” 1. Researchers tabulate the frequency of transitions of each lag and plot the conditional probability of making a transition of a given lag across datasets. The high values within the red rectange of this plot where lags are close to zero illustrates the temporal contiguity effect.\nIn turn, this pattern reinforces our view that participants iteratively evolve how they probe their memory based on previous probing to search for new items to retrieve."
  },
  {
    "objectID": "projects\\Instance_CMR\\slides\\committee.html#section",
    "href": "projects\\Instance_CMR\\slides\\committee.html#section",
    "title": "compmemlearn",
    "section": "—",
    "text": "To account for phenomena like this temporal contiguity effect and how people might perform memory search, the formal literature has largely converged on retrieved context theories of memory search that centers a evolving representation of temporal context as the dynamicaly updating probe driving the process.\nBy this account, during encoding, items are associated with states of temporal context in memory and vice versa. A key result of this is that items with other items based on temporal contiguity. During recall, the current state of temporal context serves as the main memory probe and items are retrieved based on their contextual associations. The contextual probe is then updated based on the contextual associations of the retrieved item, thereby constructing a cue biased toward items temporally contiguous to the last recalled item, accounting for the temporal contiguity effect - and many other interesting memory phenomena.\nFor this project, I took an established specification of this theory - the context maintenance and retrieval model - and compared prototype- and instance-based implementations of its mechanisms across various datasets."
  },
  {
    "objectID": "projects\\Instance_CMR\\slides\\committee.html#section-1",
    "href": "projects\\Instance_CMR\\slides\\committee.html#section-1",
    "title": "compmemlearn",
    "section": "—",
    "text": "The original implementation of CMR is prototype-based, encoding and retrieving item-to-context and context-to-item associations using a pair of simple linear associator memories called MFC and MCF, with F referring to item features and C to contextual features. Encoding item features retrieves contextual associations updates a contextual state. Coactivated contextual and item features update the weights of each network, establishing associations.\nAfter exploring various possibilities, I found that an instance-based variant of this model based in the MINERVA 2 architecture I reviewed earlier can be readily implemented by storing coactive item and contextual features within a single memory trace, otherwise preserving model mechanisms. During retrieval, instead of using a separate memory to contact item-to-context or context-to-item associations, the content of the probe decides which associations are retrieved. A probe with item features constructs an echo aggregating traces with similar item features, thus pulling an contextual representation, and vice versa otherwise.\nI do simplify the model a bit with this explanation, but the simplicity of this approach offers a surprisingly neat recipe for integrating RCT and account for temporal order effects into any pre-existing instance-based model: you sort of just have to track context across stimulus presentation and store its state along with a representation of a stimulus. Using and updating your contextual probe as specified by CMR is also key for model success, but yeah - it’s a portable model."
  },
  {
    "objectID": "projects\\Instance_CMR\\slides\\committee.html#section-2",
    "href": "projects\\Instance_CMR\\slides\\committee.html#section-2",
    "title": "compmemlearn",
    "section": "—",
    "text": "Next though I outline how I know this approach actually works.\nWe apply an evaluation technique for free recall data surprisingly only recently introduced by Morton and Polyn in 2016.\nTo simulate free recall, CMR generates a probability distribution for each item that still hasn’t been recalled, given every simulated study and recall event that has happened so far in the trial.\nTo evaluate a model, we can simulate and record the probability of each event in dataset, then pooling the probabilities into a log-likelihood score.\nThen using a genetic optimization algorithm called differential evolution, we can search for the model parameters that maximize the likelihood of our observed data.\nWe can fit the model per participant to compare distributions of optimized log-likelihood scores between model variants. Alternatively, we can fit the models across an entire dataset and then produce a simulated dataset using model mechanisms, and compare important benchmark summary statistics between fitted models and the data. I do both!"
  },
  {
    "objectID": "projects\\Instance_CMR\\slides\\committee.html#section-3",
    "href": "projects\\Instance_CMR\\slides\\committee.html#section-3",
    "title": "compmemlearn",
    "section": "—",
    "text": "First, I should clarify what I mean by benchmark summary statistics. These are the memory search phenomena that have received the most focus in the literature, rooted in the idea that free recall is composed by initiation, transitions, and then - though it’s not getting much focus here - termination.\nWe’ve already talked about the lag-CRP and how it measures the temporal contiguity effect."
  },
  {
    "objectID": "projects\\Instance_CMR\\slides\\committee.html#section-4",
    "href": "projects\\Instance_CMR\\slides\\committee.html#section-4",
    "title": "compmemlearn",
    "section": "",
    "text": ""
  },
  {
    "objectID": "projects\\Likelihood_Without_First_Recall.html#likelihood-functions",
    "href": "projects\\Likelihood_Without_First_Recall.html#likelihood-functions",
    "title": "compmemlearn",
    "section": "Likelihood Functions",
    "text": "Differences from original functions: - likelihood initialized with one fewer column since one less item is recalled - likelihood only populated with a value for events after recall_index 0 - column recall_index-1 instead of recall_index is populated with each likelihood value since we skip 0.\nImportant commonalities: - First recall event is still simulated each time as in original function\nimport numpy as np\nfrom numba import njit, prange\nfrom compmemlearn.models import Classic_CMR\nfrom numba.typed import Dict\nfrom numba.core import types\n\n@njit(fastmath=True, nogil=True, parallel=True)\ndef murdock_data_likelihood(data_to_fit, item_counts, model_class, parameters):\n\n    result = 0.0\n    for i in prange(len(item_counts)):\n        item_count = item_counts[i]\n        trials = data_to_fit[i]\n        likelihood = np.ones((len(trials), item_count-1))\n\n        model = model_class(item_count, item_count, parameters)\n        model.experience(model.items)\n\n        for trial_index in range(len(trials)):\n            trial = trials[trial_index]\n\n            model.force_recall()\n            for recall_index in range(len(trial) + 1):\n\n                # identify index of item recalled; if zero then recall is over\n                if recall_index == len(trial) and len(trial) < item_count:\n                    recall = 0\n                else:\n                    recall = trial[recall_index]\n\n                # store probability of and simulate recall of indexed item \n                if recall_index > 0:\n                    likelihood[trial_index, recall_index-1] = \\\n                        model.outcome_probabilities()[recall] + 10e-7\n                \n                if recall == 0:\n                    break\n                model.force_recall(recall)\n\n            # reset model to its pre-retrieval (but post-encoding) state\n            model.force_recall(0)\n        \n        result -= np.sum(np.log(likelihood))\n\n    return result\n\ndef murdock_objective_function(data_to_fit, item_counts, model_class, fixed_parameters, free_parameters):\n    \"\"\"\n    Configures cmr_likelihood for search over specified free/fixed parameters.\n    \"\"\"\n\n    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n    for name, value in fixed_parameters.items():\n        parameters[name] = value\n    \n    def objective_function(x):\n        for i in range(len(free_parameters)):\n            parameters[free_parameters[i]] = x[i]\n        return murdock_data_likelihood(data_to_fit, item_counts, model_class, parameters)\n\n    return objective_function\nimport numpy as np\nfrom numba import njit, prange\nfrom compmemlearn.models import Classic_CMR\nfrom numba.typed import Dict\nfrom numba.core import types\n\n@njit(fastmath=True, nogil=True, parallel=True)\ndef lohnas_data_likelihood(trials, presentations, model_class, parameters):\n\n    list_length = len(presentations[0])\n    likelihood = np.ones((len(trials), list_length-1)) \n\n    for trial_index in prange(len(trials)):\n\n        item_count = np.max(presentations[trial_index])+1\n        trial = trials[trial_index]\n        model = model_class(item_count, list_length, parameters)\n        model.experience(model.items[presentations[trial_index]])\n\n        model.force_recall()\n        for recall_index in range(len(trial) + 1):\n\n            # identify index of item recalled; if zero then recall is over\n            if recall_index == len(trial) and len(trial) < item_count:\n                recall = 0\n            elif trial[recall_index] == 0:\n                recall = 0\n            else:\n                recall = presentations[trial_index][trial[recall_index]-1] + 1\n\n            # store probability of and simulate recalling item with this index\n            if recall_index > 0:                        \n                likelihood[trial_index, recall_index-1] = \\\n                    model.outcome_probabilities()[recall] + 10e-7\n\n            if recall == 0:\n                break\n            model.force_recall(recall)\n\n        # reset model to its pre-retrieval (but post-encoding) state\n        model.force_recall(0)\n\n    return -np.sum(np.log(likelihood))\n\ndef lohnas_objective_function(data_to_fit, presentations, model_class, fixed_parameters, free_parameters):\n\n    \"\"\"\n    Generates and returns an objective function for input to support search \n    through parameter space for model fit using an optimization function.\n\n    Returns a function that accepts a vector x specifying arbitrary values for \n    free parameters and returns evaluation of likelihood using the model \n    class, all parameters, and provided data.\n    \"\"\"\n\n    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n    for name, value in fixed_parameters.items():\n        parameters[name] = value\n\n    def objective_function(x):\n        for i in range(len(free_parameters)):\n            parameters[free_parameters[i]] = x[i]\n        return lohnas_data_likelihood(data_to_fit, presentations, model_class, parameters)\n\n    return objective_function"
  },
  {
    "objectID": "projects\\Likelihood_Without_First_Recall.html#simulation-functions",
    "href": "projects\\Likelihood_Without_First_Recall.html#simulation-functions",
    "title": "compmemlearn",
    "section": "Simulation Functions",
    "text": "We want to make sure we are always simulating the first recalls that correspond to the datasets we fit the model to. Using our force_recall function should make that work. We’ll add support for a first_recall_item array argument that identifies for each experiment trial a first recall to simulate. Like the values in our trials arrays, the values should be one-indexed.\nimport pandas as pd\nfrom psifr import fr\nimport numpy as np\nfrom numba import int32\nfrom numba import njit\n\ndef simulate_df(model, experiment_count, first_recall_item=np.array([])):\n    \"\"\"\n    Initialize a model with specified parameters and experience sequences and \n    then populate a psifr-formatted dataframe with the outcomes of performing `free recall`. \n    \n    **Required model attributes**:\n    - item_count: specifies number of items encoded into memory\n    - context: vector representing an internal contextual state\n    - experience: adding a new trace to the memory model\n    - free_recall: function that freely recalls a given number of items or until recall stops\n    \"\"\"\n    \n    # encode items\n    model.experience(model.items)\n\n    # simulate retrieval for the specified number of times, tracking results in df\n    trial_count = experiment_count\n    if first_recall_item.size > 0:\n        trial_count = experiment_count * first_recall_item.size\n    \n    data = []\n    for trial_index in range(trial_count):\n        data += [[trial_index, 0, 'study', i + 1, i] for i in range(model.item_count)]\n    for trial_index in range(trial_count):\n        if first_recall_item.size > 0:\n            experiment = int(trial_index/first_recall_item.size)\n            model.force_recall(first_recall_item[trial_index - (experiment * first_recall_item.size)])\n        data += [[trial_index, 0, 'recall', i + 1, o] for i, o in enumerate(model.free_recall())]\n    data = pd.DataFrame(data, columns=['subject', 'list', 'trial_type', 'position', 'item'])\n    merged = fr.merge_free_recall(data)\n    \n    return merged\n\nsimulate_data = simulate_df\n@njit(fastmath=True, nogil=True)\ndef simulate_array(model, experiment_count, first_recall_item=np.array([])):\n    \n    # encode items\n    model.experience(model.items)\n\n    # simulate retrieval for the specified number of times, tracking results in array\n    if first_recall_item.size > 0:\n        experiment_count *= first_recall_item.size\n    trials = np.zeros((experiment_count, len(model.items)), dtype=int32)\n    \n    for trial_index in range(len(trials)):\n        \n        if first_recall_item.size > 0:\n            experiment = int(trial_index/first_recall_item.size)\n            model.force_recall(\n                first_recall_item[trial_index - (\n                    experiment * first_recall_item.size)])\n        \n        recalled = model.free_recall()\n        trials[trial_index, :len(recalled)] = recalled + 1\n        \n    return trials\n#TODO: Need First Recall Item Argument to Identify Item Indices like Presentation Does and Like Trial Doesn't!\n\n@njit(nogil=True)\ndef simulate_array_from_presentations(\n    model_class, parameters, presentations, experiment_count,  first_recall_item=np.array([])):\n\n    # simulate retrieval for the specified number of times, tracking results in trials array\n    trials = np.zeros((experiment_count * len(presentations), np.max(presentations)+1), dtype=int32)\n    \n    for experiment in range(experiment_count):\n        for trial_index in range(len(presentations)):\n        \n            # retrieve presentation sequence for this trial and measure number of unique items\n            presentation = presentations[trial_index]\n            item_count = np.max(presentation)+1\n            \n            # simulate recall and identify first study position of each recalled item\n            model = model_class(item_count, len(presentation), parameters)\n            model.experience(model.items[presentation])\n            \n            if first_recall_item.size > 0:\n                model.force_recall(first_recall_item[trial_index])\n            \n            recalled = model.free_recall()\n            \n            for i in range(len(recalled)):\n                trials[experiment*len(presentations) + trial_index, i] = find_first(recalled[i], presentation) + 1\n    \n    return trials\n\n@njit(nogil=True)\ndef find_first(item, vec):\n    \"\"\"return the index of the first occurence of item in vec\"\"\"\n    for i in range(len(vec)):\n        if item == vec[i]:\n            return i\n    return -1"
  },
  {
    "objectID": "projects\\Likelihood_Without_First_Recall.html#fitting-condition-1-of-lohnas-dataset-with-both-likelihood-functions",
    "href": "projects\\Likelihood_Without_First_Recall.html#fitting-condition-1-of-lohnas-dataset-with-both-likelihood-functions",
    "title": "compmemlearn",
    "section": "Fitting Condition 1 of Lohnas Dataset With Both Likelihood Functions",
    "text": "from compmemlearn.datasets import prepare_murdock1962_data, prepare_murdock1970_data, prepare_lohnas2014_data\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../data/repFR.mat')\n\nfree_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate'\n)\n\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nbounds = (\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n)\n\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\nLoading and Optimizing Along Cost Function\n\nfrom scipy.optimize import differential_evolution\nimport numpy as np\n\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\ncost_function = lohnas_objective_function(\n    trials[list_types == 1], \n    presentations[list_types == 1], \n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    free_parameters)\n\nlohnas_result = differential_evolution(cost_function, bounds, disp=True)\nprint(lohnas_result)\n\ndifferential_evolution step 1: f(x)= 24877.6\ndifferential_evolution step 2: f(x)= 22147\ndifferential_evolution step 3: f(x)= 22147\ndifferential_evolution step 4: f(x)= 21216.5\ndifferential_evolution step 5: f(x)= 19343.9\ndifferential_evolution step 6: f(x)= 19343.9\ndifferential_evolution step 7: f(x)= 19343.9\ndifferential_evolution step 8: f(x)= 19343.9\ndifferential_evolution step 9: f(x)= 19343.9\ndifferential_evolution step 10: f(x)= 19343.9\ndifferential_evolution step 11: f(x)= 19343.9\ndifferential_evolution step 12: f(x)= 19136.3\ndifferential_evolution step 13: f(x)= 18672.3\ndifferential_evolution step 14: f(x)= 17729.3\ndifferential_evolution step 15: f(x)= 17729.3\ndifferential_evolution step 16: f(x)= 17729.3\ndifferential_evolution step 17: f(x)= 17729.3\ndifferential_evolution step 18: f(x)= 17729.3\ndifferential_evolution step 19: f(x)= 17729.3\ndifferential_evolution step 20: f(x)= 17640\ndifferential_evolution step 21: f(x)= 17640\ndifferential_evolution step 22: f(x)= 17640\ndifferential_evolution step 23: f(x)= 17640\ndifferential_evolution step 24: f(x)= 17640\ndifferential_evolution step 25: f(x)= 17640\ndifferential_evolution step 26: f(x)= 17554.7\ndifferential_evolution step 27: f(x)= 17554.7\ndifferential_evolution step 28: f(x)= 17554.7\ndifferential_evolution step 29: f(x)= 17554.7\ndifferential_evolution step 30: f(x)= 17554.7\ndifferential_evolution step 31: f(x)= 17513.6\ndifferential_evolution step 32: f(x)= 17513.6\ndifferential_evolution step 33: f(x)= 17513.6\ndifferential_evolution step 34: f(x)= 17513.6\ndifferential_evolution step 35: f(x)= 17505.4\ndifferential_evolution step 36: f(x)= 17476.4\ndifferential_evolution step 37: f(x)= 17455.2\ndifferential_evolution step 38: f(x)= 17455.2\n     fun: 17397.533835842947\n     jac: array([-0.04147296, -0.00145519, -0.29613147,  0.02764864,  0.02510205,\n        0.01418812,  0.00291038,  0.        , -0.15170372,  0.29067451,\n       -0.12041709, -0.0003638 ])\n message: 'Optimization terminated successfully.'\n    nfev: 9061\n     nit: 38\n success: True\n       x: array([7.55813076e-01, 7.89655494e-01, 9.23309281e-01, 7.99845601e-01,\n       8.67256168e-01, 6.68956944e-01, 6.52056568e-01, 7.02569359e+01,\n       2.57444793e-02, 8.70280471e-02, 1.00000000e+01, 2.21156982e-08])\n\n\n\nfrom compmemlearn.fitting import apply_and_concatenate\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(lohnas_result.x)):\n    fitted_parameters[free_parameters[i]] = lohnas_result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nmodel0 = Classic_CMR(40, 40, fitted_parameters)\n\nsim_df0 = simulate_df(model0, 2, trials[list_types==1][:, 0])\ntrue_df0 = events.loc[events.condition==1]\n\ncmr_spc0 = apply_and_concatenate(fr.spc, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp0 = apply_and_concatenate(fr.lag_crp, sim_df0, true_df0, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr0 = apply_and_concatenate(fr.pnr, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr0 = cmr_pfr0.query('output <= 1')\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 12/3), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0], data=cmr_spc0, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0].set_xticks(np.arange(1, list_length+1, 3))\naxes[0].set_ylim((0, 1))\n\n# lag CRP\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1].set_xticks(np.arange(-5, 6, 1))\naxes[1].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=cmr_pfr0, x='input', y='prob', err_style='bars', ax=axes[2], hue='source', legend=True)\naxes[2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2].set_xticks(np.arange(1, list_length+1, 3))\naxes[2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=2)\n\n\n\n\n\n\nLet’s compare this result with what we’d obtain if we fit using murdock_data_likelihood.\n\nfrom scipy.optimize import differential_evolution\nimport numpy as np\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\ncost_function = murdock_objective_function(\n    (trials[list_types==1], ), \n    (40, ), \n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    free_parameters)\n\nmurdock_result = differential_evolution(cost_function, bounds, disp=True)\nprint(murdock_result)\n\ndifferential_evolution step 1: f(x)= 20429.6\ndifferential_evolution step 2: f(x)= 20429.6\ndifferential_evolution step 3: f(x)= 19671.6\ndifferential_evolution step 4: f(x)= 19319\ndifferential_evolution step 5: f(x)= 19319\ndifferential_evolution step 6: f(x)= 19202.3\ndifferential_evolution step 7: f(x)= 18877.5\ndifferential_evolution step 8: f(x)= 18877.5\ndifferential_evolution step 9: f(x)= 18366.8\ndifferential_evolution step 10: f(x)= 18152.5\ndifferential_evolution step 11: f(x)= 18152.5\ndifferential_evolution step 12: f(x)= 18152.5\ndifferential_evolution step 13: f(x)= 18009.6\ndifferential_evolution step 14: f(x)= 18009.6\ndifferential_evolution step 15: f(x)= 18009.6\ndifferential_evolution step 16: f(x)= 17965.1\ndifferential_evolution step 17: f(x)= 17557.8\ndifferential_evolution step 18: f(x)= 17557.8\ndifferential_evolution step 19: f(x)= 17557.8\ndifferential_evolution step 20: f(x)= 17557.8\ndifferential_evolution step 21: f(x)= 17504.4\ndifferential_evolution step 22: f(x)= 17504.4\ndifferential_evolution step 23: f(x)= 17504.4\ndifferential_evolution step 24: f(x)= 17484.2\ndifferential_evolution step 25: f(x)= 17477.3\ndifferential_evolution step 26: f(x)= 17477.3\ndifferential_evolution step 27: f(x)= 17473.9\ndifferential_evolution step 28: f(x)= 17469.3\ndifferential_evolution step 29: f(x)= 17469.3\ndifferential_evolution step 30: f(x)= 17457.9\n     fun: 17397.533842605546\n     jac: array([-0.19354047, -0.01964509,  0.12551027, -0.16007107, -0.01928129,\n       -0.04292815, -0.00836735,  0.        , -0.61700121,  0.14224497,\n       -0.09640643,  0.        ])\n message: 'Optimization terminated successfully.'\n    nfev: 7998\n     nit: 30\n success: True\n       x: array([7.55826965e-01, 7.89320574e-01, 9.23286854e-01, 7.99614742e-01,\n       8.65995433e-01, 6.69516249e-01, 6.51724781e-01, 4.70748465e+01,\n       2.57434103e-02, 8.70291613e-02, 1.00000000e+01, 2.22044605e-16])\n\n\n\nfrom compmemlearn.fitting import apply_and_concatenate\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(murdock_result.x)):\n    fitted_parameters[free_parameters[i]] = murdock_result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nmodel0 = Classic_CMR(40, 40, fitted_parameters)\n\nsim_df0 = simulate_df(model0, 3, trials[list_types==1][:, 0])\ntrue_df0 = events.loc[events.condition==1]\n\ncmr_spc0 = apply_and_concatenate(fr.spc, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp0 = apply_and_concatenate(fr.lag_crp, sim_df0, true_df0, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr0 = apply_and_concatenate(fr.pnr, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr0 = cmr_pfr0.query('output <= 1')\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 12/3), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0], data=cmr_spc0, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0].set_xticks(np.arange(1, list_length+1, 3))\naxes[0].set_ylim((0, 1))\n\n# lag CRP\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1].set_xticks(np.arange(-5, 6, 1))\naxes[1].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=cmr_pfr0, x='input', y='prob', err_style='bars', ax=axes[2], hue='source', legend=True)\naxes[2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2].set_xticks(np.arange(1, list_length+1, 3))\naxes[2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=2)"
  },
  {
    "objectID": "projects\\Likelihood_Without_First_Recall.html#fitting-murdock-1970-dataset",
    "href": "projects\\Likelihood_Without_First_Recall.html#fitting-murdock-1970-dataset",
    "title": "compmemlearn",
    "section": "Fitting Murdock 1970 Dataset",
    "text": "trials, events, list_length = prepare_murdock1970_data('../data/mo1970.txt')\n\ncost_function = murdock_objective_function(\n    (trials, ),  \n    (list_length, ),\n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, \n     'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    free_parameters)\n\nmurdock_result = differential_evolution(cost_function, bounds, disp=True)\n\ndifferential_evolution step 1: f(x)= 24214.4\ndifferential_evolution step 2: f(x)= 24214.4\ndifferential_evolution step 3: f(x)= 23360.6\ndifferential_evolution step 4: f(x)= 21132\ndifferential_evolution step 5: f(x)= 20786.5\ndifferential_evolution step 6: f(x)= 20786.5\ndifferential_evolution step 7: f(x)= 20786.5\ndifferential_evolution step 8: f(x)= 20786.5\ndifferential_evolution step 9: f(x)= 20786.5\ndifferential_evolution step 10: f(x)= 20512.7\ndifferential_evolution step 11: f(x)= 20113\ndifferential_evolution step 12: f(x)= 20113\ndifferential_evolution step 13: f(x)= 20113\ndifferential_evolution step 14: f(x)= 19287.5\ndifferential_evolution step 15: f(x)= 19287.5\ndifferential_evolution step 16: f(x)= 19287.5\ndifferential_evolution step 17: f(x)= 19287.5\ndifferential_evolution step 18: f(x)= 19287.5\ndifferential_evolution step 19: f(x)= 19287.5\ndifferential_evolution step 20: f(x)= 19287.5\ndifferential_evolution step 21: f(x)= 19226.1\ndifferential_evolution step 22: f(x)= 19226.1\ndifferential_evolution step 23: f(x)= 19226.1\ndifferential_evolution step 24: f(x)= 19165.9\ndifferential_evolution step 25: f(x)= 19165.9\ndifferential_evolution step 26: f(x)= 19150.1\ndifferential_evolution step 27: f(x)= 19150.1\ndifferential_evolution step 28: f(x)= 19150.1\ndifferential_evolution step 29: f(x)= 19144.4\ndifferential_evolution step 30: f(x)= 19088\ndifferential_evolution step 31: f(x)= 19088\ndifferential_evolution step 32: f(x)= 19088\ndifferential_evolution step 33: f(x)= 19088\ndifferential_evolution step 34: f(x)= 19088\ndifferential_evolution step 35: f(x)= 18999.6\ndifferential_evolution step 36: f(x)= 18946.9\ndifferential_evolution step 37: f(x)= 18946.9\ndifferential_evolution step 38: f(x)= 18946.9\ndifferential_evolution step 39: f(x)= 18946.9\n\n\n\nfrom compmemlearn.fitting import apply_and_concatenate\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(murdock_result.x)):\n    fitted_parameters[free_parameters[i]] = murdock_result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nmodel0 = Classic_CMR(20, 20, fitted_parameters)\n\nsim_df0 = simulate_df(model0, 3, trials[:, 0])\ntrue_df0 = events\n\ncmr_spc0 = apply_and_concatenate(fr.spc, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp0 = apply_and_concatenate(fr.lag_crp, sim_df0, true_df0, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr0 = apply_and_concatenate(fr.pnr, sim_df0, true_df0, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr0 = cmr_pfr0.query('output <= 1')\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 12/3), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0], data=cmr_spc0, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0].set_xticks(np.arange(1, list_length+1, 3))\naxes[0].set_ylim((0, 1))\n\n# lag CRP\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1], data=cmr_lag_crp0.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1].set(xlabel='Lag From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1].set_xticks(np.arange(-5, 6, 1))\naxes[1].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=cmr_pfr0, x='input', y='prob', err_style='bars', ax=axes[2], hue='source', legend=True)\naxes[2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[2].set_xticks(np.arange(1, list_length+1, 3))\naxes[2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=2)"
  },
  {
    "objectID": "projects\\Likelihood_Without_First_Recall.html#fitting-to-mixed-lists-in-lohnas-2014-dataset",
    "href": "projects\\Likelihood_Without_First_Recall.html#fitting-to-mixed-lists-in-lohnas-2014-dataset",
    "title": "compmemlearn",
    "section": "Fitting to Mixed Lists in Lohnas 2014 Dataset",
    "text": "trials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../data/repFR.mat')\n\nfree_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate',\n    'drift_familiarity_scale',\n)\n\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nbounds = (\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n    (lb, ub)\n)\n\nLoading and Optimizing Along Cost Function\n\nfrom scipy.optimize import differential_evolution\nimport numpy as np\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\ncost_function = lohnas_objective_function(\n    trials[list_types == 4], \n    presentations[list_types == 4], \n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0}, \n    free_parameters)\n\nlohnas_result = differential_evolution(cost_function, bounds, disp=True)\nprint(lohnas_result)\n\ndifferential_evolution step 1: f(x)= 20682.8\ndifferential_evolution step 2: f(x)= 20682.8\ndifferential_evolution step 3: f(x)= 18603.6\ndifferential_evolution step 4: f(x)= 18603.6\ndifferential_evolution step 5: f(x)= 18274.4\ndifferential_evolution step 6: f(x)= 18274.4\ndifferential_evolution step 7: f(x)= 18274.4\ndifferential_evolution step 8: f(x)= 18247.6\ndifferential_evolution step 9: f(x)= 17450.5\ndifferential_evolution step 10: f(x)= 17450.5\ndifferential_evolution step 11: f(x)= 17450.5\ndifferential_evolution step 12: f(x)= 17450.5\ndifferential_evolution step 13: f(x)= 17450.5\ndifferential_evolution step 14: f(x)= 17044.4\ndifferential_evolution step 15: f(x)= 17044.4\ndifferential_evolution step 16: f(x)= 17044.4\ndifferential_evolution step 17: f(x)= 16604.4\ndifferential_evolution step 18: f(x)= 16485.7\ndifferential_evolution step 19: f(x)= 16133.2\ndifferential_evolution step 20: f(x)= 16133.2\ndifferential_evolution step 21: f(x)= 16133.2\ndifferential_evolution step 22: f(x)= 16133.2\ndifferential_evolution step 23: f(x)= 16119.4\ndifferential_evolution step 24: f(x)= 16079.8\ndifferential_evolution step 25: f(x)= 16079.8\ndifferential_evolution step 26: f(x)= 16079.8\ndifferential_evolution step 27: f(x)= 15993.2\ndifferential_evolution step 28: f(x)= 15971.1\ndifferential_evolution step 29: f(x)= 15971.1\ndifferential_evolution step 30: f(x)= 15961.6\ndifferential_evolution step 31: f(x)= 15912\ndifferential_evolution step 32: f(x)= 15912\ndifferential_evolution step 33: f(x)= 15912\ndifferential_evolution step 34: f(x)= 15912\ndifferential_evolution step 35: f(x)= 15888.3\ndifferential_evolution step 36: f(x)= 15888.3\ndifferential_evolution step 37: f(x)= 15888.3\ndifferential_evolution step 38: f(x)= 15876.2\ndifferential_evolution step 39: f(x)= 15876.2\ndifferential_evolution step 40: f(x)= 15876.2\ndifferential_evolution step 41: f(x)= 15876.2\ndifferential_evolution step 42: f(x)= 15876.2\ndifferential_evolution step 43: f(x)= 15876.2\ndifferential_evolution step 44: f(x)= 15876.2\ndifferential_evolution step 45: f(x)= 15876.2\ndifferential_evolution step 46: f(x)= 15876.2\ndifferential_evolution step 47: f(x)= 15876.2\ndifferential_evolution step 48: f(x)= 15876.2\ndifferential_evolution step 49: f(x)= 15876.2\ndifferential_evolution step 50: f(x)= 15876.2\ndifferential_evolution step 51: f(x)= 15876.2\n     fun: 15765.037256539877\n     jac: array([-1.83063093,  0.54260454,  0.19463187,  1.2352757 ,  0.08876668,\n       -0.72850526,  0.01182343,  0.134969  ,  0.94041752,  0.35233825,\n       -0.25684131,  0.83782652, -0.00527507])\n message: 'Optimization terminated successfully.'\n    nfev: 14186\n     nit: 51\n success: True\n       x: array([0.88669978, 0.11887846, 0.94681617, 0.04760541, 0.88864142,\n       0.04585966, 5.17172382, 8.00427889, 0.02249963, 0.10413299,\n       1.51616036, 0.99879117, 0.5847791 ])\n\n\nfrom compmemlearn.analyses import fast_rpl\n\nfitted_parameters = Dict.empty(\n    key_type=types.unicode_type, value_type=types.float64)\nfor j in range(len(lohnas_result.x)):\n    fitted_parameters[free_parameters[j]] = lohnas_result.x[j]\n\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nexperiment_count = 1000\nnew_sim_array = simulate_array_from_presentations(\n    init_cmr, fitted_parameters, presentations[list_types==4], \n    experiment_count, trials[list_types==4][:, 0])\nimport numpy.matlib\n\nresult = fast_rpl(np.matlib.repmat(presentations[list_types==4], experiment_count, 1), new_sim_array)\nbinned = np.zeros(5)\nbinned[0] = result[0]\nbinned[1] = result[1]\nbinned[2] = (result[2] + result[3])/2\nbinned[3] = (result[4] + result[5] + result[6])/3\nbinned[4] = (result[7] + result[8] + result[9])/3\nprint(binned)\nimport matplotlib.pyplot as plt\n\nfit_sources = ['lohnas_4']\nfit_rpls = [binned]\n\nfor i in range(len(fit_sources)):\n    plt.plot(fit_rpls[i], label=fit_sources[i])\n\nresult = fast_rpl(presentations[list_types==4], trials[list_types==4])\nbinned = np.zeros(5)\nbinned[0] = result[0]\nbinned[1] = result[1]\nbinned[2] = (result[2] + result[3])/2\nbinned[3] = (result[4] + result[5] + result[6])/3\nbinned[4] = (result[7] + result[8] + result[9])/3\nplt.plot(binned, label='data')\nlags = ['N/A', '0', '1-2', '3-5', '6-8']\nplt.xticks(np.arange(len(lags)), lags)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
  },
  {
    "objectID": "projects\\Narrative_CMR\\00_Text_Preprocessing.html#dataset-overview",
    "href": "projects\\Narrative_CMR\\00_Text_Preprocessing.html#dataset-overview",
    "title": "compmemlearn",
    "section": "Dataset Overview",
    "text": "We render an overview of the dataset prepared for our publication:\nfrom IPython.display import Markdown\n\ndef render_tex(tex_path, bib_path, csl_path):\n    result = !pandoc -C --ascii {tex_path} -f latex -t markdown_mmd --bibliography {bib_path} --csl {csl_path}\n    return Markdown('\\n'.join(result))\n\nrender_tex('writing/BrownSchmidt_Dataset.tex', 'writing/references.bib', 'writing/main/apa.csl')\nRecall for narratives, if split into idea units – “meaningful chunks of information that convey a piece of the narrative” – that are numbered according to chronological order, can be examined using analytic techniques developed for free and serial list recall tasks. This framework enables direct comparison between ideas, assumptions, and models applied to understand how people remember sequences such as word lists and those used to understand memory for narrative texts. To support analysis of narrative recall this way, we considered a dataset collected, preprocessed, and presented by Cutler et al. (2019). In corresponding experiments, research participants read 6 distinct short stories. Upon reading a story, participants performed immediate free recall of the narrative twice. Three weeks later, participants performed free recall of each narrative again. Each recall period was limited to five minutes. Following data collection, a pair of research assistants in the Brown-Schmidt laboratory were each instructed to independently split stories and participant responses into idea units as defined above, and to identify correspondences between idea units in participant responses and corresponding studied stories reflecting recall. Following this initial preprocessing, research assistants then compared and discussed their results and recorded consensus decisions regarding the segmentation and correspondence of idea units across the dataset. Further analysis focused on the sequences of story idea units recalled by participants on each trial as tracked by these researchers.\n\n\nCutler, R., Palan, J., Polyn, S., & Brown-Schmidt, S. (2019). Semantic and temporal structure in memory for narratives: A benefit for semantically congruent ideas. Context and Episodic Memory Symposium."
  },
  {
    "objectID": "projects\\Narrative_CMR\\00_Text_Preprocessing.html#standardizing-text-representations",
    "href": "projects\\Narrative_CMR\\00_Text_Preprocessing.html#standardizing-text-representations",
    "title": "compmemlearn",
    "section": "Standardizing Text Representations",
    "text": "Using the data in raw, we produce in texts one subdirectory for each passage (with passage contents at base) and in each subdirectory, one file for each recall period. Each file will contain only the recalled text associated with a particular passage, subject, and recall period and be labeled accordingly (e.g. as Supermarket_1_1.txt). At the base of texts, the text of the source passages will each be included as separate files.\n\nWe start with some initial dependencies and constants.\n# import dependencies\nimport os\nimport pathlib\nimport docxpy\nimport ftfy\n\n# key paths\nsource_directory = os.path.join('data', 'raw')\ntarget_directory = os.path.join('data', 'texts')\n\nsource_names = ['Fisherman', 'Supermarket', 'Flight', 'Cat', 'Fog', 'Beach']\nsource_titles = ['where does susie go at noon?']\ntitle_tags = [['''man and the bear'''], ['''act of kindness'''], \n              [\"\"\"a man can’t just sit\"\"\", \"a man just can’t sit\"], \n              [\"where does susie go at noon?\"], [\"fog: a maine t\"], \n              [\"day at the beach\"]]\nauthor_tags = ['author unknown', 'anonymous', 'chris holm', 'adapted from',\n               'unknown', 'anonymous']\n\n\nNext we create directories in our file system to organize preprocessed data.\n# make a pooled subdirectory if one doesn't already exist\nif not os.path.isdir(target_directory):\n    os.mkdir(target_directory)\n\n# generate subdirectory for each passage\nfor source_name in source_names:\n    passage_path = os.path.join(target_directory, source_name)\n    if not os.path.isdir(passage_path):\n        os.mkdir(passage_path)\n\n\nPreprocess raw docx files and store as text\n# for each pt1 written recall file, extract text and remove boilerplate, \n# and save to correct location in `pooled`\nfor path, subdirs, files in os.walk(os.path.join(\n    source_directory, 'recall', 'Written Recall Part 1')):\n    for name in files:\n        recall_path = str(pathlib.PurePath(path, name))\n        \n        # extract text and remove boilerplate\n        recall_text = '\\n'.join(\n            docxpy.process(recall_path).split('\\n')[1:]).strip()\n        passage_index = recall_path[-9:-8]\n        subject_index = recall_path.split(name)[0][-3:-1]\n        phase_index = recall_path[-7:-6]\n        targetname = '{}_{}_{}.txt'.format(\n            source_names[int(passage_index)-1], int(subject_index), phase_index)\n        \n        # handle special cases??\n        recall_text = recall_text.replace(\n            'vbeach', 'beach').replace('Susie gp at noon', 'Susie go at noon')\n        \n        # filter out source titles from recall data\n        if any([each in recall_text[:recall_text.find(\n            '.')].lower() for each in title_tags[int(passage_index)-1]]):\n            if len(recall_text[:recall_text.find('\\n')]) < 100:\n                recall_text = recall_text[recall_text.find('\\n'):].strip()\n                \n        # filter out source authors from recall data\n        if (recall_text[:len(author_tags[int(\n            passage_index)-1])].lower() == author_tags[int(passage_index)-1]):\n            recall_text = recall_text[recall_text.find('\\n'):].strip()\n            \n        # clean the data\n        recall_text = ftfy.fix_text(recall_text)\n            \n        # save to correct location in pooled\n        with open(\n            os.path.join(target_directory, source_names[int(passage_index)-1], \n                         targetname), 'w', encoding='utf-8') as f:\n            f.write(recall_text)\nPart 1 and Part 2 data were collected in slightly different contexts, so they are preprocessed a little differently:\n# for each pt2 written recall file, extract text and remove boilerplate, \n# and save to correct location in `pooled`\nfor path, subdirs, files in os.walk(\n    os.path.join(source_directory, 'recall', 'Written Recall Part 2')):\n    for name in files:\n        recall_path = str(pathlib.PurePath(path, name))\n        \n        # identify correct location in pooled\n        passage_index = recall_path[-7:-6]\n        subject_index, phase_index =  recall_path.split(name)[0][-3:-1], 3\n        if len(passage_index.strip()) == 0:\n            continue\n        targetname = '{}_{}_{}.txt'.format(\n            source_names[int(passage_index)-1], int(subject_index), phase_index)\n\n        # extract text and remove boilerplate\n        boilerplate = 'You have 5 minutes to type the story you just read for memory. There is no word limit. Please write as much as you can remember.'\n        recall_text = docxpy.process(\n            recall_path).replace(boilerplate, '').strip()\n        recall_text = '\\n'.join(recall_text.split('\\n')[1:]).strip()\n        \n        # clean text\n        recall_text = ftfy.fix_text(recall_text)\n        \n        # save to correct location\n        with open(os.path.join(\n            target_directory, source_names[int(passage_index)-1], \n            targetname), 'w', encoding='utf-8') as f:\n            f.write(recall_text)\n\n\nThe result is an organized directory of text representations of participant responses absent methodology-specific details such as the content of the recall prompt."
  },
  {
    "objectID": "projects\\Narrative_CMR\\01_Data_Preparation.html#dataset-overview",
    "href": "projects\\Narrative_CMR\\01_Data_Preparation.html#dataset-overview",
    "title": "compmemlearn",
    "section": "Dataset Overview",
    "text": "#from IPython.display import Markdown\n\n#def render_tex(tex_path, bib_path, csl_path):\n#    result = !pandoc -C --ascii {tex_path} -f latex -t markdown_mmd --bibliography {bib_path} --csl {csl_path}\n#    return Markdown('\\n'.join(result))\n\n#render_tex('writing/BrownSchmidt_Dataset.tex', 'writing/references.bib', 'writing/main/apa.csl')\nHuman raters have gotten us most of what we want in the spreadsheet at data/raw/Narrative Recall Data.xlsx. Most preprocessing using external data is devoted to identifying otherwise ambiguous relationships between source idea units.\n# dependencies\nimport os\nimport spacy\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sentence_transformers import SentenceTransformer, util\n\n# model for computing sentence embeddings\nembedding_model = SentenceTransformer(\"paraphrase-MiniLM-L12-v2\")\n\n# model for detecting reading cycles\nnlp = spacy.load(\"en_core_web_trf\")\n\n# key paths\nsource_directory = os.path.join('data', 'raw')\ntext_directory = os.path.join('data', 'texts')\ntarget_directory = os.path.join('data', 'sequences', 'human')\n\n# names for relevant passages\npassage_names = ['Fisherman', 'Supermarket', 'Flight', 'Cat', 'Fog', 'Beach']\n\n# we use the original xlsx\ndata = pd.read_excel(os.path.join(\n    source_directory, 'Narrative Recall Data.xlsx'), \n                     list(range(22)), engine='openpyxl')\n\ndata[0].head()"
  },
  {
    "objectID": "projects\\Narrative_CMR\\01_Data_Preparation.html#story-information",
    "href": "projects\\Narrative_CMR\\01_Data_Preparation.html#story-information",
    "title": "compmemlearn",
    "section": "Story Information",
    "text": "Strings identifying idea units within each story\nSemantic similarity matrix between source idea units\nCycles grouping source idea units based on co-occurence in the same sentence\n\nLater when we process specific trials, we’ll retrieve this information to identify study events in our final table.\nall_cycles = []\nall_source_units = []\nall_similarities = []\nstory_sequence = []\n\nfor trial_index, trial in tqdm(data[0].groupby(['story', 'timeTest'])):\n    \n    # we only consider each story once\n    if trial['timeTest'].values[0] > 1:\n        continue\n    \n    # identify story\n    story_index = trial['story'].values[0]\n    story_sequence.append(story_index)\n    \n    # source units are reproduced perfectly in xlsx file\n    source_units = [each for each in list(trial['origText']) if type(each) == str]\n    \n    # collect relevant text\n    with open(os.path.join(\n        text_directory, passage_names[story_index-1] + '.txt'), encoding='utf8') as f:\n        story_text = f.read()\n        \n    # sort units into cycles based on co-occurence in the same sentence\n    # build cycle vector assigning a cycle index to each idea unit\n    cycles = []\n    cycle_index = 0\n    last = 0\n    story_doc = nlp(story_text)\n    \n    for unit in source_units:\n        \n        # locate the unit in story_text\n        unit_loc = story_text.index(unit)\n        \n        # find the sentence corresponding to its first character\n        unit_sentence = story_doc.char_span(unit_loc, unit_loc+len(unit.strip())).sent.start\n        \n        # if the sentence differs from the last considered one, that's a new cycle\n        if unit_sentence != last:\n            cycle_index += 1\n            last = unit_sentence\n\n        cycles.append(cycle_index)\n                \n    # track semantic similarity between each source unit\n    embeddings = embedding_model.encode(source_units)\n    similarities = util.pytorch_cos_sim(embeddings, embeddings).detach().tolist()\n    \n    all_cycles.append(cycles)\n    all_similarities.append(similarities)\n    all_source_units.append(source_units)\nLet’s do a sanity check: lengths of cycle, similarity, and source unit vectors should be the same.\nfor i in range(len(all_source_units)):\n    print(len(all_cycles[i]), len(all_similarities[i]), len(all_source_units[i]))"
  },
  {
    "objectID": "projects\\Narrative_CMR\\01_Data_Preparation.html#trial-information",
    "href": "projects\\Narrative_CMR\\01_Data_Preparation.html#trial-information",
    "title": "compmemlearn",
    "section": "Trial Information",
    "text": "results = []\n\n# consider each unique trial\nfor subject_index, subject in enumerate(data):\n    for trial_index, trial in enumerate(\n        data[subject].groupby(['story', 'timeTest'])):\n        \n        # identify story, timeTest (we already have subject_index)\n        story_index = trial[0][0]-1\n        timeTest = trial[0][1]\n        passage_name = passage_names[story_index]\n        \n        # build study event list based on extracted story information\n        for unit_index, unit in enumerate(all_source_units[story_index]):\n            results.append(\n                [subject, trial_index, 'study', unit_index+1, \n                 unit, unit_index, all_cycles[story_index][unit_index], \n                 story_index, passage_name, timeTest])\n        \n        # we only care about the posRec column\n        # create a recall event wherever a value is stored\n        for serialPos, posRec in enumerate(list(trial[1]['posRec'])):\n            \n            # move to next entry if value can't be cast as integer\n            try:\n                posRec = int(posRec)\n            except ValueError:\n                continue\n            \n            results.append(\n                [subject, trial_index, 'recall', posRec,\n                 all_source_units[story_index][serialPos-1], serialPos-1,\n                 all_cycles[story_index][serialPos-1], \n                 story_index, passage_name, timeTest])\n            \nresults = pd.DataFrame(results, columns=[\n    'subject', 'list', 'trial_type', 'position', 'item', 'item_index', 'cycle', \n    'story_index', 'story_name', 'time_test'])\n\nresults.head()"
  },
  {
    "objectID": "projects\\Narrative_CMR\\01_Data_Preparation.html#store-results",
    "href": "projects\\Narrative_CMR\\01_Data_Preparation.html#store-results",
    "title": "compmemlearn",
    "section": "Store Results",
    "text": "import json\n\n# similarities\nsimilarity_result = {passage_names[i]: all_similarities[i] \n                     for i in range(len(all_similarities))}\n\nwith open('data/similarities.json', 'w') as f:\n    f.write(json.dumps(similarity_result))\n    \nresults.to_csv('data/psifr_sbs.csv', index=False)"
  },
  {
    "objectID": "projects\\Narrative_CMR\\Benchmark_Memory_Effects.html",
    "href": "projects\\Narrative_CMR\\Benchmark_Memory_Effects.html",
    "title": "compmemlearn",
    "section": "",
    "text": "pass"
  },
  {
    "objectID": "projects\\Narrative_CMR\\Cutler_Poster_Reproduction.html",
    "href": "projects\\Narrative_CMR\\Cutler_Poster_Reproduction.html",
    "title": "compmemlearn",
    "section": "",
    "text": "pass"
  },
  {
    "objectID": "projects\\Parameter_Shifting.html#dependencies",
    "href": "projects\\Parameter_Shifting.html#dependencies",
    "title": "compmemlearn",
    "section": "Dependencies",
    "text": "We’ll need each relevant parameter configuration, helper functions, and models.\nimport scipy.io as sio\nimport numpy as np\nimport pandas as pd\nfrom psifr import fr\nfrom InstanceCMR import InstanceCMR\nfrom PrototypeCMR import PrototypeCMR\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef prepare_okadata(path):\n    \"\"\"\n    Prepares data formatted like `data/MurdData_clean.mat` for fitting.\n\n    Loads data from `path` with same format as `data/MurdData_clean.mat` and \n    returns a selected dataset as an array of unique recall trials and a \n    dataframe of unique study and recall events organized according to `psifr`\n    specifications.  \n\n    **Arguments**:  \n    - path: source of data file  \n    - dataset_index: index of the dataset to be extracted from the file\n\n    **Returns**:\n    - trials: int64-array where rows identify a unique trial of responses and \n        columns corresponds to a unique recall index.  \n    - merged: as a long format table where each row describes one study or \n        recall event.  \n    - list_length: length of lists studied in the considered dataset\n    \"\"\"\n    \n    with open(path) as f:\n        oka_data = f.read()\n\n    counter = 0\n    trials = []\n    subjects = []\n    list_length = 20\n\n    for line in oka_data.split('\\n'):\n\n        if not line:\n            continue\n\n        # build subjects array\n        if counter == 0:\n            subjects.append(int(line.strip().split('    ')[1]))\n\n        # build trials array\n        if counter == 1:\n\n            trial = [int(each) for each in line.strip().split('    ')]\n            trial = [each for each in trial if each <= 20]\n            already = []\n            for each in trial:\n                if each not in already:\n                    already.append(each)\n            trial = already\n            \n            while len(trial) < 13:\n                trial.append(0)\n\n            trials.append(trial)\n\n        # keep track of which row we are on for the given trial\n        counter += 1\n        if counter == 3:\n            counter = 0\n\n    trials = np.array(trials).astype('int64')\n    \n    data = []\n    for trial_index, trial in enumerate(trials):\n\n        # every time the subject changes, reset list_index\n        if not data or data[-1][0] != subjects[trial_index]:\n            list_index = 0\n        list_index += 1\n\n        # add study events\n        for i in range(list_length):\n            data += [[subjects[trial_index], \n                      list_index, 'study', i+1, i+1]]\n\n        # add recall events\n        for recall_index, recall_event in enumerate(trial):\n            if recall_event != 0:\n                data += [[subjects[trial_index], list_index, \n                          'recall', recall_index+1, recall_event]]\n\n    data = pd.DataFrame(data, columns=[\n        'subject', 'list', 'trial_type', 'position', 'item'])\n    merged = fr.merge_free_recall(data)\n    return trials, merged, list_length\n\nmurd_trials, murd_events, murd_length = prepare_okadata('data/mo1970.txt')\n\nmurd_events.head()\n\nfree_parameters = [\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity']\n\nparameters = {\n    'item_count':murd_length,\n    'presentation_count': murd_length,\n    'sampling_rule': 0\n}\n\ncmr_fit = np.array([ 0.67729029,  0.0789752 ,  0.84475351,  0.32843236,  0.04606376,\n        0.25014697,  4.09477771, 35.20917629,  0.03838687,  0.29442883,\n        5.03376164])\n\ncmr_params = {**parameters, **{free_parameters[i]:cmr_fit[i] for i in range(len(cmr_fit))}}\ncmr_params\n\nfree_parameters = [\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'feature_sensitivity']\n\nparameters = {\n    'item_count':murd_length,\n    'presentation_count': murd_length,\n    'context_sensitivity': 1,\n    'choice_sensitivity': 1,\n}\n\nicmr_fit = np.array([7.04157544e-01, 2.22044605e-16, 8.42679777e-01, 6.84111237e-04,\n       3.31835533e-02, 1.01371142e-02, 4.34918696e+00, 1.43883032e+00,\n       2.98134948e-02, 3.42612961e-01, 2.39278982e+00])\n\nicmr_params = {**parameters, **{free_parameters[i]:icmr_fit[i] for i in range(len(icmr_fit))}}\nicmr_params"
  },
  {
    "objectID": "projects\\Parameter_Shifting.html#simulation-demo",
    "href": "projects\\Parameter_Shifting.html#simulation-demo",
    "title": "compmemlearn",
    "section": "Simulation Demo",
    "text": "Let’s confirm that I can (efficiently) simulate the model okay and plot an example serial position curve before I try scaling up.\n\ndef simulate_data(model, experiment_count, first_recall_item=None):\n    \"\"\"\n    Initialize a model with specified parameters and experience sequences and \n    then populate a psifr-formatted dataframe with the outcomes of performing `free recall`. \n    \n    **Required model attributes**:\n    - item_count: specifies number of items encoded into memory\n    - context: vector representing an internal contextual state\n    - experience: adding a new trace to the memory model\n    - free_recall: function that freely recalls a given number of items or until recall stops\n    \"\"\"\n    \n    # encode items\n    try:\n        model.experience(np.eye(model.item_count, model.item_count + 1, 1))\n    except ValueError:\n        # so we can apply to CMR\n        model.experience(np.eye(model.item_count, model.item_count))\n\n    # simulate retrieval for the specified number of times, tracking results in df\n    data = []\n    for experiment in range(experiment_count):\n        data += [[experiment, 0, 'study', i + 1, i] for i in range(model.item_count)]\n    for experiment in range(experiment_count):\n        if first_recall_item is not None:\n            model.force_recall(first_recall_item)\n        data += [[experiment, 0, 'recall', i + 1, o] for i, o in enumerate(model.free_recall())]\n\n    data = pd.DataFrame(data, columns=['subject', 'list', 'trial_type', 'position', 'item'])\n    merged = fr.merge_free_recall(data)\n    \n    return merged\n\nmodel = PrototypeCMR(**cmr_params)\nmodel = InstanceCMR(**icmr_params)\nevents = simulate_data(model, 1000)\nspc = events.query('study').pivot_table(\n    index=['subject', 'input'], values=['recall']).reset_index()\nspc.reset_index(level=0, inplace=True)\nspc.head()\nsns.set(style='darkgrid')\ng = sns.lineplot(data=spc, x='input', y='recall',  palette='pastel')\nplt.xlabel('Study Position')\nplt.ylabel('Probability Recall');\nIt’s snappy enough that I don’t have to try jit-compiling the data simulation function. Now to scale up."
  },
  {
    "objectID": "projects\\Parameter_Shifting.html#approach",
    "href": "projects\\Parameter_Shifting.html#approach",
    "title": "compmemlearn",
    "section": "Approach",
    "text": "How am I gonna tackle this? Simulate data for each unique parameter configuration and then extract relevant analysis dataframe. Add a new column identified varied values across simulations so I can hue or facet based on the variable.\nWhich analyses am I interested in doing? Uh, let’s start with encoding drift rate and just one parameter varied per simulation.\nfrom tqdm import tqdm\n\nminimum = 0\nmaximum = .5\ninterval = .1\n\nscore_ranges = {\n    'item_support': np.arange(.01, .1, .02),\n}\n\nfor model in [InstanceCMR]:\n\n    if model.__name__ == 'PrototypeCMR':\n        parameters = cmr_params\n    else:\n        parameters = icmr_params\n\n    for varied_parameter in score_ranges.keys():\n        crps = []\n        spcs = []\n        pfrs = []\n\n        for parameter_value in tqdm(score_ranges[varied_parameter]):\n\n            # simulate data with this parameter value modified\n            sub_params = parameters.copy()\n            sub_params[varied_parameter] = parameter_value\n            subset = simulate_data(model(**sub_params), 200)\n\n            # accumulate spcs, crps, pfrs\n            spc = subset.query('study').pivot_table(\n            index=['subject', 'input'], values=['recall'])\n            spc[varied_parameter] = parameter_value\n            spcs.append(spc)\n\n            crp = fr.lag_crp(subset)\n            crp[varied_parameter] = parameter_value\n            crps.append(crp)\n\n            pfr = fr.pnr(subset).query('output <= 1')\n            pfr[varied_parameter] = parameter_value\n            pfrs.append(pfr)\n\n        # concatenate result into a single table\n        spc = pd.concat(spcs).reset_index()\n        crp = pd.concat(crps).reset_index()\n        pfr = pd.concat(pfrs).reset_index()\n\n        sns.set(style='darkgrid')\n        fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n\n        sns.lineplot(ax=axes[0], data=spc, x='input', y='recall', hue=varied_parameter, ci=None)\n        #axes[0].set_xlabel('Study Position')\n        #axes[0].set_ylabel('Probability Recall')\n        axes[0].set_title('SPC')\n        axes[0].legend([], []);\n        #plt.show()\n\n        max_lag = 10\n        filt_neg = f'{-max_lag} <= lag < 0'\n        filt_pos = f'0 < lag <= {max_lag}'\n\n        sns.lineplot(ax=axes[1], data=crp.query(filt_neg), x='lag', y='prob', hue=varied_parameter, ci=None)\n        sns.lineplot(ax=axes[1], data=crp.query(filt_pos), x='lag', y='prob', hue=varied_parameter, ci=None)\n\n        #axes[1].set_xlabel('Lag')\n        #axes[1].set_ylabel('conditional response probability')\n        axes[1].legend(np.round(score_ranges[varied_parameter], 5));\n        axes[1].set_title('Lag-CRP')\n        #plt.show()\n\n        sns.lineplot(ax=axes[2], data=pfr, x='input', y='prob', hue=varied_parameter, ci=None)\n        #axes[2].set_xlabel('Study Position')\n        #axes[2].set_ylabel('Probability of First Recall')\n        axes[2].set_title('PFR')\n        axes[2].legend([], []);\n\n        fig.suptitle(varied_parameter.replace('_', ' ').upper())\n        plt.savefig('results/{}_{}.svg'.format(model.__name__, varied_parameter))\n        plt.show()"
  },
  {
    "objectID": "projects\\Repetition_CMR\\04_Baseline_Comparison copy 2.html#simulation-of-murdock-and-okada-1970",
    "href": "projects\\Repetition_CMR\\04_Baseline_Comparison copy 2.html#simulation-of-murdock-and-okada-1970",
    "title": "compmemlearn",
    "section": "Simulation of Murdock and Okada (1970)",
    "text": "We start by comparing how our prototype- and instance-based implementations of CMR account for behavior in a classic experiment where each item is presented just once per study phase. For these simulations, we used the dataset reported by @murdock1970interresponse. Each of 72 undergraduates performed 20 trials with study lists each consisting of 20 unique words visually presented at either 60 or 120 words per minute. Given a particular subject, words were unique both within and across trials, and randomly selected from the Toronto Word Pool [@friendly1982toronto], a widely-used collection of high frequency nouns, adjectives, and verbs.\nWhile the major focus of the original report by @murdock1970interresponse was to investigate inter-response times in single-trial free recall, here we focus consideration on the content of recorded recall sequences. Because it excludes within-list repetitions of studied items, this dataset presents the opportunity to compare model performance under simplified conditions. Since items’ feature representations are assumed orthogonal under considered variants of CMR, retrieving a pattern of contextual associations given an item-based cue only requires abstraction over the cued item’s pre-experimental and single experimental contextual associations. Interpretation of apparent differences in performance across model variants thus focus primarily on mechanisms for context-based item representation retrieval.\nfrom compmemlearn.fitting import murdock_objective_function, apply_and_concatenate\nfrom compmemlearn.models import Classic_CMR\nfrom compmemlearn.models import Trace_Reinstatement_CMR\nfrom compmemlearn.datasets import prepare_murdock1970_data, simulate_data\nfrom scipy.optimize import differential_evolution\nfrom numba.typed import List, Dict\nfrom numba.core import types\nfrom numba import njit\nfrom psifr import fr\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nmurd_trials0, murd_events0, murd_length0 = prepare_murdock1970_data('../../../data/mo1970.txt')\nWe compared the original prototype-based implementation of CMR against our novel instance-based implementation. First we evaluated each model variant based on their ability to predict the specific sequences of recalls exhibited by each participant. Considering all 20 trials performed by each participant in the dataset, we applied the differential evolution optimization technique to find for each model the parameter configuration that maximized the likelihood of recorded recall sequences. We obtained a unique optimal parameter configuration for each unique participant and each considered model variant. To measure the goodness-of-fit for each parameter configuration and corresponding model, Figure 1 plots the log-likelihood of each participant’s recall sequences given each model variant’s corresponding optimized parameter configuration. The distribution of log-likelihood scores between participants for the PrototypeCMR and InstanceCMR model variants only marginally differ, suggesting little meaningful difference between variants in their effectiveness accounting for participant recall performance across the dataset.\n\ncmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate'\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ncmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\nsubject_trial_count = 20 # Each subject gets 20 trials/lists a piece.\ncmr_results = []\n\nfor subject, start_index in enumerate(range(0, len(murd_trials0), subject_trial_count)):\n    print(subject, start_index)\n\n    # cost function to be minimized\n    # ours scales inversely with the probability that the data could have been \n    # generated using the specified parameters and our model\n    cost_function = murdock_objective_function(\n        List([murd_trials0[start_index:start_index+subject_trial_count]]), \n        List([murd_length0]),\n        init_cmr,\n        {'sampling_rule': 0, 'mfc_familiarity_scale': 0, \n         'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n        cmr_free_parameters)\n\n    cmr_results.append(differential_evolution(cost_function, cmr_bounds, disp=False))\n    print(cmr_results[-1].fun)\n\n\nicmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n    'context_sensitivity',\n#    'feature_sensitivity'\n    'delay_drift_rate',\n    'context_reinstatement'\n)\n\nicmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n#    (lb, 10),\n#    (lb, 10)\n    (lb, ub),\n    (1, 10)\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_icmr(item_count, presentation_count, parameters):\n    return Trace_Reinstatement_CMR(item_count, presentation_count, parameters)\n\nsubject_trial_count = 20 # Each subject gets 20 trials/lists a piece.\nicmr_results = []\n\nfor subject, start_index in enumerate(range(0, len(murd_trials0), subject_trial_count)):\n    print(subject, start_index)\n\n    # cost function to be minimized\n    # ours scales inversely with the probability that the data could have been \n    # generated using the specified parameters and our model\n    cost_function = murdock_objective_function(\n    List([murd_trials0[start_index:start_index+subject_trial_count]]),  \n    List([murd_length0]),\n    init_icmr,\n    {'choice_sensitivity': 1, 'feature_sensitivity': 1}, \n    icmr_free_parameters)\n\n    icmr_results.append(differential_evolution(cost_function, icmr_bounds, disp=False))\n    print(icmr_results[-1].fun)\n\n\nplt.style.use('default')\n\nindividual_fits = [result.fun for result in cmr_results] + [result.fun for result in icmr_results]\nlabels = ['PrototypeCMR'] * len(cmr_results) + ['InstanceCMR'] * len(icmr_results)\nindividual_df = pd.DataFrame(individual_fits, index=labels, columns=['Fit']).reset_index()\nindividual_df.columns = ['Model', 'Fit']\n\nsns.set(style=\"darkgrid\")\n\ng = sns.catplot(x='Model', y='Fit', data=individual_df, kind='violin', inner='stick')\nsns.swarmplot(x=\"Model\", y=\"Fit\", color=\"k\", size=3, data=individual_df, ax=g.ax)\ng.ax.set_ylabel('Individual-Level Fitted Model Log-Likelihoods');\n#plt.savefig('individual_murdock1970.pdf', bbox_inches=\"tight\")\n\nsummary_table = pd.DataFrame(group.describe().rename(columns={'Fit':name}).squeeze()\n            for name, group in individual_df.groupby('Model')).T.to_markdown()\n\n\n\n\n\nprint(summary_table)\n\n\n\n\n\n\n\n\n\nInstanceCMR with Novel Mechanism\nPrototypeCMR\n\n\n\n\ncount\n72\n72\n\n\nmean\n327.197\n295.883\n\n\nstd\n78.9126\n52.6059\n\n\nmin\n150.454\n150.732\n\n\n25%\n276.716\n260.961\n\n\n50%\n314.061\n297.756\n\n\n75%\n380.375\n330.162\n\n\nmax\n489.85\n390.498\n\n\n\n\n\nFigure 1: Distribution of log-likelihood scores of recall sequences exhibited by each subject under each considered model across list-lengths [@murdock1970interresponse]\n\n\nAs a follow-up, we also compared how readily each model could account for organizational summary statistics in the dataset. We found for each model variant the optimal parameter configuration maximizing the likelihood of the entire dataset rather than participant-by-participant. Using each fitted model variant, we simulated 1000 unique free recall trials and measured summary statistics from the result. Figure 2 plots for each model against the corresponding statistics collected over the dataset how recall probability varies as a function of serial position, how the probability of recalling an item first varies as a function of serial position, and how the conditional recall probabability of an item varies as a function of its serial lag from the previously recalled item. Recapitulating our comparison of log-likelihood distributions fitted over discrete participants, we found that both our prototype-based and instance-based CMR implementations account for these benchmark organizational summary statistics across the full dataset to similar extents. To build on this finding of broad model equivalence with respect to the results reported by @murdock1970interresponse, we consider the model variants under broader experimental conditions.\n\ncost_function = murdock_objective_function(\n    List([murd_trials0]),  \n    List([murd_length0]),\n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, \n     'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    cmr_free_parameters)\n\ncmr_result = differential_evolution(cost_function, cmr_bounds, disp=True)\n\n\ncost_function = murdock_objective_function(\n    List([murd_trials0]),  \n    List([murd_length0]),\n    init_icmr,\n    {'choice_sensitivity': 1, 'feature_sensitivity': 1}, \n    icmr_free_parameters)\n\nicmr_result = differential_evolution(cost_function, icmr_bounds, disp=True)\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(cmr_result.x)):\n    fitted_parameters[cmr_free_parameters[i]] = cmr_result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nmodel = Classic_CMR(murd_length0, murd_length0, fitted_parameters)\n\nsim_df = simulate_data(model, 1000)\ntrue_df = murd_events0.copy()\n\ncmr_spc = apply_and_concatenate(fr.spc, sim_df, true_df, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp = apply_and_concatenate(fr.lag_crp, sim_df, true_df, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr = apply_and_concatenate(fr.pnr, sim_df, true_df, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr = cmr_pfr.query('output <= 1')\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(icmr_result.x)):\n    fitted_parameters[icmr_free_parameters[i]] = icmr_result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['choice_sensitivity'] = 1\nfitted_parameters['feature_sensitivity'] = 1\n\nmodel = init_icmr(murd_length0, murd_length0, fitted_parameters)\n\nsim_df = simulate_data(model, 1000)\nicmr_spc = apply_and_concatenate(fr.spc, sim_df, true_df, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_lag_crp = apply_and_concatenate(fr.lag_crp, sim_df, true_df, 'source', ['InstanceCMR', 'data'])\nicmr_pfr = apply_and_concatenate(fr.pnr, sim_df, true_df, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_pfr = icmr_pfr.query('output <= 1')\n\nimport matplotlib.pyplot as plt\n\nsns.set(style='darkgrid')\n\nfig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 15/2), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0, 0], data=icmr_spc, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0, 0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0, 0].set_xticks(np.arange(1, 21, 2))\naxes[0, 0].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[1, 0], data=cmr_spc, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[1, 0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[1, 0].set_xticks(np.arange(1, 21, 2))\naxes[1, 0].set_ylim((0, 1))\n\n# lag crp curve\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[0, 1], data=icmr_lag_crp.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[0, 1], data=icmr_lag_crp.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[0, 1].set(xlabel='Item\\'s Lag In Study List From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[0, 1].set_xticks(np.arange(-5, 6, 1))\naxes[0, 1].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[1, 1], data=cmr_lag_crp.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1, 1], data=cmr_lag_crp.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1, 1].set(xlabel='Item\\'s Lag In Study List From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1, 1].set_xticks(np.arange(-5, 6, 1))\naxes[1, 1].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=icmr_pfr, x='input', y='prob', err_style='bars', ax=axes[0, 2], hue='source')\naxes[0, 2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[0, 2].set_xticks(np.arange(1, 21, 2))\naxes[0, 2].set_ylim((0, 1))\n\nsns.lineplot(data=cmr_pfr, x='input', y='prob', err_style='bars', ax=axes[1, 2], hue='source')\naxes[1, 2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[1, 2].set_xticks(np.arange(1, 21, 2))\naxes[1, 2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[0, 2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\naxes[1, 2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\nplt.tight_layout(pad=3)\nplt.savefig('overall_murdock1970.pdf', bbox_inches='tight')\n\n\n\n\n\n\n\nFigure 2: Comparison of summary statistics between each model against observed data [@murdock1970interresponse]"
  },
  {
    "objectID": "projects\\Repetition_CMR\\04_Baseline_Comparison copy.html#simulation-of-murdock-and-okada-1970",
    "href": "projects\\Repetition_CMR\\04_Baseline_Comparison copy.html#simulation-of-murdock-and-okada-1970",
    "title": "compmemlearn",
    "section": "Simulation of Murdock and Okada (1970)",
    "text": "We start by comparing how our prototype- and instance-based implementations of CMR account for behavior in a classic experiment where each item is presented just once per study phase. For these simulations, we used the dataset reported by @murdock1970interresponse. Each of 72 undergraduates performed 20 trials with study lists each consisting of 20 unique words visually presented at either 60 or 120 words per minute. Given a particular subject, words were unique both within and across trials, and randomly selected from the Toronto Word Pool [@friendly1982toronto], a widely-used collection of high frequency nouns, adjectives, and verbs.\nWhile the major focus of the original report by @murdock1970interresponse was to investigate inter-response times in single-trial free recall, here we focus consideration on the content of recorded recall sequences. Because it excludes within-list repetitions of studied items, this dataset presents the opportunity to compare model performance under simplified conditions. Since items’ feature representations are assumed orthogonal under considered variants of CMR, retrieving a pattern of contextual associations given an item-based cue only requires abstraction over the cued item’s pre-experimental and single experimental contextual associations. Interpretation of apparent differences in performance across model variants thus focus primarily on mechanisms for context-based item representation retrieval.\nfrom compmemlearn.fitting import murdock_objective_function, apply_and_concatenate\nfrom compmemlearn.models import Classic_CMR, Instance_CMR\nfrom compmemlearn.models import Trace_Reinstatement_CMR\nfrom compmemlearn.datasets import prepare_murdock1970_data, simulate_data\nfrom scipy.optimize import differential_evolution\nfrom numba.typed import List, Dict\nfrom numba.core import types\nfrom numba import njit\nfrom psifr import fr\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nmurd_trials0, murd_events0, murd_length0 = prepare_murdock1970_data('../../../data/mo1970.txt')\nWe compared the original prototype-based implementation of CMR against our novel instance-based implementation. First we evaluated each model variant based on their ability to predict the specific sequences of recalls exhibited by each participant. Considering all 20 trials performed by each participant in the dataset, we applied the differential evolution optimization technique to find for each model the parameter configuration that maximized the likelihood of recorded recall sequences. We obtained a unique optimal parameter configuration for each unique participant and each considered model variant. To measure the goodness-of-fit for each parameter configuration and corresponding model, ?@fig-murdokafits plots the log-likelihood of each participant’s recall sequences given each model variant’s corresponding optimized parameter configuration. The distribution of log-likelihood scores between participants for the PrototypeCMR and InstanceCMR model variants only marginally differ, suggesting little meaningful difference between variants in their effectiveness accounting for participant recall performance across the dataset.\n\ncmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate'\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ncmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\nsubject_trial_count = 20 # Each subject gets 20 trials/lists a piece.\ncmr_results = []\n\nfor subject, start_index in enumerate(range(0, len(murd_trials0), subject_trial_count)):\n    print(subject, start_index)\n\n    # cost function to be minimized\n    # ours scales inversely with the probability that the data could have been \n    # generated using the specified parameters and our model\n    cost_function = murdock_objective_function(\n        List([murd_trials0[start_index:start_index+subject_trial_count]]), \n        List([murd_length0]),\n        init_cmr,\n        {'sampling_rule': 0, 'mfc_familiarity_scale': 0, \n         'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n        cmr_free_parameters)\n\n    cmr_results.append(differential_evolution(cost_function, cmr_bounds, disp=False))\n    print(cmr_results[-1].fun)\n\n\nicmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n    'context_sensitivity',\n#    'feature_sensitivity'\n    'delay_drift_rate',\n)\n\nicmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n#    (lb, 10),\n#    (lb, 10)\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_icmr(item_count, presentation_count, parameters):\n    return Trace_Reinstatement_CMR(item_count, presentation_count, parameters)\n\nsubject_trial_count = 20 # Each subject gets 20 trials/lists a piece.\nicmr_results = []\n\nfor subject, start_index in enumerate(range(0, len(murd_trials0), subject_trial_count)):\n    print(subject, start_index)\n\n    # cost function to be minimized\n    # ours scales inversely with the probability that the data could have been \n    # generated using the specified parameters and our model\n    cost_function = murdock_objective_function(\n    List([murd_trials0[start_index:start_index+subject_trial_count]]),  \n    List([murd_length0]),\n    init_icmr,\n    {'choice_sensitivity': 1, 'feature_sensitivity': 1, 'context_reinstatement': 7}, \n    icmr_free_parameters)\n\n    icmr_results.append(differential_evolution(cost_function, icmr_bounds, disp=False))\n    print(icmr_results[-1].fun)\n\n\nplt.style.use('default')\n\nindividual_fits = [result.fun for result in cmr_results] + [result.fun for result in icmr_results]\nlabels = ['PrototypeCMR'] * len(cmr_results) + ['InstanceCMR'] * len(icmr_results)\nindividual_df = pd.DataFrame(individual_fits, index=labels, columns=['Fit']).reset_index()\nindividual_df.columns = ['Model', 'Fit']\n\nsns.set(style=\"darkgrid\")\n\ng = sns.catplot(x='Model', y='Fit', data=individual_df, kind='violin', inner='stick')\nsns.swarmplot(x=\"Model\", y=\"Fit\", color=\"k\", size=3, data=individual_df, ax=g.ax)\ng.ax.set_ylabel('Individual-Level Fitted Model Log-Likelihoods');\n#plt.savefig('individual_murdock1970.pdf', bbox_inches=\"tight\")\n\nsummary_table = pd.DataFrame(group.describe().rename(columns={'Fit':name}).squeeze()\n            for name, group in individual_df.groupby('Model')).T.to_markdown()\n\n\n\n\n\nprint(summary_table)\n\nAs a follow-up, we also compared how readily each model could account for organizational summary statistics in the dataset. We found for each model variant the optimal parameter configuration maximizing the likelihood of the entire dataset rather than participant-by-participant. Using each fitted model variant, we simulated 1000 unique free recall trials and measured summary statistics from the result. Figure 1 plots for each model against the corresponding statistics collected over the dataset how recall probability varies as a function of serial position, how the probability of recalling an item first varies as a function of serial position, and how the conditional recall probabability of an item varies as a function of its serial lag from the previously recalled item. Recapitulating our comparison of log-likelihood distributions fitted over discrete participants, we found that both our prototype-based and instance-based CMR implementations account for these benchmark organizational summary statistics across the full dataset to similar extents. To build on this finding of broad model equivalence with respect to the results reported by @murdock1970interresponse, we consider the model variants under broader experimental conditions.\n\ncost_function = murdock_objective_function(\n    List([murd_trials0]),  \n    List([murd_length0]),\n    init_cmr,\n    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, \n     'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n    cmr_free_parameters)\n\ncmr_result = differential_evolution(cost_function, cmr_bounds, disp=True)\n\n\ncost_function = murdock_objective_function(\n    List([murd_trials0]),  \n    List([murd_length0]),\n    init_icmr,\n    {'choice_sensitivity': 1, 'feature_sensitivity': 1}, \n    icmr_free_parameters)\n\nicmr_result = differential_evolution(cost_function, icmr_bounds, disp=True)\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(cmr_result.x)):\n    fitted_parameters[cmr_free_parameters[i]] = cmr_result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['mfc_familiarity_scale'] = 0\nfitted_parameters['mcf_familiarity_scale'] = 0\nfitted_parameters['drift_familiarity_scale'] = 0\n\nmodel = Classic_CMR(murd_length0, murd_length0, fitted_parameters)\n\nsim_df = simulate_data(model, 1000)\ntrue_df = murd_events0.copy()\n\ncmr_spc = apply_and_concatenate(fr.spc, sim_df, true_df, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_lag_crp = apply_and_concatenate(fr.lag_crp, sim_df, true_df, 'source', ['PrototypeCMR', 'data'])\ncmr_pfr = apply_and_concatenate(fr.pnr, sim_df, true_df, contrast_name='source', labels=['PrototypeCMR', 'data'])\ncmr_pfr = cmr_pfr.query('output <= 1')\n\nfitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\nfor i in range(len(icmr_result.x)):\n    fitted_parameters[icmr_free_parameters[i]] = icmr_result.x[i]\nfitted_parameters['sampling_rule'] = 0\nfitted_parameters['choice_sensitivity'] = 1\nfitted_parameters['feature_sensitivity'] = 1\n\nmodel = init_icmr(murd_length0, murd_length0, fitted_parameters)\n\nsim_df = simulate_data(model, 1000)\nicmr_spc = apply_and_concatenate(fr.spc, sim_df, true_df, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_lag_crp = apply_and_concatenate(fr.lag_crp, sim_df, true_df, 'source', ['InstanceCMR', 'data'])\nicmr_pfr = apply_and_concatenate(fr.pnr, sim_df, true_df, contrast_name='source', labels=['InstanceCMR', 'data'])\nicmr_pfr = icmr_pfr.query('output <= 1')\n\nimport matplotlib.pyplot as plt\n\nsns.set(style='darkgrid')\n\nfig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 15/2), sharey=False)\n\n# serial position curve\nsns.lineplot(ax=axes[0, 0], data=icmr_spc, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[0, 0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[0, 0].set_xticks(np.arange(1, 21, 2))\naxes[0, 0].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[1, 0], data=cmr_spc, x='input', y='recall', err_style='bars', hue='source', legend=False)\naxes[1, 0].set(xlabel='Study Position', ylabel='Recall Rate')\naxes[1, 0].set_xticks(np.arange(1, 21, 2))\naxes[1, 0].set_ylim((0, 1))\n\n# lag crp curve\nmax_lag = 5\nfilt_neg = f'{-max_lag} <= lag < 0'\nfilt_pos = f'0 < lag <= {max_lag}'\n\nsns.lineplot(ax=axes[0, 1], data=icmr_lag_crp.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[0, 1], data=icmr_lag_crp.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[0, 1].set(xlabel='Item\\'s Lag In Study List From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[0, 1].set_xticks(np.arange(-5, 6, 1))\naxes[0, 1].set_ylim((0, 1))\n\nsns.lineplot(ax=axes[1, 1], data=cmr_lag_crp.query(filt_neg), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\nsns.lineplot(ax=axes[1, 1], data=cmr_lag_crp.query(filt_pos), x='lag', y='prob', \n             err_style='bars', hue='source', legend=False)\naxes[1, 1].set(xlabel='Item\\'s Lag In Study List From Last Recalled Item', ylabel='Conditional Recall Rate')\naxes[1, 1].set_xticks(np.arange(-5, 6, 1))\naxes[1, 1].set_ylim((0, 1))\n\n# pfr\nsns.lineplot(data=icmr_pfr, x='input', y='prob', err_style='bars', ax=axes[0, 2], hue='source')\naxes[0, 2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[0, 2].set_xticks(np.arange(1, 21, 2))\naxes[0, 2].set_ylim((0, 1))\n\nsns.lineplot(data=cmr_pfr, x='input', y='prob', err_style='bars', ax=axes[1, 2], hue='source')\naxes[1, 2].set(xlabel='Study Position', ylabel='Probability of First Recall')\naxes[1, 2].set_xticks(np.arange(1, 21, 2))\naxes[1, 2].set_ylim((0, 1))\n\n# set legend of axis 2 outside the plot, to the right\naxes[0, 2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\naxes[1, 2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\nplt.tight_layout(pad=3)\nplt.savefig('overall_murdock1970.pdf', bbox_inches='tight')\n\nNameError: name 'sns' is not defined\n\n\n\n\n\nFigure 1: Comparison of summary statistics between each model against observed data [@murdock1970interresponse]"
  },
  {
    "objectID": "projects\\Repetition_CMR\\report\\ClairExpt6.html#data-overview",
    "href": "projects\\Repetition_CMR\\report\\ClairExpt6.html#data-overview",
    "title": "compmemlearn",
    "section": "Data Overview",
    "text": "import numpy as np\nfrom numba import njit, prange\nfrom compmemlearn.models import Classic_CMR\nfrom numba.typed import Dict\nfrom numba.core import types\n\n@njit(fastmath=True, nogil=True, parallel=True)\ndef lohnas_data_likelihood(trials, presentations, model_class, parameters):\n\n    list_length = len(presentations[0])\n    likelihood = np.ones((len(trials), list_length))\n\n    for trial_index in prange(len(trials)):\n\n        item_count = np.max(presentations[trial_index])\n        trial = trials[trial_index]\n        model = model_class(item_count, list_length, parameters)\n        presentation = presentations[trial_index][presentations[trial_index] > 0] -1 ## modify to support odd indexing\n        model.experience(model.items[presentation])\n\n        model.force_recall()\n        for recall_index in range(len(trial) + 1):\n\n            # identify index of item recalled; if zero then recall is over\n            if recall_index == len(trial) and len(trial) < item_count:\n                recall = 0\n            elif trial[recall_index] == 0:\n                recall = 0\n            else:\n                recall = presentation[trial[recall_index]-1] + 1\n\n            # store probability of and simulate recalling item with this index\n            likelihood[trial_index, recall_index] = \\\n                model.outcome_probabilities()[recall] + 10e-7\n\n            if recall == 0:\n                break\n            model.force_recall(recall)\n\n        # reset model to its pre-retrieval (but post-encoding) state\n        model.force_recall(0)\n\n    return -np.sum(np.log(likelihood))\n\ndef lohnas_objective_function(data_to_fit, presentations, model_class, fixed_parameters, free_parameters):\n\n    \"\"\"\n    Generates and returns an objective function for input to support search \n    through parameter space for model fit using an optimization function.\n\n    Returns a function that accepts a vector x specifying arbitrary values for \n    free parameters and returns evaluation of likelihood using the model \n    class, all parameters, and provided data.\n    \"\"\"\n\n    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n    for name, value in fixed_parameters.items():\n        parameters[name] = value\n\n    def objective_function(x):\n        for i in range(len(free_parameters)):\n            parameters[free_parameters[i]] = x[i]\n        return lohnas_data_likelihood(data_to_fit, presentations, model_class, parameters)\n\n    return objective_function"
  },
  {
    "objectID": "projects\\Repetition_CMR\\report\\ClairExpt6.html#condition-wise-fitting",
    "href": "projects\\Repetition_CMR\\report\\ClairExpt6.html#condition-wise-fitting",
    "title": "compmemlearn",
    "section": "Condition-Wise Fitting",
    "text": "cmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ncmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n]\n\nconditions = ['Control', 'RP']\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\ncmr_results = []\nfor condition in [0, 1]:\n    selection = list_types == condition\n    cost_function = lohnas_objective_function(\n        trials[selection], \n        presentations[selection],\n        init_cmr,\n        {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0, 'delay_drift_rate': 0}, \n        cmr_free_parameters)\n\n    cmr_results.append(differential_evolution(cost_function, cmr_bounds, disp=True))\n\ndifferential_evolution step 1: f(x)= 5050.66\ndifferential_evolution step 2: f(x)= 3739.1\ndifferential_evolution step 3: f(x)= 3280.2\ndifferential_evolution step 4: f(x)= 3280.2\ndifferential_evolution step 5: f(x)= 3158.42\ndifferential_evolution step 6: f(x)= 3158.42\ndifferential_evolution step 7: f(x)= 3133.04\ndifferential_evolution step 8: f(x)= 3122.74\ndifferential_evolution step 9: f(x)= 3122.74\ndifferential_evolution step 10: f(x)= 3114.31\ndifferential_evolution step 11: f(x)= 3114.31\ndifferential_evolution step 12: f(x)= 3106.81\ndifferential_evolution step 13: f(x)= 3106.81\ndifferential_evolution step 14: f(x)= 3106.81\ndifferential_evolution step 15: f(x)= 3103.33\ndifferential_evolution step 16: f(x)= 3083.54\ndifferential_evolution step 17: f(x)= 3042.02\ndifferential_evolution step 18: f(x)= 3042.02\ndifferential_evolution step 19: f(x)= 3033.52\ndifferential_evolution step 20: f(x)= 3007.12\ndifferential_evolution step 21: f(x)= 3007.12\ndifferential_evolution step 22: f(x)= 3007.12\ndifferential_evolution step 23: f(x)= 3007.12\ndifferential_evolution step 24: f(x)= 3007.12\ndifferential_evolution step 25: f(x)= 3007.12\ndifferential_evolution step 26: f(x)= 3007.12\ndifferential_evolution step 27: f(x)= 3007.12\ndifferential_evolution step 28: f(x)= 3007.12\ndifferential_evolution step 29: f(x)= 3002.45\ndifferential_evolution step 30: f(x)= 3002.45\ndifferential_evolution step 31: f(x)= 3002.45\ndifferential_evolution step 32: f(x)= 3002.45\ndifferential_evolution step 33: f(x)= 3002.45\ndifferential_evolution step 34: f(x)= 3002.45\ndifferential_evolution step 35: f(x)= 3002.45\ndifferential_evolution step 36: f(x)= 3002.45\ndifferential_evolution step 37: f(x)= 2996.18\ndifferential_evolution step 38: f(x)= 2996.18\ndifferential_evolution step 39: f(x)= 2996.18\ndifferential_evolution step 40: f(x)= 2992.88\ndifferential_evolution step 1: f(x)= 5564.48\ndifferential_evolution step 2: f(x)= 4870.95\ndifferential_evolution step 3: f(x)= 4369.42\ndifferential_evolution step 4: f(x)= 3623.9\ndifferential_evolution step 5: f(x)= 3448.84\ndifferential_evolution step 6: f(x)= 3448.84\ndifferential_evolution step 7: f(x)= 3448.84\ndifferential_evolution step 8: f(x)= 3420.41\ndifferential_evolution step 9: f(x)= 3417.5\ndifferential_evolution step 10: f(x)= 3394.18\ndifferential_evolution step 11: f(x)= 3317.27\ndifferential_evolution step 12: f(x)= 3317.27\ndifferential_evolution step 13: f(x)= 3317.27\ndifferential_evolution step 14: f(x)= 3317.27\ndifferential_evolution step 15: f(x)= 3293.09\ndifferential_evolution step 16: f(x)= 3293.09\ndifferential_evolution step 17: f(x)= 3293.09\ndifferential_evolution step 18: f(x)= 3271.59\ndifferential_evolution step 19: f(x)= 3271.59\ndifferential_evolution step 20: f(x)= 3271.59\ndifferential_evolution step 21: f(x)= 3271.59\ndifferential_evolution step 22: f(x)= 3267.88\ndifferential_evolution step 23: f(x)= 3267.88\ndifferential_evolution step 24: f(x)= 3267.72\ndifferential_evolution step 25: f(x)= 3250.9\ndifferential_evolution step 26: f(x)= 3250.9\ndifferential_evolution step 27: f(x)= 3250.9\ndifferential_evolution step 28: f(x)= 3232.47\ndifferential_evolution step 29: f(x)= 3194.53\ndifferential_evolution step 30: f(x)= 3194.53\ndifferential_evolution step 31: f(x)= 3194.53\n\n\n\ncmr_results\n\n[     fun: 2975.134867581669\n      jac: array([-0.06730261, -0.19517756, -0.01059561,  0.04656613, -0.01514309,\n        -9.09153637,  7.70419319,  0.        ,  0.07862582, -0.03537934,\n        -0.04138201])\n  message: 'Optimization terminated successfully.'\n     nfev: 7377\n      nit: 40\n  success: True\n        x: array([6.94621761e-01, 9.00820304e-01, 8.27694497e-01, 6.29486794e-01,\n        8.02814419e-02, 1.00000000e+00, 2.22044605e-16, 6.19704899e+01,\n        4.03765537e-02, 1.29131693e-01, 5.84921887e+00]),\n      fun: 3160.6782599545445\n      jac: array([ 0.05397851, -0.10190888, -0.00568434,  0.00204636, -0.00422915,\n         0.00104592, -0.00304681,  0.01127773,  0.02678462,  0.01732587,\n        -0.00927685])\n  message: 'Optimization terminated successfully.'\n     nfev: 6900\n      nit: 31\n  success: True\n        x: array([0.77422693, 0.84571273, 0.82856235, 0.13214982, 0.88051187,\n        0.29551315, 4.76381681, 0.31516321, 0.03725594, 0.12108304,\n        1.3268154 ])]\n\n\nfrom numba import int32\n\n@njit(nogil=True)\ndef simulate_array_from_presentations(model_class, parameters, presentations, experiment_count):\n\n    # simulate retrieval for the specified number of times, tracking results in trials array\n    trials = np.zeros((experiment_count * len(presentations), np.max(presentations)), dtype=int32)\n    \n    for experiment in range(experiment_count):\n        for trial_index in range(len(presentations)):\n        \n            # retrieve presentation sequence for this trial and measure number of unique items\n            #presentation = presentations[trial_index]\n            presentation = presentations[trial_index][presentations[trial_index] > 0] -1\n            item_count = np.max(presentation)+1\n            \n            # simulate recall and identify first study position of each recalled item\n            model = model_class(item_count, len(presentation), parameters)\n            model.experience(model.items[presentation])\n            recalled = model.free_recall()\n            \n            for i in range(len(recalled)):\n                trials[experiment*len(presentations) + trial_index, i] = find_first(recalled[i], presentation) + 1\n    \n    return trials\n\n@njit(nogil=True)\ndef find_first(item, vec):\n    \"\"\"return the index of the first occurence of item in vec\"\"\"\n    for i in range(len(vec)):\n        if item == vec[i]:\n            return i\n    return -1\n# simulate data corresponding to each cmr_result\n\nfrom numba.typed import Dict\nfrom numba.core import types\nfrom numpy import matlib\n\nexperiment_count = 1000\n\nsim_trials = []\nsim_presentations = []\nfitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\n\nfor i, cmr_result in enumerate(cmr_results):\n\n    for j in range(len(cmr_result.x)):\n        fitted_parameters[cmr_free_parameters[j]] = cmr_result.x[j]\n        \n    fitted_parameters['sampling_rule'] = 0\n    fitted_parameters['mfc_familiarity_scale'] = 0\n    fitted_parameters['mcf_familiarity_scale'] = 0\n    fitted_parameters['drift_familiarity_scale'] = 0\n    fitted_parameters['delay_drift_rate'] = 0\n\n    sim_trials.append(simulate_array_from_presentations(\n        init_cmr, fitted_parameters, presentations[list_types==i], experiment_count))\n    sim_presentations.append(np.matlib.repmat(presentations[list_types==i], experiment_count, 1))\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(2):\n    \n    test_spc= flex_mixed_spc(trials[list_types==condition], presentations[list_types==condition, :-3])\n    axes[0].plot(np.arange(len(test_spc)), test_spc, label=conditions[condition])\n\n    sim_spc = flex_mixed_spc(sim_trials[condition], sim_presentations[condition][:, :-3])\n    axes[1].plot(np.arange(len(sim_spc)), sim_spc, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='Recall Rate') \nfig.suptitle(\"Serial Position Curve\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nitem_count = 25\nfor condition in range(2):\n\n    test_crp= flex_mixed_crp(trials[list_types==condition], presentations[list_types==condition, :-3])\n    test_crp[item_count-1] = np.nan\n    axes[0].plot(np.arange(len(test_crp)), test_crp, label=conditions[condition])\n\n    sim_crp = flex_mixed_crp(sim_trials[condition], sim_presentations[condition][:, :-3])\n    sim_crp[item_count-1] = np.nan\n    axes[1].plot(np.arange(len(sim_crp)), sim_crp, label=conditions[condition])\n\n#plt.xlabel('Lag')\n#plt.ylabel('Conditional Response Probability')   \naxes[0].set_xticks(np.arange(0, len(test_crp), 4))\naxes[0].set_xticklabels(np.arange(0, len(test_crp), 4) - (item_count - 1))\naxes[1].set_xticks(np.arange(0, len(sim_crp), 4))\naxes[1].set_xticklabels(np.arange(0, len(sim_crp), 4) - (item_count - 1))\nfig.suptitle('Lag-CRP')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(2):\n\n    test_pfr = flex_mixed_pfr(trials[list_types==condition], presentations[list_types==condition, :-3])\n    axes[0].plot(np.arange(len(test_pfr)), test_pfr, label=conditions[condition])\n\n    sim_pfr = flex_mixed_pfr(sim_trials[condition], sim_presentations[condition][:, :-3])\n    axes[1].plot(np.arange(len(sim_pfr)), sim_pfr, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='First Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='First Recall Rate') \nfig.suptitle(\"Probability of First Recall\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(2):\n    test_csp = fast_csp(trials[list_types==condition], list_length)\n    test_csp[test_csp==0] = np.nan\n    axes[0].plot(np.arange(list_length+1), test_csp, label=conditions[condition])\n\n    sim_csp = fast_csp(sim_trials[condition], list_length)\n    sim_csp[sim_csp==0] = np.nan\n    axes[1].plot(np.arange(list_length+1), sim_csp, label=conditions[condition])\n\n#plt.xlabel('Recall Position')\n#plt.ylabel('Conditional Stop Probability')\nfig.suptitle('Conditional Stop Probability')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)"
  },
  {
    "objectID": "projects\\Repetition_CMR\\report\\Data_Overview.html#data-overview",
    "href": "projects\\Repetition_CMR\\report\\Data_Overview.html#data-overview",
    "title": "compmemlearn",
    "section": "Data Overview",
    "text": "Our analyses focus on data reported by Lohnas & Kahana (2014) to evaluate a retrieved context account of spacing and repetition effects in free recall. Across 4 sessions, 35 subjects performed delayed free recall of 48 lists. Subjects were University of Pennsylvania undergraduates, graduates and staff, age 18-32. List items were drawn from a pool of 1638 words taken from the University of South Florida free association norms (Nelson, McEvoy, & Schreiber, 2004; Steyvers, Shiffrin, & Nelson, 2004, available at http://memory.psych.upenn.edu/files/wordpools/PEERS_wordpool.zip). Within each session, words were drawn without replacement. Words could repeat across sessions so long as they did not repeat in two successive sessions. Words were also selected to ensure that no strong semantic associates co-occurred in a given list (i.e., the semantic relatedness between any two words on a given list, as determined using WAS (Steyvers et al., 2004), did not exceed a threshold value of 0.55).\nSubjects encountered four different types of lists: 1. Control lists that contained all once-presented items;\n2. pure massed lists containing all twice-presented items; 3. pure spaced lists consisting of items presented twice at lags 1-8, where lag is defined as the number of intervening items between a repeated item’s presentations; 4. mixed lists consisting of once presented, massed and spaced items. Within each session, subjects encountered three lists of each of these four types.\nIn each list there were 40 presentation positions, such that in the control lists each position was occupied by a unique list item, and in the pure massed and pure spaced lists, 20 unique words were presented twice to occupy the 40 positions. In the mixed lists 28 once-presented and six twice-presented words occupied the 40 positions. In the pure spaced lists, spacings of repeated items were chosen so that each of the lags 1-8 occurred with equal probability. In the mixed lists, massed repetitions (lag=0) and spaced repetitions (lags 1-8) were chosen such that each of the 9 lags of 0-8 were used exactly twice within each session. The order of presentation for the different list types was randomized within each session. For the first session, the first four lists were chosen so that each list type was presented exactly once. An experimenter sat in with the subject for these first four lists, though no subject had difficulty understanding the task. The data for this experiment is stored in data/repFR.mat.\n\nfrom compmemlearn.datasets import prepare_lohnas2014_data\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../../data/repFR.mat')\n\nevents.head()\n\n\n\n\n  \n    \n      \n      subject\n      list\n      item\n      input\n      output\n      study\n      recall\n      repeat\n      intrusion\n      condition\n    \n  \n  \n    \n      0\n      1\n      1\n      0\n      1\n      1.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      1\n      1\n      1\n      1\n      2\n      2.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      2\n      1\n      1\n      2\n      3\n      3.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      3\n      1\n      1\n      3\n      4\n      4.0\n      True\n      True\n      0\n      False\n      4\n    \n    \n      4\n      1\n      1\n      4\n      5\n      5.0\n      True\n      True\n      0\n      False\n      4\n    \n  \n\n\n\n\n\nBenchmark Summary Statistics\nWith some modifications to their codebase, I can extract benchmark summary statistics – serial position curve, lag-CRP curve, PFR curve, stop probability – from each condition of this dataset.\nfrom compmemlearn.analyses import flex_mixed_spc, flex_mixed_crp, flex_mixed_pfr, fast_csp, alternative_contiguity, rpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nconditions = ['Control', 'Massed', 'Spaced', 'Mixed']\n\nplt.figure(figsize=(7.5, 5))\n\nfor condition in range(4):\n    test_spc= flex_mixed_spc(trials[list_types==condition+1], presentations[list_types==condition+1])\n    plt.plot(np.arange(len(test_spc)), test_spc, label=conditions[condition])\n\nplt.title('Serial Position Curve')\nplt.xlabel('Presentation Position')\nplt.ylabel('Recall Rate')    \nplt.legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\nplt.figure(figsize=(7.5, 5))\n\nfor condition in range(4):\n    test_crp= flex_mixed_crp(trials[list_types==condition+1], presentations[list_types==condition+1])\n    test_crp[len(presentations[0])-1] = np.nan\n    plt.plot(np.arange(len(test_crp)), test_crp, label=conditions[condition])\n\nplt.title('Lag-CRP')\nplt.xlabel('Lag')\nplt.ylabel('Conditional Response Probability')   \nplt.xticks(np.arange(0, len(test_crp), 4), np.arange(0, len(test_crp), 4) - 39)    \nplt.legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\nplt.figure(figsize=(7.5, 5))\n\nfor condition in range(4):\n    test_pfr= flex_mixed_pfr(trials[list_types==condition+1], presentations[list_types==condition+1])\n    plt.plot(np.arange(list_length), test_pfr, label=conditions[condition])\n\nplt.title('Probability of First Recall')\nplt.xlabel('Presentation Position')\nplt.ylabel('First Recall Rate')    \nplt.legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\nplt.figure(figsize=(7.5, 5))\n\nfor condition in range(4):\n    test_csp = fast_csp(trials[list_types==condition+1], list_length)\n    test_csp[test_csp==0] = np.nan\n    plt.plot(np.arange(list_length+1), test_csp, label=conditions[condition])\n\nplt.xlabel('Recall Position')\nplt.ylabel('Conditional Stop Probability')\nplt.title('Conditional Stop Probability')\nplt.legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)"
  },
  {
    "objectID": "projects\\Repetition_CMR\\report\\Data_Overview.html#repetition-effects",
    "href": "projects\\Repetition_CMR\\report\\Data_Overview.html#repetition-effects",
    "title": "compmemlearn",
    "section": "Repetition Effects",
    "text": "for condition in range(2, 4):\n    plt.figure(figsize=(7.5, 5))\n    test_altcrp= alternative_contiguity(\n        trials[list_types==condition+1], presentations[list_types==condition+1], 6, 2)\n    test_altcrp[:, len(presentations[0])-1] = np.nan\n    plt.plot(np.arange(7), test_altcrp[0][list_length-1-3:list_length-1+4], label='First Presentation')\n    plt.plot(np.arange(7), test_altcrp[1][list_length-1-3:list_length-1+4], label='Second Presentation')\n    plt.xticks(np.arange(7), np.arange(7) -3)   \n    plt.legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    plt.title('Alternative Contiguity, ' + conditions[condition] + ' Condition')\n    plt.tight_layout(pad=3)\n    plt.xlabel('Lag')\n    plt.ylabel('Conditional Response Probability')   \n\n\n\n\n\n\n\n\nplt.figure(figsize=(7.5, 5))\ntest_altcrp= alternative_contiguity(\n    trials[list_types>=3], presentations[list_types>=3], 6, 2)\ntest_altcrp[:, len(presentations[0])-1] = np.nan\nplt.plot(np.arange(7), test_altcrp[0][list_length-1-3:list_length-1+4], label='First Presentation')\nplt.plot(np.arange(7), test_altcrp[1][list_length-1-3:list_length-1+4], label='Second Presentation')\nplt.xticks(np.arange(7), np.arange(7) -3)    \nplt.legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.title('Alternative Contiguity, Spaced + Mixed Conditions')\nplt.tight_layout(pad=3)\nplt.xlabel('Lag')\nplt.ylabel('Conditional Response Probability');\n\n\n\n\n\nimport seaborn as sns\n\ncondition = 4\nsource = 'Lohnas & Kahana (2014)'\n\nsubject_count = len(np.unique(events.subject))\ntrial_count = int(np.max(events.list)/4)\n\ndata = rpl(\n    presentations[list_types==condition], trials[list_types==condition], \n    subject_count, trial_count, list_length)\n\nplt.figure(figsize=(7.5, 5))\nsns.barplot(data=data, x='lag', y='prob')\n\nplt.title('Condition {}, {}'.format(condition, source))\nplt.xlabel('Number of Intervening Items Between Repetitions')\nplt.ylabel('Recall Probability');\n\n\n\n\nStill debugging: - OR Score (not really a repetition effect, though!) - Transition Rate Between Neighbors of Item Repetitions"
  },
  {
    "objectID": "projects\\Repetition_CMR\\report\\Likelihood_Based_Fitting.html#likelihood-based-model-evaluation",
    "href": "projects\\Repetition_CMR\\report\\Likelihood_Based_Fitting.html#likelihood-based-model-evaluation",
    "title": "compmemlearn",
    "section": "Likelihood-based Model Evaluation",
    "text": "To evaluate how effectively a model accounts for the responses in our datasets, we applied a likelihood-based model comparison technique introduced by @kragel2015neural that assesses model variants based on how accurately they can predict the specific sequence in which items are recalled. According to this method, repeated items and intrusions (responses naming items not presented in the list) are included from participants’ recall sequences. Given an arbitrary parameter configuration and a sequences of recalls to predict, a model simulates encoding of each item presented in the corresponding study list in its respective order. Then, beginning with the first item the participant recalled in the trial, the probability assigned by the model to the recall event is recorded. Next, the model simulates retrieval of that item, and given its updated state is used to similarly predict the next event in the recall sequence - either retrieval of another item, or termination of recall - and so on until retrieval terminates. The probability that the model assigns to each event in the recall sequence conditional on previous trial events are thus all recorded. These recorded probabilities are then log-transformed and summed to obtain the log-likelihood of the entire sequence. Across an entire dataset containing multiple trials, sequence log-likelihoods can be summed to obtain a log-likelihood of the entire dataset given the model and its parameters. Higher log-likelihoods assigned to datasets by a model correspond to better effectiveness accounting for those datasets.\nTo find the parameter configuration for each model that maximizes its predicted likelihood of observed data, we applied the optimization technique called differential evolution [@storn1997differential] as implemented in the Python library scipy. Differential evolution maintains a population of possible parameter configurations; at each update, the algorithm mutates each population member by stochastically mixing them with other members of the population. If the new configuration of a member is an improvement over its previous configuration, then it becomes part of the updated population. Otherwise, the new parameter configuration is discarded. Through repetition of this process, gradually driving the population toward configurations that maximize the log-likelihood of the observed data assigned by the considered model. This maximal log-likelihood and its corresponding parameter configurations form the basis of comparison between models.\nWhen exploring how effectively the model accounts for qualitative benchmark phenomena in free recall performance such as the temporal contiguity and serial position effects, we optimized parameter configurations and evaluated performance across all subjects in the considered dataset, except where otherwise noted. For direct comparison of the log-likelihoods of recall sequences, however, we search for optimal parameters and perform comparison at the subject level, considering distributions of log-likelihood values calculated between subjects when contrasting model versions.\nfrom compmemlearn.datasets import prepare_lohnas2014_data, simulate_array_from_presentations\nfrom compmemlearn.fitting import lohnas_objective_function\nfrom compmemlearn.models import Classic_CMR\nfrom scipy.optimize import differential_evolution\nfrom numba import njit\nimport numpy as np\nfrom numba import int32\nfrom compmemlearn.analyses import flex_mixed_spc, flex_mixed_crp, flex_mixed_pfr, fast_csp, alternative_contiguity, rpl\nimport matplotlib.pyplot as plt\n\nconditions = ['Control', 'Massed', 'Spaced', 'Mixed']\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../../data/repFR.mat')\n\nConditionwise Fits\nWe’ll fit CMR to the Lohnas Conditions One-By-One instead of altogether. Tests of generalization between study conditions will be reserved to another section.\n\ncmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'delay_drift_rate'\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ncmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\ncmr_results = []\nfor condition in [1, 2, 3, 4]:\n    selection = list_types == condition\n    cost_function = lohnas_objective_function(\n        trials[selection], \n        presentations[selection],\n        init_cmr,\n        {'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n        cmr_free_parameters)\n\n    cmr_results.append(differential_evolution(cost_function, cmr_bounds, disp=True))\n\n# simulate data corresponding to each cmr_result\n\nfrom numba.typed import Dict\nfrom numba.core import types\nfrom numpy import matlib\n\nexperiment_count = 1000\n\nsim_trials = []\nsim_presentations = []\nfitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\n\nfor i, cmr_result in enumerate(cmr_results):\n\n    for j in range(len(cmr_result.x)):\n        fitted_parameters[cmr_free_parameters[j]] = cmr_result.x[j]\n        \n    fitted_parameters['sampling_rule'] = 0\n    fitted_parameters['mfc_familiarity_scale'] = 0\n    fitted_parameters['mcf_familiarity_scale'] = 0\n    fitted_parameters['drift_familiarity_scale'] = 0\n\n    sim_trials.append(simulate_array_from_presentations(\n        init_cmr, fitted_parameters, presentations[list_types==i+1], experiment_count))\n    sim_presentations.append(np.matlib.repmat(presentations[list_types==i+1], experiment_count, 1))\n\n\nSerial Position Curve\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n    \n    test_spc= flex_mixed_spc(trials[list_types==condition+1], presentations[list_types==condition+1])\n    axes[0].plot(np.arange(len(test_spc)), test_spc, label=conditions[condition])\n\n    sim_spc = flex_mixed_spc(sim_trials[condition], sim_presentations[condition])\n    axes[1].plot(np.arange(len(sim_spc)), sim_spc, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='Recall Rate') \nfig.suptitle(\"Serial Position Curve\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nLag-CRP\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n\n    test_crp= flex_mixed_crp(trials[list_types==condition+1], presentations[list_types==condition+1])\n    test_crp[len(presentations[0])-1] = np.nan\n    axes[0].plot(np.arange(len(test_crp)), test_crp, label=conditions[condition])\n\n    sim_crp = flex_mixed_crp(sim_trials[condition], sim_presentations[condition])\n    sim_crp[len(presentations[0])-1] = np.nan\n    axes[1].plot(np.arange(len(sim_crp)), sim_crp, label=conditions[condition])\n\n#plt.xlabel('Lag')\n#plt.ylabel('Conditional Response Probability')   \naxes[0].set_xticks(np.arange(0, len(test_crp), 4))\naxes[0].set_xticklabels(np.arange(0, len(test_crp), 4) - 39)\naxes[1].set_xticks(np.arange(0, len(sim_crp), 4))\naxes[1].set_xticklabels(np.arange(0, len(sim_crp), 4) - 39)\nfig.suptitle('Lag-CRP')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nProbability of First Recall\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n\n    test_pfr = flex_mixed_pfr(trials[list_types==condition+1], presentations[list_types==condition+1])\n    axes[0].plot(np.arange(len(test_pfr)), test_pfr, label=conditions[condition])\n\n    sim_pfr = flex_mixed_pfr(sim_trials[condition], sim_presentations[condition])\n    axes[1].plot(np.arange(len(sim_pfr)), sim_pfr, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='First Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='First Recall Rate') \nfig.suptitle(\"Probability of First Recall\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nConditional Stop Probability\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n    test_csp = fast_csp(trials[list_types==condition+1], list_length)\n    test_csp[test_csp==0] = np.nan\n    axes[0].plot(np.arange(list_length+1), test_csp, label=conditions[condition])\n\n    sim_csp = fast_csp(sim_trials[condition], list_length)\n    sim_csp[sim_csp==0] = np.nan\n    axes[1].plot(np.arange(list_length+1), sim_csp, label=conditions[condition])\n\n#plt.xlabel('Recall Position')\n#plt.ylabel('Conditional Stop Probability')\nfig.suptitle('Conditional Stop Probability')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nAlternative Contiguity\n\nfor condition in range(2, 4):\n    \n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n    \n    test_altcrp= alternative_contiguity(\n        trials[list_types==condition+1], presentations[list_types==condition+1], 6, 2)\n    test_altcrp[:, list_length-1] = np.nan\n    axes[0].plot(np.arange(7), test_altcrp[0][list_length-1-3:list_length-1+4], label='First Presentation')\n    axes[0].plot(np.arange(7), test_altcrp[1][list_length-1-3:list_length-1+4], label='Second Presentation')\n    axes[0].set_xticks(np.arange(7))\n    axes[0].set_xticklabels(np.arange(7) -3) \n\n    sim_altcrp = alternative_contiguity(\n        sim_trials[condition], sim_presentations[condition], 6, 2)\n    sim_altcrp[:, list_length-1] = np.nan\n    axes[1].plot(np.arange(7), sim_altcrp[0][list_length-1-3:list_length-1+4], label='First Presentation')\n    axes[1].plot(np.arange(7), sim_altcrp[1][list_length-1-3:list_length-1+4], label='Second Presentation')\n    axes[1].set_xticks(np.arange(7))\n    axes[1].set_xticklabels(np.arange(7) -3)\n\n    axes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    fig.suptitle('Alternative Contiguity, ' + conditions[condition] + ' Condition')\n    plt.tight_layout(pad=3)\n    #plt.xlabel('Lag')\n    #plt.ylabel('Conditional Response Probability')   \n\n\n\n\n\n\n\n\n\nSpacing Effect\n\nimport seaborn as sns\n\ncondition = 4\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nsubject_count = len(np.unique(events.subject))\ntrial_count = int(np.max(events.list)/4)\n\ndata = rpl(\n    presentations[list_types==condition], trials[list_types==condition], \n    subject_count, trial_count, list_length)\n\nsns.barplot(ax=axes[0], data=data, x='lag', y='prob')\n\nsim_data = rpl(\n    sim_presentations[3], sim_trials[3],\n    subject_count, trial_count, list_length)\n\nsns.barplot(ax=axes[1], data=sim_data, x='lag', y='prob')\n    \nfig.suptitle(\"Recall Probability by Spacing\")\nplt.tight_layout(pad=3)"
  },
  {
    "objectID": "projects\\Repetition_CMR\\report\\Likelihood_Based_Fitting_CMRDE.html#excluding-the-delay-drift-rate-parameter",
    "href": "projects\\Repetition_CMR\\report\\Likelihood_Based_Fitting_CMRDE.html#excluding-the-delay-drift-rate-parameter",
    "title": "compmemlearn",
    "section": "Excluding the Delay Drift Rate Parameter",
    "text": "To evaluate how effectively a model accounts for the responses in our datasets, we applied a likelihood-based model comparison technique introduced by @kragel2015neural that assesses model variants based on how accurately they can predict the specific sequence in which items are recalled. According to this method, repeated items and intrusions (responses naming items not presented in the list) are included from participants’ recall sequences. Given an arbitrary parameter configuration and a sequences of recalls to predict, a model simulates encoding of each item presented in the corresponding study list in its respective order. Then, beginning with the first item the participant recalled in the trial, the probability assigned by the model to the recall event is recorded. Next, the model simulates retrieval of that item, and given its updated state is used to similarly predict the next event in the recall sequence - either retrieval of another item, or termination of recall - and so on until retrieval terminates. The probability that the model assigns to each event in the recall sequence conditional on previous trial events are thus all recorded. These recorded probabilities are then log-transformed and summed to obtain the log-likelihood of the entire sequence. Across an entire dataset containing multiple trials, sequence log-likelihoods can be summed to obtain a log-likelihood of the entire dataset given the model and its parameters. Higher log-likelihoods assigned to datasets by a model correspond to better effectiveness accounting for those datasets.\nTo find the parameter configuration for each model that maximizes its predicted likelihood of observed data, we applied the optimization technique called differential evolution [@storn1997differential] as implemented in the Python library scipy. Differential evolution maintains a population of possible parameter configurations; at each update, the algorithm mutates each population member by stochastically mixing them with other members of the population. If the new configuration of a member is an improvement over its previous configuration, then it becomes part of the updated population. Otherwise, the new parameter configuration is discarded. Through repetition of this process, gradually driving the population toward configurations that maximize the log-likelihood of the observed data assigned by the considered model. This maximal log-likelihood and its corresponding parameter configurations form the basis of comparison between models.\nWhen exploring how effectively the model accounts for qualitative benchmark phenomena in free recall performance such as the temporal contiguity and serial position effects, we optimized parameter configurations and evaluated performance across all subjects in the considered dataset, except where otherwise noted. For direct comparison of the log-likelihoods of recall sequences, however, we search for optimal parameters and perform comparison at the subject level, considering distributions of log-likelihood values calculated between subjects when contrasting model versions.\nfrom compmemlearn.datasets import prepare_lohnas2014_data, simulate_array_from_presentations\nfrom compmemlearn.fitting import lohnas_objective_function\nfrom compmemlearn.models import Classic_CMR\nfrom scipy.optimize import differential_evolution\nfrom numba import njit\nimport numpy as np\nfrom numba import int32\nfrom compmemlearn.analyses import flex_mixed_spc, flex_mixed_crp, flex_mixed_pfr, fast_csp, alternative_contiguity, rpl\nimport matplotlib.pyplot as plt\n\nconditions = ['Control', 'Massed', 'Spaced', 'Mixed']\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../../data/repFR.mat')\n\nConditionwise Fits\nWe’ll fit CMR to the Lohnas Conditions One-By-One instead of altogether. Tests of generalization between study conditions will be reserved to another section.\n\ncmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n    'mcf_familiarity_scale'\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ncmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n    (lb, 100)\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\ncmr_results = []\nfor condition in [1, 2, 3, 4]:\n    selection = list_types == condition\n    cost_function = lohnas_objective_function(\n        trials[selection], \n        presentations[selection],\n        init_cmr,\n        {'delay_drift_rate':0, 'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n        cmr_free_parameters)\n\n    cmr_results.append(differential_evolution(cost_function, cmr_bounds, disp=True))\n\n# simulate data corresponding to each cmr_result\n\nfrom numba.typed import Dict\nfrom numba.core import types\nfrom numpy import matlib\n\nexperiment_count = 1000\n\nsim_trials = []\nsim_presentations = []\nfitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\n\nfor i, cmr_result in enumerate(cmr_results):\n\n    for j in range(len(cmr_result.x)):\n        fitted_parameters[cmr_free_parameters[j]] = cmr_result.x[j]\n        \n    fitted_parameters['sampling_rule'] = 0\n    fitted_parameters['mfc_familiarity_scale'] = 0\n    fitted_parameters['drift_familiarity_scale'] = 0\n    fitted_parameters['delay_drift_rate'] = 0\n\n    sim_trials.append(simulate_array_from_presentations(\n        init_cmr, fitted_parameters, presentations[list_types==i+1], experiment_count))\n    sim_presentations.append(np.matlib.repmat(presentations[list_types==i+1], experiment_count, 1))\n\n\nSerial Position Curve\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n    \n    test_spc= flex_mixed_spc(trials[list_types==condition+1], presentations[list_types==condition+1])\n    axes[0].plot(np.arange(len(test_spc)), test_spc, label=conditions[condition])\n\n    sim_spc = flex_mixed_spc(sim_trials[condition], sim_presentations[condition])\n    axes[1].plot(np.arange(len(sim_spc)), sim_spc, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='Recall Rate') \nfig.suptitle(\"Serial Position Curve\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nLag-CRP\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n\n    test_crp= flex_mixed_crp(trials[list_types==condition+1], presentations[list_types==condition+1])\n    test_crp[len(presentations[0])-1] = np.nan\n    axes[0].plot(np.arange(len(test_crp)), test_crp, label=conditions[condition])\n\n    sim_crp = flex_mixed_crp(sim_trials[condition], sim_presentations[condition])\n    sim_crp[len(presentations[0])-1] = np.nan\n    axes[1].plot(np.arange(len(sim_crp)), sim_crp, label=conditions[condition])\n\n#plt.xlabel('Lag')\n#plt.ylabel('Conditional Response Probability')   \naxes[0].set_xticks(np.arange(0, len(test_crp), 4))\naxes[0].set_xticklabels(np.arange(0, len(test_crp), 4) - 39)\naxes[1].set_xticks(np.arange(0, len(sim_crp), 4))\naxes[1].set_xticklabels(np.arange(0, len(sim_crp), 4) - 39)\nfig.suptitle('Lag-CRP')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nProbability of First Recall\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n\n    test_pfr = flex_mixed_pfr(trials[list_types==condition+1], presentations[list_types==condition+1])\n    axes[0].plot(np.arange(len(test_pfr)), test_pfr, label=conditions[condition])\n\n    sim_pfr = flex_mixed_pfr(sim_trials[condition], sim_presentations[condition])\n    axes[1].plot(np.arange(len(sim_pfr)), sim_pfr, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='First Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='First Recall Rate') \nfig.suptitle(\"Probability of First Recall\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nConditional Stop Probability\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n    test_csp = fast_csp(trials[list_types==condition+1], list_length)\n    test_csp[test_csp==0] = np.nan\n    axes[0].plot(np.arange(list_length+1), test_csp, label=conditions[condition])\n\n    sim_csp = fast_csp(sim_trials[condition], list_length)\n    sim_csp[sim_csp==0] = np.nan\n    axes[1].plot(np.arange(list_length+1), sim_csp, label=conditions[condition])\n\n#plt.xlabel('Recall Position')\n#plt.ylabel('Conditional Stop Probability')\nfig.suptitle('Conditional Stop Probability')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nAlternative Contiguity\n\nfor condition in range(2, 4):\n    \n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n    \n    test_altcrp= alternative_contiguity(\n        trials[list_types==condition+1], presentations[list_types==condition+1], 6, 2)\n    test_altcrp[:, list_length-1] = np.nan\n    axes[0].plot(np.arange(7), test_altcrp[0][list_length-1-3:list_length-1+4], label='First Presentation')\n    axes[0].plot(np.arange(7), test_altcrp[1][list_length-1-3:list_length-1+4], label='Second Presentation')\n    axes[0].set_xticks(np.arange(7))\n    axes[0].set_xticklabels(np.arange(7) -3) \n\n    sim_altcrp = alternative_contiguity(\n        sim_trials[condition], sim_presentations[condition], 6, 2)\n    sim_altcrp[:, list_length-1] = np.nan\n    axes[1].plot(np.arange(7), sim_altcrp[0][list_length-1-3:list_length-1+4], label='First Presentation')\n    axes[1].plot(np.arange(7), sim_altcrp[1][list_length-1-3:list_length-1+4], label='Second Presentation')\n    axes[1].set_xticks(np.arange(7))\n    axes[1].set_xticklabels(np.arange(7) -3)\n\n    axes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    fig.suptitle('Alternative Contiguity, ' + conditions[condition] + ' Condition')\n    plt.tight_layout(pad=3)\n    #plt.xlabel('Lag')\n    #plt.ylabel('Conditional Response Probability')   \n\n\n\n\n\n\n\n\n\nSpacing Effect\n\nimport seaborn as sns\n\ncondition = 4\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nsubject_count = len(np.unique(events.subject))\ntrial_count = int(np.max(events.list)/4)\n\ndata = rpl(\n    presentations[list_types==condition], trials[list_types==condition], \n    subject_count, trial_count, list_length)\n\nsns.barplot(ax=axes[0], data=data, x='lag', y='prob')\n\nsim_data = rpl(\n    sim_presentations[3], sim_trials[3],\n    subject_count, trial_count, list_length)\n\nsns.barplot(ax=axes[1], data=sim_data, x='lag', y='prob')\n    \nfig.suptitle(\"Recall Probability by Spacing\")\nplt.tight_layout(pad=3)"
  },
  {
    "objectID": "projects\\Repetition_CMR\\report\\Likelihood_Based_Fitting_InstanceCMR.html#likelihood-based-model-evaluation",
    "href": "projects\\Repetition_CMR\\report\\Likelihood_Based_Fitting_InstanceCMR.html#likelihood-based-model-evaluation",
    "title": "compmemlearn",
    "section": "Likelihood-based Model Evaluation",
    "text": "To evaluate how effectively a model accounts for the responses in our datasets, we applied a likelihood-based model comparison technique introduced by @kragel2015neural that assesses model variants based on how accurately they can predict the specific sequence in which items are recalled. According to this method, repeated items and intrusions (responses naming items not presented in the list) are included from participants’ recall sequences. Given an arbitrary parameter configuration and a sequences of recalls to predict, a model simulates encoding of each item presented in the corresponding study list in its respective order. Then, beginning with the first item the participant recalled in the trial, the probability assigned by the model to the recall event is recorded. Next, the model simulates retrieval of that item, and given its updated state is used to similarly predict the next event in the recall sequence - either retrieval of another item, or termination of recall - and so on until retrieval terminates. The probability that the model assigns to each event in the recall sequence conditional on previous trial events are thus all recorded. These recorded probabilities are then log-transformed and summed to obtain the log-likelihood of the entire sequence. Across an entire dataset containing multiple trials, sequence log-likelihoods can be summed to obtain a log-likelihood of the entire dataset given the model and its parameters. Higher log-likelihoods assigned to datasets by a model correspond to better effectiveness accounting for those datasets.\nTo find the parameter configuration for each model that maximizes its predicted likelihood of observed data, we applied the optimization technique called differential evolution [@storn1997differential] as implemented in the Python library scipy. Differential evolution maintains a population of possible parameter configurations; at each update, the algorithm mutates each population member by stochastically mixing them with other members of the population. If the new configuration of a member is an improvement over its previous configuration, then it becomes part of the updated population. Otherwise, the new parameter configuration is discarded. Through repetition of this process, gradually driving the population toward configurations that maximize the log-likelihood of the observed data assigned by the considered model. This maximal log-likelihood and its corresponding parameter configurations form the basis of comparison between models.\nWhen exploring how effectively the model accounts for qualitative benchmark phenomena in free recall performance such as the temporal contiguity and serial position effects, we optimized parameter configurations and evaluated performance across all subjects in the considered dataset, except where otherwise noted. For direct comparison of the log-likelihoods of recall sequences, however, we search for optimal parameters and perform comparison at the subject level, considering distributions of log-likelihood values calculated between subjects when contrasting model versions.\nfrom compmemlearn.datasets import prepare_lohnas2014_data, simulate_array_from_presentations\nfrom compmemlearn.fitting import lohnas_objective_function\nfrom compmemlearn.models import Instance_CMR\nfrom scipy.optimize import differential_evolution\nfrom numba import njit\nimport numpy as np\nfrom numba import int32\nfrom compmemlearn.analyses import flex_mixed_spc, flex_mixed_crp, flex_mixed_pfr, fast_csp, alternative_contiguity, rpl\nimport matplotlib.pyplot as plt\n\nconditions = ['Control', 'Massed', 'Spaced', 'Mixed']\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../../data/repFR.mat')\n\nConditionwise Fits\nWe’ll fit CMR to the Lohnas Conditions One-By-One instead of altogether. Tests of generalization between study conditions will be reserved to another section.\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\nicmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n#    'choice_sensitivity',\n    'context_sensitivity',\n#    'feature_sensitivity'\n    'delay_drift_rate',\n)\n\nicmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n#    (lb, 10),\n#    (lb, 10)\n    (lb, ub),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_icmr(item_count, presentation_count, parameters):\n    return Instance_CMR(item_count, presentation_count, parameters)\n\ncmr_results = []\nfor condition in [1, 2, 3, 4]:\n    selection = list_types == condition\n    cost_function = lohnas_objective_function(\n        trials[selection], \n        presentations[selection],\n        init_icmr,\n        {'choice_sensitivity': 1, 'feature_sensitivity': 1},\n        icmr_free_parameters)\n\n    cmr_results.append(differential_evolution(cost_function, icmr_bounds, disp=True))\n\n# simulate data corresponding to each cmr_result\n\nfrom numba.typed import Dict\nfrom numba.core import types\nfrom numpy import matlib\n\nexperiment_count = 1000\n\nsim_trials = []\nsim_presentations = []\nfitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\n\nfor i, cmr_result in enumerate(cmr_results):\n\n    for j in range(len(cmr_result.x)):\n        fitted_parameters[icmr_free_parameters[j]] = cmr_result.x[j]\n        \n    fitted_parameters['choice_sensitivity'] = 1\n    fitted_parameters['feature_sensitivity'] = 1\n\n    sim_trials.append(simulate_array_from_presentations(\n        init_icmr, fitted_parameters, presentations[list_types==i+1], experiment_count))\n    sim_presentations.append(np.matlib.repmat(presentations[list_types==i+1], experiment_count, 1))\n\n\nSerial Position Curve\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n    \n    test_spc= flex_mixed_spc(trials[list_types==condition+1], presentations[list_types==condition+1])\n    axes[0].plot(np.arange(len(test_spc)), test_spc, label=conditions[condition])\n\n    sim_spc = flex_mixed_spc(sim_trials[condition], sim_presentations[condition])\n    axes[1].plot(np.arange(len(sim_spc)), sim_spc, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='Recall Rate') \nfig.suptitle(\"Serial Position Curve\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nLag-CRP\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n\n    test_crp= flex_mixed_crp(trials[list_types==condition+1], presentations[list_types==condition+1])\n    test_crp[len(presentations[0])-1] = np.nan\n    axes[0].plot(np.arange(len(test_crp)), test_crp, label=conditions[condition])\n\n    sim_crp = flex_mixed_crp(sim_trials[condition], sim_presentations[condition])\n    sim_crp[len(presentations[0])-1] = np.nan\n    axes[1].plot(np.arange(len(sim_crp)), sim_crp, label=conditions[condition])\n\n#plt.xlabel('Lag')\n#plt.ylabel('Conditional Response Probability')   \naxes[0].set_xticks(np.arange(0, len(test_crp), 4))\naxes[0].set_xticklabels(np.arange(0, len(test_crp), 4) - 39)\naxes[1].set_xticks(np.arange(0, len(sim_crp), 4))\naxes[1].set_xticklabels(np.arange(0, len(sim_crp), 4) - 39)\nfig.suptitle('Lag-CRP')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nProbability of First Recall\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n\n    test_pfr = flex_mixed_pfr(trials[list_types==condition+1], presentations[list_types==condition+1])\n    axes[0].plot(np.arange(len(test_pfr)), test_pfr, label=conditions[condition])\n\n    sim_pfr = flex_mixed_pfr(sim_trials[condition], sim_presentations[condition])\n    axes[1].plot(np.arange(len(sim_pfr)), sim_pfr, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='First Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='First Recall Rate') \nfig.suptitle(\"Probability of First Recall\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nConditional Stop Probability\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n    test_csp = fast_csp(trials[list_types==condition+1], list_length)\n    test_csp[test_csp==0] = np.nan\n    axes[0].plot(np.arange(list_length+1), test_csp, label=conditions[condition])\n\n    sim_csp = fast_csp(sim_trials[condition], list_length)\n    sim_csp[sim_csp==0] = np.nan\n    axes[1].plot(np.arange(list_length+1), sim_csp, label=conditions[condition])\n\n#plt.xlabel('Recall Position')\n#plt.ylabel('Conditional Stop Probability')\nfig.suptitle('Conditional Stop Probability')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nAlternative Contiguity\n\nfor condition in range(2, 4):\n    \n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n    \n    test_altcrp= alternative_contiguity(\n        trials[list_types==condition+1], presentations[list_types==condition+1], 6, 2)\n    test_altcrp[:, list_length-1] = np.nan\n    axes[0].plot(np.arange(7), test_altcrp[0][list_length-1-3:list_length-1+4], label='First Presentation')\n    axes[0].plot(np.arange(7), test_altcrp[1][list_length-1-3:list_length-1+4], label='Second Presentation')\n    axes[0].set_xticks(np.arange(7))\n    axes[0].set_xticklabels(np.arange(7) -3) \n\n    sim_altcrp = alternative_contiguity(\n        sim_trials[condition], sim_presentations[condition], 6, 2)\n    sim_altcrp[:, list_length-1] = np.nan\n    axes[1].plot(np.arange(7), sim_altcrp[0][list_length-1-3:list_length-1+4], label='First Presentation')\n    axes[1].plot(np.arange(7), sim_altcrp[1][list_length-1-3:list_length-1+4], label='Second Presentation')\n    axes[1].set_xticks(np.arange(7))\n    axes[1].set_xticklabels(np.arange(7) -3)\n\n    axes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    fig.suptitle('Alternative Contiguity, ' + conditions[condition] + ' Condition')\n    plt.tight_layout(pad=3)\n    #plt.xlabel('Lag')\n    #plt.ylabel('Conditional Response Probability')   \n\n\n\n\n\n\n\n\n\nSpacing Effect\n\nimport seaborn as sns\n\ncondition = 4\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nsubject_count = len(np.unique(events.subject))\ntrial_count = int(np.max(events.list)/4)\n\ndata = rpl(\n    presentations[list_types==condition], trials[list_types==condition], \n    subject_count, trial_count, list_length)\n\nsns.barplot(ax=axes[0], data=data, x='lag', y='prob')\n\nsim_data = rpl(\n    sim_presentations[3], sim_trials[3],\n    subject_count, trial_count, list_length)\n\nsns.barplot(ax=axes[1], data=sim_data, x='lag', y='prob')\n    \nfig.suptitle(\"Recall Probability by Spacing\")\nplt.tight_layout(pad=3)"
  },
  {
    "objectID": "projects\\Repetition_CMR\\report\\Likelihood_Based_Fitting_Without_Delay_Drift.html#excluding-the-delay-drift-rate-parameter",
    "href": "projects\\Repetition_CMR\\report\\Likelihood_Based_Fitting_Without_Delay_Drift.html#excluding-the-delay-drift-rate-parameter",
    "title": "compmemlearn",
    "section": "Excluding the Delay Drift Rate Parameter",
    "text": "To evaluate how effectively a model accounts for the responses in our datasets, we applied a likelihood-based model comparison technique introduced by @kragel2015neural that assesses model variants based on how accurately they can predict the specific sequence in which items are recalled. According to this method, repeated items and intrusions (responses naming items not presented in the list) are included from participants’ recall sequences. Given an arbitrary parameter configuration and a sequences of recalls to predict, a model simulates encoding of each item presented in the corresponding study list in its respective order. Then, beginning with the first item the participant recalled in the trial, the probability assigned by the model to the recall event is recorded. Next, the model simulates retrieval of that item, and given its updated state is used to similarly predict the next event in the recall sequence - either retrieval of another item, or termination of recall - and so on until retrieval terminates. The probability that the model assigns to each event in the recall sequence conditional on previous trial events are thus all recorded. These recorded probabilities are then log-transformed and summed to obtain the log-likelihood of the entire sequence. Across an entire dataset containing multiple trials, sequence log-likelihoods can be summed to obtain a log-likelihood of the entire dataset given the model and its parameters. Higher log-likelihoods assigned to datasets by a model correspond to better effectiveness accounting for those datasets.\nTo find the parameter configuration for each model that maximizes its predicted likelihood of observed data, we applied the optimization technique called differential evolution [@storn1997differential] as implemented in the Python library scipy. Differential evolution maintains a population of possible parameter configurations; at each update, the algorithm mutates each population member by stochastically mixing them with other members of the population. If the new configuration of a member is an improvement over its previous configuration, then it becomes part of the updated population. Otherwise, the new parameter configuration is discarded. Through repetition of this process, gradually driving the population toward configurations that maximize the log-likelihood of the observed data assigned by the considered model. This maximal log-likelihood and its corresponding parameter configurations form the basis of comparison between models.\nWhen exploring how effectively the model accounts for qualitative benchmark phenomena in free recall performance such as the temporal contiguity and serial position effects, we optimized parameter configurations and evaluated performance across all subjects in the considered dataset, except where otherwise noted. For direct comparison of the log-likelihoods of recall sequences, however, we search for optimal parameters and perform comparison at the subject level, considering distributions of log-likelihood values calculated between subjects when contrasting model versions.\nfrom compmemlearn.datasets import prepare_lohnas2014_data, simulate_array_from_presentations\nfrom compmemlearn.fitting import lohnas_objective_function\nfrom compmemlearn.models import Classic_CMR\nfrom scipy.optimize import differential_evolution\nfrom numba import njit\nimport numpy as np\nfrom numba import int32\nfrom compmemlearn.analyses import flex_mixed_spc, flex_mixed_crp, flex_mixed_pfr, fast_csp, alternative_contiguity, rpl\nimport matplotlib.pyplot as plt\n\nconditions = ['Control', 'Massed', 'Spaced', 'Mixed']\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../../data/repFR.mat')\n\nConditionwise Fits\nWe’ll fit CMR to the Lohnas Conditions One-By-One instead of altogether. Tests of generalization between study conditions will be reserved to another section.\n\ncmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ncmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\ncmr_results = []\nfor condition in [1, 2, 3, 4]:\n    selection = list_types == condition\n    cost_function = lohnas_objective_function(\n        trials[selection], \n        presentations[selection],\n        init_cmr,\n        {'delay_drift_rate':0, 'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n        cmr_free_parameters)\n\n    cmr_results.append(differential_evolution(cost_function, cmr_bounds, disp=True))\n\n# simulate data corresponding to each cmr_result\n\nfrom numba.typed import Dict\nfrom numba.core import types\nfrom numpy import matlib\n\nexperiment_count = 1000\n\nsim_trials = []\nsim_presentations = []\nfitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\n\nfor i, cmr_result in enumerate(cmr_results):\n\n    for j in range(len(cmr_result.x)):\n        fitted_parameters[cmr_free_parameters[j]] = cmr_result.x[j]\n        \n    fitted_parameters['sampling_rule'] = 0\n    fitted_parameters['mfc_familiarity_scale'] = 0\n    fitted_parameters['mcf_familiarity_scale'] = 0\n    fitted_parameters['drift_familiarity_scale'] = 0\n    fitted_parameters['delay_drift_rate'] = 0\n\n    sim_trials.append(simulate_array_from_presentations(\n        init_cmr, fitted_parameters, presentations[list_types==i+1], experiment_count))\n    sim_presentations.append(np.matlib.repmat(presentations[list_types==i+1], experiment_count, 1))\n\n\nSerial Position Curve\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n    \n    test_spc= flex_mixed_spc(trials[list_types==condition+1], presentations[list_types==condition+1])\n    axes[0].plot(np.arange(len(test_spc)), test_spc, label=conditions[condition])\n\n    sim_spc = flex_mixed_spc(sim_trials[condition], sim_presentations[condition])\n    axes[1].plot(np.arange(len(sim_spc)), sim_spc, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='Recall Rate') \nfig.suptitle(\"Serial Position Curve\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nLag-CRP\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n\n    test_crp= flex_mixed_crp(trials[list_types==condition+1], presentations[list_types==condition+1])\n    test_crp[len(presentations[0])-1] = np.nan\n    axes[0].plot(np.arange(len(test_crp)), test_crp, label=conditions[condition])\n\n    sim_crp = flex_mixed_crp(sim_trials[condition], sim_presentations[condition])\n    sim_crp[len(presentations[0])-1] = np.nan\n    axes[1].plot(np.arange(len(sim_crp)), sim_crp, label=conditions[condition])\n\n#plt.xlabel('Lag')\n#plt.ylabel('Conditional Response Probability')   \naxes[0].set_xticks(np.arange(0, len(test_crp), 4))\naxes[0].set_xticklabels(np.arange(0, len(test_crp), 4) - 39)\naxes[1].set_xticks(np.arange(0, len(sim_crp), 4))\naxes[1].set_xticklabels(np.arange(0, len(sim_crp), 4) - 39)\nfig.suptitle('Lag-CRP')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nProbability of First Recall\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n\n    test_pfr = flex_mixed_pfr(trials[list_types==condition+1], presentations[list_types==condition+1])\n    axes[0].plot(np.arange(len(test_pfr)), test_pfr, label=conditions[condition])\n\n    sim_pfr = flex_mixed_pfr(sim_trials[condition], sim_presentations[condition])\n    axes[1].plot(np.arange(len(sim_pfr)), sim_pfr, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='First Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='First Recall Rate') \nfig.suptitle(\"Probability of First Recall\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nConditional Stop Probability\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n    test_csp = fast_csp(trials[list_types==condition+1], list_length)\n    test_csp[test_csp==0] = np.nan\n    axes[0].plot(np.arange(list_length+1), test_csp, label=conditions[condition])\n\n    sim_csp = fast_csp(sim_trials[condition], list_length)\n    sim_csp[sim_csp==0] = np.nan\n    axes[1].plot(np.arange(list_length+1), sim_csp, label=conditions[condition])\n\n#plt.xlabel('Recall Position')\n#plt.ylabel('Conditional Stop Probability')\nfig.suptitle('Conditional Stop Probability')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nAlternative Contiguity\n\nfor condition in range(2, 4):\n    \n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n    \n    test_altcrp= alternative_contiguity(\n        trials[list_types==condition+1], presentations[list_types==condition+1], 6, 2)\n    test_altcrp[:, list_length-1] = np.nan\n    axes[0].plot(np.arange(7), test_altcrp[0][list_length-1-3:list_length-1+4], label='First Presentation')\n    axes[0].plot(np.arange(7), test_altcrp[1][list_length-1-3:list_length-1+4], label='Second Presentation')\n    axes[0].set_xticks(np.arange(7))\n    axes[0].set_xticklabels(np.arange(7) -3) \n\n    sim_altcrp = alternative_contiguity(\n        sim_trials[condition], sim_presentations[condition], 6, 2)\n    sim_altcrp[:, list_length-1] = np.nan\n    axes[1].plot(np.arange(7), sim_altcrp[0][list_length-1-3:list_length-1+4], label='First Presentation')\n    axes[1].plot(np.arange(7), sim_altcrp[1][list_length-1-3:list_length-1+4], label='Second Presentation')\n    axes[1].set_xticks(np.arange(7))\n    axes[1].set_xticklabels(np.arange(7) -3)\n\n    axes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    fig.suptitle('Alternative Contiguity, ' + conditions[condition] + ' Condition')\n    plt.tight_layout(pad=3)\n    #plt.xlabel('Lag')\n    #plt.ylabel('Conditional Response Probability')   \n\n\n\n\n\n\n\n\n\nSpacing Effect\n\nimport seaborn as sns\n\ncondition = 4\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nsubject_count = len(np.unique(events.subject))\ntrial_count = int(np.max(events.list)/4)\n\ndata = rpl(\n    presentations[list_types==condition], trials[list_types==condition], \n    subject_count, trial_count, list_length)\n\nsns.barplot(ax=axes[0], data=data, x='lag', y='prob')\n\nsim_data = rpl(\n    sim_presentations[3], sim_trials[3],\n    subject_count, trial_count, list_length)\n\nsns.barplot(ax=axes[1], data=sim_data, x='lag', y='prob')\n    \nfig.suptitle(\"Recall Probability by Spacing\")\nplt.tight_layout(pad=3)"
  },
  {
    "objectID": "projects\\Repetition_CMR\\report\\Likelihood_Based_Fitting_Without_First_Recall.html#excluding-the-first-recall",
    "href": "projects\\Repetition_CMR\\report\\Likelihood_Based_Fitting_Without_First_Recall.html#excluding-the-first-recall",
    "title": "compmemlearn",
    "section": "Excluding the First Recall",
    "text": "To evaluate how effectively a model accounts for the responses in our datasets, we applied a likelihood-based model comparison technique introduced by @kragel2015neural that assesses model variants based on how accurately they can predict the specific sequence in which items are recalled. According to this method, repeated items and intrusions (responses naming items not presented in the list) are included from participants’ recall sequences. Given an arbitrary parameter configuration and a sequences of recalls to predict, a model simulates encoding of each item presented in the corresponding study list in its respective order. Then, beginning with the first item the participant recalled in the trial, the probability assigned by the model to the recall event is recorded. Next, the model simulates retrieval of that item, and given its updated state is used to similarly predict the next event in the recall sequence - either retrieval of another item, or termination of recall - and so on until retrieval terminates. The probability that the model assigns to each event in the recall sequence conditional on previous trial events are thus all recorded. These recorded probabilities are then log-transformed and summed to obtain the log-likelihood of the entire sequence. Across an entire dataset containing multiple trials, sequence log-likelihoods can be summed to obtain a log-likelihood of the entire dataset given the model and its parameters. Higher log-likelihoods assigned to datasets by a model correspond to better effectiveness accounting for those datasets.\nTo find the parameter configuration for each model that maximizes its predicted likelihood of observed data, we applied the optimization technique called differential evolution [@storn1997differential] as implemented in the Python library scipy. Differential evolution maintains a population of possible parameter configurations; at each update, the algorithm mutates each population member by stochastically mixing them with other members of the population. If the new configuration of a member is an improvement over its previous configuration, then it becomes part of the updated population. Otherwise, the new parameter configuration is discarded. Through repetition of this process, gradually driving the population toward configurations that maximize the log-likelihood of the observed data assigned by the considered model. This maximal log-likelihood and its corresponding parameter configurations form the basis of comparison between models.\nWhen exploring how effectively the model accounts for qualitative benchmark phenomena in free recall performance such as the temporal contiguity and serial position effects, we optimized parameter configurations and evaluated performance across all subjects in the considered dataset, except where otherwise noted. For direct comparison of the log-likelihoods of recall sequences, however, we search for optimal parameters and perform comparison at the subject level, considering distributions of log-likelihood values calculated between subjects when contrasting model versions.\nfrom compmemlearn.datasets import prepare_lohnas2014_data\nfrom compmemlearn.models import Classic_CMR\nfrom scipy.optimize import differential_evolution\nfrom numba import njit\nimport numpy as np\nfrom numba import int32\nfrom compmemlearn.analyses import flex_mixed_spc, flex_mixed_crp, flex_mixed_pfr, fast_csp, alternative_contiguity, rpl\nimport matplotlib.pyplot as plt\n\nconditions = ['Control', 'Massed', 'Spaced', 'Mixed']\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../../data/repFR.mat')\n\nUnique Dependencies\nimport numpy as np\nfrom numba import njit, prange\nfrom compmemlearn.models import Classic_CMR\nfrom numba.typed import Dict\nfrom numba.core import types\n\n@njit(fastmath=True, nogil=True, parallel=True)\ndef lohnas_data_likelihood(trials, presentations, model_class, parameters):\n\n    list_length = len(presentations[0])\n    likelihood = np.ones((len(trials), list_length-1)) \n\n    for trial_index in prange(len(trials)):\n\n        item_count = np.max(presentations[trial_index])+1\n        trial = trials[trial_index]\n        model = model_class(item_count, list_length, parameters)\n        model.experience(model.items[presentations[trial_index]])\n\n        model.force_recall()\n        for recall_index in range(len(trial) + 1):\n\n            # identify index of item recalled; if zero then recall is over\n            if recall_index == len(trial) and len(trial) < item_count:\n                recall = 0\n            elif trial[recall_index] == 0:\n                recall = 0\n            else:\n                recall = presentations[trial_index][trial[recall_index]-1] + 1\n\n            # store probability of and simulate recalling item with this index\n            if recall_index > 0:                        \n                likelihood[trial_index, recall_index-1] = \\\n                    model.outcome_probabilities()[recall] + 10e-7\n\n            if recall == 0:\n                break\n            model.force_recall(recall)\n\n        # reset model to its pre-retrieval (but post-encoding) state\n        model.force_recall(0)\n\n    return -np.sum(np.log(likelihood))\n\ndef lohnas_objective_function(data_to_fit, presentations, model_class, fixed_parameters, free_parameters):\n\n    \"\"\"\n    Generates and returns an objective function for input to support search \n    through parameter space for model fit using an optimization function.\n\n    Returns a function that accepts a vector x specifying arbitrary values for \n    free parameters and returns evaluation of likelihood using the model \n    class, all parameters, and provided data.\n    \"\"\"\n\n    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n    for name, value in fixed_parameters.items():\n        parameters[name] = value\n\n    def objective_function(x):\n        for i in range(len(free_parameters)):\n            parameters[free_parameters[i]] = x[i]\n        return lohnas_data_likelihood(data_to_fit, presentations, model_class, parameters)\n\n    return objective_function\nint32=int\n\n#@njit(nogil=True)\ndef simulate_array_from_presentations(\n    model_class, parameters, presentations, experiment_count,  first_recall_item=np.array([])):\n\n    # simulate retrieval for the specified number of times, tracking results in trials array\n    trials = np.zeros((experiment_count * len(presentations), np.max(presentations)+1), dtype=int32)\n    \n    for experiment in range(experiment_count):\n        for trial_index in range(len(presentations)):\n        \n            # retrieve presentation sequence for this trial and measure number of unique items\n            presentation = presentations[trial_index]\n            item_count = np.max(presentation)+1\n            \n            # simulate recall and identify first study position of each recalled item\n            model = model_class(item_count, len(presentation), parameters)\n            model.experience(model.items[presentation])\n            \n            if first_recall_item.size > 0:\n                model.force_recall(first_recall_item[trial_index])\n            \n            recalled = model.free_recall()\n            \n            for i in range(len(recalled)):\n                trials[experiment*len(presentations) + trial_index, i] = find_first(recalled[i], presentation) + 1\n    \n    return trials\n\n#@njit(nogil=True)\ndef find_first(item, vec):\n    \"\"\"return the index of the first occurence of item in vec\"\"\"\n    for i in range(len(vec)):\n        if item == vec[i]:\n            return i\n    return -1\n\n\nConditionwise Fits\nWe’ll fit CMR to the Lohnas Conditions One-By-One instead of altogether. Tests of generalization between study conditions will be reserved to another section.\ncmr_free_parameters = (\n    'encoding_drift_rate',\n    'start_drift_rate',\n    'recall_drift_rate',\n    'shared_support',\n    'item_support',\n    'learning_rate',\n    'primacy_scale',\n    'primacy_decay',\n    'stop_probability_scale',\n    'stop_probability_growth',\n    'choice_sensitivity',\n)\n\nlb = np.finfo(float).eps\nub = 1-np.finfo(float).eps\n\ncmr_bounds = [\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, ub),\n    (lb, 100),\n    (lb, 100),\n    (lb, ub),\n    (lb, 10),\n    (lb, 10),\n]\n\n# cost function to be minimized\n# ours scales inversely with the probability that the data could have been \n# generated using the specified parameters and our model\n@njit(fastmath=True, nogil=True)\ndef init_cmr(item_count, presentation_count, parameters):\n    return Classic_CMR(item_count, presentation_count, parameters)\n\ncmr_results = [\n    [0.75063888, 0.75094444, 0.92366083, 0.66503613, 0.90901694, 0.56730153,\n     0.85689934, 1.29818073, 0.02575404, 0.08702174, 8.19615376], \n    [8.86888535e-01, 8.45701472e-01, 9.03811989e-01, 9.19054930e-01,\n     4.23494614e-02, 1.00000000e+00, 1.56118802e+00, 8.17149013e+01,\n     1.11164590e-02, 2.05599328e-01, 6.72137961e+00], \n    [0.82563326, 0.93089048, 0.88646915, 0.63187823, 1.,         0.31325542,\n    1.26629335, 0.39640346, 0.00757724, 0.22299189, 4.84950264], \n    [0.85324254, 0.93086086, 0.9543999,  0.0847418,  0.73612449, 0.36308409,\n    2.28671447, 0.37075445, 0.02250586, 0.10411078, 1.65456177]]\ncmr_results = []\nfor condition in [1, 2, 3, 4]:\n    selection = list_types == condition\n    cost_function = lohnas_objective_function(\n        trials[selection], \n        presentations[selection],\n        init_cmr,\n        {'delay_drift_rate':0, 'sampling_rule': 0, 'mfc_familiarity_scale': 0, 'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n        cmr_free_parameters)\n\n    cmr_results.append(differential_evolution(cost_function, cmr_bounds, disp=True))\n    print(cmr_results[-1].x)\n# simulate data corresponding to each cmr_result\nfrom numba.typed import Dict\nfrom numba.core import types\nfrom numpy import matlib\n\n\nexperiment_count = 1\n\nsim_trials = []\nsim_presentations = []\nfitted_parameters = Dict.empty(\n        key_type=types.unicode_type, value_type=types.float64)\n\nfor i, cmr_result in enumerate(cmr_results):\n\n    for j in range(len(cmr_result)):\n        fitted_parameters[cmr_free_parameters[j]] = cmr_result[j]\n        \n    fitted_parameters['sampling_rule'] = 0\n    fitted_parameters['mfc_familiarity_scale'] = 0\n    fitted_parameters['mcf_familiarity_scale'] = 0\n    fitted_parameters['drift_familiarity_scale'] = 0\n    fitted_parameters['delay_drift_rate'] = 0\n\n    sim_trials.append(simulate_array_from_presentations(\n        init_cmr, fitted_parameters, presentations[list_types==i+1], experiment_count, trials[list_types==i+1][:, 0]))\n    sim_presentations.append(np.matlib.repmat(presentations[list_types==i+1], experiment_count, 1))\n\n\nSerial Position Curve\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n    \n    test_spc= flex_mixed_spc(trials[list_types==condition+1], presentations[list_types==condition+1])\n    axes[0].plot(np.arange(len(test_spc)), test_spc, label=conditions[condition])\n\n    sim_spc = flex_mixed_spc(sim_trials[condition], sim_presentations[condition])\n    axes[1].plot(np.arange(len(sim_spc)), sim_spc, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='Recall Rate') \nfig.suptitle(\"Serial Position Curve\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nLag-CRP\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n\n    test_crp= flex_mixed_crp(trials[list_types==condition+1], presentations[list_types==condition+1])\n    test_crp[len(presentations[0])-1] = np.nan\n    axes[0].plot(np.arange(len(test_crp)), test_crp, label=conditions[condition])\n\n    sim_crp = flex_mixed_crp(sim_trials[condition], sim_presentations[condition])\n    sim_crp[len(presentations[0])-1] = np.nan\n    axes[1].plot(np.arange(len(sim_crp)), sim_crp, label=conditions[condition])\n\n#plt.xlabel('Lag')\n#plt.ylabel('Conditional Response Probability')   \naxes[0].set_xticks(np.arange(0, len(test_crp), 4))\naxes[0].set_xticklabels(np.arange(0, len(test_crp), 4) - 39)\naxes[1].set_xticks(np.arange(0, len(sim_crp), 4))\naxes[1].set_xticklabels(np.arange(0, len(sim_crp), 4) - 39)\nfig.suptitle('Lag-CRP')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nProbability of First Recall\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n\n    test_pfr = flex_mixed_pfr(trials[list_types==condition+1], presentations[list_types==condition+1])\n    axes[0].plot(np.arange(len(test_pfr)), test_pfr, label=conditions[condition])\n\n    sim_pfr = flex_mixed_pfr(sim_trials[condition], sim_presentations[condition])\n    axes[1].plot(np.arange(len(sim_pfr)), sim_pfr, label=conditions[condition])\n\n#axes[0].set(xlabel='Presentation Position', ylabel='First Recall Rate') \n#axes[1].set(xlabel='Presentation Position', ylabel='First Recall Rate') \nfig.suptitle(\"Probability of First Recall\")\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nConditional Stop Probability\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nfor condition in range(4):\n    test_csp = fast_csp(trials[list_types==condition+1], list_length)\n    test_csp[test_csp==0] = np.nan\n    axes[0].plot(np.arange(list_length+1), test_csp, label=conditions[condition])\n\n    sim_csp = fast_csp(sim_trials[condition], list_length)\n    sim_csp[sim_csp==0] = np.nan\n    axes[1].plot(np.arange(list_length+1), sim_csp, label=conditions[condition])\n\n#plt.xlabel('Recall Position')\n#plt.ylabel('Conditional Stop Probability')\nfig.suptitle('Conditional Stop Probability')\naxes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.tight_layout(pad=3)\n\n\n\n\n\n\nAlternative Contiguity\n\nfor condition in range(2, 4):\n    \n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n    \n    test_altcrp= alternative_contiguity(\n        trials[list_types==condition+1], presentations[list_types==condition+1], 6, 2)\n    test_altcrp[:, list_length-1] = np.nan\n    axes[0].plot(np.arange(7), test_altcrp[0][list_length-1-3:list_length-1+4], label='First Presentation')\n    axes[0].plot(np.arange(7), test_altcrp[1][list_length-1-3:list_length-1+4], label='Second Presentation')\n    axes[0].set_xticks(np.arange(7))\n    axes[0].set_xticklabels(np.arange(7) -3) \n\n    sim_altcrp = alternative_contiguity(\n        sim_trials[condition], sim_presentations[condition], 6, 2)\n    sim_altcrp[:, list_length-1] = np.nan\n    axes[1].plot(np.arange(7), sim_altcrp[0][list_length-1-3:list_length-1+4], label='First Presentation')\n    axes[1].plot(np.arange(7), sim_altcrp[1][list_length-1-3:list_length-1+4], label='Second Presentation')\n    axes[1].set_xticks(np.arange(7))\n    axes[1].set_xticklabels(np.arange(7) -3)\n\n    axes[1].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    fig.suptitle('Alternative Contiguity, ' + conditions[condition] + ' Condition')\n    plt.tight_layout(pad=3)\n    #plt.xlabel('Lag')\n    #plt.ylabel('Conditional Response Probability')   \n\n\n\n\n\n\n\n\n\nSpacing Effect\n\nimport seaborn as sns\n\ncondition = 4\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15/2), sharey=True)\n\nsubject_count = len(np.unique(events.subject))\ntrial_count = int(np.max(events.list)/4)\n\ndata = rpl(\n    presentations[list_types==condition], trials[list_types==condition], \n    subject_count, trial_count, list_length)\n\nsns.barplot(ax=axes[0], data=data, x='lag', y='prob')\n\nsim_data = rpl(\n    sim_presentations[3], sim_trials[3],\n    subject_count, trial_count, list_length)\n\nsns.barplot(ax=axes[1], data=sim_data, x='lag', y='prob')\n    \nfig.suptitle(\"Recall Probability by Spacing\")\nplt.tight_layout(pad=3)"
  },
  {
    "objectID": "projects\\Repetition_CMR\\report\\references.html#references",
    "href": "projects\\Repetition_CMR\\report\\references.html#references",
    "title": "compmemlearn",
    "section": "References",
    "text": ""
  },
  {
    "objectID": "projects\\Repetition_CMR\\report\\Statistic_Based_Fitting_to_Repetition_Effects.html#statistic-focused-fitting",
    "href": "projects\\Repetition_CMR\\report\\Statistic_Based_Fitting_to_Repetition_Effects.html#statistic-focused-fitting",
    "title": "compmemlearn",
    "section": "Statistic-Focused Fitting",
    "text": "Example driven review and analysis fo how fitting model to a specific selection of phenomena helps clarify model limitations. Useful for establishing that model can or cannot account for the considered effect in principle. But limited, even in aggregate, as measure of overall performance.\n\nWhen fitting across an array of phenomena results in a poor account of one or more of them, it’s possible to systematically sleuth for more specific tension-points in our model by fitting the model to each possible combination of 1 or more phenomena in the array, effectively isolating the patterns proving problematic for the model. This approach identifies patterns cannot account for individually, but also those it can account for only when at least one other relevant pattern is ignored. We’ve done a demo-driven explanation of all this using the PFR plateau. Now we extend the method to clarify just how hard it is for CMR to account for the alternative contiguity effect we’ve been scratching our heads about for so long now.\nfrom compmemlearn.datasets import prepare_lohnas2014_data, simulate_array_from_presentations\nfrom compmemlearn.fitting import lohnas_objective_function\nfrom compmemlearn.models import Classic_CMR\nfrom scipy.optimize import differential_evolution\nfrom numba import njit\nimport numpy as np\nfrom numba import int32\nfrom numba.typed import List, Dict\nfrom numba.core import types\nfrom numba import njit, literal_unroll, prange\nfrom compmemlearn.analyses import flex_mixed_spc, flex_mixed_crp, flex_mixed_pfr, fast_csp, alternative_contiguity, rpl, fast_rpl\nimport matplotlib.pyplot as plt\n\nconditions = ['Control', 'Massed', 'Spaced', 'Mixed']\n\ntrials, events, list_length, presentations, list_types, rep_data, subjects = prepare_lohnas2014_data(\n    '../../../data/repFR.mat')\n\nFunctions\n@njit(nogil=True)\ndef lohnas_mse(\n    trials, presentations, statistics, model_class, parameters):\n    \n    # generate simulation data from model\n    sim_trials = simulate_array_from_presentations(model_class, parameters, presentations, 1)\n    \n    # collect MSE for each relevant statistic\n    result = 0\n    for statistic in literal_unroll(statistics):\n        simulation_outcome = statistic(sim_trials, presentations)\n        data_outcome = statistic(trials, presentations)\n        \n        result += np.nanmean(np.square(simulation_outcome - data_outcome))\n        \n    # return mean of results across statistics\n    return result/len(statistics)\n\ndef lohnas_mse_objective_function(\n    data_to_fit, presentations, statistics, model_class, fixed_parameters, free_parameters):\n\n    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n    for name, value in fixed_parameters.items():\n        parameters[name] = value\n    \n    def objective_function(x):\n        for i in range(len(free_parameters)):\n            parameters[free_parameters[i]] = x[i]\n        return lohnas_mse(\n            data_to_fit, presentations, statistics, model_class, parameters)\n\n    return objective_function"
  },
  {
    "objectID": "projects\\Sleep_CMR\\Context_Recurrence_Sleep.html#tasks",
    "href": "projects\\Sleep_CMR\\Context_Recurrence_Sleep.html#tasks",
    "title": "compmemlearn",
    "section": "Tasks",
    "text": "In general, the focus in this research is on how sleep affects people’s ability to extract hidden regularities from recently encoded stimuli. Across tasks though, there’s a common thread:\n\nIn these studies, participants are asked to perform a simple task, which can be easily accomplished by following a given set of instructions; however, unknown to participants, the stimuli in the task embed some hidden regularities that, if discovered (either implicitly or explicitly), can lead to a marked improvement in performance.\n\nAcross many influential studies using these tasks, sleep – particularly short-wave sleep – was found to “facilitate such incidental discovery more than simple time passed in wake”.\nTamas focuses on three tasks: transitive inference, paired associate learning, and serial reaction time. Let’s review these tasks and the main sleep effects, then circle back to paradigms across the broader literature examined in Lerner & Gluck’s (2019) review."
  },
  {
    "objectID": "projects\\Sleep_CMR\\Context_Recurrence_Sleep.html#transitive-inference-sleep-facilitates-inference-of-indirect-associations",
    "href": "projects\\Sleep_CMR\\Context_Recurrence_Sleep.html#transitive-inference-sleep-facilitates-inference-of-indirect-associations",
    "title": "compmemlearn",
    "section": "Transitive Inference: Sleep Facilitates Inference of Indirect Associations",
    "text": "Transitive inference is an ability to derive a relation “Mary is taller than Kate” from the premises “Mary is taller than Ann” and “Ann is taller than Kate”.\nOne highly cited study examining this capacity (Ellenbogen et al, 2007) uses this approach:\n\nOn each trial, subjects were presented with a pair of abstract images and asked to choose between them, after which they received feedback for their choice. Through trial and error, subjects needed to discover which image in each pair should be preferred over the other. The images were chosen from 6 stimuli with a hidden rule governing the preferences hierarchy: A > B > C > D > E > F. Only adjacent pairs were presented during training (e.g., AB, BC, CD), in random order. At test, subjects needed to once again choose, without further feedback, the preferred stimuli from the learned pairs, but also from unlearned “inference” pairs (e.g., BD, CE, BE) for which the correct answer follows the same hierarchy rule (e.g., B > E). Results showed that sleep facilitates performance for the inference pairs in an implicit way (i.e., more correct answers than in the wake condition), but does not benefit explicit recognition of the hidden rule (feedback condition).\n\nAnother studied had subjects associate between sets of images A and B, and between images in sets B and C, and then tested for indirect associations (A and C). More SWS during a nap correlated with stronger indirect associations.\nTamas modeled this by measuring cosine similarities between relevant echo representations.\n\n\n\nimage.png\n\n\n\nPaired Associate: Sleep Protects Against Interference Between Memory Traces\nParticipants learn 60 paired associated (A-B) in two phases. First, study only. Second, anticipation-plus-study where a computer presents the A words and the participant gets feedback on their answer. After sleep (or just a delay), some participants do another study phase where they learn 20 A-C pairs, inducing retroactive interference for the A-B pairs. Then after a short ten minute delay, participants perform cued recall of associated B and associated C words for each A-cue.\nInterference is less harmful for recall of A-B and A-C pairs after sleep!\n\n\n\nimage.png"
  },
  {
    "objectID": "projects\\Sleep_CMR\\Context_Recurrence_Sleep.html#serial-reaction-time-task",
    "href": "projects\\Sleep_CMR\\Context_Recurrence_Sleep.html#serial-reaction-time-task",
    "title": "compmemlearn",
    "section": "Serial Reaction Time Task",
    "text": "Pariticipants learn two (12-item) sequences of button presses (A and B). For each trial, a visual cue appeared with a tone in one of four locations, corresponding to keys of the same configuration, and pressed the key as quickly as possible while minimizing errors. Cousins et al replayed tones associated with one learned sequence during slow-wave sleep for one group, but not another which instead did the replay while awake. After waking, participants with the sleep-based reactivation, demonstrated greater explicit knowledge (p 0.005) and more improved procedural skill (p 0.04) forthe cued sequence relative to the uncued sequence.\nTo model reaction time, they took an idea from tje iterative resonance model. Exponent for activation is set to 1 at time 1. Then exponent is increased with each timestep. Exaggerates differences in similarity of probe to each trace. Count how many times it takes for model to retrieve trace that exceeds decision threshold of the model.\nThis could prove an interesting way to model reaction times in free recall!\n\n\n\nimage.png\n\n\n\nNumber reduction task\nNot a focus of Andrei’s modeling but apparently the most cited paradigm used to suggest that sleep inspires insight, according to Lerner % McGluck.\n\nSubjects perform computations on a series of digit pairs in succession. For each pair (comprised of the digits 1, 4, and 9), they need to produce a third digit based on a simple pre-taught rule. In each trial, eight digits are presented, and subjects are required to go over them serially by first applying the rule to the first two digits; then applying the rule to their response together with the third digit; then to their new response and the fourth digit, and so on. Subjects thus produce a total of seven digits one after the other throughout each trial by continually employing the rule, with the final digit considered the ultimate answer for that trial. Subjects are told, however, that if they happen to realize what the last digit will be before having gone through all seven computations, they can respond with that answer immediately and end the trial early. Indeed, unrevealed to the subjects, there is a hidden rule that governs the required responses and which, if detected, allows the subjects to predict the last digit prematurely: The inputs are organized such that, for a given trial, the last three required responses always mirror the preceding three responses (e.g., 4, 9, 4, 1, 1, 4, 9). If subjects recognize this regularity, they can predict the final answer for the trial as soon as they compute the second response and thus considerably reduce their RT for that trial. Studying the effects of sleep on performance, it isregularly found that sleep dramatically increases the probability of subjects explicitly discovering the hidden rule (evident by both a large decrease in RTs and in stating the relation between the 2nd and 7th response in a follow-up questionnaire [9,31]), with some studies linking the effect specifically to SWS [12,31]. Implicit effects of sleep (i.e., gradual reduction of RTs to each of the three predictable responses before the insight occurs), in contrast, are rarely found.\n\n\n\nOther tasks\n\nArtificial grammar learning. subjects are exposed to sentences made of gibberish words or syllables. A hidden grammatical rule governs these sentences and restricts the order of words such that not all possible combinations are allowed (e.g., 3- word sentences in which the first word always determines the identity of the third word). Learning effect generally found implicitly but not explicitly.\nStatistical learning. Weather Prediction Task. subjects are presented with abstract images and asked to learn, by trial and error, whether they predict Sun or Rain. Various combinations of 1, 2 or 3 images (out of possible 4) are displayed on different trials, with a complex and probabilistic relation linking each combination to the correct answer. Subjects can improve performance above chance even if not fully realizing the complex rule, by developing simple strategies that take under consideration only some of the images.\nInformation-integration. subjects are exposed to a set stimuli differing on two dimensions, both of which could be visual (e.g., a grating pattern differing on orientation and frequency), or one auditory and one visual (e.g., location of an image and an accompanying tone). The stimuli are differentiated to two groups based on a linear decision bound in the 2D stimuli space, such that information from both dimensions need be taken under consideration simultaneously for optimal performance. One study [30] found sleep enhances categorization performance. A second study [51] found sleep did not enhance performance immediately, but enhanced the effects of retraining on the same rule following sleep. An explicit test of rule knowledge (using a generation task) showed no sleep effects. A third study [29] found no facilitatory effects of sleep at all.\nGeneralization of categorical learning. subjects learn to classify a group of exemplars to two or more categories based on instructions or through trial and error; and are subsequently tested on their knowledge of the categories when required to classify new exemplars, or the never-seen category prototypes, without feedback. stimuli vary greatly, and Results were highly polarized."
  },
  {
    "objectID": "projects\\Sleep_CMR\\Context_Recurrence_Sleep.html#patterns-across-literature",
    "href": "projects\\Sleep_CMR\\Context_Recurrence_Sleep.html#patterns-across-literature",
    "title": "compmemlearn",
    "section": "Patterns Across Literature",
    "text": "Overall, findings tended to be replicated across studies that used the same task.\nNo simple effects of experimental design.\nSleep facilitates explicit detection of temporal, not stationary regularities (MRT, SRTT – not transitive inference?)\nA facilitatory effect of sleep on implicit detection of a hidden regularity was common to all paradigms\n\nThe common theme for both the NRT and SRTT is the use of a hidden regularity with a temporal (or sequential) nature: event x on time t predicts event y happening a few seconds later. The only other task to show a sleep-related effect on explicit detection of a hidden rule, the surveillance task, employed a similar type of regularity.\n(Knocks the idea that temporal contextual relations might be more explicit, as TCM has already been applied to model transitive inference.)"
  },
  {
    "objectID": "projects\\Sleep_CMR\\Context_Recurrence_Sleep.html#proposed-accounts",
    "href": "projects\\Sleep_CMR\\Context_Recurrence_Sleep.html#proposed-accounts",
    "title": "compmemlearn",
    "section": "Proposed Accounts",
    "text": "Temporal Scaffolding Hypothesis\nwhen regularities have a temporal nature that depends on information occurring over several seconds or more, the typical timescale of Hebbian mechanisms (approximately 50e200 ms; [73]) may not be sufficient to create the necessary associations in real time. But One critical feature of memory replay in the hippocampus during SWS is that it does not occur in the same rate of the original experience; in fact, it is time-compressed, by a factor of up to 20 of the original speed.\nIt is, however, important to note that since the evidence for timecompressed memory replay almost exclusively relies on rodent research, the temporal scaffolding model remains speculative until further corroboration from human studies.\n\n\nActive System Consolidation\nHippocampal memories are reactivated during SWS in coordination with cortical activity (memory replay). suggests that memory reactivation supports the transformation of hippocampally-dependent episodic memories into cortically-dependent semantic ones [18]. Through this process, regularities embedded within the encoded memories are slowly extracted, avoiding catastrophic interference, and then distributed within existing knowledge structures for long-term memory storage [18,19].\n\n\nSignal-Boosting\nBased on data suggesting that SWS leads to a net reduction in synaptic strength within the hippocampus and cortex, sleep may act to maintain stable levels of synaptic strength (known as synaptic homeostasis) by reducing and even eliminating excessive connectivity created during wake. Such homeostasis has the potential to improve signal to noise ratio and maintain the important common aspects of memories while reducing the salience of their less relevant idiosyncratic features, thus creating generalized representations of the individual experiences.\n\nThis article proposes a mechanism by which the reactivation of newly learned memories during sleep could actively underpin both schema formation and the addition of new knowledge to existing schemata. Under this model, the overlapping replay of related memories selectively strengthens shared elements. Repeated reactivation of memories in different combinations progressively builds schematic representations of the relationships between stimuli. We argue that this selective strengthening forms the basis of cognitive abstraction, and explain how it facilitates insight and false memory formation."
  },
  {
    "objectID": "projects\\Sleep_CMR\\Context_Recurrence_Sleep.html#computational-mechanisms",
    "href": "projects\\Sleep_CMR\\Context_Recurrence_Sleep.html#computational-mechanisms",
    "title": "compmemlearn",
    "section": "Computational Mechanisms?",
    "text": "Recurrent Similarity Computation\nProposes recurrent similarity computation where two-way cexcitatory onnections between feature and conjunctive layers of a neural network enable recurrent reactivation that facilitates efficient discovery of higher-order relationships. Originally to account for generalization.\nCited limitations: no learning algorithm proposed for how conjunctive layer is formed. Not clear how to model tasks where a priori conjunctive nodes arne’t obvious.\n\n\n\nimage.png\n\n\nTamas et al show the same mechanisms work fine when implemented in MINERVA, where the echo retrieved by a probe is iteratively used as a probe to “sharpen” the echo, progressively retrieving a smaller and smaller subset of memories in way that improves retrieval. How? Protects against interference? Do we store echoes as traces or what?\n\n\n\nimage.png\n\n\nPulls replay and “sharpening” together into one neat mechanism!\n\n\nTCM - Items are tagged w/ contextual codes/associations\nTCM argues that contextual states, rather thanitem–item associations, act as the primary cues for recall of items. As such, items are retrieved as a function of their similarity to thecurrent state of context, which in turn is influenced by both theitems themselves and a general tendency to drift over time. Common features due to temporal co-occurrence enables generalization.\nDon’t think Howard & Kahana evaluate this idea very much, at least not in their 2005 paper, but it’s definitely very reasonable given our work on CMR and other work I’ve seen on recognition.\nBut then what does this have to do with sleep? I suspect composing two qualitatively distinct mechanisms within one model could prove more robust than models encoding just one, and maybe obtain flexibility to account for discrepancies between task outcomes reviewed in Lerner & Gluck’s meta-analysis (we could suppose one mechanism might prove more influential in some tasks than others)."
  },
  {
    "objectID": "projects\\Sleep_CMR\\Recurrence_Demo\\Recurrence_Demo.html#the-minerva-2-model",
    "href": "projects\\Sleep_CMR\\Recurrence_Demo\\Recurrence_Demo.html#the-minerva-2-model",
    "title": "Exploring Recurrence in Instance-Based Modeling",
    "section": "The MINERVA 2 Model",
    "text": "Figure 2 from Hintzman, 1986.\n\n\nWe start by specifying an ExemplarModel class that implements the instance-based model architecture. Under the architecture, every experience is represented as a vector - an ordered list of feature values along many dimensions. A record of each experience - called a trace is stored as a new, separate row in a m x n memory matrix where rows correspond to memory traces and columns correspond to feature dimensions.\nTo retrieve information from memory, a feature vector can be presented as a probe. The probe activates all traces in memory in parallel. Each trace’s activation is a cubed function of its cosine similarity to the probe: \\[A(i) = S(i)^3\\] The sum of these traces weighted by their activation represents an echo summarizing the memory system’s response to the probe. The content and intensity of this echo can serve downstream behavior such as recognition, word sense disambiguation, and even free recall. For example, to compare memory representations associated with two probes, the model can compute the resemblance (cosine similarity) between the echoes associated with probes A and B.\nWe will simulate the recurrence mechanism within this model by iteratively conversion of retrieved echo representations into new probe representations. For most experiments, though we’re studying recurrence as a mechanism of memory consolidation, we’ll generally directly compare recurrently-retrieved representations\nTo represent items, we’ll follow the lead of Kelly, Mewhort, & West (2017). We’ll use vectors of 64 dimensions whose values are randomly sampled from a normal distribution. And to represent co-encoding of items, we’ll use a sum of corresponding item vectors.\n\ncode – an ExemplarModel class that implements the instance-based model architecture\nimport numpy as np\nfrom numpy.linalg import norm\n\n\nclass ExemplarModel:\n    \"\"\"\n    The basic exemplar model of memory as originated by Hintzman (1984, 1986, 1988) in MINERVA 2.\n\n    Under the architecture, every `experience` is represented as a vector - an ordered list of\n    feature values along many dimensions. A record of each experience - called a `trace` is stored\n    as a new, separate row in a m x n `memory` matrix where rows correspond to memory traces and\n    columns correspond to feature dimensions.\n\n    To retrieve information from memory, a feature vector can be presented as a `probe`. The probe\n    activates all traces in memory in parallel. Each trace's `activation` is a cubed function of\n    its `similarity` to the probe. The sum of these traces weighted by their activation represents\n    an `echo` summarizing the memory system's response to the probe. The content and intensity of\n    this echo can serve downstream behavior such as recognition, word sense disambiguation, and\n    even free recall. For example, to compare memory representations associated with two probes,\n    the model can compute the resemblance (cosine similarity) between the echoes associated with\n    probes A and B.\n\n    Attributes:\n    - memory: array where rows correspond to accumulated memory traces and columns correspond to\n    feature dims\n    \"\"\"\n\n    def __init__(self, experiences=None):\n        \"\"\"\n        Inits exemplar model with initial set of experiences in memory (if any).\n        \"\"\"\n        self.memory = None\n        if experiences is not None:\n            self.experience(experiences)\n\n    def experience(self, experiences):\n        \"\"\"\n        Adds new experience(s) to model memory, represented as new row(s) in the model's memory\n        array.\n        \"\"\"\n        self.memory = (\n            np.vstack((self.memory, np.array(experiences)))\n            if self.memory\n            else np.array(experiences)\n        )\n\n    def probe(self, probe):\n        \"\"\"\n        Presents a cue to memory system, fetching echo reflecting its pattern of activation across\n        traces. The probe activates all traces in memory in parallel. Each trace's `activation` is\n        a cubed function of its `similarity` to the probe. The sum of these traces weighted by\n        their activation is an `echo` summarizing the memory system's response to the probe.\n\n        Raises error if no traces are yet stored in memory.\n        \"\"\"\n        # computes and cubes similarity value to find activation for each trace in memory\n        activation = np.power(\n            np.sum(self.memory * probe, axis=1)\n            / (norm(self.memory, axis=1) * norm(probe)),\n            3,\n        )\n\n        # multiply each trace by its associated activation\n        # and take a column-wise sum to retrieve echo\n        echo = np.sum((self.memory.T * activation).T, axis=0)\n        return echo\n\n    def compare_probes(self, first_probe, second_probe):\n        \"\"\"\n        Compute the resemblance (cosine similarity) between the echoes associated with probes A\n        and B.\n\n        Raises error if no traces are yet stored in memory.\n        \"\"\"\n        echoes = self.probe(first_probe), self.probe(second_probe)\n        return np.sum(echoes[0] * echoes[1]) / (norm(echoes[0]) * norm(echoes[1]))"
  },
  {
    "objectID": "projects\\Sleep_CMR\\Recurrence_Demo\\Recurrence_Demo.html#the-transitive-inference-task",
    "href": "projects\\Sleep_CMR\\Recurrence_Demo\\Recurrence_Demo.html#the-transitive-inference-task",
    "title": "Exploring Recurrence in Instance-Based Modeling",
    "section": "The Transitive Inference Task",
    "text": "Figure 1 from Ellenbogen, 2007.\n\n\nIn the transitive inference task, subjects start with a phase of premise pair learning. They may study six pairs of novel visual patterns, with each pair randomly assigned to a particular hierarchical order. Participants learned these individual premise pairs (represented schematically as A>B, B>C, C>D, D>E, and E>F to a high degree of proficiency and were subsequently tested after the respective delay periods. Participants were instructed that they were learning individual comparisons (e.g., B>C) but were not informed of the hierarchical structure (A>B>C>D>E>F) from which inferences could be made (e.g., B>D and C>E – inference pairs with “1 degree of separation” – or B>E, a pair with “2 degrees of separation”). After the time delay (20m, 12hrs, or 24hrs), premise pair performance was tested (e.g., B?C) together with novel item combinations never learned (e.g., B?E), thereby probing inferential ability.\nParticipants were instructed that two visual objects would appear side by side on the screen, one at a time. On each trial, participants saw one of the five premise pairs (either A-B, B-C, C-D, D-E, or E-F). Subjects were instructed to select the correct item, at first by trial and error, but that with practice, they may be able to learn which of the two object items was correct, based on cued feedback. Participants were trained on the premise pairs until they reached a performance criterion. After delay, they did the same task but without any feedback.\nTo model this task, we encode paired items as a sum of corresponding item representations, weighting this sum to prioritize the reinforced / hierarchically higher item. Then to measure recall upon presentation of a premise pair, we construct an unweighted sum of corresponding item representations and use it as a probe to the model. Recall is successful if the retrieved echo is more similar to the hierarchically higher item than to the hierarchically lower item in the probe.\n\ncode – parameters and dependencies for transitive inference experiment\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n## recursion iterations to try out before doing similarity test\nrecursion_iteration_counts = [0, 1, 10]\n\n## number of unique experiments to simulate\nexperiment_count = 1000\n\n## reinforced item is `reinforcement_scale` times more prominent in encoded trace than distractor\nreinforcement_scale = 3\n\n## item features including number of items, dimensionality, mean and std of sampled feature values\nnumber_of_items = 5\nitem_dimensionality = 64\nitem_mean = 0\nitem_standard_deviation = 1\n\n## trial features including number of blocks\n# in a block, participants encoded each premise pair twice\n# on average participants practiced ~13 blocks before obtaining threshold (>80%) decision accuracy\nblock_count = 13\nrepeats_per_block = 2\n\n## degrees of separation to consider\n# in Ellenbogen et al, 2007, researchers only go up to 2\nconsidered_degrees_of_separation = [0, 1, 2]\n\n\n\ncode – transitive inference simulation experiment\n# results are binned by recursion_iteration_counts and considered_degree_of_separation\ncorrect = np.zeros((len(recursion_iteration_counts), len(considered_degrees_of_separation)))\ntotal = correct.copy()\n\nfor recurrence_index, recurrence_iterations in enumerate(recursion_iteration_counts):\n\n    for experiment in range(experiment_count):\n\n        # generate item representations for this experiment\n        items = np.random.normal(\n            item_mean, item_standard_deviation, (number_of_items, item_dimensionality)\n        )\n\n        # initialize model memory based on specified block_count, item_count, and repeats_per_block\n        experiences = []\n        for block in range(block_count):\n            for item_index in range(len(items) - 1):\n                for repeat_iteration in range(repeats_per_block):\n\n                    # study event is weighted composite of item i and item i+1\n                    experiences.append(\n                        (reinforcement_scale * items[item_index])\n                        + items[item_index + 1]\n                    )\n\n        # initialize model with array representation of experiences\n        model = ExemplarModel(np.array(experiences))\n\n        # test memory for premise pairs after specified number of recurrence iterations\n        for degree_index, degree_of_separation in enumerate(considered_degrees_of_separation):\n            for item_index in range(len(items) - (1 + degree_of_separation)):\n\n                # this time the pairing is an unweighted composition\n                item_pair = items[item_index] + items[item_index + (1 + degree_of_separation)]\n\n                # we find an initial echo and then perform recurrence through echo-probe conversion\n                echo = model.probe(item_pair)\n                for i in range(recurrence_iterations):\n                    echo = model.probe(echo)\n\n                # finally, we compare the echo to each item in the pair to form a decision\n                target_similarity = np.sum(echo * items[item_index]) / (\n                    norm(echo) * norm(items[item_index])\n                )\n                distractor_similarity = np.sum(echo * items[item_index + (1 + degree_of_separation)]) / (\n                    norm(echo) * norm(items[item_index + (1 + degree_of_separation)])\n                )\n\n                correct[recurrence_index, degree_index] += target_similarity > distractor_similarity\n                total[recurrence_index, degree_index] += 1\n\nresult = correct/total\n\nresult_df = pd.DataFrame(\n    {\n        \"Recurrence Iterations\": ['0'] * 3 + ['1'] * 3 + ['10'] * 3,\n        \"Item Pair\": ['Premise', '1° Inference', '2° Inference']*3,\n        \"Accuracy\": result.flatten(),\n    }\n)\n\nresult_df\n\n\n\n\n\n  \n    \n      \n      Recurrence Iterations\n      Item Pair\n      Accuracy\n    \n  \n  \n    \n      0\n      0\n      Premise\n      0.894250\n    \n    \n      1\n      0\n      1° Inference\n      0.664333\n    \n    \n      2\n      0\n      2° Inference\n      0.752000\n    \n    \n      3\n      1\n      Premise\n      0.913750\n    \n    \n      4\n      1\n      1° Inference\n      0.658000\n    \n    \n      5\n      1\n      2° Inference\n      0.737500\n    \n    \n      6\n      10\n      Premise\n      0.921500\n    \n    \n      7\n      10\n      1° Inference\n      0.660000\n    \n    \n      8\n      10\n      2° Inference\n      0.745500\n    \n  \n\n\n\n\n\n\nbar plot visualization of experiment outcome\nsns.catplot(x=\"Item Pair\", y=\"Accuracy\", col='Recurrence Iterations', kind='bar', data=result_df)\nplt.show()"
  },
  {
    "objectID": "weeklies\\01_12_2022\\00_RepFR.html#the-datasets",
    "href": "weeklies\\01_12_2022\\00_RepFR.html#the-datasets",
    "title": "compmemlearn",
    "section": "The Datasets",
    "text": "Lohnas & Kahana, 2014\n\n\nHoward & Kahana, 2005"
  },
  {
    "objectID": "weeklies\\01_12_2022\\00_RepFR.html#benchmark-summary-statistics",
    "href": "weeklies\\01_12_2022\\00_RepFR.html#benchmark-summary-statistics",
    "title": "compmemlearn",
    "section": "Benchmark Summary Statistics",
    "text": "Serial Position Effect\n\n\nProbability of First Recall\n\n\nLag-Contiguity Effect\n\n\nStop Probability by Recall Position"
  },
  {
    "objectID": "weeklies\\01_12_2022\\00_RepFR.html#measuring-repetition-and-spacing-effects",
    "href": "weeklies\\01_12_2022\\00_RepFR.html#measuring-repetition-and-spacing-effects",
    "title": "compmemlearn",
    "section": "Measuring Repetition and Spacing Effects",
    "text": "Spacing Effect\nThere is a significant recall advantage for recall of spaced items over massed items (the spacing effect), and recall probability correlates with lag for spaced items.\n\n\nDeficient Secondary Contiguity\nUpon recall of a repeatedly presented item in a mixed list, subjects are more likely to transition to items with low serial lags from their first presentation than from their second.\n\n\nOR Score Effect\nThe probability of recalling one item or the other (OR score) increases with the number of items intervening between their presentations.\n\n\nStudy-Phase Retrieval Effect\nSubjects are more likely to make transitions between items that follow a shared repeated item"
  },
  {
    "objectID": "weeklies\\01_12_2022\\00_RepFR.html#likelihood-based-cmr-fits",
    "href": "weeklies\\01_12_2022\\00_RepFR.html#likelihood-based-cmr-fits",
    "title": "compmemlearn",
    "section": "Likelihood-Based CMR Fits",
    "text": "Control Lists\n\n\nMixed Lists"
  },
  {
    "objectID": "weeklies\\01_12_2022\\00_RepFR.html#statistic-based-fitting",
    "href": "weeklies\\01_12_2022\\00_RepFR.html#statistic-based-fitting",
    "title": "compmemlearn",
    "section": "Statistic-Based Fitting",
    "text": "Single Statistics\n\n\nSelected Combinations"
  },
  {
    "objectID": "weeklies\\01_12_2022\\00_RepFR.html#generalization-tests",
    "href": "weeklies\\01_12_2022\\00_RepFR.html#generalization-tests",
    "title": "compmemlearn",
    "section": "Generalization Tests",
    "text": "Murdock 1962 Baseline\n\n\nLohnas 2014 Summary Statistics"
  },
  {
    "objectID": "weeklies\\01_12_2022\\00_RepFR.html#cmr-de",
    "href": "weeklies\\01_12_2022\\00_RepFR.html#cmr-de",
    "title": "compmemlearn",
    "section": "CMR-DE",
    "text": ""
  },
  {
    "objectID": "weeklies\\01_12_2022\\00_RepFR.html#trace-based-retrieval",
    "href": "weeklies\\01_12_2022\\00_RepFR.html#trace-based-retrieval",
    "title": "compmemlearn",
    "section": "Trace-Based Retrieval?",
    "text": ""
  },
  {
    "objectID": "weeklies\\01_12_2022\\01_ICMR.html#prepared-and-fit-model-variants-to-peers-dataset",
    "href": "weeklies\\01_12_2022\\01_ICMR.html#prepared-and-fit-model-variants-to-peers-dataset",
    "title": "compmemlearn",
    "section": "Prepared and Fit Model Variants to PEERS Dataset",
    "text": "Still working on data preparation."
  },
  {
    "objectID": "weeklies\\01_12_2022\\01_ICMR.html#regaining-server-accessing",
    "href": "weeklies\\01_12_2022\\01_ICMR.html#regaining-server-accessing",
    "title": "compmemlearn",
    "section": "Regaining Server Accessing",
    "text": ""
  },
  {
    "objectID": "weeklies\\01_12_2022\\01_ICMR.html#contextual-representations",
    "href": "weeklies\\01_12_2022\\01_ICMR.html#contextual-representations",
    "title": "compmemlearn",
    "section": "Contextual Representations",
    "text": ""
  },
  {
    "objectID": "weeklies\\01_12_2022\\02_NarrativeFR.html",
    "href": "weeklies\\01_12_2022\\02_NarrativeFR.html",
    "title": "compmemlearn",
    "section": "",
    "text": ""
  }
]