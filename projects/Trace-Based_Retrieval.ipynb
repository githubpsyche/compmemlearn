{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f7d02d3-2718-44de-a48e-89f1494af550",
   "metadata": {},
   "source": [
    "# Trace-Based Retrieval\n",
    "A variant of CMR/InstanceCMR that retrieves and reinstances stored traces rather than prototypical representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ee923-f5d2-4420-8530-c06d0542c7f8",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0a5542-e1b7-4f92-9789-7aad0ebdf30f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_14448/1702804013.py, line 114)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\gunnj\\AppData\\Local\\Temp/ipykernel_14448/1702804013.py\"\u001b[1;36m, line \u001b[1;32m114\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "@jitclass(cmr_spec)\n",
    "class Trace_Retrieval_CMR:\n",
    "\n",
    "    def __init__(self, item_count, presentation_count, encoding_drift_rate,\n",
    "                 start_drift_rate, recall_drift_rate, shared_support, \n",
    "                 item_support, learning_rate, primacy_scale, primacy_decay, \n",
    "                 stop_probability_scale, stop_probability_growth, \n",
    "                 choice_sensitivity):\n",
    "        \"\"\"\n",
    "        Same as for Instance_CMR, except preallocated item probabilities vector is of length presentation_count.\n",
    "        We also add self.identities to track item corresponding to each memory trace.\n",
    "        \"\"\"\n",
    "        \n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = encoding_drift_rate\n",
    "        self.delay_drift_rate = delay_drift_rate\n",
    "        self.start_drift_rate = start_drift_rate\n",
    "        self.recall_drift_rate = recall_drift_rate\n",
    "        self.shared_support = shared_support\n",
    "        self.item_support = item_support\n",
    "        self.learning_rate = learning_rate\n",
    "        self.primacy_scale = primacy_scale\n",
    "        self.primacy_decay = primacy_decay\n",
    "        self.stop_probability_scale = stop_probability_scale\n",
    "        self.stop_probability_growth = stop_probability_growth\n",
    "        self.choice_sensitivity = choice_sensitivity\n",
    "        \n",
    "        # at the start of the list context is initialized with a state \n",
    "        # orthogonal to the pre-experimental context\n",
    "        # associated with the set of items\n",
    "        self.context = np.zeros(item_count + 1)\n",
    "        self.context[0] = 1\n",
    "        self.preretrieval_context = self.context\n",
    "        self.recall = np.zeros(item_count) # recalls has at most `item_count` entries\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "        \n",
    "        # predefine activation weighting vectors\n",
    "        self.item_weighting = np.ones(item_count+presentation_count)\n",
    "        self.context_weighting = np.ones(item_count+presentation_count)\n",
    "        self.item_weighting[item_count:] = learning_rate\n",
    "        self.context_weighting[item_count:] = \\\n",
    "            primacy_scale * np.exp(-primacy_decay * np.arange(presentation_count)) + 1\n",
    "        self.all_weighting = self.item_weighting * self.context_weighting\n",
    "        \n",
    "        # preallocate for outcome_probabilities - one for each presentation this time!\n",
    "        self.probabilities = np.zeros((presentation_count + 1))\n",
    "        \n",
    "        # initialize memory\n",
    "        # we now conceptualize it as a pairing of two stores Mfc and Mcf respectively\n",
    "        # representing feature-to-context and context-to-feature associations\n",
    "        mfc = np.eye(item_count, item_count + 1, 1) * (1 - learning_rate)\n",
    "        mcf = np.ones((item_count, item_count)) * shared_support\n",
    "        for i in range(item_count):\n",
    "            mcf[i, i] = item_support\n",
    "        mcf = np.hstack((np.zeros((item_count, 1)), mcf))\n",
    "        self.memory = np.zeros((item_count + presentation_count, item_count * 2 + 2))\n",
    "        self.memory[:item_count,] = np.hstack((mfc, mcf))\n",
    "        self.encoding_index = item_count\n",
    "        self.items = np.eye(item_count, item_count + 1, 1)\n",
    "        \n",
    "        self.identities = np.zeros(item_count + presentation_count, dtype=int32)\n",
    "        self.identities[:item_count] = np.arange(item_count, dtype=int32)\n",
    "        \n",
    "    def experience(self, experiences):\n",
    "\n",
    "        for i in range(len(experiences)):\n",
    "            self.memory[self.encoding_index, :self.item_count+1] = experiences[i]\n",
    "            self.update_context(self.encoding_drift_rate, self.memory[self.encoding_index])\n",
    "            self.memory[self.encoding_index, self.item_count+1:] = self.context\n",
    "            self.encoding_index += 1\n",
    "            \n",
    "    def update_context(self, drift_rate, experience=None):\n",
    "        \"\"\"\n",
    "        InstanceCMR retrieves an echo representation over memory based on the probe.\n",
    "        Our version should instead reinstate the contextual state corresponding to a particular memory trace.\n",
    "        Though perhaps echo-based reinstatement is appropriate in some circumstances?\n",
    "        \"\"\"\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if experience is not None:\n",
    "            context_input = self.echo(experience)[self.item_count + 1:]\n",
    "            context_input = context_input / np.sqrt(np.sum(np.square(context_input))) # norm to length 1\n",
    "        else:\n",
    "            context_input = np.zeros((self.item_count+1))\n",
    "            context_input[0] = 1\n",
    "\n",
    "        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)) - (\n",
    "                drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "        \n",
    "    def echo(self, probe):\n",
    "\n",
    "        return np.dot(self.activations(probe), self.memory[:self.encoding_index])\n",
    "    \n",
    "    def activations(self, probe):\n",
    "        \"\"\"\n",
    "        Retrieves an activation level for each trace in memory based on similarity to a probe\n",
    "        and parametrized learning rate modulations. Simplified to sidestep the feature/context\n",
    "        sensitivity issue.\n",
    "        \"\"\"\n",
    "\n",
    "        # computes and cubes similarity value to find activation for each trace in memory\n",
    "        activation = np.dot(self.memory[:self.encoding_index], probe) / (\n",
    "            np.sqrt(np.sum(np.square(self.memory[:self.encoding_index]), axis=1)) * np.sqrt(\n",
    "                np.sum(np.square(probe))))\n",
    "\n",
    "        # weight activations based on whether probe contains item or contextual features or both\n",
    "        if np.any(probe[:self.item_count + 1]):\n",
    "            if np.any(probe[self.item_count + 1:]):\n",
    "                # both mfc and mcf weightings, see below\n",
    "                activation *= self.all_weighting[:self.encoding_index]\n",
    "            else:\n",
    "                # just mfc weightings - scale by gamma for each experimental trace\n",
    "                activation *= self.item_weighting[:self.encoding_index]\\\n",
    "        else:\n",
    "            # just mcf weightings - scale by primacy/attention function based on serial position\n",
    "            activation *= self.context_weighting[:self.encoding_index]\n",
    "            \n",
    "        return activation + 10e-7\n",
    "    \n",
    "    def outcome_probabilities(self, activation_cue):\n",
    "        \"\"\"\n",
    "        Outcome probabilities originally depended directly on echo representation corresponding\n",
    "        to activation cue. Now it depends on the individual trace activations themselves.\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        activation = self.activations(activation_cue)\n",
    "        activation = np.power(activation, self.choice_sensitivity)\n",
    "        \n",
    "        self.probabilities = np.zeros((self.presentation_count + 1))\n",
    "        self.probabilities[0] = min(self.stop_probability_scale * np.exp(\n",
    "            self.recall_total * self.stop_probability_growth), 1.0 - (self.presentation_count * 10e-7))\n",
    "\n",
    "        if self.probabilities[0] < 1:\n",
    "            for already_recalled_item in self.recall[:self.recall_total]:\n",
    "                echo[int(already_recalled_item)] = 0\n",
    "        self.probabilities[1:] = (1-self.probabilities[0]) * echo / np.sum(echo)\n",
    "        \n",
    "        return self.probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58d92f1-3c10-48de-b759-0e23728be4dd",
   "metadata": {},
   "source": [
    "## Likelihood Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81385a7f-850f-4dcf-9bd9-6a9cd9ec9c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cbc51a2-cff4-491b-a05d-51e0cf959c52",
   "metadata": {},
   "source": [
    "## Demo\n",
    "First we wanna show that the model (quickly) fits to a single subject's performance on pure list trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0c4efc-9df0-46d1-97ea-b3318e1f7b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>item</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>study</th>\n",
       "      <th>recall</th>\n",
       "      <th>repeat</th>\n",
       "      <th>intrusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  list  item  input  output  study  recall  repeat  intrusion\n",
       "0        1     1     1      1     NaN   True   False       0      False\n",
       "1        1     1     2      2     NaN   True   False       0      False\n",
       "2        1     1     3      3     NaN   True   False       0      False\n",
       "3        1     1     4      4     NaN   True   False       0      False\n",
       "4        1     1     5      5     NaN   True   False       0      False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from compmemlearn.datasets import prepare_murdock1970_data\n",
    "\n",
    "murd_trials0, murd_events0, murd_length0 = prepare_murdock1970_data('../data/mo1970.txt')\n",
    "\n",
    "murd_events0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f56f7c3-4f93-4633-84f8-65e9188e87d3",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00939c45-b1e3-44f6-915f-dc4bba0da814",
   "metadata": {},
   "source": [
    "How is CMR different?\n",
    "- sizes of mcf, context different\n",
    "- context input is sometimes experience - probably for the delay_context_input and start_context_input\n",
    "- sampling rule, familiarity stuff\n",
    "- different definition of weightings\n",
    "\n",
    "Testing..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e37e71",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
