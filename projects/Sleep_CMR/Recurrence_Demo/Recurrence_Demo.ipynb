{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Exploring Recurrence in Instance-Based Modeling\n",
    "author: Jordan Gunn\n",
    "date: \"February 6, 2022\"\n",
    "format:\n",
    "    html: \n",
    "        code-fold: true\n",
    "        theme: dark\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A common feature of learning models is recurrence -- where the outputs of the model are related back to the model as inputs. Here, we're particularly interested in implementing and understanding the MINERVA 2 model's recurrence mechanism. In MINERVA, recursion enables memory systems to confine activation to a particular subset of traces containing a particular pattern of weights. To study the efficacy of this mechanism, we'll document the model's capacity to account for tasks used to study rest-dependent memory consolidation. According to an account proposed by Foldes (2021), people replay memories of study events during rest, leading to improvements in recall performance. MINERVA 2's recurrence mechanism is thought to be a good model of this sort of replay. We'll present a specification of the model and apply it to simulate benchmark rest-dependent memory consolidation effects in three tasks: transitive inference, paired associate learning, and serial reaction time. \n",
    "\n",
    "- From here, will give the mechanism a little more scrutiny. If we take as a given that the main effect of recurrence of recurrence in MINERVA 2 is to confine echo content to a particular subset of traces, then what distinguishes it from, say, applying an higher exponent during probing to each trace's activation before aggregating traces to form an echo? By tradition, this exponent is held at 3, but higher values similarly concentrate activation to traces most similar to the item probe and is less computationally taxing. We'll explore whether increasing MINERVA II's nonlinear scaling parameter transforms retrieved model representations in the same way recurrence does or not.\n",
    "\n",
    "- The context maintenance and retrieval model of free recall (CMR; Polyn & Kahana, 2009) includes its own nonlinear activation scaling parameter. But if we do find that recurrence in MINERVA II has different effects on retrieval than increased nonlinear activation scaling, we'll next explore the consequences of introducing MINERVA-style recurrence into an instance-based implementation of the model, identifying the kinds of predictions that the mechanism corresponds to. We'll then relate these insights back to the rest-dependent memory consolidation tasks initially modeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MINERVA 2 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 2 from Hintzman, 1986.](Hintzman1986fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by specifying an `ExemplarModel` class that implements the instance-based model architecture. Under the architecture, every `experience` is represented as a vector - an ordered list of feature values along many dimensions. A record of each experience - called a `trace` is stored as a new, separate row in a m x n `memory` matrix where rows correspond to memory traces and columns correspond to feature dimensions.\n",
    "\n",
    "To retrieve information from memory, a feature vector can be presented as a `probe`. The probe activates all traces in memory in parallel. Each trace's `activation` is a cubed function of its cosine `similarity` to the probe: $$A(i) = S(i)^3$$ The sum of these traces weighted by their activation represents an `echo` summarizing the memory system's response to the probe. The content and intensity of this echo can serve downstream behavior such as recognition, word sense disambiguation, and even free recall. For example, to compare memory representations associated with two probes, the model can compute the resemblance (cosine similarity) between the echoes associated with probes A and B.\n",
    "\n",
    "We will simulate the recurrence mechanism within this model by iteratively conversion of retrieved echo representations into new probe representations. For most experiments, though we're studying recurrence as a mechanism of memory consolidation, we'll generally directly compare recurrently-retrieved representations\n",
    "\n",
    "To represent items, we'll follow the lead of Kelly, Mewhort, & West (2017). We'll use vectors of 64 dimensions whose values are randomly sampled from a normal distribution. And to represent co-encoding of items, we'll use a sum of corresponding item vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: code -- an `ExemplarModel` class that implements the instance-based model architecture\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "class ExemplarModel:\n",
    "    \"\"\"\n",
    "    The basic exemplar model of memory as originated by Hintzman (1984, 1986, 1988) in MINERVA 2.\n",
    "\n",
    "    Under the architecture, every `experience` is represented as a vector - an ordered list of\n",
    "    feature values along many dimensions. A record of each experience - called a `trace` is stored\n",
    "    as a new, separate row in a m x n `memory` matrix where rows correspond to memory traces and\n",
    "    columns correspond to feature dimensions.\n",
    "\n",
    "    To retrieve information from memory, a feature vector can be presented as a `probe`. The probe\n",
    "    activates all traces in memory in parallel. Each trace's `activation` is a cubed function of\n",
    "    its `similarity` to the probe. The sum of these traces weighted by their activation represents\n",
    "    an `echo` summarizing the memory system's response to the probe. The content and intensity of\n",
    "    this echo can serve downstream behavior such as recognition, word sense disambiguation, and\n",
    "    even free recall. For example, to compare memory representations associated with two probes,\n",
    "    the model can compute the resemblance (cosine similarity) between the echoes associated with\n",
    "    probes A and B.\n",
    "\n",
    "    Attributes:\n",
    "    - memory: array where rows correspond to accumulated memory traces and columns correspond to\n",
    "    feature dims\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, experiences=None):\n",
    "        \"\"\"\n",
    "        Inits exemplar model with initial set of experiences in memory (if any).\n",
    "        \"\"\"\n",
    "        self.memory = None\n",
    "        if experiences is not None:\n",
    "            self.experience(experiences)\n",
    "\n",
    "    def experience(self, experiences):\n",
    "        \"\"\"\n",
    "        Adds new experience(s) to model memory, represented as new row(s) in the model's memory\n",
    "        array.\n",
    "        \"\"\"\n",
    "        self.memory = (\n",
    "            np.vstack((self.memory, np.array(experiences)))\n",
    "            if self.memory\n",
    "            else np.array(experiences)\n",
    "        )\n",
    "\n",
    "    def probe(self, probe):\n",
    "        \"\"\"\n",
    "        Presents a cue to memory system, fetching echo reflecting its pattern of activation across\n",
    "        traces. The probe activates all traces in memory in parallel. Each trace's `activation` is\n",
    "        a cubed function of its `similarity` to the probe. The sum of these traces weighted by\n",
    "        their activation is an `echo` summarizing the memory system's response to the probe.\n",
    "\n",
    "        Raises error if no traces are yet stored in memory.\n",
    "        \"\"\"\n",
    "        # computes and cubes similarity value to find activation for each trace in memory\n",
    "        activation = np.power(\n",
    "            np.sum(self.memory * probe, axis=1)\n",
    "            / (norm(self.memory, axis=1) * norm(probe)),\n",
    "            3,\n",
    "        )\n",
    "\n",
    "        # multiply each trace by its associated activation\n",
    "        # and take a column-wise sum to retrieve echo\n",
    "        echo = np.sum((self.memory.T * activation).T, axis=0)\n",
    "        return echo\n",
    "\n",
    "    def compare_probes(self, first_probe, second_probe):\n",
    "        \"\"\"\n",
    "        Compute the resemblance (cosine similarity) between the echoes associated with probes A\n",
    "        and B.\n",
    "\n",
    "        Raises error if no traces are yet stored in memory.\n",
    "        \"\"\"\n",
    "        echoes = self.probe(first_probe), self.probe(second_probe)\n",
    "        return np.sum(echoes[0] * echoes[1]) / (norm(echoes[0]) * norm(echoes[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Transitive Inference Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 1 from Ellenbogen, 2007.](ellenbogen2007figure1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the transitive inference task, subjects start with a phase of premise pair learning. They may study six pairs of novel visual patterns, with each pair randomly assigned to a particular hierarchical order. Participants learned these individual premise pairs (represented schematically as A>B, B>C, C>D, D>E, and E>F to a high degree of proficiency and were subsequently tested after the respective delay periods. Participants were instructed that they were learning individual comparisons (e.g., B>C) but were not informed of the hierarchical structure (A>B>C>D>E>F) from which inferences could be made (e.g., B>D and C>E -- inference pairs with \"1 degree of separation\" -- or B>E, a pair with \"2 degrees of separation\"). After the time delay (20m, 12hrs, or 24hrs), premise pair performance was tested (e.g., B?C) together with novel item combinations never learned (e.g., B?E), thereby probing inferential ability.\n",
    "\n",
    "Participants were instructed that two visual objects would appear side by side on the screen, one at a time. On each trial, participants saw one of the five premise pairs (either A-B, B-C, C-D, D-E, or E-F). Subjects were instructed to select the correct item, at first by trial and error, but that with practice, they may be able to learn which of the two object items was correct, based on cued feedback. Participants were trained on the premise pairs until they reached a performance criterion. After delay, they did the same task but without any feedback.\n",
    "\n",
    "To model this task, we encode paired items as a sum of corresponding item representations, weighting this sum to prioritize the reinforced / hierarchically higher item. Then to measure recall upon presentation of a premise pair, we construct an unweighted sum of corresponding item representations and use it as a probe to the model. Recall is successful if the retrieved echo is more similar to the hierarchically higher item than to the hierarchically lower item in the probe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: code -- parameters and dependencies for transitive inference experiment\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "## recursion iterations to try out before doing similarity test\n",
    "recursion_iteration_counts = [0, 1, 10]\n",
    "\n",
    "## number of unique experiments to simulate\n",
    "experiment_count = 1000\n",
    "\n",
    "## reinforced item is `reinforcement_scale` times more prominent in encoded trace than distractor\n",
    "reinforcement_scale = 3\n",
    "\n",
    "## item features including number of items, dimensionality, mean and std of sampled feature values\n",
    "number_of_items = 5\n",
    "item_dimensionality = 64\n",
    "item_mean = 0\n",
    "item_standard_deviation = 1\n",
    "\n",
    "## trial features including number of blocks\n",
    "# in a block, participants encoded each premise pair twice\n",
    "# on average participants practiced ~13 blocks before obtaining threshold (>80%) decision accuracy\n",
    "block_count = 13\n",
    "repeats_per_block = 2\n",
    "\n",
    "## degrees of separation to consider\n",
    "# in Ellenbogen et al, 2007, researchers only go up to 2\n",
    "considered_degrees_of_separation = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recurrence Iterations</th>\n",
       "      <th>Item Pair</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Premise</td>\n",
       "      <td>0.894250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1° Inference</td>\n",
       "      <td>0.664333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2° Inference</td>\n",
       "      <td>0.752000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Premise</td>\n",
       "      <td>0.913750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1° Inference</td>\n",
       "      <td>0.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2° Inference</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>Premise</td>\n",
       "      <td>0.921500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>1° Inference</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>2° Inference</td>\n",
       "      <td>0.745500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Recurrence Iterations     Item Pair  Accuracy\n",
       "0                     0       Premise  0.894250\n",
       "1                     0  1° Inference  0.664333\n",
       "2                     0  2° Inference  0.752000\n",
       "3                     1       Premise  0.913750\n",
       "4                     1  1° Inference  0.658000\n",
       "5                     1  2° Inference  0.737500\n",
       "6                    10       Premise  0.921500\n",
       "7                    10  1° Inference  0.660000\n",
       "8                    10  2° Inference  0.745500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-summary: code -- transitive inference simulation experiment\n",
    "\n",
    "# results are binned by recursion_iteration_counts and considered_degree_of_separation\n",
    "correct = np.zeros((len(recursion_iteration_counts), len(considered_degrees_of_separation)))\n",
    "total = correct.copy()\n",
    "\n",
    "for recurrence_index, recurrence_iterations in enumerate(recursion_iteration_counts):\n",
    "\n",
    "    for experiment in range(experiment_count):\n",
    "\n",
    "        # generate item representations for this experiment\n",
    "        items = np.random.normal(\n",
    "            item_mean, item_standard_deviation, (number_of_items, item_dimensionality)\n",
    "        )\n",
    "\n",
    "        # initialize model memory based on specified block_count, item_count, and repeats_per_block\n",
    "        experiences = []\n",
    "        for block in range(block_count):\n",
    "            for item_index in range(len(items) - 1):\n",
    "                for repeat_iteration in range(repeats_per_block):\n",
    "\n",
    "                    # study event is weighted composite of item i and item i+1\n",
    "                    experiences.append(\n",
    "                        (reinforcement_scale * items[item_index])\n",
    "                        + items[item_index + 1]\n",
    "                    )\n",
    "\n",
    "        # initialize model with array representation of experiences\n",
    "        model = ExemplarModel(np.array(experiences))\n",
    "\n",
    "        # test memory for premise pairs after specified number of recurrence iterations\n",
    "        for degree_index, degree_of_separation in enumerate(considered_degrees_of_separation):\n",
    "            for item_index in range(len(items) - (1 + degree_of_separation)):\n",
    "\n",
    "                # this time the pairing is an unweighted composition\n",
    "                item_pair = items[item_index] + items[item_index + (1 + degree_of_separation)]\n",
    "\n",
    "                # we find an initial echo and then perform recurrence through echo-probe conversion\n",
    "                echo = model.probe(item_pair)\n",
    "                for i in range(recurrence_iterations):\n",
    "                    echo = model.probe(echo)\n",
    "\n",
    "                # finally, we compare the echo to each item in the pair to form a decision\n",
    "                target_similarity = np.sum(echo * items[item_index]) / (\n",
    "                    norm(echo) * norm(items[item_index])\n",
    "                )\n",
    "                distractor_similarity = np.sum(echo * items[item_index + (1 + degree_of_separation)]) / (\n",
    "                    norm(echo) * norm(items[item_index + (1 + degree_of_separation)])\n",
    "                )\n",
    "\n",
    "                correct[recurrence_index, degree_index] += target_similarity > distractor_similarity\n",
    "                total[recurrence_index, degree_index] += 1\n",
    "\n",
    "result = correct/total\n",
    "\n",
    "result_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Recurrence Iterations\": ['0'] * 3 + ['1'] * 3 + ['10'] * 3,\n",
    "        \"Item Pair\": ['Premise', '1° Inference', '2° Inference']*3,\n",
    "        \"Accuracy\": result.flatten(),\n",
    "    }\n",
    ")\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| code-summary: bar plot visualization of experiment outcome\n",
    "\n",
    "sns.catplot(x=\"Item Pair\", y=\"Accuracy\", col='Recurrence Iterations', kind='bar', data=result_df)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
