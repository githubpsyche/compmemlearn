{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Instance CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import float64, int32, boolean\n",
    "from numba.experimental import jitclass\n",
    "\n",
    "icmr_spec = [\n",
    "    ('item_count', int32), \n",
    "    ('encoding_drift_rate', float64),\n",
    "    ('start_drift_rate', float64),\n",
    "    ('recall_drift_rate', float64),\n",
    "    ('delay_drift_rate', float64),\n",
    "    ('shared_support', float64),\n",
    "    ('item_support', float64),\n",
    "    ('learning_rate', float64),\n",
    "    ('primacy_scale', float64),\n",
    "    ('primacy_decay', float64),\n",
    "    ('stop_probability_scale', float64),\n",
    "    ('stop_probability_growth', float64),\n",
    "    ('choice_sensitivity', float64),\n",
    "    ('context_sensitivity', float64),\n",
    "    ('feature_sensitivity', float64),\n",
    "    ('context', float64[::1]),\n",
    "    ('start_context_input', float64[::1]),\n",
    "    ('delay_context_input', float64[::1]),\n",
    "    ('preretrieval_context', float64[::1]),\n",
    "    ('recall', int32[::1]),\n",
    "    ('retrieving', boolean),\n",
    "    ('recall_total', int32),\n",
    "    ('item_weighting', float64[::1]),\n",
    "    ('context_weighting', float64[::1]),\n",
    "    ('all_weighting', float64[::1]),\n",
    "    ('probabilities', float64[::1]),\n",
    "    ('memory', float64[:,::1]),\n",
    "    ('encoding_index', int32),\n",
    "    ('items', float64[:,::1]),\n",
    "    ('norm', float64[::1]),\n",
    "]\n",
    "\n",
    "int32 = int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#@jitclass(icmr_spec)\n",
    "class Instance_CMR:\n",
    "\n",
    "    def __init__(self, item_count, presentation_count, parameters):\n",
    "\n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = parameters['encoding_drift_rate']\n",
    "        self.delay_drift_rate = parameters['delay_drift_rate']\n",
    "        self.start_drift_rate = parameters['start_drift_rate']\n",
    "        self.recall_drift_rate = parameters['recall_drift_rate']\n",
    "        self.shared_support = parameters['shared_support']\n",
    "        self.item_support = parameters['item_support']\n",
    "        self.learning_rate = parameters['learning_rate']\n",
    "        self.primacy_scale = parameters['primacy_scale']\n",
    "        self.primacy_decay = parameters['primacy_decay']\n",
    "        self.stop_probability_scale = parameters['stop_probability_scale']\n",
    "        self.stop_probability_growth = parameters['stop_probability_growth']\n",
    "        self.choice_sensitivity = parameters['choice_sensitivity']\n",
    "        self.context_sensitivity = parameters['context_sensitivity']\n",
    "        self.feature_sensitivity = parameters['feature_sensitivity']\n",
    "        \n",
    "        # at the start of the list context is initialized with a state \n",
    "        # orthogonal to the pre-experimental context associated with the set of items\n",
    "        self.context = np.zeros(item_count + 2)\n",
    "        self.context[0] = 1\n",
    "        self.preretrieval_context = self.context\n",
    "        self.recall = np.zeros(item_count, int32) # recalls has at most `item_count` entries\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "\n",
    "        # predefine activation weighting vectors\n",
    "        self.item_weighting = np.ones(item_count+presentation_count)\n",
    "        self.context_weighting = np.ones(item_count+presentation_count)\n",
    "        self.item_weighting[item_count:] = self.learning_rate\n",
    "        self.context_weighting[item_count:] = \\\n",
    "            self.primacy_scale * np.exp(-self.primacy_decay * np.arange(presentation_count)) + 1\n",
    "        self.all_weighting = self.item_weighting * self.context_weighting\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((item_count + 1))\n",
    "\n",
    "        # predefine contextual input vectors relevant for delay_drift_rate and start_drift_rate parameters\n",
    "        self.start_context_input = np.zeros((self.item_count+2))\n",
    "        self.start_context_input[0] = 1\n",
    "        self.delay_context_input = np.zeros((self.item_count+2))\n",
    "        self.delay_context_input[-1] = 1\n",
    "\n",
    "        # initialize memory\n",
    "        # we now conceptualize it as a pairing of two stores Mfc and Mcf respectively\n",
    "        # representing feature-to-context and context-to-feature associations\n",
    "        mfc = np.eye(item_count, item_count + 2, 1) * (1 - self.learning_rate)\n",
    "        mcf = np.ones((item_count, item_count)) * self.shared_support\n",
    "        for i in range(item_count):\n",
    "            mcf[i, i] = self.item_support\n",
    "        mcf = np.hstack((np.zeros((item_count, 1)), mcf,  np.zeros((item_count, 1))))\n",
    "        self.memory = np.zeros((item_count + presentation_count, item_count * 2 + 4))\n",
    "        self.memory[:item_count,] = np.hstack((mfc, mcf))\n",
    "\n",
    "        self.norm = np.zeros(item_count + presentation_count)\n",
    "        self.norm[:item_count] = np.sqrt(np.sum(np.square(self.memory[0])))\n",
    "        self.norm[item_count:] = np.sqrt(2)\n",
    "        self.encoding_index = item_count\n",
    "        self.items = np.hstack((np.eye(item_count, item_count + 2, 1), np.zeros(\n",
    "            (item_count, item_count+2))))\n",
    "\n",
    "    def experience(self, experiences):\n",
    "\n",
    "        for i in range(len(experiences)):\n",
    "            self.memory[self.encoding_index] = experiences[i]\n",
    "            self.update_context(self.encoding_drift_rate, self.memory[self.encoding_index])\n",
    "            self.memory[self.encoding_index, self.item_count+2:] = self.context\n",
    "            self.encoding_index += 1\n",
    "\n",
    "    def update_context(self, drift_rate, experience=None):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if experience is not None:\n",
    "            context_input = self.echo(experience)[self.item_count + 2:]\n",
    "            context_input = context_input / np.sqrt(np.sum(np.square(context_input))) # norm to length 1\n",
    "        else:\n",
    "            context_input = np.zeros((self.item_count+2))\n",
    "            context_input[0] = 1\n",
    "\n",
    "        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)) - (\n",
    "                drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "\n",
    "    def echo(self, probe):\n",
    "\n",
    "        return np.dot(self.activations(probe), self.memory[:self.encoding_index])\n",
    "\n",
    "    def activations(self, probe, probe_norm=1.0):\n",
    "\n",
    "        # computes and cubes similarity value to find activation for each trace in memory\n",
    "        # activation = np.dot(self.memory[:self.encoding_index], probe) / (\n",
    "        #     np.sqrt(np.sum(np.square(self.memory[:self.encoding_index]), axis=1)) * np.sqrt(\n",
    "        #         np.sum(np.square(probe))))\n",
    "\n",
    "        activation = np.dot(self.memory[:self.encoding_index], probe) / (\n",
    "             self.norm[:self.encoding_index] * probe_norm)\n",
    "\n",
    "        # weight activations based on whether probe contains item or contextual features or both\n",
    "        if np.any(probe[:self.item_count + 2]):\n",
    "            if np.any(probe[self.item_count + 2:]):\n",
    "                # both mfc and mcf weightings, see below\n",
    "                activation *= self.all_weighting[:self.encoding_index]\n",
    "            else:\n",
    "                # mfc weightings - scale by gamma for each experimental trace\n",
    "                activation *= self.item_weighting[:self.encoding_index]\n",
    "            activation = np.power(activation, self.context_sensitivity)\n",
    "        else:\n",
    "            # mcf weightings - scale by primacy/attention function based on experience position\n",
    "            activation *= self.context_weighting[:self.encoding_index]\n",
    "            if self.feature_sensitivity != 1.0:\n",
    "                activation = np.power(activation, self.feature_sensitivity)\n",
    "            else:\n",
    "                activation = np.power(activation, self.context_sensitivity)\n",
    "            \n",
    "        return activation + 10e-7\n",
    "\n",
    "    def outcome_probabilities(self):\n",
    "        \n",
    "        self.probabilities[0] = min(self.stop_probability_scale * np.exp(\n",
    "            self.recall_total * self.stop_probability_growth), 1.0 - (\n",
    "                 (self.item_count-self.recall_total) * 10e-7))\n",
    "        self.probabilities[1:] = 10e-7\n",
    "\n",
    "        if self.probabilities[0] < (1.0 - ((self.item_count-self.recall_total) * 10e-7)):\n",
    "\n",
    "            # measure activation for each item\n",
    "            activation_cue = np.hstack((np.zeros(self.item_count + 2), self.context))\n",
    "            activation = self.echo(activation_cue)[1:self.item_count+1]\n",
    "\n",
    "            # already recalled items have zero activation\n",
    "            activation[self.recall[:self.recall_total]] = 0\n",
    "            \n",
    "            # recall probability is a function of activation\n",
    "            if np.sum(activation) > 0:\n",
    "                activation = np.power(activation, self.choice_sensitivity)\n",
    "                self.probabilities[1:] = (1-self.probabilities[0]) * activation / np.sum(activation)\n",
    "        \n",
    "        return self.probabilities\n",
    "\n",
    "    def free_recall(self, steps=None):\n",
    "\n",
    "        # some pre-list context is reinstated before initiating recall\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.start_drift_rate)\n",
    "            self.retrieving = True\n",
    "            \n",
    "        # number of items to retrieve is infinite if steps is unspecified\n",
    "        if steps is None:\n",
    "            steps = self.item_count - self.recall_total\n",
    "        steps = self.recall_total + steps\n",
    "\n",
    "        # at each recall attempt\n",
    "        while self.recall_total < steps:\n",
    "\n",
    "            # the current state of context is used as a retrieval cue to \n",
    "            # attempt recall of a studied item compute outcome probabilities \n",
    "            # and make choice based on distribution\n",
    "            outcome_probabilities = self.outcome_probabilities(\n",
    "                np.hstack((np.zeros(self.item_count + 1), self.context)))\n",
    "            if np.any(outcome_probabilities[1:]):\n",
    "                choice = np.sum(\n",
    "                    np.cumsum(outcome_probabilities) < np.random.rand(), dtype=int32)\n",
    "            else:\n",
    "                choice = 0\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made (0)\n",
    "            if choice == 0:\n",
    "                self.retrieving = False\n",
    "                self.context = self.preretrieval_context\n",
    "                break\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "        return self.recall[:self.recall_total]\n",
    "    \n",
    "    def force_recall(self, choice=None):\n",
    "\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.start_drift_rate)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        elif choice > 0:\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(\n",
    "                self.recall_drift_rate, self.items[choice - 1])\n",
    "        else:\n",
    "            self.retrieving = False\n",
    "            self.context = self.preretrieval_context\n",
    "        return self.recall[:self.recall_total]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "\n",
    "#@njit(fastmath=True, nogil=True, parallel=True)\n",
    "def murdock_data_likelihood(data_to_fit, item_counts, model_class, parameters):\n",
    "\n",
    "    result = 0.0\n",
    "    for i in prange(len(item_counts)):\n",
    "        item_count = item_counts[i]\n",
    "        trials = data_to_fit[i]\n",
    "        likelihood = np.ones((len(trials), item_count))\n",
    "\n",
    "        model = model_class(item_count, item_count, parameters)\n",
    "        model.experience(model.items)\n",
    "\n",
    "        for trial_index in range(len(trials)):\n",
    "            trial = trials[trial_index]\n",
    "\n",
    "            model.force_recall()\n",
    "            for recall_index in range(len(trial) + 1):\n",
    "\n",
    "                # identify index of item recalled; if zero then recall is over\n",
    "                if recall_index == len(trial) and len(trial) < item_count:\n",
    "                    recall = 0\n",
    "                else:\n",
    "                    recall = trial[recall_index]\n",
    "\n",
    "                # store probability of and simulate recall of indexed item \n",
    "                likelihood[trial_index, recall_index] = model.outcome_probabilities()[recall]\n",
    "                \n",
    "                if recall == 0:\n",
    "                    break\n",
    "                model.force_recall(recall)\n",
    "\n",
    "            # reset model to its pre-retrieval (but post-encoding) state\n",
    "            model.force_recall(0)\n",
    "            \n",
    "        result -= np.sum(np.log(likelihood))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.typed import Dict\n",
    "from numba.core import types\n",
    "\n",
    "def murdock_objective_function(\n",
    "    data_to_fit, item_counts, model_class, fixed_parameters, free_parameters):\n",
    "    \"\"\"\n",
    "    Configures cmr_likelihood for search over specified free/fixed parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n",
    "    for name, value in fixed_parameters.items():\n",
    "        parameters[name] = value\n",
    "    \n",
    "    def objective_function(x):\n",
    "        for i in range(len(free_parameters)):\n",
    "            parameters[free_parameters[i]] = x[i]\n",
    "        return murdock_data_likelihood(data_to_fit, item_counts, model_class, parameters)\n",
    "\n",
    "    return objective_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.typed import Dict, List\n",
    "from numba.core import types\n",
    "from numba import njit\n",
    "from compmemlearn.datasets import prepare_murdock1962_data\n",
    "\n",
    "murd_trials0, murd_events0, murd_length0 = prepare_murdock1962_data('../../data/MurdData_clean.mat', 0)\n",
    "murd_trials1, murd_events1, murd_length1 = prepare_murdock1962_data('../../data/MurdData_clean.mat', 1)\n",
    "murd_trials2, murd_events2, murd_length2 = prepare_murdock1962_data('../../data/MurdData_clean.mat', 2)\n",
    "free_parameters = [\n",
    "    'encoding_drift_rate',\n",
    "    'start_drift_rate',\n",
    "    'recall_drift_rate',\n",
    "    'shared_support',\n",
    "    'item_support',\n",
    "    'learning_rate',\n",
    "    'primacy_scale',\n",
    "    'primacy_decay',\n",
    "    'stop_probability_scale',\n",
    "    'stop_probability_growth',\n",
    "#    'choice_sensitivity',\n",
    "    'context_sensitivity',\n",
    "#    'feature_sensitivity'\n",
    "]\n",
    "\n",
    "fit_values = np.array([7.25392222e-01, 2.22044605e-16, 9.04899967e-01, 1.16637532e-05,\n",
    "       1.35117327e-03, 7.14751007e-03, 6.26753336e+00, 1.73084858e+00,\n",
    "       3.05537134e-02, 3.38091912e-01, 1.54964510e+00])\n",
    "\n",
    "fit_values = np.array([7.66747592e-01, 1.68847562e-03, 8.46922217e-01, 4.25187058e-03,\n",
    "       1.00000000e+00, 2.07232433e-01, 8.68402303e+00, 5.53375476e+01,\n",
    "       2.40297656e-02, 2.61885572e-01, 1.29423172e+00])\n",
    "\n",
    "icmr_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n",
    "for i in range(len(fit_values)):\n",
    "    icmr_parameters[free_parameters[i]] = fit_values[i]\n",
    "icmr_parameters['choice_sensitivity'] = 1.0\n",
    "icmr_parameters['feature_sensitivity'] = 1.0\n",
    "icmr_parameters['delay_drift_rate'] = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80352.67114034739"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@njit(fastmath=True, nogil=True)\n",
    "def init_icmr(item_count, presentation_count, parameters):\n",
    "    return Instance_CMR(item_count, presentation_count, parameters)\n",
    "\n",
    "murdock_data_likelihood(List([murd_trials0, murd_trials1, murd_trials2]), List([murd_length0,murd_length1, murd_length2]), init_icmr, icmr_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "80350.5961565577\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1 s ± 60.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "murdock_data_likelihood(List([murd_trials0, murd_trials1, murd_trials2]), List([murd_length0,murd_length1, murd_length2]),init_icmr, icmr_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "350ms -> 216ms -> 148ms\n",
    "379ms -> 380ms -> 369ms -> 147ms\n",
    "\n",
    "4.24s -> 4.01 -> 3.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 5.20968 s\n",
      "\n",
      "Could not find file C:\\Users\\gunnj\\AppData\\Local\\Temp/ipykernel_11900/565983307.py\n",
      "Are you sure you are running this program from the same directory\n",
      "that you ran the profiler from?\n",
      "Continuing without the function's contents.\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     5                                           \n",
      "     6                                           \n",
      "     7         1         22.0     22.0      0.0  \n",
      "     8         4        175.0     43.8      0.0  \n",
      "     9         3        744.0    248.0      0.0  \n",
      "    10         3        498.0    166.0      0.0  \n",
      "    11         3       2071.0    690.3      0.0  \n",
      "    12                                           \n",
      "    13         3      14794.0   4931.3      0.0  \n",
      "    14         3      73738.0  24579.3      0.1  \n",
      "    15                                           \n",
      "    16      3603      22189.0      6.2      0.0  \n",
      "    17      3600      33001.0      9.2      0.1  \n",
      "    18                                           \n",
      "    19      3600     740538.0    205.7      1.4  \n",
      "    20     31717     275527.0      8.7      0.5  \n",
      "    21                                           \n",
      "    22                                           \n",
      "    23     31717     257049.0      8.1      0.5  \n",
      "    24        21        112.0      5.3      0.0  \n",
      "    25                                           \n",
      "    26     31696     236841.0      7.5      0.5  \n",
      "    27                                           \n",
      "    28                                           \n",
      "    29     31717   29166223.0    919.6     56.0  \n",
      "    30                                           \n",
      "    31     31717     404938.0     12.8      0.8  \n",
      "    32      3600      20147.0      5.6      0.0  \n",
      "    33     28117   20727998.0    737.2     39.8  \n",
      "    34                                           \n",
      "    35                                           \n",
      "    36      3600     110970.0     30.8      0.2  \n",
      "    37                                           \n",
      "    38         3       9258.0   3086.0      0.0  \n",
      "    39                                           \n",
      "    40         1          4.0      4.0      0.0"
     ]
    }
   ],
   "source": [
    "%lprun -f murdock_data_likelihood murdock_data_likelihood(List([murd_trials0, murd_trials1, murd_trials2]), List([murd_length0,murd_length1, murd_length2]), init_icmr, icmr_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`outcome_probabilities` and `force_recall` are the bottlenecks. Can I get the speed closer to regular CMR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (40,44) and (43,) not aligned: 44 (dim 1) != 43 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11900/2381911028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mactivation_cue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_count\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation_cue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11900/315303380.py\u001b[0m in \u001b[0;36mactivations\u001b[1;34m(self, probe, probe_norm)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;31m#         np.sum(np.square(probe))))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         activation = np.dot(self.memory[:self.encoding_index], probe) / (\n\u001b[0m\u001b[0;32m    102\u001b[0m              self.norm[:self.encoding_index] * probe_norm)\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (40,44) and (43,) not aligned: 44 (dim 1) != 43 (dim 0)"
     ]
    }
   ],
   "source": [
    "def fake_data_likelihood(data_to_fit, item_counts, model_class, parameters):\n",
    "\n",
    "    result = 0.0\n",
    "    for i in prange(len(item_counts)):\n",
    "        item_count = item_counts[i]\n",
    "        trials = data_to_fit[i]\n",
    "        likelihood = np.ones((len(trials), item_count))\n",
    "\n",
    "        model = model_class(item_count, item_count, parameters)\n",
    "        model.experience(model.items)\n",
    "\n",
    "        for trial_index in range(len(trials)):\n",
    "            trial = trials[trial_index]\n",
    "\n",
    "            model.force_recall()\n",
    "            for recall_index in range(len(trial) + 1):\n",
    "\n",
    "                # identify index of item recalled; if zero then recall is over\n",
    "                if recall_index == len(trial) and len(trial) < item_count:\n",
    "                    recall = 0\n",
    "                else:\n",
    "                    recall = trial[recall_index]\n",
    "\n",
    "                # store probability of and simulate recall of indexed item \n",
    "                return model\n",
    "\n",
    "test = fake_data_likelihood(List([murd_trials0, murd_trials1, murd_trials2]), List([murd_length0,murd_length1, murd_length2]), init_icmr, icmr_parameters)\n",
    "\n",
    "activation_cue = np.hstack((np.zeros(test.item_count + 1), test.context))\n",
    "test.activations(activation_cue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.0002235 s\n",
      "\n",
      "Could not find file C:\\Users\\gunnj\\AppData\\Local\\Temp/ipykernel_12592/1997441375.py\n",
      "Are you sure you are running this program from the same directory\n",
      "that you ran the profiler from?\n",
      "Continuing without the function's contents.\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   110                                           \n",
      "   111                                           \n",
      "   112         1        500.0    500.0     22.4  \n",
      "   113         1       1309.0   1309.0     58.6  \n",
      "   114         1         37.0     37.0      1.7  \n",
      "   115                                           \n",
      "   116         1         32.0     32.0      1.4  \n",
      "   117         3         58.0     19.3      2.6  \n",
      "   118         2         13.0      6.5      0.6  \n",
      "   119                                           \n",
      "   120         1         19.0     19.0      0.9  \n",
      "   121         1         35.0     35.0      1.6  \n",
      "   122                                           \n",
      "   123         1        224.0    224.0     10.0  \n",
      "   124                                           \n",
      "   125         1          8.0      8.0      0.4"
     ]
    }
   ],
   "source": [
    "%lprun -f test.outcome_probabilities test.outcome_probabilities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_count = 20\n",
    "\n",
    "np.shape(np.eye(1, 2*(item_count+2), item_count+2).flatten()[item_count+2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.zeros(item_count + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = .7\n",
    "\n",
    "np.eye(item_count, item_count + 2, 1) * (1 - learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0.3, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0.3, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(item_count, item_count + 1, 1) * .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((np.eye(item_count, item_count + 2, 1), np.zeros(\n",
    "            (item_count, item_count+2))))[:, :item_count+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
