{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Visualizing Model States\n",
    "> quick exploratory analysis of model states at arbitrary points along simulation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We often simulate a simple free recall experiment and visualize model states throughout to explore their capacity to\n",
    "exhibit classical patterns of primacy, recency, and temporal contiguity. Any arbitrary configuration of parameters can\n",
    "be specified for the model, including an `experiment_count`, determining the number of simulations with the given\n",
    "parameters.\n",
    "\n",
    "In each experiment:\n",
    "1. A specified number of unique items are each experienced once,\n",
    "2. Context is momentarily drifted toward its pre-experimental state, and\n",
    "3. The model freely recalls items until it stops, with retrieval of previously experienced items disallowed.\n",
    "\n",
    "To visualize model state, we add to our `model_analysis` submodule three basic categories of visualizations. To\n",
    "visualize model state throughout encoding, we track the state of `context` and the amount of `support` for recall of\n",
    "each item based on contextual state. We also prepare a visualization of the final state of `memory` once encoding is\n",
    "finished. To visualize model state throughout retrieval, we similarly track `context` and `support` at each step of\n",
    "recall. An additional visualization makes clearer the distribution of outcome probabilities at a particular index of\n",
    "recall (e.g. after a second item has been recalled)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Demo Parameters\n",
    "For a demo of these functions, you can specify default model parameters (or even alter which model is considered) in the following code cell:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# you can change the imported model and assign it the alias CMR and use it for \n",
    "# this demo if it supports the same functions\n",
    "from repfr.models import DefaultCMR as CMR\n",
    "\n",
    "# entries and values in this dict will be passed as model parameters\n",
    "cmr_parameters = {\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting Encoding States\n",
    "First we create simulations and visualizations to track model state throughout encoding of new memories. \n",
    "\n",
    "To do this,we produce two parallel functions, `encoding_states` and `plot_states` that collect and visualize encoding states, respectively. \n",
    "\n",
    "An additional wrapper function called `encoding_visualizations` plots these states in addition to the\n",
    "final overall state of model memory."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def encoding_states(model):\n",
    "    \"\"\"\n",
    "    Tracks state of context, and item supports across encoding. Model is also advanced to a state of fully encoded\n",
    "    memories.\n",
    "\n",
    "    **Required model attributes**:\n",
    "    - item_count: specifies number of items encoded into memory\n",
    "    - context: vector representing an internal contextual state\n",
    "    - experience: adding a new trace to the memory model\n",
    "    - activations: function returning item activations given a vector probe\n",
    "    - outcome_probabilities: function returning item supports given a set of activations\n",
    "\n",
    "    **Returns** array representations of context and support for retrieval of each item at each increment of item\n",
    "    encoding. Each has shape model.item_count by model.item_count + 1.\n",
    "    \"\"\"\n",
    "\n",
    "    experiences = np.eye(model.item_count, model.item_count + 1, 1)\n",
    "    cmr_experiences = np.eye(model.item_count, model.item_count)\n",
    "    encoding_contexts, encoding_supports = model.context, []\n",
    "\n",
    "    # track model state across experiences\n",
    "    for i in range(len(experiences)):\n",
    "        model.experience(cmr_experiences[i].reshape((1, -1)))\n",
    "\n",
    "        # track model contexts and item supports\n",
    "        encoding_contexts = np.vstack((encoding_contexts, model.context))\n",
    "\n",
    "        activation_cue = lambda model: model.context\n",
    "\n",
    "        if len(encoding_supports) > 0:\n",
    "            encoding_supports = np.vstack((encoding_supports, model.outcome_probabilities(activation_cue(model))))\n",
    "        else:\n",
    "            encoding_supports = model.outcome_probabilities(activation_cue(model))\n",
    "\n",
    "    return encoding_contexts, encoding_supports"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# export\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_states(matrix, title, figsize=(15, 15), savefig=False):\n",
    "    \"\"\"\n",
    "    Plots an array of model states as a value-annotated heatmap with an arbitrary title.\n",
    "\n",
    "    **Arguments**:\n",
    "    - matrix: an array of model states, ideally with columns representing unique feature indices and rows\n",
    "        representing unique update indices\n",
    "    - title: a title for the generated plot, ideally conveying what array values represent at each entry\n",
    "    - savefig: boolean deciding whether generated figure is saved (True if Yes)\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(matrix, annot=True, linewidths=.5)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Update Index')\n",
    "    if savefig:\n",
    "        plt.savefig('figures/{}.jpeg'.format(title).replace(' ', '_').lower(), bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# export\n",
    "\n",
    "def encoding_visualizations(model, savefig=True):\n",
    "    \"\"\"\n",
    "    Plots encoding contexts, encoding supports as heatmaps.\n",
    "\n",
    "    **Required model attributes**:\n",
    "    - item_count: specifies number of items encoded into memory\n",
    "    - context: vector representing an internal contextual state\n",
    "    - experience: adding a new trace to the memory model\n",
    "    - activations: function returning item activations given a vector probe\n",
    "    - outcome_probabilities: function returning item supports given a set of activations\n",
    "    - memory: a unitary representation of the current state of memory\n",
    "\n",
    "    **Also** requires savefig:  boolean deciding if generated figure is saved\n",
    "    \"\"\"\n",
    "\n",
    "    encoding_contexts, encoding_supports = encoding_states(model)\n",
    "    plot_states(encoding_contexts, 'Encoding Contexts', savefig=savefig)\n",
    "    plot_states(encoding_supports, 'Supports For Each Item At Each Increment of Encoding', savefig=savefig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Demo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = CMR(**cmr_parameters)\n",
    "encoding_visualizations(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`plot_states` is flexible enough to visualize other model representations, too:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = CMR(**parameters)\n",
    "encoding_states(model)\n",
    "print(model.__class__.__name__)\n",
    "plot_states(model.mfc, 'CMR Mfc')\n",
    "plot_states(model.mcf, 'CMR Mcf')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting Retrieval States"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tracking model state across each step of retrieval. Since retrieval stochastic, these values change with each random seed. An additional optional parameter `first_recall_item` can control which item is recalled first by the model (`0` denotes termination of recall while actual items are 1-indexed); it is useful for testing hypotheses about model dynamics during recall. We leave the parameter set at `None`, for now, indicating no controlled first recall."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def retrieval_states(model, first_recall_item=None):\n",
    "    \"\"\"\n",
    "    Tracks state of context, and item supports across retrieval. Model is also advanced into a state of\n",
    "    completed free recall.\n",
    "\n",
    "    **Required model attributes**:\n",
    "    - item_count: specifies number of items encoded into memory\n",
    "    - context: vector representing an internal contextual state\n",
    "    - experience: adding a new trace to the memory model\n",
    "    - activations: function returning item activations given a vector probe\n",
    "    - outcome_probabilities: function returning item supports given a set of activations\n",
    "    - free_recall: function that freely recalls a given number of items or until recall stops\n",
    "    - state: indicates whether model is encoding or engaged in recall with a string\n",
    "\n",
    "    **Also** optionally uses first_recall_item: can specify an item for first recall\n",
    "\n",
    "    **Returns** array representations of context and support for retrieval of each item at each increment of item\n",
    "    retrieval. Also returns recall train associated with simulation.\n",
    "    \"\"\"\n",
    "\n",
    "    activation_cue = lambda model: model.context\n",
    "\n",
    "    # encoding items, presuming model is freshly initialized\n",
    "    encoding_states(model)\n",
    "    retrieval_contexts, retrieval_supports = model.context, model.outcome_probabilities(\n",
    "        activation_cue(model))\n",
    "\n",
    "    # pre-retrieval distraction\n",
    "    model.free_recall(0)\n",
    "    retrieval_contexts = np.vstack((retrieval_contexts, model.context))\n",
    "    retrieval_supports = np.vstack((retrieval_supports, model.outcome_probabilities(\n",
    "        activation_cue(model))))\n",
    "\n",
    "    # optional forced first item recall\n",
    "    if first_recall_item is not None:\n",
    "        model.force_recall(first_recall_item)\n",
    "        retrieval_contexts = np.vstack((retrieval_contexts, model.context))\n",
    "        retrieval_supports = np.vstack((retrieval_supports, model.outcome_probabilities(\n",
    "            activation_cue(model))))\n",
    "\n",
    "    # actual recall\n",
    "    while model.retrieving:\n",
    "        model.free_recall(1)\n",
    "        retrieval_contexts = np.vstack((retrieval_contexts, model.context))\n",
    "        retrieval_supports = np.vstack((retrieval_supports, model.outcome_probabilities(\n",
    "            activation_cue(model))))\n",
    "\n",
    "    return retrieval_contexts, retrieval_supports, model.recall[:model.recall_total]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# export\n",
    "\n",
    "def outcome_probs_at_index(model, support_index_to_plot=1, savefig=True):\n",
    "    \"\"\"\n",
    "    Plots outcome probability distribution at a specific index of free recall.\n",
    "\n",
    "    **Required model attributes**:\n",
    "    - item_count: specifies number of items encoded into memory\n",
    "    - context: vector representing an internal contextual state\n",
    "    - experience: adding a new trace to the memory model\n",
    "    - activations: function returning item activations given a vector probe\n",
    "    - outcome_probabilities: function returning item supports given a set of activations\n",
    "    - free_recall: function that freely recalls a given number of items or until recall stops\n",
    "    - state: indicates whether model is encoding or engaged in recall with a string\n",
    "\n",
    "    **Other arguments**:\n",
    "    - support_index_to_plot: index of retrieval to plot\n",
    "    - savefig: whether to save or display the figure of interest\n",
    "\n",
    "    **Generates** a plot of outcome probabilities as a line graph. Also returns vector representation of the\n",
    "    generated probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    retrieval_supports = retrieval_states(model)[1]\n",
    "    plt.plot(np.arange(model.item_count + 1), retrieval_supports[support_index_to_plot])\n",
    "    plt.xlabel('Choice Index')\n",
    "    plt.ylabel('Outcome Probability')\n",
    "    plt.title('Outcome Probabilities At Recall Index {}'.format(support_index_to_plot))\n",
    "    plt.show()\n",
    "    return retrieval_supports[support_index_to_plot]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# export\n",
    "\n",
    "def retrieval_visualizations(model, savefig=True):\n",
    "    \"\"\"\n",
    "    Plots incremental retrieval contexts and supports, as heatmaps, and prints recalled items.\n",
    "\n",
    "    **Required model attributes**:\n",
    "    - item_count: specifies number of items encoded into memory\n",
    "    - context: vector representing an internal contextual state\n",
    "    - experience: adding a new trace to the memory model\n",
    "    - activations: function returning item activations given a vector probe\n",
    "    - outcome_probabilities: function returning item supports given a set of activations\n",
    "\n",
    "    **Also** uses savefig: boolean deciding whether figures are saved (True) or displayed\n",
    "    \"\"\"\n",
    "\n",
    "    retrieval_contexts, retrieval_supports, recall = retrieval_states(model)\n",
    "    plot_states(retrieval_contexts, 'Retrieval Contexts', savefig=savefig)\n",
    "    plot_states(retrieval_supports, 'Supports For Each Item At Each Increment of Retrieval',\n",
    "                savefig=savefig)\n",
    "    return recall"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Demo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = CMR(**cmr_parameters)\n",
    "retrieval_visualizations(model)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}