{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's The Status?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I did that pointless analysis that I finished June 10, I was facing a fork in the road.\n",
    "\n",
    "On the one hand, I considered finally implementing CMR-DE (a version of CMR with differential encoding) and exploring its consequences for fit. This would be a natural progression for the project, but I worried it skipped a step. After all, CMR-DE is only really warranted if CMR can't do a good on its own of accounting for repetition effects in free recall -- and I haven't incontrovertibly established yet. \n",
    "\n",
    "Along those lines, I considered reproducing the entire curve-based fitting technique demoed by Polyn et al, 2009, essentially improving on my simpler MSE-based fitting algorithm. This was intended to set up a stronger test of the hypothesis that CMR can't account for the spacing effect to the extent that it should. The idea -- one I'm more dubious about now, for reasons I might review later -- was that if I could show that CMR can't simultaneously exhibit a good CRP, SPC, and so on along with a good spacing effect curve, then CMR has to be dumped. \n",
    "\n",
    "In the end, though, I got caught up in the idea of coming up with a novel analysis that aimed to detect differential encoding in recall behavior. However, I found the opposite pattern in the Lohnas (2014) dataset than what I was looking to find. Worse, I'm still not sure if the analysis was even sound. In retrospect, a key error in my development process was not first validating it on simulated data that I knew to either enforce or not enforce the difference I wanted to test. With CMR and a newly implemented CMR-DE, I would have been able to do that. Furthermore, I'd have been able to explore the behavior of CMR-DE to help identify a more rigorous analysis approach worthy of the development time. I'd have been able to experiment and *see* rather than try to reason out the behavioral \"forks in the road\" implied to be taken by different values of the differential encoding parameter.\n",
    "\n",
    "Another gap in my approach here is probably how amateurishly I'm conceptualizing statistical testing here. We already know for sure that CMR can approximate the spacing curve to some extent, even after fitting. What we don't even know yet is if the difference I'm obsessing over between the data and the model simulation is meaningful or not. If I can figure out the applicable math, there's probably a straightforward statistical test I can apply to measure whether there's a significant difference between the spacing curve I'm observing and what CMR predicts given the data I have. If I can't measure a significant difference, the bar this project has to scale gets super high. And I wouldn't really need an additional complex analysis to show it.\n",
    "\n",
    "What I'd like to see is evidence that improving fit to one analysis outcome improves fit to the others - the OR score analysis and so on. The idea behind those analysis is that they each identify unique aspects of CMR that contribute to the spacing effect, so something that simple is unlikely to happen. But clarifying how differential encoding within RCT relates to those patterns will be very valuable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So What to Do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm the Difference is Real\n",
    "I should probably first confirm that the difference in spacing effect distributions between the fitted CMR model and the actual data is significant, maybe applying a Chi-Square Test to show as much. A limitation of the test I noted suggest that it's trivial at high sample sizes, so maybe I should confirm with someone that the result would convince anyone that it's a gap worth addressing with research. But if the difference is not significant anyway, then the project is poorly motivated as I've been conceiving it.\n",
    "\n",
    "I might be wrong, but I don't think I need another fitting method here after all. Even if it were the case that a certain parameter configuration for CMR can account for CRP, SPC, PFR, and the spacing curves to some extent (I'm sort of already sure there is?), it's enough to demonstrate that the fit leaves a lot to be desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement CMR-DE\n",
    "Can consider two kinds - a simple serial-position-based learning rate modulator, or one that tests for contextual similarity. This should come before I attempt to design another clever analysis that tries to measure differential encoding, since simulation experiments with the model would be very useful for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm that Extending CMR this Way Significantly Improves Fits\n",
    "Another chi-square test should show as much; comparisons would offer a useful visualization. At the same time, it's a foregone conclusion that adding a parameter to a model makes it easier to fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characterize How Different Values of the Modulatory Parameter Affect Predicted Recall and Associated Repetition Effects\n",
    "This is where we start actually learning things about the model that we don't already presuppose. The big question of the paper is not whether CMR-DE will do better, but to clarify why CMR struggles to account for repetition effects. Understanding what CMR-DE captures _behaviorally_ that CMR is the way we try to find that out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
