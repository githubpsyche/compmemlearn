Currently have three avenues for further work in mind. 

The first focuses on getting a handle on the whole "serial recall" aspect of this -- clarifying through literature review how serial recall data should be modeled and analyzed differently to reveal the most about how people represent stories in memory. Gordon recently-ish published a paper on serial order memory that CMR substantially inspires; I might take that as a starting point.

The others focus on testing common assumptions from the theories of reading comprehension I've read about. The landscape model of comprehension, for example, has two that seem to diverge from CMR's assumptions.

Comprehension models (but not Base CMR or Semantic CMR) assume that semantic similarity is pivotal in how items are reinstated into context throughout story reading. For example, reading about "bears" in one idea unit and about "wild animals" in a later idea unit can remind you of the "bear" unit and bring it back into active context to shape learned associations.

Neal's item-cue variant of Semantic CMR that I examined doesn't quite contain this assumption. Instead, Semantic CMR assumes that semantic similarity directly influences only the recall process. Still, given our results, I'm unsure if we'll find evidence of similarity-driven contextual reinstatement in our data. One could pursue either a behavioral analysis or a model evaluation route to evaluate this idea. The model evaluation route involves creating and fitting a variant of CMR that contains the assumption we're examining. As for behavioral analyses, I think there are ways to extend repetition effect analyses developed by Lohnas & Kahana (2014) to instead reinstatement effects driven by semantic similarity (or other factors), though the analyses might require different data from what we have at hand.

Finally, comprehension models assume that syntax can group idea units in memory. For example, two adjacent idea units in the same sentence should be recalled together more reliably than two adjacent idea units that aren't in the same sentence. In the landscape model, this assumption is implemented through unit co-processing. By contrast, Base CMR and Semantic CMR always process one item at a time in the order they're encoded. But I don't think it would be tough to modify these models to allow unit co-processing. An analysis that would test this assumption would presumably involve looking at rates of +1 lag transitions between units in the same sentence vs. separate sentences. We could end up needing to recode idea units according to a more principled methodology if we emphasized this issue. 

The landscape model otherwise doesn't differ much from CMR, aside from its weaker assumptions about how free recall happens. So what next? 

I get the feeling that digging into the unique features of serial recall might help me avoid analytical pitfalls that accompany the assumption that contiguity in recall corresponds to connectivity in memory. At the same time, the similarity-driven context reinstatement idea is something I can start exploring relatively readily in word list FR data, sidestepping this issue. And the syntactic grouping idea doesn't hinge on the serial/free recall issue.

If I want to examine the landscape model itself and its extensions, I'll have to add some unit co-processing support to my model evaluation codebase. How urgent is that? It depends on how much a prospective paper emphasizes the landscape model -- which might not prove much. Good to keep on the radar as a motive for going that line.

And similarity-driven contextual reinstatement's differences from Semantic CMR's assumptions aren't enough to explain why Semantic CMR couldn't outperform Base CMR here. After all, similarity worked reasonably fine as a direct cue in the other dataset. I'm sure similarity-driven context reinstatement is part of the story here. Still, I'm unsure if implementing and performing the model-based evaluation of the mechanism would provide evidence that it helps explain narrative 'free' recall.

If I can't find evidence of similarity-driven contextual reinstatement in free recall, any paper I make focusing on narrative memory will be that much weaker. But how much more vulnerable? Base CMR still seems like a good account of narrative free recall. It fits relatively well with the SPC, CRP, and PFR. I'm just missing encoding and semantic phenomena. These are big deals; comprehension is practically all semantic and encoding phenomena. I can say CMR has to be in the neighborhood given its performance, but many models that don't contain RCT assumptions can account for serial recall, including perhaps the landscape model.

If narrative recall is performed as serial recall, then I can't easily test the similarity-driven context reinstatement hypothesis using this data, even with a fitting approach. But I can arguably test it in the context of free recall with the recent dataset from Mike. If I can't find the effect, then assuming similarity driven context reinstatement must be part of the story of comprehension, I'll be cut off from being able to tell that story in terms of a model mechanisms that also account for word list recall.

Would that be the end of my research on narrative recall? Perhaps, but perhaps not. A paper about the otherwise hidden differences between the tasks could still be possible. I still believe that I can make a variant of CMR that broadly makes the same predictions as the landscape model and thus have all the same feats, even if it has a worse ability to account for word list memory. But the fact that Neal has been working on CMR variants that set aside a separate context representation that evolves based on semantic features implies to me that I won't be so unlucky.

My implementation of the Landscape model is missing a similarity-driven info reinstatement step. Wait, no, that's sigma. context_input is calculated as dot product of experience and memory in both models. In CMR, then this value is blended with previous context to make current context. In the landscape model, it looks like I "blend" context_input with maximal activation of the current item(s). I'll need to revisit the code to make sure that's right.

Okay, so it's right to focus on the similarity-driven context reinstatement stuff. It won't directly test whether I can account for comprehension with a CMR variant. But it will test whether a common account of word list and narrative recall is even possible. From there I get to either keep drawing connections or more aggressively highlight distinctions, probably by finding more phenomena to simulate.