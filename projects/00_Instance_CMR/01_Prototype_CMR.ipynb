{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb672a9-a48d-4de8-ad54-8099cd1dc4cb",
   "metadata": {},
   "source": [
    "# The Prototype-Based Account of Context Maintenance and Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606883c-7705-4177-81b6-d3d21ad54e94",
   "metadata": {},
   "source": [
    "Retrieved context theories explain memory search in terms of interactions between between two representations across experience: one of temporal context (a context layer, $C$) and another of features of studied items (an item layer, $F$). While this paper introduces an instance-based account of these interactions, we here specify a variant of the original prototype-based context maintenance and retrieval (CMR) model [@polyn2009context] to support comparison against this account. The instance-based model we emphasize tracks the history of interactions between context and item features by storing a discrete record of each experience in memory for later inspection. In contrast, PrototypeCMR maintains a simplified neural network whose connection weights accumulate a center of tendency representation reflecting context and item interactions across experience. \n",
    "\n",
    "\n",
    "| Structure Type        | Symbol            | Name                    | Description                                                 |\n",
    "|:----------------------|:------------------|:------------------------|:------------------------------------------------------------|\n",
    "| Architecture          |                   |                         |                                                             |\n",
    "|                       | $C$               | temporal context        | A recency-weighted average of encoded items      |\n",
    "|                       | $F$               | item features           | Current pattern of item feature unit activations      |\n",
    "|                       | $M^{FC}$          |                         | encoded feature-to-context associations      |\n",
    "|                       | $M^{CF}$          |                         | encoded context-to-feature associations      |\n",
    "| Context Updating      |                   |                         |                                                             |\n",
    "|                       | ${\\beta}_{enc}$   | encoding drift rate     | Rate of context drift during item encoding                  |\n",
    "|                       | ${\\beta}_{start}$ | start drift rate        | Amount of start-list context retrieved at start of recall   |\n",
    "|                       | ${\\beta}_{rec}$   | recall drift rate       | Rate of context drift during recall                         |\n",
    "| Associative Structure |                   |                         |                                                             |\n",
    "|                       | ${\\alpha}$        | shared support          | Amount of support items initially have for one another      |\n",
    "|                       | ${\\delta}$        | item support            | Initial pre-experimental contextual self-associations       |\n",
    "|                       | ${\\gamma}$        | learning rate           | Amount of experimental context retrieved by a recalled item |\n",
    "|                       | ${\\phi}_{s}$      | primacy scale           | Scaling of primacy gradient on trace activations            |\n",
    "|                       | ${\\phi}_{d}$      | primacy decay           | Rate of decay of primacy gradient                           |\n",
    "| Retrieval Dynamics    |                   |                         |                                                             |\n",
    "|                       | ${\\tau}$          | choice sensitivity      | Exponential weighting of similarity-driven activation       |\n",
    "|                       | ${\\theta}_{s}$    | stop probability scale  | Scaling of the stop probability over output position        |\n",
    "|                       | ${\\theta}_{r}$    | stop probability growth | Rate of increase in stop probability over output position   |\n",
    "\n",
    " : Parameters and structures specifying CMR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f9d53e-96a1-4f20-a5c8-b49a509e0a6c",
   "metadata": {},
   "source": [
    "## Initial State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594c338-d1c8-47d8-8bf1-261d88071709",
   "metadata": {},
   "source": [
    "Associative connections built within prototypeCMR are represented by matrices $M^{FC}$ and $M^{CF}$.\n",
    "\n",
    "To summarize pre-experimental associations built between relevant item features and possible contextual states, we initialize $M^{FC}$ according to:\n",
    "\n",
    "\\begin{equation} \\label{eq:1}\n",
    "M^{FC}_{pre(ij)} = \\begin{cases} \\begin{alignedat}{2} 1 - \\gamma \\text{, if } i=j \\\\\\\n",
    "          0 \\text{, if } i \\neq j\n",
    "       \\end{alignedat} \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "This connects each unit on $F$ to a unique unit on $C$. Used this way, $\\gamma$ controls the relative contribution of pre-experimentally acquired associations to the course of retrieval compared to experimentally acquired associations. Correspondingly, context-to-feature associations tracked by $M^{CF}$ are set according to:\n",
    "\n",
    "\\begin{equation} \\label{eq:2}\n",
    "M^{CF}_{pre(ij)} = \\begin{cases} \\begin{alignedat}{2} 1 - \\delta \\text{, if } i=j \\\\\\\n",
    "          \\alpha \\text{, if } i \\neq j\n",
    "       \\end{alignedat} \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Like $\\gamma$ with respect to $M^{FC}$, the $\\delta$ parameter controls the contribution of pre-experimental context-to-feature associations relative to experimentally acquired ones. Since context-to-feature associations organizes the competition of items for retrieval, the $\\alpha$ parameter specifies a uniform baseline extent to which items support one another in that competition.\n",
    "\n",
    "Context is initialized with a state orthogonal to any of those pre-experimentally associated with an relevant item feature. Feature representations corresponding to items are also assumed to be orthonormal with respect to one another such that each unit on $F$ corresponds to one item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58842904-344c-40c2-aca1-6a0ba73feb0e",
   "metadata": {},
   "source": [
    "## Encoding Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c828c6-920c-484f-9326-b92c05847093",
   "metadata": {},
   "source": [
    "Whenever an item $i$ is presented for study, its corresponding feature representation $f_i$ is activated on $F$ and its contextual associations encoded into $M^{FC}$ are retrieved, altering the current state of context $C$.\n",
    "\n",
    "The input to context is determined by:\n",
    "\n",
    "\\begin{equation} \\label{eq:3}\n",
    "c^{IN}_{i} = M^{FC}f_{i}\n",
    "\\end{equation}\n",
    "\n",
    "and normalized to have length 1. Context is updated based on this input according to:\n",
    "\n",
    "\\begin{equation} \\label{eq:4}\n",
    "c_i = \\rho_ic_{i-1} + \\beta_{enc} c_{i}^{IN}\n",
    "\\end{equation}\n",
    "\n",
    "with $\\beta$ (for encoding we use $\\beta_{enc}$) shaping the rate of contextual drift with each new experience, and $\\rho$ enforces the length of $c_i$ to 1 according to:\n",
    "\n",
    "\\begin{equation} \n",
    "\\rho_i = \\sqrt{1 + \\beta^2\\left[\\left(c_{i-1} \\cdot c^{IN}_i\\right)^2 - 1\\right]} - \\beta\\left(c_{i-1} \\cdot\n",
    "c^{IN}_i\\right)\n",
    "\\label{eq:5}\n",
    "\\end{equation}\n",
    "\n",
    "Associations between each $c_i$ and $f_i$ are built through Hebbian learning:\n",
    "\n",
    "\\begin{equation} \\label{eq:6\n",
    "}\\Delta M^{FC}_{exp} = \\gamma c_i f^{'}_i\n",
    "\\end{equation}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{equation} \\label{eq:7}\n",
    "\\Delta M^{CF}_{exp} = \\phi_i f_i c^{'}_i\n",
    "\\end{equation}\n",
    "\n",
    "where $\\phi_i$ enforces a primacy effect, scales the amount of learning based on the serial position of the studied item according to\n",
    "\n",
    "\\begin{equation} \\label{eq:8}\n",
    "\\phi_i = \\phi_se^{-\\phi_d(i-1)} + 1\n",
    "\\end{equation}\n",
    "\n",
    "This function decays over time, such that $\\phi_{s}$ modulates the strength of primacy while $\\phi_{d}$ modulates the rate of decay.\n",
    "\n",
    "This extended Hebbian learning process characterizes how PrototypeCMR performs abstraction. When each item is encoded with a particular temporal context, representations are updated to aggregate a prototypical summary of the item's temporal contextual associations in $M^{FC}$ and vice versa in $M^{CF}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96cc8a5-2fd9-4a11-8cfd-b312a9a6b139",
   "metadata": {},
   "source": [
    "## Retrieval Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebfd5ca-053b-4325-9ec6-23fe1dd7b30a",
   "metadata": {},
   "source": [
    "To help the model account for the primacy effect, we assume that between the encoding and retrieval phase of a task, the content of $C$ has drifted some amoung back toward its pre-experimental state and set the state of context at the start of retrieval according to following, with $\\rho$ calculated as specified above:\n",
    "\n",
    "\\begin{equation} \\label{eq:9}\n",
    "c_{start} = \\rho_{N+1}c_N + \\beta_{start}c_0\n",
    "\\end{equation}\n",
    "\n",
    "At each recall attempt, the current state of context is used as a cue to attempt retrieval of some studied item. An activation $a$ is solicited for each item according to:\n",
    "\n",
    "\\begin{equation} \\label{eq:10}\n",
    "a = M^{CF}c\n",
    "\\end{equation}\n",
    "\n",
    "Each item gets a minimum activation of $10^{-7}$. To determine the probability of a given recall event, we first calculate the probability of stopping recall - returning no item and ending memory search. This probability varies as a function of output position $j$:\n",
    "\n",
    "\\begin{equation} \\label{eq:11}\n",
    "P(stop, j) = \\theta_se^{j\\theta_r}\n",
    "\\end{equation}\n",
    "\n",
    "In this way, $\\theta_s$ and $\\theta_r$ control the scaling and rate of increase of this exponential function. Given that recall is not stopped, the probability $P(i)$ of recalling a given item depends mainly on its activation strength according\n",
    "\n",
    "\\begin{equation} \\label{eq:12}\n",
    "P(i) = (1-P(stop))\\frac{a^{\\tau}_i}{\\sum_{k}^{N}a^{\\tau}_k}\n",
    "\\end{equation}\n",
    "\n",
    "$\\tau$ here shapes the contrast between well-supported and poorly supported items: exponentiating a large activation and a small activation by a large value of $\\tau$ widens the difference between those activations, making recall of the most activated item even more likely. Small values of $\\tau$ can alternatively driven recall likelihoods of differentially activated items toward one another.\n",
    "\n",
    "If an item is recalled, then that item is reactivated on $F$, and its contextual associations retrieved for integration into context again according to:\n",
    "\n",
    "\\begin{equation} \\label{eq:13}\n",
    "c^{IN}_{i} = M^{FC}f_{i}\n",
    "\\end{equation}\n",
    "\n",
    "Context is updated again based on this input (using $\\beta_{rec}$ instead of $\\beta_{enc}$) and used to cue a successive recall attempt. This process continues until recall stops."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
