1. We wanted to show that these were similar, and that was true!

Introduce variants in methods description where we choose an implementation.
Here's how we form associations. Here's how context evolution is the same. Etc.

The goal is a unified model that can do all these things "recognition, free, serial, cued". We have models that can do one or the other. But yeah.

Since most models in other domains are instance-based, this represents one step toward that. We show that mechanisms of RCT can be readily embedded in instance framework, supporting future work toward a unified model.

if you need to flexibly re-weight traces based on probe, instance-model can do it, linear associator sometimes can't w/o extra accomodation.

These aren't formally mathematically equivalent, 

Goal is to remove boundary between these frameworks, not set them against one another. It's artificial. You can tackle these other issues. 

Focus on providing insight into how each model works.

cross validation at level of subject: fit to all but one session, prediction on held-out session. makes models look more similar.

one shortcoming of both models is the stop rule! 
as easy with instance and linear associator models to swap out decision rule (latency)

end of ch4 kahana book has paired associate learning thing focused on symmetry