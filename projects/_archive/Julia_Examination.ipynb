{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e66e0124-da6b-4d86-af94-a126cfd257fa",
   "metadata": {},
   "source": [
    "# Am I Better Off With Julia?\n",
    "Is Julia better for the kind of work I do? To find out, I explore how hard it is to write Julia code that runs as or more quickly as my Numba-compiled Python code that produces...\n",
    "- A Serial Position Curve\n",
    "- A Lag-CRP\n",
    "- A Fitted CMR parameter configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ae08a-4303-4ee3-8eca-7a24f424f9c3",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ec777d-fae1-4271-9fe9-39b9d197057c",
   "metadata": {},
   "source": [
    "### PyCall\n",
    "First let's work out how cleanly and quickly Pycall can retrieve the output of my `prepare_murdock1962_data` function that will form the basis of these tests.\n",
    "\n",
    "At first I copied my matching code cell from my Python-based notebook and tried to call it with PyCall. I found that the library could not find my compmemlearn package. This is because PyCall installed and uses a separate version of Python in my .julia folder. I have to use that to install packages. \n",
    "\n",
    "Doing the editable install through my terminal this way worked ok enough, but installing an online package caused trouble because \"the SSL module is not available\". When I open PyCall's `python.exe`, `import ssl` results in a corresponding ModuleNotFoundError.\n",
    "\n",
    "In the end, I set PyCall's environment to use my main Python instance instead of the workspace it created. I ran this sample based on [a solution shared by angelv](https://discourse.julialang.org/t/import-package-from-python/47144/12) as a code cell and restarted my kernel:\n",
    "\n",
    "```python\n",
    "ENV[\"PYTHON\"]=\"c:/programdata/miniconda3/python.exe\"                                                                                              \n",
    "using Pkg\n",
    "pkg\"build PyCall\"\n",
    "using PyCall\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e1f3f8-f874-4772-979e-b142c45ed917",
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d05d4-7390-4f9a-b27d-5563c444bf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "[15, 16, 17, 18, 20, 11, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>item</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>study</th>\n",
       "      <th>recall</th>\n",
       "      <th>repeat</th>\n",
       "      <th>intrusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PyObject    subject  list  item  input  output  study  recall  repeat  intrusion\n",
       "0        1     1     1      1     NaN   True   False       0      False\n",
       "1        1     1     2      2     NaN   True   False       0      False\n",
       "2        1     1     3      3     NaN   True   False       0      False\n",
       "3        1     1     4      4     NaN   True   False       0      False\n",
       "4        1     1     5      5     NaN   True   False       0      False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py\"\"\"\n",
    "from compmemlearn.datasets import prepare_murdock1970_data\n",
    "\n",
    "trials, events, list_length = prepare_murdock1970_data('../../data/mo1970.txt')\n",
    "events.head()\n",
    "\"\"\"\n",
    "\n",
    "println(py\"list_length\" + py\"list_length\")\n",
    "println(py\"trials[0]\")\n",
    "py\"events\".head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8b076e-0d2a-4766-b81c-f4f1d2bbbba0",
   "metadata": {},
   "source": [
    "This executes pretty quickly (no apparent compilation after the first using) and these variables are surprisingly easy to play with. However, if we check their types, we see we're not totally finished pulling the DataFrame out of Julia, though other variables are converted cleanly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a1cc8-4025-416c-83e5-1f493dc2285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64\n",
      "PyObject\n",
      "Matrix{Int64}\n"
     ]
    }
   ],
   "source": [
    "println(typeof(py\"list_length\"))\n",
    "println(typeof(py\"events\"))\n",
    "println(typeof(py\"trials\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f1ee81-cdd7-400d-b5de-aea6067a8471",
   "metadata": {},
   "source": [
    "A `pd_to_df` function [proposed by lungben](https://discourse.julialang.org/t/converting-pandas-dataframe-returned-from-pycall-to-julia-dataframe/43001/2) seems to finish the conversion quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1c9ca-1f43-45ce-b16c-0258130efa7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 9 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>subject</th><th>list</th><th>item</th><th>input</th><th>output</th><th>study</th><th>recall</th><th>repeat</th><th>intrusion</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Bool\">Bool</th><th title=\"Bool\">Bool</th><th title=\"Int32\">Int32</th><th title=\"Bool\">Bool</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>1</td><td>1</td><td>1</td><td>NaN</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>2</th><td>1</td><td>1</td><td>2</td><td>2</td><td>NaN</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>3</th><td>1</td><td>1</td><td>3</td><td>3</td><td>NaN</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>4</th><td>1</td><td>1</td><td>4</td><td>4</td><td>NaN</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>5</th><td>1</td><td>1</td><td>5</td><td>5</td><td>NaN</td><td>1</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& subject & list & item & input & output & study & recall & repeat & intrusion\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Float64 & Bool & Bool & Int32 & Bool\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 1 & 1 & NaN & 1 & 0 & 0 & 0 \\\\\n",
       "\t2 & 1 & 1 & 2 & 2 & NaN & 1 & 0 & 0 & 0 \\\\\n",
       "\t3 & 1 & 1 & 3 & 3 & NaN & 1 & 0 & 0 & 0 \\\\\n",
       "\t4 & 1 & 1 & 4 & 4 & NaN & 1 & 0 & 0 & 0 \\\\\n",
       "\t5 & 1 & 1 & 5 & 5 & NaN & 1 & 0 & 0 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×9 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m subject \u001b[0m\u001b[1m list  \u001b[0m\u001b[1m item  \u001b[0m\u001b[1m input \u001b[0m\u001b[1m output  \u001b[0m\u001b[1m study \u001b[0m\u001b[1m recall \u001b[0m\u001b[1m repeat \u001b[0m\u001b[1m intrusion\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64   \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Bool  \u001b[0m\u001b[90m Bool   \u001b[0m\u001b[90m Int32  \u001b[0m\u001b[90m Bool     \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │       1      1      1      1      NaN   true   false       0      false ⋯\n",
       "   2 │       1      1      2      2      NaN   true   false       0      false\n",
       "   3 │       1      1      3      3      NaN   true   false       0      false\n",
       "   4 │       1      1      4      4      NaN   true   false       0      false\n",
       "   5 │       1      1      5      5      NaN   true   false       0      false ⋯"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames\n",
    "\n",
    "function pd_to_df(df_pd)\n",
    "    df= DataFrame()\n",
    "    for col in df_pd.columns\n",
    "        df[!, col] = getproperty(df_pd, col).values\n",
    "    end\n",
    "    df\n",
    "end\n",
    "\n",
    "trials = py\"trials\"\n",
    "list_length = py\"list_length\"\n",
    "events = pd_to_df(py\"events\")\n",
    "first(events, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c4bc6c-d932-412a-96fa-1b8f603bc304",
   "metadata": {},
   "source": [
    "I gotta wonder if PythonCall handles this transfer more cleanly or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af627a6e-aeac-431a-a3fd-94f660961b65",
   "metadata": {},
   "source": [
    "## Serial Position Effect\n",
    "\n",
    "My first attempt uses StatsBase and the global scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e462b8e4-4660-4fe2-99a5-6a324eae534c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000034 seconds (2 allocations: 448 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20-element Vector{Float64}:\n",
       " 0.44305555555555554\n",
       " 0.29097222222222224\n",
       " 0.2222222222222222\n",
       " 0.18958333333333333\n",
       " 0.1388888888888889\n",
       " 0.15694444444444444\n",
       " 0.15486111111111112\n",
       " 0.14097222222222222\n",
       " 0.16041666666666668\n",
       " 0.18958333333333333\n",
       " 0.15347222222222223\n",
       " 0.1875\n",
       " 0.21875\n",
       " 0.2534722222222222\n",
       " 0.27847222222222223\n",
       " 0.3125\n",
       " 0.3972222222222222\n",
       " 0.5875\n",
       " 0.6881944444444444\n",
       " 0.7875"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using StatsBase\n",
    "\n",
    "fast_spc(trials, item_count) = counts(trials, item_count) / size(trials, 1)\n",
    "\n",
    "fast_spc(trials, 20);\n",
    "@time fast_spc(trials, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989baeab-f15c-408f-b83b-ebd6274ba7a1",
   "metadata": {},
   "source": [
    "## Lag-CRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe66e2-c555-4cdf-a8cd-db60db980551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fast_crp (generic function with 1 method)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fast_crp(trials, item_count)\n",
    "    \n",
    "    lag_range = item_count\n",
    "    total_actual_lags = zeros(lag_range * 2 + 1)\n",
    "    total_possible_lags = zeros(lag_range * 2 + 1)\n",
    "    terminus = sum(trials .!= 0, dims=2) .- 1\n",
    "    \n",
    "    # compute actual serial lag b/t recalls\n",
    "    actual_lags = trials[:, 2:end] - trials[:, begin:end-1]\n",
    "    actual_lags = actual_lags .+ lag_range\n",
    "    \n",
    "    # tabulate bin totals for actual and possible lags\n",
    "    for i in 1:size(trials, 1)\n",
    "        possible_items = 1:(item_count + 1)\n",
    "        previous_item = 0\n",
    "        \n",
    "        for recall_index in 1:terminus[i]\n",
    "            \n",
    "            # track possible and actual lags\n",
    "            if recall_index > 1\n",
    "                total_actual_lags[actual_lags[i, recall_index-1]] += 1\n",
    "                                \n",
    "                # exploit equivalence b/t item index and study position to track possible lags\n",
    "                possible_lags = possible_items .- previous_item \n",
    "                possible_lags .+= lag_range\n",
    "                total_possible_lags[possible_lags] .+= 1\n",
    "                \n",
    "            end\n",
    "            \n",
    "            # update pool of possible items to exclude recalled item\n",
    "            previous_item = trials[i, recall_index]\n",
    "            possible_items = possible_items[possible_items .!= previous_item]\n",
    "            \n",
    "        end\n",
    "        \n",
    "        # small correction to avoid nans\n",
    "        total_possible_lags[total_actual_lags.==0] .+= 1\n",
    "    end\n",
    "    \n",
    "    return total_actual_lags/total_possible_lags\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c59e1d-caa0-4c76-88a6-6e79eab55d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41×41 Matrix{Float64}:\n",
       " 0.000252908  0.000486841  0.000695565  …  0.000479522  0.00039034\n",
       " 0.000143477  0.000276189  0.000394599     0.000272037  0.000221443\n",
       " 0.000184817  0.000355768  0.000508297     0.00035042   0.000285249\n",
       " 0.000131318  0.000252783  0.000361159     0.000248983  0.000202677\n",
       " 0.00014834   0.000285551  0.000407975     0.000281258  0.00022895\n",
       " 0.00017509   0.000337044  0.000481545  …  0.000331977  0.000270236\n",
       " 0.000204272  0.000393218  0.000561802     0.000387306  0.000315275\n",
       " 0.000213999  0.000411942  0.000588555     0.00040575   0.000330288\n",
       " 0.000177522  0.000341725  0.000488233     0.000336588  0.000273989\n",
       " 0.000233454  0.000449392  0.00064206      0.000442636  0.000360314\n",
       " 0.000196976  0.000379174  0.000541738  …  0.000373474  0.000304015\n",
       " 0.000226158  0.000435348  0.000621995     0.000428804  0.000349054\n",
       " 0.000303976  0.000585146  0.000836015     0.000576349  0.000469159\n",
       " ⋮                                      ⋱               ⋮\n",
       " 0.000102136  0.000196609  0.000280901     0.000193653  0.000157637\n",
       " 6.56588e-5   0.000126391  0.000180579  …  0.000124491  0.000101338\n",
       " 7.5386e-5    0.000145116  0.000207332     0.000142935  0.000116351\n",
       " 4.13407e-5   7.95798e-5   0.000113698     7.83834e-5   6.38056e-5\n",
       " 3.40453e-5   6.55363e-5   9.36337e-5      6.45511e-5   5.25458e-5\n",
       " 4.62043e-5   8.89421e-5   0.000127074     8.7605e-5    7.13122e-5\n",
       " 3.64771e-5   7.02175e-5   0.000100322  …  6.91619e-5   5.62991e-5\n",
       " 3.40453e-5   6.55363e-5   9.36337e-5      6.45511e-5   5.25458e-5\n",
       " 3.16135e-5   6.08551e-5   8.69456e-5      5.99403e-5   4.87925e-5\n",
       " 7.29542e-6   1.40435e-5   2.00644e-5      1.38324e-5   1.12598e-5\n",
       " 0.0          0.0          0.0             0.0          0.0\n",
       " 0.0          0.0          0.0          …  0.0          0.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_crp(trials, list_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952085cf-af0b-40de-b23e-708498876a53",
   "metadata": {},
   "source": [
    "### Trying Out PythonCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dc3a75-dce1-4373-ba0e-ed7b7f5bbc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"JULIA_PYTHONCALL_EXE\"]=\"c:/programdata/miniconda3/python.exe\"                                                                                              \n",
    "using Pkg\n",
    "pkg\"build PythonCall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a8a10-58af-4faa-aa36-ef581a2e3252",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: MethodError: no method matching var\"@py\"(::LineNumberNode, ::Module, ::Symbol, ::Expr, ::Expr)\n\u001b[0mClosest candidates are:\n\u001b[0m  var\"@py\"(::LineNumberNode, ::Module, ::Any) at C:\\Users\\gunnj\\.julia\\packages\\PythonCall\\7klbm\\src\\py_macro.jl:799\nin expression starting at In[8]:2",
     "output_type": "error",
     "traceback": [
      "LoadError: MethodError: no method matching var\"@py\"(::LineNumberNode, ::Module, ::Symbol, ::Expr, ::Expr)\n\u001b[0mClosest candidates are:\n\u001b[0m  var\"@py\"(::LineNumberNode, ::Module, ::Any) at C:\\Users\\gunnj\\.julia\\packages\\PythonCall\\7klbm\\src\\py_macro.jl:799\nin expression starting at In[8]:2",
      "",
      "Stacktrace:",
      " [1] eval",
      "   @ .\\boot.jl:373 [inlined]",
      " [2] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "using PythonCall\n",
    "@py from compmemlearn.analyses import prepare_murdock1970_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4b453-b9e4-4c54-b5dc-ac37ba319f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[1mPython int: \u001b[22m3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@py 1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea92d6-6539-4dd7-80d1-f827618714d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@py import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838be520-d8c5-42e5-a0a8-d7ebfb42c44b",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: MethodError: no method matching var\"@py\"(::LineNumberNode, ::Module, ::Symbol, ::Expr, ::Expr)\n\u001b[0mClosest candidates are:\n\u001b[0m  var\"@py\"(::LineNumberNode, ::Module, ::Any) at C:\\Users\\gunnj\\.julia\\packages\\PythonCall\\7klbm\\src\\py_macro.jl:799\nin expression starting at In[17]:1",
     "output_type": "error",
     "traceback": [
      "LoadError: MethodError: no method matching var\"@py\"(::LineNumberNode, ::Module, ::Symbol, ::Expr, ::Expr)\n\u001b[0mClosest candidates are:\n\u001b[0m  var\"@py\"(::LineNumberNode, ::Module, ::Any) at C:\\Users\\gunnj\\.julia\\packages\\PythonCall\\7klbm\\src\\py_macro.jl:799\nin expression starting at In[17]:1",
      "",
      "Stacktrace:",
      " [1] eval",
      "   @ .\\boot.jl:373 [inlined]",
      " [2] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "@py from compmemlearn.analyses import prepare_murdock1970_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199dbc18-b53e-4312-a325-8898fc7fbd1c",
   "metadata": {},
   "source": [
    "I can't get it to eval imports that use `from` I guess?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e662e731-6a49-451a-a539-1442d735b84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46b02093-c57e-450c-92fb-c2aae5ea5a2e",
   "metadata": {},
   "source": [
    "## General Notes\n",
    "- Installing new packages like PyCall and DataFrames takes a long time compared to pip!\n",
    "- There isn't just PyCall. PythonCall and JuliaCall seem to be newer and have some nice features to make cross-use more seamless.\n",
    "- No tradition of selective function imports that make clear which functions are available in the global namespace or not. I kinda don't like that. Ah -- I can use import instead. Thank goodness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7933aefa-dfb4-427c-a529-e7631d40ffce",
   "metadata": {},
   "source": [
    "## Language Learning Notes\n",
    "Pycall uses a string macro to handle my short python scripts. That's why it doesn't look like I'm using a normal `function(arg1, arg2)`. \n",
    "\n",
    "Check item types with `typeof`. Use `isa` to test for types -- ex. `1 isa Number`.\n",
    "\n",
    "Print with `println`.\n",
    "\n",
    "`show` seems to be the closest thing to `head` here. Actually, `first(events, 5)` might be closer.\n",
    "\n",
    "I wonder what the exclamation point in my `pd_to_df` function is doing. \n",
    "\n",
    "> ! in indexing is specific to DataFrames, and signals that you want a reference to the underlying vector storing the data, rather than a copy of it. \n",
    "\n",
    "> Columns can be directly (i.e. without copying) accessed via df.col or df[!, :col]. [...] Since df[!, :col] does not make a copy, changing the elements of the column vector returned by this syntax will affect the values stored in the original df. To get a copy of the column use df[:, :col]: changing the vector returned by this syntax does not change df.\n",
    "\n",
    "Since the indexing with ! does not involve any data copy, it will generally be more efficient. How does a character like ! become package-exclusive like that? Another macro?\n",
    "\n",
    "Functions can modify (mutate) the contents of the objects their arguments refer to. (The names of functions which do this are conventionally suffixed with '!'.) That helps explain why `!` is used in this context since the ! denotes mutation rather than copying. But we're using it as an index. How is this cool? `!` is a generic function itself so maybe it just interprets that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05acf087-6574-4d56-b6dd-0862200d991d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
