{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "752e131a-1e9a-4e60-bb3e-a22f3b6727b3",
   "metadata": {},
   "source": [
    "# Characterizing Model Failure\n",
    "> Background, motivation, approach. Try to rewrite with general audience in mind, avoiding or narrowing details they don't know about yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3ac570",
   "metadata": {},
   "source": [
    "Likelihood-based model fitting often has limited value when you want know if a model can account for one or more specific behavioral patterns in a dataset. By our normal approach using the method, we fit the model's parameters to maximize the likelihood of each recall event in the dataset. Then we simulate a dataset using the configured model and compare a measurement of the behavioral pattern in question between the actual and artificial datasets. Discrepancies between measurements might be thought to imply that the model can't account for phenomena in the data.\n",
    "\n",
    "The problem with this approach is that since the model is fit to the *entire* dataset, measurement discrepancies between simulated and observed datasets don't necessarily imply that the model can't in principle account for the specific pattern under examination. In fact, there may still be parameter configurations for the model that capture the considered behavioral phenomenon perfectly. What such a result would suggest though is that model parameter configurations that would capture the considered pattern perfectly would on the other hand account for the overall dataset *worse* than the parameter configuration obtained through likelihood-based fitting. The likelihood-based method thus tells us that there's some problem, some tension between the model's account of the considered behavioral pattern and model's account of the data overall, but offers little characterization of the tension.\n",
    "\n",
    "Our fitting results in the ICMR paper illustrate one way this problem can emerge. If you compared the results of our lag-CRP analysis for our observed and simulated data (dervied via simulation of fitted models), discrepancies might suggest as if our models can account for the sharp temporal contiguity effects exhibited by most participants in our datasets. But a different analysis -- measurement of probability of first recall as a function of serial position -- with our grasp of relevant model dynamics has led us to a more plausible hypothesis about how our models configure their contextual cue before recall initiates. \n",
    "\n",
    "This insight saves us from wasting time on red herrings in this well-understood scenario hinging on characterization of benchmark free recall phenomena, but what about murkier waters, like the item repetition memory phenomena documented in Lohnas & Kahana, 2016? In our work, we've identified across a host of relevant analyses many discrepancies between fitted model predictions and the observed data. We've even gone beyond benchmark analyses to identify further limitations of our model. And while we've proposed and explored several potential explanations for why our model struggles to account for the data and these phenomena, none have proven very effective.\n",
    "\n",
    "In both these examples, our goal is to characterize a model's failure to the extent that we have an accurate theory of what it gets wrong about how humans remember, and to apply this understanding to improve the model. This goal is central to what we do as computational memory scientists, no matter what project we're working on, but the analytical tools at our disposal for achieving as much are limited, leaving us to rely on hunches and trial-and-error to achieve innovations. Here, we try to develop a more systematic workflow for identifying and characterizing model failure in the domain of free recall research."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
