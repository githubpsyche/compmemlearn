{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "duplicate-cargo",
   "metadata": {},
   "source": [
    "Let's try something a little more incremental. Let's get a faster initialization first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-cleaning",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distinct-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from numba import float64, int32, int64, boolean\n",
    "from numba.experimental import jitclass\n",
    "\n",
    "cmr_spec = [\n",
    "    ('item_count', int32), \n",
    "    ('encoding_drift_rate', float64),\n",
    "    ('start_drift_rate', float64),\n",
    "    ('recall_drift_rate', float64),\n",
    "    ('shared_support', float64),\n",
    "    ('item_support', float64),\n",
    "    ('learning_rate', float64),\n",
    "    ('primacy_scale', float64),\n",
    "    ('primacy_decay', float64),\n",
    "    ('stop_probability_scale', float64),\n",
    "    ('stop_probability_growth', float64),\n",
    "    ('choice_sensitivity', float64),\n",
    "    ('context', float64[:, ::1]),\n",
    "    ('recall', int32[:, ::1]),\n",
    "    ('retrieving', boolean),\n",
    "    ('recall_total', int32),\n",
    "    ('primacy_weighting', float64[::1]),\n",
    "    ('probabilities', float64[:, ::1]),\n",
    "    ('mfc', float64[:, :, ::1]),\n",
    "    ('mcf', float64[:, :, ::1]),\n",
    "    ('encoding_index', int32),\n",
    "    ('items', float64[:,::1]),\n",
    "    ('trial_count', int64),\n",
    "    ('context_input', float64[:,::1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "experienced-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "@jitclass(cmr_spec)\n",
    "class CMR:\n",
    "\n",
    "    def __init__(self, item_count, presentation_count, trial_count, \n",
    "                 encoding_drift_rate, start_drift_rate, recall_drift_rate, \n",
    "                 shared_support, item_support, learning_rate, primacy_scale, \n",
    "                 primacy_decay, stop_probability_scale, \n",
    "                 stop_probability_growth, choice_sensitivity):\n",
    "        \n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = encoding_drift_rate\n",
    "        self.start_drift_rate = start_drift_rate\n",
    "        self.recall_drift_rate = recall_drift_rate\n",
    "        self.shared_support = shared_support\n",
    "        self.item_support = item_support\n",
    "        self.learning_rate = learning_rate\n",
    "        self.primacy_scale = primacy_scale\n",
    "        self.primacy_decay = primacy_decay\n",
    "        self.stop_probability_scale = stop_probability_scale\n",
    "        self.stop_probability_growth = stop_probability_growth\n",
    "        self.choice_sensitivity = choice_sensitivity\n",
    "        \n",
    "        # at the start of the list context is initialized with a state \n",
    "        # orthogonal to the pre-experimental context associated with the items\n",
    "        self.context = np.zeros((trial_count, item_count+1))\n",
    "        self.context[:, 0] = 1\n",
    "        self.recall = np.zeros((trial_count, item_count), dtype='int32') # preallocation\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "        \n",
    "        # predefine primacy weighting vectors\n",
    "        self.primacy_weighting = primacy_scale * np.exp(\n",
    "            -primacy_decay * np.arange(presentation_count)) + 1\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((trial_count, item_count+1))\n",
    "        \n",
    "        # The two layers communicate with one another through two sets of \n",
    "        # associative connections represented by matrices Mfc and Mcf. Pre-\n",
    "        # experimental Mfc is 1-learning_rate and pre-experimental Mcf is \n",
    "        # item_support for i=j. For i!=j, Mcf is shared_support.\n",
    "        self.mfc = np.zeros((trial_count, item_count+1, item_count))\n",
    "        self.mfc[:,] = np.eye(item_count+1, item_count, -1) * (1 - learning_rate)\n",
    "        self.mcf = np.zeros((trial_count, item_count+1, item_count))\n",
    "        self.mcf[:,] = np.ones((item_count+1, item_count)) * shared_support\n",
    "        for i in range(item_count):\n",
    "            self.mcf[:, i+1, i] = item_support\n",
    "        self.mcf[:,1,:] = 0\n",
    "        self.encoding_index = 0\n",
    "        self.items = np.eye(item_count, item_count)\n",
    "        self.trial_count = trial_count\n",
    "        self.context_input = np.zeros((trial_count, self.item_count+1))\n",
    "        \n",
    "    def experience(self, experiences):\n",
    "        for i in range(len(experiences[0])):\n",
    "            self.update_context(self.encoding_drift_rate, experiences[i, :])\n",
    "            \n",
    "            for j in range(self.trial_count):\n",
    "                self.mfc[j] += self.learning_rate * np.outer(\n",
    "                    self.context[j], experiences[i, j])\n",
    "                self.mcf[j] += self.primacy_weighting[\n",
    "                    self.encoding_index] * np.outer(\n",
    "                    self.context[j], experiences[i, j])\n",
    "                \n",
    "            self.encoding_index += 1\n",
    "            \n",
    "    def update_context(self, drift_rate, experience=None):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        self.context_input[:] = 0\n",
    "        if experience is not None:\n",
    "            self.context_input = np.sum(self.mfc * experience.reshape((-1, *np.shape(experience))), axis=2)\n",
    "            \n",
    "            for i in range(self.trial_count):\n",
    "                #self.context_input[i, :] = np.sum(experience[i] * self.mfc[i], axis=1)\n",
    "                self.context_input[i, :] = self.context_input[i, :] / np.sqrt(\n",
    "                    np.sum(np.square(self.context_input[i, :]))) # make len 1\n",
    "        else:\n",
    "            self.context_input[:, 0] = 1\n",
    "\n",
    "        # updated context is sum of context and input, modulated by rho to \n",
    "        # have len 1 and some drift_rate\n",
    "        rho = np.sqrt(1 + np.square(drift_rate) * (np.square(\n",
    "            self.context * self.context_input) - 1)) - (drift_rate * (\n",
    "            self.context * self.context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * self.context_input)\n",
    "        \n",
    "    def activations(self, probe, use_mfc=False):\n",
    "        \n",
    "        if use_mfc:\n",
    "            activation = np.zeros((self.trial_count, len(self.mfc[0, 0])))\n",
    "            for i in range(self.trial_count):\n",
    "                activation[i] = np.dot(probe[i], self.mfc[i]) + 10e-7\n",
    "        else:\n",
    "            activation = np.zeros((self.trial_count, len(self.mcf[0, 0])))\n",
    "            for i in range(self.trial_count):\n",
    "                activation[i] = np.dot(probe[i], self.mcf[i]) + 10e-7\n",
    "        return activation\n",
    "        \n",
    "    def outcome_probabilities(self, activation_cue):\n",
    "\n",
    "        activation = self.activations(activation_cue)\n",
    "        activation = np.power(activation, self.choice_sensitivity)\n",
    "\n",
    "        self.probabilities[:, 1:] = 0\n",
    "        self.probabilities[:, 0] = min(self.stop_probability_scale * np.exp(\n",
    "            self.recall_total * self.stop_probability_growth), 1.0  - (\n",
    "            self.item_count * 10e-7))\n",
    "        \n",
    "        # also set stop probability to 1 where recall has terminated\n",
    "        if self.recall_total > 0:\n",
    "            self.probabilities[self.recall[:, self.recall_total-1] == 0, 0] = 1\n",
    "        \n",
    "        # track for each trial whether recall termination is guaranteed or not\n",
    "        termination_not_guaranteed = self.probabilities[:, 0] < 1\n",
    "        \n",
    "        # suppress activation for already recalled items to 0\n",
    "        for trial_index in range(self.trial_count):\n",
    "            if termination_not_guaranteed[trial_index]:\n",
    "                for each in self.recall[trial_index, :self.recall_total]:\n",
    "                    activation[trial_index, each-1] = 0\n",
    "                self.probabilities[trial_index, 1:] = (\n",
    "                    1-self.probabilities[trial_index, 0]) * activation[trial_index] / np.sum(activation[trial_index])\n",
    "\n",
    "        return self.probabilities\n",
    "    \n",
    "    def force_recall(self, choice=None):\n",
    "        \n",
    "        if not self.retrieving:\n",
    "            self.update_context(self.start_drift_rate)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        else:\n",
    "            self.recall[:, self.recall_total] = choice\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "\n",
    "        return self.recall[:, :self.recall_total]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-apparatus",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "super-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "from numba.typed import List\n",
    "from numba.typed import List\n",
    "\n",
    "@njit(fastmath=True, nogil=True)\n",
    "def cmr_murd_likelihood(\n",
    "    data_to_fit, item_counts, encoding_drift_rate, start_drift_rate, \n",
    "    recall_drift_rate, shared_support, item_support, learning_rate, \n",
    "    primacy_scale, primacy_decay, stop_probability_scale, \n",
    "    stop_probability_growth, choice_sensitivity):\n",
    "    \n",
    "    result = 0.0\n",
    "    for i in range(len(item_counts)):\n",
    "        item_count = item_counts[i]\n",
    "        trials = data_to_fit[i]\n",
    "        \n",
    "        model = CMR(item_count, item_count, len(trials), encoding_drift_rate, \n",
    "                    start_drift_rate, recall_drift_rate, shared_support,\n",
    "                    item_support, learning_rate, primacy_scale, \n",
    "                    primacy_decay, stop_probability_scale, \n",
    "                    stop_probability_growth, choice_sensitivity)\n",
    "        \n",
    "        # same sequence of experiences across trials\n",
    "        experiences = np.zeros((len(trials), item_count, item_count))\n",
    "        experiences[:,] = np.eye(item_count, item_count)\n",
    "        model.experience(experiences.T.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vital-addiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 (1200, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>item</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>study</th>\n",
       "      <th>recall</th>\n",
       "      <th>repeat</th>\n",
       "      <th>intrusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  list  item  input  output  study  recall  repeat  intrusion\n",
       "0        1     1     1      1     5.0   True    True       0      False\n",
       "1        1     1     2      2     7.0   True    True       0      False\n",
       "2        1     1     3      3     NaN   True   False       0      False\n",
       "3        1     1     4      4     NaN   True   False       0      False\n",
       "4        1     1     5      5     NaN   True   False       0      False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from instance_cmr.datasets import *\n",
    "\n",
    "murd_trials0, murd_events0, murd_length0 = prepare_murddata(\n",
    "    '../data/MurdData_clean.mat', 0)\n",
    "print(murd_length0, np.shape(murd_trials0))\n",
    "\n",
    "murd_events0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fantastic-factor",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unable to broadcast argument 1 to output array\nFile \"<ipython-input-2-8bfbb419f176>\", line 1, ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fe6c54fbba2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;34m'choice_sensitivity'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m }\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mcmr_murd_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmurd_trials0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhand_fit_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: unable to broadcast argument 1 to output array\nFile \"<ipython-input-2-8bfbb419f176>\", line 1, "
     ]
    }
   ],
   "source": [
    "lb = np.finfo(float).eps\n",
    "hand_fit_parameters = {\n",
    "    'item_counts': List([murd_length0]),\n",
    "    'encoding_drift_rate': .8,\n",
    "    'start_drift_rate': .7,\n",
    "    'recall_drift_rate': .8,\n",
    "    'shared_support': 0.01,\n",
    "    'item_support': 1.0,\n",
    "    'learning_rate': .3,\n",
    "    'primacy_scale': 1,\n",
    "    'primacy_decay': 1,\n",
    "    'stop_probability_scale': 0.01,\n",
    "    'stop_probability_growth': 0.3,\n",
    "    'choice_sensitivity': 2\n",
    "}\n",
    "cmr_murd_likelihood(List([murd_trials0[:80]]), **hand_fit_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "cmr_murd_likelihood(List([murd_trials0[:80]]), **hand_fit_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-machinery",
   "metadata": {},
   "source": [
    "experience (80, 20)\n",
    "mfc (80, 21, 20)\n",
    "context_input (80, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfc = np.arange(24).reshape((2, 3, 4))\n",
    "mfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience = np.arange(8).reshape((2, 4))\n",
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_input = np.zeros((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "for i in range(2):\n",
    "    context_input[i, :] = np.sum(experience[i] * mfc[i], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np.sum(mfc * experience[:, np.newaxis], axis=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
