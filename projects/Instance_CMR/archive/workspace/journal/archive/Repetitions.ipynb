{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "placed-group",
   "metadata": {},
   "source": [
    "# Modeling Repetitions\n",
    "> Do CMR and ICMR track the consequences of item repetition for free recall differently?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-lancaster",
   "metadata": {},
   "source": [
    "There are some signs that InstanceCMR and CMR track the consequences of item repetitions for free recall differently. Here, using the dataset associated with a 2014 paper focused on spacing and repetition effects in free recall, \n",
    "\n",
    "> Lohnas, L. J., & Kahana, M. J. (2014). A retrieved context account of spacing and repetition effects in free recall. Journal of Experimental Psychology: Learning, Memory, and Cognition, 40(3), 755.\n",
    "\n",
    "We'll investigate these possible differences and develop an account of them. Before I get into the datasets, I'll try to test my intuitions about how repetitions drive learning between the two models w/ some toy simulations plotting how recall probabilities change as items are repeatedly encoded. Once that's cleared up, I'll do the fitting and assess outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-spouse",
   "metadata": {},
   "source": [
    "## Premise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-macro",
   "metadata": {},
   "source": [
    "There seems to be substantive differences in the way CMR and ICMR apply a sensitivity parameter to nonlinearly increase the gap between highly supported and less supported recall outcomes. InstanceCMR, like MINERVA 2, has the option to apply its sensitivity scaling operation (i.e. an exponent to each value) to activations of individual traces - that is, before integration into a unitary vector tracking retrieval support. CMR, on the other hand, has no access to any trace activations and thus applies its sensitity scaling to the integrated result. \n",
    "\n",
    "The latter operation is hypothesized to more strongly differentiate strongly from weakly supported items than the former. Suppose a constant sensitivity parameter $\\tau$ and that two distinct experiences each contributed a support of $c$ for a given feature unit in the current recall. Under trace-based sensitivity scaling, the retrieval support for that feature unit would be $c^{\\tau} + c^{\\tau}$. But under echo-based sensitity scaling, support would be ${(c + c)}^{\\tau}$, a much larger quantity. \n",
    "\n",
    "When feature representations associated with each presentation encoded into models are all orthogonal, this distinction doesn't emerge. Since each trace corresponds to activation of a unique feature unit, no equivalent of the $c^{\\tau} + c^{\\tau}$ operation from the above example ever emerges. But experiments where items are presented repeatedly offer an opportunity to explore this distinction. It could be that parameter fitting avoids any of the main consequences for this mechanism difference, much as InstanceCMR and CMR learn similar retrieval dynamics despite implementing distinct associative networks with distinct learning algorithms. And alternatively it could be that more subtle manipulations, such as the use of partially overlapping rather than identical-but-otherwise-orthogonal feature representations, could explore this mechanistic distinction more thoughtfully. We'll see!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-english",
   "metadata": {},
   "source": [
    "## Initial Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-count",
   "metadata": {},
   "source": [
    "A straightforward way to initiate analysis of how the models might differentially handle item repetitions is to measure how the probability of recalling an item given a static contextual cue changes as the item is repeatedly encoded. We expect it to increase linearly (by $x^{\\tau}$) with respect to `InstanceCMR`, but exponentially within `CMR`. If this reasoning survives scrutiny, that's a big deal.\n",
    "\n",
    "Parameters, contextual cue, and repeated item shouldn't matter here. We'll try to set them to values that aren't distracting and vary them to ensure our simulation results aren't contingent on any particular configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env NUMBA_DISABLE_JIT 1\n",
    "\n",
    "from instance_cmr.models import *\n",
    "from instance_cmr.model_analysis import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# selected parameters\n",
    "parameters = {\n",
    "    'item_count': 20,\n",
    "    'presentation_count': 70,\n",
    "    'encoding_drift_rate': .6,\n",
    "    'start_drift_rate': .7,\n",
    "    'recall_drift_rate': .6,\n",
    "    'shared_support': 0.01,\n",
    "    'item_support': 1.0,\n",
    "    'learning_rate': .3,\n",
    "    'primacy_scale': 1,\n",
    "    'primacy_decay': 1,\n",
    "    'stop_probability_scale': 0.01,\n",
    "    'stop_probability_growth': 0.3,\n",
    "    'choice_sensitivity': 2\n",
    "}\n",
    "\n",
    "experiment_count = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-salem",
   "metadata": {},
   "source": [
    "### InstanceCMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros((experiment_count, 1+parameters['presentation_count']-parameters['item_count']))\n",
    "\n",
    "for experiment in range(experiment_count):\n",
    "    # arbitrary item and contextual cue\n",
    "    repeated_item = np.random.randint(parameters['item_count'])\n",
    "    cue = np.concatenate((np.zeros(parameters['item_count']+1), np.random.rand(parameters['item_count']+1)))\n",
    "\n",
    "    # initialize model\n",
    "    model = InstanceCMR(**parameters)\n",
    "    model.experience(np.eye(parameters['item_count'], parameters['item_count'] + 1, 1))\n",
    "    results[experiment, 0] = model.outcome_probabilities(cue)[repeated_item+1]\n",
    "    \n",
    "    # track outcome probability of selected item as it is repeatedly encoded\n",
    "    for i in range(parameters['presentation_count']-parameters['item_count']):\n",
    "        \n",
    "        model.experience(np.eye(parameters['item_count'], parameters['item_count'] + 1, 1)[repeated_item:repeated_item+1])\n",
    "        \n",
    "        # cue = np.concatenate((np.zeros(parameters['item_count']+1), model.context)) # for when i want context to be the cue\n",
    "        results[experiment, i+1] = model.outcome_probabilities(cue)[repeated_item+1]\n",
    "\n",
    "# plot an example trial    \n",
    "#print('repeated item:\\n', repeated_item, np.eye(parameters['item_count'], parameters['item_count'] + 1, 1)[repeated_item:repeated_item+1])\n",
    "#print('cue:\\n', cue)\n",
    "#print('outcome probability for repeated item:\\n', results[-1])\n",
    "#plot_states(model.memory, \"memory\")\n",
    "\n",
    "plt.plot(np.mean(results, axis=0))\n",
    "plt.title('InstanceCMR Average Increase in Recall Probability of Repeated Item')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-algeria",
   "metadata": {},
   "source": [
    "### CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros((experiment_count, 1+parameters['presentation_count']-parameters['item_count']))\n",
    "\n",
    "for experiment in range(experiment_count):\n",
    "    # arbitrary item and contextual cue\n",
    "    repeated_item = np.random.randint(parameters['item_count'])\n",
    "    cue = np.random.rand(parameters['item_count'] + 1)\n",
    "\n",
    "    # initialize model\n",
    "    model = CMR(**parameters)\n",
    "    model.experience(np.eye(parameters['item_count'], parameters['item_count']))\n",
    "    results[experiment, 0] = model.outcome_probabilities(cue)[repeated_item+1]\n",
    "    \n",
    "    # track outcome probability of selected item as it is repeatedly encoded\n",
    "    for i in range(parameters['presentation_count']-parameters['item_count']):\n",
    "        \n",
    "        model.experience(np.eye(parameters['item_count'], parameters['item_count'])[repeated_item:repeated_item+1])\n",
    "        \n",
    "        #cue = model.context # for when i want context to be the cue\n",
    "        results[experiment, i+1] = model.outcome_probabilities(cue)[repeated_item+1]\n",
    "        \n",
    "# plot an example trial    \n",
    "#print('repeated item:\\n', repeated_item, np.eye(parameters['item_count'], parameters['item_count'])[repeated_item:repeated_item+1])\n",
    "#print('cue:\\n', cue)\n",
    "#print('outcome probability for repeated item:\\n', results[-1])\n",
    "#plot_states(model.mcf, \"memory\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.mean(results, axis=0))\n",
    "plt.title('CMR Average Increase in Recall Probability of Repeated Item')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-testimony",
   "metadata": {},
   "source": [
    "The models seem to differ in the manner predicted. But whether this difference matters when it comes to fitting parameters to items only repeated a few times is ambiguous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-driver",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-sharing",
   "metadata": {},
   "source": [
    "Across 4 sessions, 35 subjects performed delayed free recall of 48 lists. Subjects were University of Pennsylvania undergraduates, graduates and staff, age 18-32. List items were drawn from a pool of 1638 words taken from the University of South Florida free association norms (Nelson, McEvoy, & Schreiber, 2004; Steyvers, Shiffrin, & Nelson, 2004, available at http://memory.psych.upenn.edu/files/wordpools/PEERS_wordpool.zip). Within each session, words were drawn without replacement. Words could repeat across sessions so long as they did not repeat in two successive sessions. Words were also selected to ensure that no strong semantic associates co-occurred in a given list (i.e., the semantic relatedness between any two words on a given list, as determined using WAS (Steyvers et al., 2004), did not exceed a threshold value of 0.55).\n",
    "\n",
    "Subjects encountered four different types of lists: \n",
    "1. Control lists that contained all once-presented items;  \n",
    "2. pure massed lists containing all twice-presented items; \n",
    "3. pure spaced lists consisting of items presented twice at lags 1-8, where lag is defined as the number of intervening items between a repeated item's presentations; \n",
    "4. mixed lists consisting of once presented, massed and spaced items. Within each session, subjects encountered three lists of each of these four types. \n",
    "\n",
    "In each list there were 40 presentation positions, such that in the control lists each position was occupied by a unique list item, and in the pure massed and pure spaced lists, 20 unique words were presented twice to occupy the 40 positions. In the mixed lists 28 once-presented and six twice-presented words occupied the 40 positions. In the pure spaced lists, spacings of repeated items were chosen so that each of the lags 1-8 occurred with equal probability. In the mixed lists, massed repetitions (lag=0) and spaced repetitions (lags 1-8) were chosen such that each of the 9 lags of 0-8 were used exactly twice within each session. The order of presentation for the different list types was randomized within each session. For the first session, the first four lists were chosen so that each list type was presented exactly once. An experimenter sat in with the subject for these first four lists, though no subject had difficulty understanding the task.\n",
    "\n",
    "The data for this experiment is stored in `data/repFR.mat`. We define a unique `prepare_repetition_data` function to build structures from the dataset that works with our existing data analysis and fitting functions.\n",
    "\n",
    "Like in `prepare_murd_data`, we need list lengths, a data frame for visualizations with psifir, and a trials array encoding recall events as sequences of presentation positions. But we'll also need an additional array tracking presentation order, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell to temporarily disable jit while debugging\n",
    "#%env NUMBA_DISABLE_JIT 1\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from psifr import fr\n",
    "\n",
    "def prepare_repetition_data(path):\n",
    "    \n",
    "    # load all the data\n",
    "    matfile = sio.loadmat(path, squeeze_me=True)['data'].item()\n",
    "    subjects = matfile[0]\n",
    "    pres_itemnos = matfile[4]\n",
    "    recalls = matfile[6]\n",
    "    list_types = matfile[7]\n",
    "    list_length = matfile[12]\n",
    "    \n",
    "    # convert pres_itemnos into rows of unique indices for easier model encoding\n",
    "    presentations = []\n",
    "    for i in range(len(pres_itemnos)):\n",
    "        seen = []\n",
    "        presentations.append([])\n",
    "        for p in pres_itemnos[i]:\n",
    "            if p not in seen:\n",
    "                seen.append(p)\n",
    "            presentations[-1].append(seen.index(p))\n",
    "    presentations = np.array(presentations)\n",
    "\n",
    "    # discard intrusions from recalls\n",
    "    trials = []\n",
    "    for i in range(len(recalls)):\n",
    "        trials.append([])\n",
    "        \n",
    "        trial = list(recalls[i])\n",
    "        for t in trial:\n",
    "            if (t > 0) and (t not in trials[-1]):\n",
    "                trials[-1].append(t)\n",
    "        \n",
    "        while len(trials[-1]) < list_length:\n",
    "            trials[-1].append(0)\n",
    "            \n",
    "    trials = np.array(trials)\n",
    "    \n",
    "    # encode dataset into psifr format\n",
    "    data = []\n",
    "    for trial_index, trial in enumerate(trials):\n",
    "        presentation = presentations[trial_index]\n",
    "        \n",
    "        # every time the subject changes, reset list_index\n",
    "        if not data or data[-1][0] != subjects[trial_index]:\n",
    "            list_index = 0\n",
    "        list_index += 1\n",
    "        \n",
    "        # add study events\n",
    "        for presentation_index, presentation_event in enumerate(presentation):\n",
    "            data += [[subjects[trial_index], \n",
    "                      list_index, 'study', presentation_index+1, presentation_event]]\n",
    "            \n",
    "        # add recall events\n",
    "        for recall_index, recall_event in enumerate(trial):\n",
    "            if recall_event != 0:\n",
    "                data += [[subjects[trial_index], list_index, \n",
    "                          'recall', recall_index+1, presentation[recall_event-1]]]\n",
    "                \n",
    "    data = pd.DataFrame(data, columns=[\n",
    "        'subject', 'list', 'trial_type', 'position', 'item'])\n",
    "    merged = fr.merge_free_recall(data)\n",
    "    \n",
    "    return trials, merged, list_length, presentations, list_types, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-messenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>item</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>study</th>\n",
       "      <th>recall</th>\n",
       "      <th>repeat</th>\n",
       "      <th>intrusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  list  item  input  output  study  recall  repeat  intrusion\n",
       "0        1     1     0      1     1.0   True    True       0      False\n",
       "1        1     1     1      2     2.0   True    True       0      False\n",
       "2        1     1     2      3     3.0   True    True       0      False\n",
       "3        1     1     3      4     4.0   True    True       0      False\n",
       "4        1     1     4      5     5.0   True    True       0      False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials, events, list_length, presentations, list_types, rep_data = prepare_repetition_data('../data/repFR.mat')\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-recording",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(presentations[list_types==4] == presentations[list_types==4][0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-pollution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  0, ..., 17, 18, 19],\n",
       "       [ 0,  1,  0, ..., 17, 18, 19],\n",
       "       [ 0,  1,  0, ..., 17, 18, 19],\n",
       "       ...,\n",
       "       [ 0,  1,  2, ..., 16, 19, 17],\n",
       "       [ 0,  1,  2, ..., 15, 17, 16],\n",
       "       [ 0,  1,  2, ..., 16, 19, 18]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(presentations[list_types==3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-warehouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  4,  6,  1,  0,  7,  2,  3,  7,  5,  6,  8,\n",
       "        9, 10, 11, 10, 12, 13, 14,  9,  8, 15, 12, 11, 13, 15, 16, 14, 17,\n",
       "       18, 19, 16, 19, 18, 17])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presentations[list_types==3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-racing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  0,  1,  3,  4,  5,  6,  7,  3,  2,  4,  8,  6,  5,  7,\n",
       "        9,  8, 10, 11, 12, 11, 10, 13,  9, 12, 14, 13, 15, 16, 14, 15, 16,\n",
       "       17, 18, 19, 17, 18, 19])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presentations[list_types==3][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-account",
   "metadata": {},
   "source": [
    "## Configuring the Parameter Search\n",
    "We'll construct unique likelihood functions for repetition datasets since they require additionally specifying the sequence of item presentations in each trial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-canal",
   "metadata": {},
   "source": [
    "### InstanceCMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "from numba.typed import List\n",
    "from instance_cmr.models import *\n",
    "from instance_cmr.model_analysis import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "@njit(fastmath=True, nogil=True, parallel=True)\n",
    "def icmr_rep_likelihood(\n",
    "        trials, presentations, list_length, encoding_drift_rate, start_drift_rate, \n",
    "        recall_drift_rate, shared_support, item_support, learning_rate, \n",
    "        primacy_scale, primacy_decay, stop_probability_scale, \n",
    "        stop_probability_growth, choice_sensitivity):\n",
    "    \"\"\"\n",
    "    Generalized cost function for fitting the InstanceCMR model optimized \n",
    "    using the numba library.\n",
    "    \n",
    "    Output scales inversely with the likelihood that the model and specified \n",
    "    parameters would generate the specified trials. For model fitting, is \n",
    "    usually wrapped in another function that fixes and frees parameters for \n",
    "    optimization.\n",
    "\n",
    "    **Arguments**:\n",
    "    - data_to_fit: typed list of int64-arrays where rows identify a unique \n",
    "        trial of responses and columns corresponds to a unique recall index.  \n",
    "    - A configuration for each parameter of `InstanceCMR` as delineated in \n",
    "        `Formal Specification`.\n",
    "\n",
    "    **Returns** the negative sum of log-likelihoods across specified trials \n",
    "    conditional on the specified parameters and the mechanisms of InstanceCMR.\n",
    "    \"\"\"\n",
    "\n",
    "    likelihood = np.ones((len(trials), list_length))\n",
    "\n",
    "    for trial_index in prange(len(trials)):\n",
    "\n",
    "        item_count = np.max(presentations[trial_index])+1\n",
    "        items = np.eye(item_count, item_count + 1, 1)\n",
    "        \n",
    "        model = InstanceCMR(\n",
    "            item_count, list_length, encoding_drift_rate, start_drift_rate, \n",
    "            recall_drift_rate, shared_support, item_support, learning_rate, \n",
    "            primacy_scale, primacy_decay, stop_probability_scale, \n",
    "            stop_probability_growth, choice_sensitivity)\n",
    "        \n",
    "        model.experience(items[presentations[trial_index]])\n",
    "        trial = trials[trial_index]\n",
    "\n",
    "        model.force_recall()\n",
    "        for recall_index in range(len(trial) + 1):\n",
    "\n",
    "            # identify index of item recalled; if zero then recall is over\n",
    "            if recall_index == len(trial) and len(trial) < item_count:\n",
    "                recall = 0\n",
    "            elif trial[recall_index] == 0:\n",
    "                recall = 0\n",
    "            else:\n",
    "                recall = presentations[trial_index][trial[recall_index]-1] + 1\n",
    "\n",
    "            # store probability of and simulate recalling item with this index\n",
    "            activation_cue = np.hstack((np.zeros(model.item_count + 1), model.context))\n",
    "            likelihood[trial_index, recall_index] = \\\n",
    "                model.outcome_probabilities(activation_cue)[recall]\n",
    "\n",
    "            if recall == 0:\n",
    "                break\n",
    "            model.force_recall(recall)\n",
    "\n",
    "        # reset model to its pre-retrieval (but post-encoding) state\n",
    "        model.force_recall(0)\n",
    "\n",
    "    return -np.sum(np.log(likelihood))\n",
    "\n",
    "def icmr_rep_objective_function(data_to_fit, presentations, list_length, fixed_parameters, free_parameters):\n",
    "    \"\"\"\n",
    "    Generates and returns an objective function for input to support search \n",
    "    through parameter space for ICMR model fit using an optimization function.\n",
    "\n",
    "    Arguments:  \n",
    "    - fixed_parameters: dictionary mapping parameter names to values they'll \n",
    "        be fixed to during search, overloaded by free_parameters if overlap  \n",
    "    - free_parameters: list of strings naming parameters for fit during search  \n",
    "    - data_to_fit: array where rows identify a unique trial of responses and \n",
    "        columns corresponds to a unique recall index\n",
    "\n",
    "    Returns a function that accepts a vector x specifying arbitrary values for \n",
    "    free parameters and returns evaluation of icmr_likelihood using the model \n",
    "    class, all parameters, and provided data.\n",
    "    \"\"\"\n",
    "    return lambda x: icmr_rep_likelihood(data_to_fit, presentations, list_length, **{**fixed_parameters, **{\n",
    "        free_parameters[i]:x[i] for i in range(len(x))}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-armenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4443.69335527225"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lb = np.finfo(float).eps\n",
    "hand_fit_parameters = {\n",
    "    'encoding_drift_rate': .8,\n",
    "    'start_drift_rate': .7,\n",
    "    'recall_drift_rate': .8,\n",
    "    'shared_support': 0.01,\n",
    "    'item_support': 1.0,\n",
    "    'learning_rate': .3,\n",
    "    'primacy_scale': 1,\n",
    "    'primacy_decay': 1,\n",
    "    'stop_probability_scale': 0.01,\n",
    "    'stop_probability_growth': 0.3,\n",
    "    'choice_sensitivity': 2\n",
    "}\n",
    "icmr_rep_likelihood(trials[:80], presentations[:80], list_length, **hand_fit_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-worthy",
   "metadata": {},
   "source": [
    "4443.693355272251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "icmr_rep_likelihood(trials[:160], presentations[:160], list_length, **hand_fit_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution\n",
    "import numpy as np\n",
    "\n",
    "free_parameters = [\n",
    "    'encoding_drift_rate',\n",
    "    'start_drift_rate',\n",
    "    'recall_drift_rate',\n",
    "    'shared_support',\n",
    "    'item_support',\n",
    "    'learning_rate',\n",
    "    'primacy_scale',\n",
    "    'primacy_decay',\n",
    "    'stop_probability_scale',\n",
    "    'stop_probability_growth',\n",
    "    'choice_sensitivity']\n",
    "\n",
    "lb = np.finfo(float).eps\n",
    "ub = 1-np.finfo(float).eps\n",
    "\n",
    "bounds = [\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, 100),\n",
    "    (lb, 100),\n",
    "    (lb, ub),\n",
    "    (lb, 10),\n",
    "    (lb, 10)\n",
    "]\n",
    "\n",
    "# cost function to be minimized\n",
    "# ours scales inversely with the probability that the data could have been \n",
    "# generated using the specified parameters and our model\n",
    "cost_function = icmr_rep_objective_function(trials, presentations, list_length, {}, free_parameters)\n",
    "\n",
    "result = differential_evolution(cost_function, bounds, disp=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-titanium",
   "metadata": {},
   "source": [
    "Sensitivity scaling after integration:\n",
    "```\n",
    "fun: 3619.5817057890545\n",
    "     jac: array([ 0.03046807, -0.09708856,  0.08521965, 13.9653821 ,  0.5622951 ,\n",
    "       -0.04638423,  1.07802408,  0.        ,  2.44758667,  0.78562152,\n",
    "       -0.30640876])\n",
    " message: 'Optimization terminated successfully.'\n",
    "    nfev: 9549\n",
    "     nit: 48\n",
    " success: True\n",
    "       x: array([8.87278300e-01, 9.13467071e-01, 9.85035079e-01, 1.20111257e-03,\n",
    "       7.69001004e-01, 2.06474640e-01, 6.73100678e+00, 2.46920873e+01,\n",
    "       9.43637973e-03, 1.72443952e-01, 8.40156503e-01])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-biology",
   "metadata": {},
   "source": [
    "And before:\n",
    "\n",
    "```\n",
    "     fun: 4332.436283221303\n",
    "     jac: array([-4.87525540e+00,  2.36468623e-02, -2.38242136e+01, -6.44049578e+00,\n",
    "       -1.98451744e-01,  1.97158885e+05,  1.86810196e-01,  2.94930942e+00,\n",
    "       -1.06220796e+01, -2.01659532e+01,  5.40596372e+01])\n",
    " message: 'Optimization terminated successfully.'\n",
    "    nfev: 5649\n",
    "     nit: 20\n",
    " success: True\n",
    "       x: array([1.38795654e-04, 2.07991977e-01, 7.48665206e-01, 5.56069504e-02,\n",
    "       3.95373716e-01, 2.22044605e-16, 6.00784478e+01, 3.28006823e-01,\n",
    "       1.00836725e-02, 1.68024644e-01, 7.52043690e-01])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-mexico",
   "metadata": {},
   "source": [
    "### CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "from numba.typed import List\n",
    "from instance_cmr.models import *\n",
    "from instance_cmr.model_analysis import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#@njit(fastmath=True, nogil=True)\n",
    "def cmr_rep_likelihood(\n",
    "        trials, presentations, list_length, encoding_drift_rate, start_drift_rate, \n",
    "        recall_drift_rate, shared_support, item_support, learning_rate, \n",
    "        primacy_scale, primacy_decay, stop_probability_scale, \n",
    "        stop_probability_growth, choice_sensitivity):\n",
    "    \"\"\"\n",
    "    Generalized cost function for fitting the InstanceCMR model optimized \n",
    "    using the numba library.\n",
    "    \n",
    "    Output scales inversely with the likelihood that the model and specified \n",
    "    parameters would generate the specified trials. For model fitting, is \n",
    "    usually wrapped in another function that fixes and frees parameters for \n",
    "    optimization.\n",
    "\n",
    "    **Arguments**:\n",
    "    - data_to_fit: typed list of int64-arrays where rows identify a unique \n",
    "        trial of responses and columns corresponds to a unique recall index.  \n",
    "    - A configuration for each parameter of `InstanceCMR` as delineated in \n",
    "        `Formal Specification`.\n",
    "\n",
    "    **Returns** the negative sum of log-likelihoods across specified trials \n",
    "    conditional on the specified parameters and the mechanisms of InstanceCMR.\n",
    "    \"\"\"\n",
    "\n",
    "    likelihood = np.ones((len(trials), list_length))\n",
    "\n",
    "    for trial_index in range(len(trials)):\n",
    "\n",
    "        item_count = np.max(presentations[trial_index])+1\n",
    "        items = np.eye(item_count, item_count)\n",
    "        \n",
    "        model = CMR(\n",
    "            item_count, list_length, encoding_drift_rate, start_drift_rate, \n",
    "            recall_drift_rate, shared_support, item_support, learning_rate, \n",
    "            primacy_scale, primacy_decay, stop_probability_scale, \n",
    "            stop_probability_growth, choice_sensitivity)\n",
    "        \n",
    "        model.experience(items[presentations[trial_index]])\n",
    "        trial = trials[trial_index]\n",
    "\n",
    "        model.force_recall()\n",
    "        for recall_index in range(len(trial) + 1):\n",
    "\n",
    "            # identify index of item recalled; if zero then recall is over\n",
    "            if recall_index == len(trial) and len(trial) < item_count:\n",
    "                recall = 0\n",
    "            elif trial[recall_index] == 0:\n",
    "                recall = 0\n",
    "            else:\n",
    "                recall = presentations[trial_index][trial[recall_index]-1] + 1\n",
    "\n",
    "            # store probability of and simulate recalling item with this index\n",
    "            likelihood[trial_index, recall_index] = \\\n",
    "                model.outcome_probabilities(model.context)[recall]\n",
    "\n",
    "            if recall == 0:\n",
    "                break\n",
    "            model.force_recall(recall)\n",
    "\n",
    "        # reset model to its pre-retrieval (but post-encoding) state\n",
    "        model.force_recall(0)\n",
    "\n",
    "    return -np.sum(np.log(likelihood))\n",
    "\n",
    "def cmr_rep_objective_function(data_to_fit, presentations, list_length, fixed_parameters, free_parameters):\n",
    "    \"\"\"\n",
    "    Generates and returns an objective function for input to support search \n",
    "    through parameter space for ICMR model fit using an optimization function.\n",
    "\n",
    "    Arguments:  \n",
    "    - fixed_parameters: dictionary mapping parameter names to values they'll \n",
    "        be fixed to during search, overloaded by free_parameters if overlap  \n",
    "    - free_parameters: list of strings naming parameters for fit during search  \n",
    "    - data_to_fit: array where rows identify a unique trial of responses and \n",
    "        columns corresponds to a unique recall index\n",
    "\n",
    "    Returns a function that accepts a vector x specifying arbitrary values for \n",
    "    free parameters and returns evaluation of icmr_likelihood using the model \n",
    "    class, all parameters, and provided data.\n",
    "    \"\"\"\n",
    "    return lambda x: cmr_rep_likelihood(data_to_fit, presentations, list_length, **{**fixed_parameters, **{\n",
    "        free_parameters[i]:x[i] for i in range(len(x))}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lb = np.finfo(float).eps\n",
    "hand_fit_parameters = {\n",
    "    'encoding_drift_rate': .8,\n",
    "    'start_drift_rate': .7,\n",
    "    'recall_drift_rate': .8,\n",
    "    'shared_support': 0.01,\n",
    "    'item_support': 1.0,\n",
    "    'learning_rate': .3,\n",
    "    'primacy_scale': 1,\n",
    "    'primacy_decay': 1,\n",
    "    'stop_probability_scale': 0.01,\n",
    "    'stop_probability_growth': 0.3,\n",
    "    'choice_sensitivity': 2\n",
    "}\n",
    "cmr_rep_likelihood(trials[:80], presentations[:80], list_length, **hand_fit_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-stevens",
   "metadata": {},
   "source": [
    "4443.693355272251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "icmr_rep_likelihood(trials[:80], presentations[:80], list_length, **hand_fit_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution\n",
    "import numpy as np\n",
    "\n",
    "free_parameters = [\n",
    "    'encoding_drift_rate',\n",
    "    'start_drift_rate',\n",
    "    'recall_drift_rate',\n",
    "    'shared_support',\n",
    "    'item_support',\n",
    "    'learning_rate',\n",
    "    'primacy_scale',\n",
    "    'primacy_decay',\n",
    "    'stop_probability_scale',\n",
    "    'stop_probability_growth',\n",
    "    'choice_sensitivity']\n",
    "\n",
    "lb = np.finfo(float).eps\n",
    "ub = 1-np.finfo(float).eps\n",
    "\n",
    "bounds = [\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, 100),\n",
    "    (lb, 100),\n",
    "    (lb, ub),\n",
    "    (lb, 10),\n",
    "    (lb, 10)\n",
    "]\n",
    "\n",
    "# cost function to be minimized\n",
    "# ours scales inversely with the probability that the data could have been \n",
    "# generated using the specified parameters and our model\n",
    "cost_function = icmr_rep_objective_function(trials[:100], presentations[:100], list_length, {}, free_parameters)\n",
    "\n",
    "result = differential_evolution(cost_function, bounds, disp=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-flooring",
   "metadata": {},
   "source": [
    "## Fit Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_fit(model_class, parameters, data, rep_data, trials, presentations, list_length, items, data_query=None, experiment_count=100, savefig=False):\n",
    "    \"\"\"\n",
    "    Apply organizational analyses to visually compare the behavior of the model with these parameters against\n",
    "    specified dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate simulation data from model\n",
    "    for experiment in range(experiment_count):\n",
    "        for trial_index in range(len(trials)):\n",
    "            \n",
    "            item_count = np.max(presentations[trial_index])+1\n",
    "            model = model_class(**{item_count, **parameters})\n",
    "            model.experience(items[presentations[trial_index]])\n",
    "\n",
    "            sim = []        \n",
    "            for experiment in range(experiment_count):\n",
    "                sim += [[experiment*10000+trial_index, 0, 'recall', i + 1, o] for i, o in enumerate(model.free_recall())]\n",
    "\n",
    "    sim = pd.DataFrame(sim, columns=['subject', 'list', 'trial_type', 'position', 'item'])\n",
    "    sim = pd.concat(sim, rep_data[rep_data['trial_type']=='study'].query(data_query).reset_index())\n",
    "    sim_data = fr.merge_free_recall(sim)\n",
    "    \n",
    "    # generate simulation-based spc, pnr, lag_crp\n",
    "    sim_spc = fr.spc(sim_data).reset_index()\n",
    "    sim_pfr = fr.pnr(sim_data).query('output <= 1') .reset_index()\n",
    "    sim_lag_crp = fr.lag_crp(sim_data).reset_index()\n",
    "    \n",
    "    # generate data-based spc, pnr, lag_crp\n",
    "    data_spc = fr.spc(data).query(data_query).reset_index()\n",
    "    data_pfr = fr.pnr(data).query('output <= 1').query(data_query).reset_index()\n",
    "    data_lag_crp = fr.lag_crp(data).query(data_query).reset_index()\n",
    "    \n",
    "    # combine representations\n",
    "    data_spc['Source'] = 'Data'\n",
    "    sim_spc['Source'] = model_class.__name__\n",
    "    combined_spc = pd.concat([data_spc, sim_spc], axis=0)\n",
    "    \n",
    "    data_pfr['Source'] = 'Data'\n",
    "    sim_pfr['Source'] = model_class.__name__\n",
    "    combined_pfr = pd.concat([data_pfr, sim_pfr], axis=0)\n",
    "    \n",
    "    data_lag_crp['Source'] = 'Data'\n",
    "    sim_lag_crp['Source'] = model_class.__name__\n",
    "    combined_lag_crp = pd.concat([data_lag_crp, sim_lag_crp], axis=0)\n",
    "    \n",
    "    # generate plots of result\n",
    "    # spc\n",
    "    g = sns.FacetGrid(dropna=False, data=combined_spc)\n",
    "    g.map_dataframe(sns.lineplot, x='input', y='recall', hue='Source')\n",
    "    g.set_xlabels('Serial position')\n",
    "    g.set_ylabels('Recall probability')\n",
    "    plt.title('P(Recall) by Serial Position Curve')\n",
    "    g.add_legend()\n",
    "    g.set(ylim=(0, 1))\n",
    "    if savefig:\n",
    "        plt.savefig('figures/{}_fit_spc.jpeg'.format(model_class.__name__), bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    #pdf\n",
    "    h = sns.FacetGrid(dropna=False, data=combined_pfr)\n",
    "    h.map_dataframe(sns.lineplot, x='input', y='prob', hue='Source')\n",
    "    h.set_xlabels('Serial position')\n",
    "    h.set_ylabels('Probability of First Recall')\n",
    "    plt.title('P(First Recall) by Serial Position')\n",
    "    h.add_legend()\n",
    "    h.set(ylim=(0, 1))\n",
    "    if savefig:\n",
    "        plt.savefig('figures/{}_fit_pfr.jpeg'.format(model_class.__name__), bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    # lag crp\n",
    "    max_lag = 5\n",
    "    filt_neg = f'{-max_lag} <= lag < 0'\n",
    "    filt_pos = f'0 < lag <= {max_lag}'\n",
    "    i = sns.FacetGrid(dropna=False, data=combined_lag_crp)\n",
    "    i.map_dataframe(\n",
    "        lambda data, **kws: sns.lineplot(data=data.query(filt_neg),\n",
    "                                         x='lag', y='prob', hue='Source', **kws))\n",
    "    i.map_dataframe(\n",
    "        lambda data, **kws: sns.lineplot(data=data.query(filt_pos),\n",
    "                                         x='lag', y='prob', hue='Source', **kws))\n",
    "    i.set_xlabels('Lag')\n",
    "    i.set_ylabels('Recall Probability')\n",
    "    plt.title('Recall Probability by Item Lag')\n",
    "    i.add_legend()\n",
    "    i.set(ylim=(0, 1))\n",
    "    if savefig:\n",
    "        plt.savefig('figures/{}_fit_crp.jpeg'.format(model_class.__name__), bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
