{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "professional-marina",
   "metadata": {},
   "source": [
    "# Faster CMR\n",
    "Is it possible to make an even faster version of our CMR likelihood function? One that can access parallelization, the GPU, and other features of numba? To find out, we'll develop a purely functional version of CMR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-ethiopia",
   "metadata": {},
   "source": [
    "## Toy Example\n",
    "Let's start by exploring whether it's possible to parallelize a function that wraps use of a jit class. We'll define a simple class that initializes with two numbers and supports a function that produces the sum of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import float64\n",
    "from numba.experimental import jitclass\n",
    "from numba import njit, prange\n",
    "\n",
    "toy_spec = [\n",
    "    ('A', float64[:]),\n",
    "]\n",
    "\n",
    "@jitclass(toy_spec)\n",
    "class Toy:\n",
    "    \n",
    "    def __init__(self, experiment_count):\n",
    "        \n",
    "        self.A = np.zeros(experiment_count)\n",
    "        \n",
    "    def toy_function(self, index, value):\n",
    "        self.A[index] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def test(experiment_count):\n",
    "    \n",
    "    toyinstance = Toy(experiment_count)\n",
    "    for i in prange(experiment_count):\n",
    "        for j in prange(experiment_count):\n",
    "            toyinstance.toy_function(i, j)\n",
    "            \n",
    "test(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-racing",
   "metadata": {},
   "source": [
    "With regular njit, 1000 iterations takes 99us. When I turn on prange, speed actually falls to 213 us. When I don't use jitclass, parallel still doesn't walk, but speed improves to 133 ns. \n",
    "\n",
    "For some reason, parallelization is slowing down code I expected to be sped up. But the relationship changes when I avoid break statements and whatnot. Maybe there's a cost to parallelizing that I need to have a reason to pay.\n",
    "\n",
    "14.1 us with parallelization. 676 without.\n",
    "\n",
    "So parallelization can optimize code that uses jit classes, even within nested loops.\n",
    "\n",
    "This means that a parallelized compute_likelihood is probably possible, even if a version of CMR that avoids jitclass is impractical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instance_cmr.models import *\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from numba.typed import List\n",
    "\n",
    "@njit(parallel=True)\n",
    "def cmr_likelihood(data_to_fit, item_counts, encoding_drift_rate, start_drift_rate, recall_drift_rate, shared_support,\n",
    "        item_support, learning_rate, primacy_scale, primacy_decay, stop_probability_scale, stop_probability_growth, \n",
    "        choice_sensitivity):\n",
    "    \"\"\"\n",
    "    Generalized cost function for fitting the InstanceCMR model optimized using the numba library.\n",
    "    \n",
    "    Output scales inversely with the likelihood that the model and specified parameters would generate the specified\n",
    "    trials. For model fitting, is usually wrapped in another function that fixes and frees parameters for optimization.\n",
    "    \n",
    "    **Arguments**:\n",
    "    - trials: int64-array where rows identify a unique trial of responses and columns corresponds to a unique recall\n",
    "      index.  \n",
    "    - A configuration for each parameter of `InstanceCMR` as delineated in `Formal Specification`.\n",
    "    \n",
    "    **Returns** the negative sum of log-likelihoods across specified trials conditional on the specified parameters and\n",
    "    the mechanisms of InstanceCMR.\n",
    "    \"\"\"\n",
    "    \n",
    "    result = 0.0\n",
    "    for i in range(len(item_counts)):\n",
    "        item_count = item_counts[i]\n",
    "        trials = data_to_fit[i]\n",
    "        \n",
    "        true_model = CMR(item_count, item_count, encoding_drift_rate, \n",
    "                    start_drift_rate, recall_drift_rate, shared_support,\n",
    "                    item_support, learning_rate, primacy_scale, \n",
    "                    primacy_decay, stop_probability_scale, \n",
    "                    stop_probability_growth, choice_sensitivity)\n",
    "\n",
    "        true_model.experience(np.eye(item_count, item_count))\n",
    "\n",
    "        likelihood = np.ones((len(trials), item_count))\n",
    "\n",
    "        for trial_index in range(len(trials)):\n",
    "            \n",
    "            model = true_model.copy()\n",
    "            \n",
    "            trial = trials[trial_index]\n",
    "\n",
    "            model.force_recall()\n",
    "            for recall_index in range(len(trial) + 1):\n",
    "\n",
    "                # identify index of item recalled; if zero then recall is over\n",
    "                if recall_index == len(trial) and len(trial) < item_count:\n",
    "                    recall = 0\n",
    "                else:\n",
    "                    recall = trial[recall_index]\n",
    "\n",
    "                # store probability of and simulate recalling item with this index\n",
    "                likelihood[trial_index, recall_index] = \\\n",
    "                    model.outcome_probabilities(model.context)[recall]\n",
    "\n",
    "                if recall == 0:\n",
    "                    break\n",
    "                model.force_recall(recall)\n",
    "\n",
    "            # reset model to its pre-retrieval (but post-encoding) state\n",
    "            model.force_recall(0)\n",
    "        \n",
    "        result -= np.sum(np.log(likelihood))\n",
    "        \n",
    "    return result\n",
    "\n",
    "def cmr_objective_function(data_to_fit, fixed_parameters, free_parameters):\n",
    "    \"\"\"\n",
    "    Configures cmr_likelihood for parameter search over specified free and fixed parameters.\n",
    "    \"\"\"\n",
    "    return lambda x: cmr_likelihood(data_to_fit, **{**fixed_parameters, **{\n",
    "        free_parameters[i]:x[i] for i in range(len(x))}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-calculator",
   "metadata": {},
   "source": [
    "Using these functions, we'll search for and visualize a parameter fit of the CMR model to a slice of data sampled from the classic Murdock (1962) study demonstrating the serial position curve, a pattern where early and later presented items tend to be recalled more often than middle items in a list-learning experiment. The data associated with the study is located at `data/MurdData_clean.mat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-snake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 (1200, 15)\n",
      "30 (1200, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>item</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>study</th>\n",
       "      <th>recall</th>\n",
       "      <th>repeat</th>\n",
       "      <th>intrusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  list  item  input  output  study  recall  repeat  intrusion\n",
       "0        1     1     1      1     NaN   True   False       0      False\n",
       "1        1     1     2      2     NaN   True   False       0      False\n",
       "2        1     1     3      3     NaN   True   False       0      False\n",
       "3        1     1     4      4     NaN   True   False       0      False\n",
       "4        1     1     5      5     NaN   True   False       0      False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from instance_cmr.model_analysis import *\n",
    "\n",
    "murd_trials0, murd_events0, murd_length0 = prepare_murddata(\n",
    "    '../data/MurdData_clean.mat', 0)\n",
    "print(murd_length0, np.shape(murd_trials0))\n",
    "\n",
    "murd_trials1, murd_events1, murd_length1 = prepare_murddata(\n",
    "    '../data/MurdData_clean.mat', 1)\n",
    "print(murd_length1, np.shape(murd_trials1))\n",
    "\n",
    "murd_events1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-timer",
   "metadata": {},
   "source": [
    "|    |   subject |   list |   item |   input |   output | study   | recall   |   repeat | intrusion   |\n",
    "|---:|----------:|-------:|-------:|--------:|---------:|:--------|:---------|---------:|:------------|\n",
    "|  0 |         1 |      1 |      1 |       1 |        5 | True    | True     |        0 | False       |\n",
    "|  1 |         1 |      1 |      2 |       2 |        7 | True    | True     |        0 | False       |\n",
    "|  2 |         1 |      1 |      3 |       3 |      nan | True    | False    |        0 | False       |\n",
    "|  3 |         1 |      1 |      4 |       4 |      nan | True    | False    |        0 | False       |\n",
    "|  4 |         1 |      1 |      5 |       5 |      nan | True    | False    |        0 | False       |\n",
    "\n",
    "First, we'll make sure cmr_likelihood returns valid values and has adequate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-reputation",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mUnknown attribute 'copy' of type instance.jitclass.CMR#207ff7fdee0<item_count:int32,encoding_drift_rate:float64,start_drift_rate:float64,recall_drift_rate:float64,shared_support:float64,item_support:float64,learning_rate:float64,primacy_scale:float64,primacy_decay:float64,stop_probability_scale:float64,stop_probability_growth:float64,choice_sensitivity:float64,context:array(float64, 1d, C),preretrieval_context:array(float64, 1d, C),recall:array(float64, 1d, C),retrieving:bool,recall_total:int32,primacy_weighting:array(float64, 1d, C),probabilities:array(float64, 1d, C),mfc:array(float64, 2d, C),mcf:array(float64, 2d, C),encoding_index:int32,items:array(float64, 2d, C)>\n\u001b[1m\nFile \"<ipython-input-3-2c96165513ff>\", line 42:\u001b[0m\n\u001b[1mdef cmr_likelihood(data_to_fit, item_counts, encoding_drift_rate, start_drift_rate, recall_drift_rate, shared_support,\n    <source elided>\n            \n\u001b[1m            model = true_model.copy()\n\u001b[0m            \u001b[1m^\u001b[0m\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of get attribute at <ipython-input-3-2c96165513ff> (42)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-3-2c96165513ff>\", line 42:\u001b[0m\n\u001b[1mdef cmr_likelihood(data_to_fit, item_counts, encoding_drift_rate, start_drift_rate, recall_drift_rate, shared_support,\n    <source elided>\n            \n\u001b[1m            model = true_model.copy()\n\u001b[0m            \u001b[1m^\u001b[0m\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cbd0c87e3de4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;34m'choice_sensitivity'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m }\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mcmr_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmurd_trials0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmurd_trials1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhand_fit_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[0merror_rewrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'typing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[1;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[1;34m(e, issue_type)\u001b[0m\n\u001b[0;32m    355\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mUnknown attribute 'copy' of type instance.jitclass.CMR#207ff7fdee0<item_count:int32,encoding_drift_rate:float64,start_drift_rate:float64,recall_drift_rate:float64,shared_support:float64,item_support:float64,learning_rate:float64,primacy_scale:float64,primacy_decay:float64,stop_probability_scale:float64,stop_probability_growth:float64,choice_sensitivity:float64,context:array(float64, 1d, C),preretrieval_context:array(float64, 1d, C),recall:array(float64, 1d, C),retrieving:bool,recall_total:int32,primacy_weighting:array(float64, 1d, C),probabilities:array(float64, 1d, C),mfc:array(float64, 2d, C),mcf:array(float64, 2d, C),encoding_index:int32,items:array(float64, 2d, C)>\n\u001b[1m\nFile \"<ipython-input-3-2c96165513ff>\", line 42:\u001b[0m\n\u001b[1mdef cmr_likelihood(data_to_fit, item_counts, encoding_drift_rate, start_drift_rate, recall_drift_rate, shared_support,\n    <source elided>\n            \n\u001b[1m            model = true_model.copy()\n\u001b[0m            \u001b[1m^\u001b[0m\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of get attribute at <ipython-input-3-2c96165513ff> (42)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-3-2c96165513ff>\", line 42:\u001b[0m\n\u001b[1mdef cmr_likelihood(data_to_fit, item_counts, encoding_drift_rate, start_drift_rate, recall_drift_rate, shared_support,\n    <source elided>\n            \n\u001b[1m            model = true_model.copy()\n\u001b[0m            \u001b[1m^\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "lb = np.finfo(float).eps\n",
    "hand_fit_parameters = {\n",
    "    'item_counts': List([murd_length0, murd_length1]),\n",
    "    'encoding_drift_rate': .8,\n",
    "    'start_drift_rate': .7,\n",
    "    'recall_drift_rate': .8,\n",
    "    'shared_support': 0.01,\n",
    "    'item_support': 1.0,\n",
    "    'learning_rate': .3,\n",
    "    'primacy_scale': 1,\n",
    "    'primacy_decay': 1,\n",
    "    'stop_probability_scale': 0.01,\n",
    "    'stop_probability_growth': 0.3,\n",
    "    'choice_sensitivity': 2\n",
    "}\n",
    "cmr_likelihood(List([murd_trials0[:80], murd_trials1[:80]]), **hand_fit_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "cmr_likelihood(List([murd_trials0[:80], murd_trials1[:80]]), **hand_fit_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-figure",
   "metadata": {},
   "source": [
    "Baseline is 4.26. \n",
    "\n",
    "What if I turn off nogil? It's about the same\n",
    "\n",
    "What if I turn off fastmath? It's slightly but not meaningfully slower.\n",
    "\n",
    "And now parallel. It's slower. 6.02 ms. \n",
    "\n",
    "Let's add some pranges. I'd have to put model initialization within the trial loop for that to make sense. Without prange, that slows down the likelihood function by a factor of 10 (to 41.2). Enabling parallelization gets it back down to 11.9.\n",
    "\n",
    "If I can find some way to simulate by trial in parallel without initializing many times, that might be great.\n",
    "\n",
    "Otherwise, I can still wield parallelization to speed up code that _must_ re-initialize the model over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-search",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
