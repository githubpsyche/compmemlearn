{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-technique",
   "metadata": {},
   "source": [
    "# Single Store Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-tuition",
   "metadata": {},
   "source": [
    "Starting in July, I developed an initial prototype of ICMR. Like the classic instance model, it represents\n",
    "and performs recall over a stack of memory trace vectors. And like classic CMR, a contextual representation\n",
    "is also maintained. Compared to the representation of current experience, it changes slowly over time,\n",
    "reflecting a recency-weighted average of information related to recently presented stimuli. New memory traces\n",
    "associate studied items with the context active during presentation. I hoped this would enable context-driven\n",
    "recall of items, and item-driven recall of context within the context of a multiple traces model. While we're\n",
    "set on this basic scheme, the prototype was found ineffective for reproducing classic phenomena from the\n",
    "sequential recall literature. I keep this prototype around though because it might inform some other modeling\n",
    "approach down the line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-depth",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-sampling",
   "metadata": {},
   "source": [
    "In the current prototype, six parameters determine the behavior of Instance-CMR during simulations of free\n",
    "recall.\n",
    "\n",
    "`item_count` specifies the number of unique items presented during encoding. For the prototype, we assume\n",
    "items are orthonormal in their features and represent them as such with unique index vectors.\n",
    "\n",
    "To represent pre-experimental memory, initial traces representing each item's feature vector are included and\n",
    "modified to have some parametrized amount of `shared_support` for all items. The parameter thus works\n",
    "similarly to to CMR's `alpha` as specified in Morton & Polyn, 2016. With the value 0, the initial traces are\n",
    "held orthogonal to each other, excluding any pre-experimental association.\n",
    "\n",
    "`drift_rate` controls the rate of contextual drift throughout an experiment - during encoding, free recall,\n",
    "and in between. Higher values cause `context` to drift more quickly as new items are experienced or recalled,\n",
    "as well as in between tasks.\n",
    "\n",
    "`learning_rate` - similar to CMR's `gamma` - controls the contribution of experimental memory relative to\n",
    "pre-experimental memory to activity patterns during echo retrieval. With the value 1, experimental memory is\n",
    "not additionally weighted. Higher values enhance experimental memory and diminish pre-experimental memory,\n",
    "while lower values do the opposite.\n",
    "\n",
    "Finally, `stop_probability_scale` and `stop_probability_growth` respectively control the scaling and the rate\n",
    "of increase of the probability of stopping during free recall over output position, implementing the same\n",
    "stopping mechanism implemented in Morton and Polyn, 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "class SingleStorePrototype(object):\n",
    "    \"\"\"\n",
    "    The context maintenance and retrieval model re-imagined as an exemplar model.\n",
    "\n",
    "    As typical of exemplar models, every `experience` is represented as a high-dimensional feature vector. A\n",
    "    record of each experience - called a `trace` - is stored as a new, separate row in a m x n `memory` matrix\n",
    "    where rows correspond to memory traces and columns correspond to feature dimensions.\n",
    "\n",
    "    As in a retrieved context model, a contextual representation is also maintained. Compared to the\n",
    "    representation of current experience, it changes slowly over time, reflecting a recency-weighted average of\n",
    "    information related to recently presented stimuli. New memory traces associate studied items with the\n",
    "    context active during presentation. This enables context-driven recall of items, and item-driven recall of\n",
    "    context.\n",
    "\n",
    "    To retrieve information from memory, a feature vector can be presented as a `probe`. The probe activates\n",
    "    all traces in memory in parallel. Each trace's `activation` is a cubed function of its `similarity` to the\n",
    "    probe. The sum of these traces weighted by their activation represents an `echo` summarizing the memory\n",
    "    system's response to the probe. The content and intensity of this echo is the information that\n",
    "    characterizes memory performance across tasks.\n",
    "\n",
    "    Attributes:  \n",
    "    - memory: array where rows correspond to accumulated memory traces and columns correspond to feature dims\n",
    "    - context: length-n vector reflecting recency-weighted average of recently presented stimuli information\n",
    "    - item_count: number of items in experiment identifying the relevant store of pre-experimental memory\n",
    "    - drift_rate: rate of context drift during item processing\n",
    "    - shared_support: uniform amount of support items initially have for one another in recall competition\n",
    "    - learning_rate: contribution of experimental associations relative to pre-experimental associations\n",
    "    - stop_probability_scale: scaling of the stop probability over output position\n",
    "    - stop_probability_growth: rate of increase in stop probability\n",
    "    - choice_sensitivity: sensitivity parameter of the Luce choice rule\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, item_count, drift_rate, shared_support, learning_rate,\n",
    "                 stop_probability_scale, stop_probability_growth, choice_sensitivity):\n",
    "        \"\"\"\n",
    "        Starts exemplar model with initial set of experiences in memory.\n",
    "\n",
    "        For the prototype, we assume items are orthonormal in their features and use unique index vectors to\n",
    "        represent them as such. To represent pre-experimental memory, a trace is initially laid for each item\n",
    "        representing its vector representation modified to have some parametrized amount of shared_support for\n",
    "        all items (similar to CMR's alpha) and another parameter learning_rate (similar to CMR's gamma)\n",
    "        controlling the contribution of experimental memory relative to pre-experimental memory to echo\n",
    "        representations.\n",
    "\n",
    "        Args:  \n",
    "        - item_count: number of unique items identifying the relevant store of pre-experimental memory\n",
    "        - drift_rate: rate of context drift during item processing\n",
    "        - shared_support: uniform amount of support items initially have for eachother in recall competition\n",
    "        - learning_rate: controls contribution of experimental memory relative to pre-experimental memory\n",
    "        - stop_probability_scale: scaling of the stop probability over output position\n",
    "        - stop_probability_growth: rate of increase in stop probability\n",
    "        \"\"\"\n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.drift_rate = drift_rate\n",
    "        self.shared_support = shared_support\n",
    "        self.learning_rate = learning_rate\n",
    "        self.stop_probability_scale = stop_probability_scale\n",
    "        self.stop_probability_growth = stop_probability_growth\n",
    "        self.choice_sensitivity = choice_sensitivity\n",
    "\n",
    "        # initialize memory and context\n",
    "        self.context = np.eye(1, item_count+1)\n",
    "        self.memory = np.eye(item_count, item_count+1, 1)\n",
    "        self.memory[np.logical_not(np.eye(item_count, item_count+1, 1, dtype=bool))] = self.shared_support\n",
    "\n",
    "    def experience(self, experiences):\n",
    "        \"\"\"\n",
    "        Adds new trace(s) to model memory, represented as new row(s) in the model's memory array. The stored\n",
    "        experience is the context representation after it's been updated by the current experience.\n",
    "        \"\"\"\n",
    "        if len(np.shape(experiences)) == 1:\n",
    "            experiences = [experiences]\n",
    "        for experience in experiences:\n",
    "            self.update_context(np.array(experience))\n",
    "            trace = (self.context + experience)/norm(self.context + experience)\n",
    "            self.memory = np.vstack((self.memory, trace))\n",
    "\n",
    "    def update_context(self, experience):\n",
    "        \"\"\"Updates contextual representation based on content of current experience.\"\"\"\n",
    "\n",
    "        # retrieves echo (memory information) associated w/ experience to serve as input to context\n",
    "        # parallel operation to equation 10 from Morton & Polyn (2016)\n",
    "        context_input = self.probe(experience)\n",
    "        context_input = context_input / norm(context_input)  # normalized to have length 1\n",
    "\n",
    "        # updated context is sum of current context and input modulated to have len 1 w/ rho and drift_rate\n",
    "        # parallel operation to equations 11-12 from Morton & Polyn (2016)\n",
    "        rho = np.sqrt(1 + np.power(self.drift_rate, 2) * (np.power(self.context * context_input, 2) - 1)) - (\n",
    "                self.drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (self.drift_rate * context_input)\n",
    "\n",
    "    def probe(self, probe):\n",
    "        \"\"\"\n",
    "        Presents a cue to memory system, fetching echo reflecting its pattern of activation across traces.\n",
    "\n",
    "        The probe activates all traces in memory in parallel. Each trace's `activation` is a cubed function of\n",
    "        `similarity` to the probe. The sum of these traces weighted by their activation is an `echo`\n",
    "        summarizing the memory system's response to the probe. The learning_rate parameter further weights the\n",
    "        relative contribution of pre-experimental and experimental traces to activity patterns.\n",
    "        \"\"\"\n",
    "        # computes and cubes similarity value to find activation for each trace in memory\n",
    "        activation = np.power(\n",
    "            np.sum(self.memory * probe, axis=1) / (norm(self.memory, axis=1) * norm(probe)), 3)\n",
    "\n",
    "        # weights traces based on learning rate\n",
    "        activation *= np.hstack((np.ones((self.item_count,)) / self.learning_rate,\n",
    "                                 np.ones((len(self.memory) - self.item_count,)) * self.learning_rate))\n",
    "\n",
    "        # multiply each trace by its associated activation and take a column-wise sum to retrieve echo\n",
    "        echo = np.sum((self.memory.T * activation).T, axis=0)\n",
    "        return echo\n",
    "\n",
    "    def compare_probes(self, first_probe, second_probe):\n",
    "        \"\"\"Compute the resemblance (cosine similarity) between the echoes associated with probes A and B.\"\"\"\n",
    "        echoes = self.probe(first_probe), self.probe(second_probe)\n",
    "        return np.sum(echoes[0] * echoes[1]) / (norm(echoes[0]) * norm(echoes[1]))\n",
    "\n",
    "    def free_recall(self, subjects=1):\n",
    "        \"\"\"\n",
    "        Simulates performance on a free recall task based on experienced items.\n",
    "\n",
    "        We initialize context similar to eq. 16 from Morton & Polyn (2016), simulating end-of-list distraction\n",
    "        and some amount of pre-list context reinstatement. This context is used as a retrieval cue (probe) to\n",
    "        attempt retrieval of a studied item, generating an associated memory echo.\n",
    "\n",
    "        At each recall attempt, we also calculate a probability of stopping recall as a function of output\n",
    "        position according to eq. 18 of Morton & Polyn (2016). The probability of recalling a given item\n",
    "        conditioned on not stopping recall is defined on the basis of the item's similarity to the current\n",
    "        contextual representation according to a formula similar to eq 19 of Morton and Polyn (2016).\n",
    "        \"\"\"\n",
    "        # drift context toward the pre-experimental context then perform recall until stop is triggered\n",
    "        for subject in range(subjects):\n",
    "            recall, outcome_probabilities = [], np.zeros((self.item_count + 1))\n",
    "            items, preretrieval_context = np.eye(self.item_count, self.item_count + 1, 1), self.context\n",
    "            self.update_context(np.eye(1, self.item_count + 1))\n",
    "            while True:\n",
    "\n",
    "                # compute outcome probabilities and make choice based on distribution\n",
    "                outcome_probabilities[:] = 0\n",
    "                outcome_probabilities[0] = self.stop_probability_scale * np.exp(\n",
    "                    len(recall) * self.stop_probability_growth)\n",
    "                if outcome_probabilities[0] < 1:\n",
    "                    for j, item in enumerate(items):\n",
    "                        if j in recall:\n",
    "                            continue\n",
    "                        outcome_probabilities[j + 1] = np.power(np.sum(self.context * items[j]) / (\n",
    "                                norm(self.context) * norm(items[j])), self.choice_sensitivity)\n",
    "                    outcome_probabilities[1:] *= (\n",
    "                        1 - outcome_probabilities[0]) / np.sum(outcome_probabilities[1:])\n",
    "                    choice = np.random.choice(len(outcome_probabilities), p=outcome_probabilities)\n",
    "                else:\n",
    "                    choice = 0.0\n",
    "\n",
    "                # store and resolve outcome\n",
    "                if not choice:\n",
    "                    break\n",
    "                recall.append(choice - 1)\n",
    "                self.update_context(self.probe(items[choice - 1]))\n",
    "\n",
    "            self.context = preretrieval_context\n",
    "        return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-contact",
   "metadata": {},
   "source": [
    "We evaluated the model in an old version of this repository; for relevant code see notebooks (stored as\n",
    "markdown files) inside `writeups/archive`."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
