{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-algorithm",
   "metadata": {},
   "source": [
    "# Dual Store ICMR Prototype\n",
    "With this version of the model, we make two kinds of modifications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-dictionary",
   "metadata": {},
   "source": [
    "## Theoretical Modifications\n",
    "Theoretically, we make a major modification to the ICMR model to improve comparison with CMR dynamics.\n",
    "\n",
    "In particular, we separate item and contextual features when representing each `experience`'s associated\n",
    "memory `trace`. If item features or context don't exist or aren't relevant for specification of a particular\n",
    "trace, that part of the trace representation will just be a zero vector.\n",
    "\n",
    "This enables us to organize retrieval selectively. A feature `echo` associated with the current `context`\n",
    "representation can be obtained by presenting `context` with a null `feature` representation as a `probe` to\n",
    "`memory`, effectively performing the role of CMR's `Mcf`. Similarly, item features can be presented with null\n",
    "context features as a memory probe to measure relevant contextual associations, operating similarly to CMR's\n",
    "`Mfc`.\n",
    "\n",
    "Besides this, we also make substantial modifications to our retrieval mechanism. Before, item activations\n",
    "were computed by comparing the current contextual representation to each item's feature representation. Now,\n",
    "we'll try an operation that hews better with the classical `echo` mechanism. We'll present `context` as a cue\n",
    "to memory in the manner described above, and use the resulting trace activations to determine recall\n",
    "competition. \n",
    "\n",
    "The way CMR and instance models compute similarity-based activation are quite similar, but a potentially\n",
    "important distinction is that while CMR generates activations for every item that might be recalled, instance\n",
    "models' echo mechanism measures activations for every stored trace. So if the same item has been presented\n",
    "repeatedly, activation vectors at minimum will exhibit different lengths. In the current version of the\n",
    "model, we allow traces associated with the same items to compete with one another in the activation function.\n",
    "However, once an item is recalled, we still rule out repeated recall of the same item for the rest of the\n",
    "experiment. This is expected to lead to similar recall dynamics as to how CMR organizes recall.\n",
    "\n",
    "We also go ahead and include support for all parameters parallel to those specified in the Morton and Polyn\n",
    "2016 paper. A key experiment down the line will be to explore whether manipulating these parameters impacts\n",
    "model performance like they would in CMR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-hybrid",
   "metadata": {},
   "source": [
    "## Operational Modifications\n",
    "To support easier inspection of model states, we include several functions that either refactor operations\n",
    "previously performed by larger superfunctions or that control model operation in novel ways.\n",
    "\n",
    "The function `activations` collects the level of activation of each stored memory trace in the model in\n",
    "response to a specified `probe`. `outcome_probabilities` alternatively computes the likelihood of retrieving\n",
    "each encoded item, and can be computed either on the basis of the current state of context or with optional\n",
    "`cue` or `activations` parameters. Finally, the `force_recall` function forces model to recall chosen item\n",
    "and update context regardless of current model state. This is useful for testing particular hypotheses about\n",
    "model dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "class DualStorePrototype(object):\n",
    "    \"\"\"\n",
    "    The context maintenance and retrieval model re-imagined as an exemplar model.\n",
    "\n",
    "    Attributes:  \n",
    "    - memory: array where rows/columns correspond to accumulated memory traces and feature dims respectively\n",
    "    - context: vector reflecting a recency-weighted average of recently presented stimuli information\n",
    "    - item_count: number of unique items relevant to model simulation\n",
    "    - encoding_drift_rate: rate of context drift during item processing\n",
    "    - start_drift_rate: amount of start-list context retrieved at start of recall\n",
    "    - recall_drift_rate: rate of context drift during recall\n",
    "    - shared_support: uniform amount of support items initially have for one another in recall competition\n",
    "    - item_support: initial strength of the diagonal of Mcf\n",
    "    - learning_rate: contribution of experimental relative to pre-experimental associations\n",
    "    - primacy_scale: scaling of primacy gradient in learning rate on Mcf\n",
    "    - primacy_decay: rate of decay of primacy gradient\n",
    "    - semantic_scale: scaling of semantic association strengths\n",
    "    - stop_probability_scale: scaling of the stop probability over output position\n",
    "    - stop_probability_growth: rate of increase in stop probability\n",
    "    - choice_sensitivity: sensitivity parameter of the Luce choice rule\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, item_count, encoding_drift_rate, start_drift_rate, recall_drift_rate, shared_support,\n",
    "                 item_support, learning_rate, primacy_scale, primacy_decay, stop_probability_scale,\n",
    "                 stop_probability_growth, choice_sensitivity):\n",
    "        \"\"\"\n",
    "        Start exemplar model with an initial set of pre-experimental associations in memory\n",
    "\n",
    "        Args:  \n",
    "            item_count: number of unique items relevant to model simulation encoding_drift_rate: rate of\n",
    "            context drift during item processing start_drift_rate: amount of start-list context retrieved at\n",
    "            start of recall recall_drift_rate: rate of context drift during recall shared_support: uniform\n",
    "            support items initially have for one another in recall competition item_support: initial strength\n",
    "            of the diagonal of Mcf learning_rate: contribution of experimental relative to pre-experimental\n",
    "            associations primacy_scale: scaling of primacy gradient in learning rate on Mcf primacy_decay: rate\n",
    "            of decay of primacy gradient semantic_scale: scaling of semantic association strengths\n",
    "            stop_probability_scale: scaling of the stop probability over output position\n",
    "            stop_probability_growth: rate of increase in stop probability choice_sensitivity: sensitivity\n",
    "            parameter of the Luce choice rule\n",
    "        \"\"\"\n",
    "\n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = encoding_drift_rate\n",
    "        self.start_drift_rate = start_drift_rate\n",
    "        self.recall_drift_rate = recall_drift_rate\n",
    "        self.shared_support = shared_support\n",
    "        self.item_support = item_support\n",
    "        self.learning_rate = learning_rate\n",
    "        self.primacy_scale = primacy_scale\n",
    "        self.primacy_decay = primacy_decay\n",
    "        # self.semantic_scale = semantic_scale\n",
    "        self.stop_probability_scale = stop_probability_scale\n",
    "        self.stop_probability_growth = stop_probability_growth\n",
    "        self.choice_sensitivity = choice_sensitivity\n",
    "\n",
    "        # at the start of the list context is initialized with a state orthogonal to the pre-experimental\n",
    "        # context associated with the set of items\n",
    "        self.context = np.eye(1, item_count + 1).flatten()\n",
    "        self.preretrieval_context = self.context\n",
    "        self.state = 'encoding'\n",
    "        self.recall = []\n",
    "\n",
    "        # initialize memory\n",
    "        # we now conceptualize it as a pairing of two stores Mfc and Mcf representing feature-to-context and\n",
    "        # context-to-feature associations, respectively\n",
    "        mfc = np.eye(item_count, item_count + 1, 1) * (1 - self.learning_rate)\n",
    "        mcf = np.eye(item_count) * self.item_support\n",
    "        mcf[np.logical_not(np.eye(item_count, dtype=bool))] = self.shared_support\n",
    "        mcf = np.hstack((np.zeros((item_count, 1)), mcf))\n",
    "        self.memory = np.hstack((mfc, mcf))\n",
    "\n",
    "        # an additional item store and KDTree organizes response selection based on retrieved F\n",
    "        self.items = np.eye(self.item_count, self.item_count + 1, 1)\n",
    "        self.item_decision_rule = spatial.KDTree(self.items)\n",
    "\n",
    "    def experience(self, experiences):\n",
    "        \"\"\"\"\n",
    "        Adds new trace(s) to model memory based on an experienced vector of item features and current context.\n",
    "            \"\"\"\n",
    "        if len(np.shape(experiences)) == 1:\n",
    "            experiences = [experiences]\n",
    "        for experience in experiences:\n",
    "            self.update_context(\n",
    "                self.encoding_drift_rate, np.hstack((np.array(experience), np.zeros((self.item_count + 1)))))\n",
    "            trace = np.hstack((experience, self.context))\n",
    "            self.memory = np.vstack((self.memory, trace))\n",
    "\n",
    "    def update_context(self, drift_rate, experience=None):\n",
    "        \"\"\"\n",
    "        Updates contextual representation based on content of current experience or, if no experience is\n",
    "        presented, on the content of initial context.\n",
    "        \"\"\"\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if experience is not None:\n",
    "            context_input = self.echo(experience)[self.item_count + 1:]\n",
    "            context_input = context_input / norm(context_input)  # normalized to have length 1\n",
    "        else:\n",
    "            context_input = np.eye(1, self.item_count + 1).flatten()\n",
    "\n",
    "        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(1 + (drift_rate ** 2) * (((self.context * context_input) ** 2) - 1)) - (\n",
    "                drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "\n",
    "    def echo(self, probe):\n",
    "        \"\"\"\n",
    "        A probe activates all traces in memory in parallel. The sum of these traces weighted by their\n",
    "        activation is an `echo` summarizing the memory system's response to the probe.\n",
    "        \"\"\"\n",
    "        return np.sum((self.memory.T * self.activations(probe)).T, axis=0)\n",
    "\n",
    "    def compare_probes(self, first_probe, second_probe):\n",
    "        \"\"\"Compute the resemblance (cosine similarity) between the echoes associated with probes A and B.\"\"\"\n",
    "        echoes = self.echo(first_probe), self.echo(second_probe)\n",
    "        return np.sum(echoes[0] * echoes[1]) / (norm(echoes[0]) * norm(echoes[1]))\n",
    "\n",
    "    def activations(self, probe):\n",
    "        \"\"\"\n",
    "        Presents a cue to memory system, activating all traces in memory in parallel. Each trace's `activation`\n",
    "        is a cubed function of its `similarity` to the probe, weighted based on item position and whether probe\n",
    "        contains contextual or item features.\n",
    "        \"\"\"\n",
    "        # computes and cubes similarity value to find activation for each trace in memory\n",
    "        activation = np.sum(self.memory * probe, axis=1) / (norm(self.memory, axis=1) * norm(probe))\n",
    "        activation = activation ** self.choice_sensitivity\n",
    "\n",
    "        # determining weighting based on whether probe contains item or contextual features mfc weightings -\n",
    "        # scale by gamma for each experimental trace\n",
    "        weighting = np.ones(len(self.memory))\n",
    "        if np.sum(probe[:self.item_count + 1]) != 0:\n",
    "            weighting[self.item_count:] = self.learning_rate\n",
    "\n",
    "        # mcf weightings - scale by primacy/attention function based on position of experimental experiences\n",
    "        if np.sum(probe[self.item_count + 1:]) != 0:\n",
    "            weighting[self.item_count:] *= self.primacy_scale * np.exp(\n",
    "                -self.primacy_decay * np.arange(len(self.memory) - self.item_count)) + 1\n",
    "\n",
    "        # weights traces based on provided scalings\n",
    "        activation *= weighting\n",
    "        return activation  + np.finfo(float).eps\n",
    "\n",
    "    def outcome_probabilities(self, activations=None, cues=None):\n",
    "        \"\"\"\n",
    "        Computes recall probability of each item given current model state and optional activation pattern/cue.\n",
    "        \"\"\"\n",
    "\n",
    "        # if no activations are provided, generate some from current context\n",
    "        if activations is None:\n",
    "            activations = self.activations(np.hstack((np.zeros(self.item_count + 1), self.context)))\n",
    "\n",
    "        # temporarily update context to reflect cue(s)\n",
    "        preretrieval_context = self.context\n",
    "        if cues is not None:\n",
    "            for cue in cues:\n",
    "                self.update_context(cue, self.retrieval_drift_rate)\n",
    "\n",
    "        outcome_probabilities = np.zeros((self.item_count + 1))\n",
    "        outcome_probabilities[0] = min(self.stop_probability_scale * np.exp(\n",
    "            len(self.recall) * self.stop_probability_growth), 1.0)\n",
    "\n",
    "        if outcome_probabilities[0] < 1:\n",
    "            for trace_index, trace in enumerate(self.memory.tolist()):\n",
    "                j = self.item_decision_rule.query(trace[:self.item_count + 1])[1]\n",
    "                if j in self.recall:\n",
    "                    continue\n",
    "                outcome_probabilities[j + 1] += activations[trace_index]\n",
    "            outcome_probabilities[1:] *= (1 - outcome_probabilities[0]) / np.sum(outcome_probabilities[1:])\n",
    "\n",
    "        self.context = preretrieval_context\n",
    "        return outcome_probabilities\n",
    "\n",
    "    def force_recall(self, choice=None):\n",
    "        \"\"\"\n",
    "        Forces model to recall chosen item and update context regardless of current model state.\n",
    "\n",
    "        Here, recall items are 1-indexed, with a choice of 0 indicating a choice to end retrieval and return to\n",
    "        preretrieval context.\n",
    "        \"\"\"\n",
    "        if self.state == 'encoding':\n",
    "            self.recall = []\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.start_drift_rate)\n",
    "            self.state = 'retrieving'\n",
    "            \n",
    "        if choice is None:\n",
    "            pass\n",
    "        elif choice == 0:\n",
    "            self.state = 'encoding'\n",
    "            self.context = self.preretrieval_context\n",
    "        else:\n",
    "            self.recall.append(choice - 1)\n",
    "            self.update_context(self.recall_drift_rate,\n",
    "                                np.hstack((self.items[choice - 1], np.zeros(self.item_count + 1))))\n",
    "        return self.recall\n",
    "\n",
    "    def free_recall(self, steps=None):\n",
    "        \"\"\"\n",
    "        Simulates performance on a free recall task based on experienced items.\n",
    "\n",
    "        We initialize context similar to eq. 16 from Morton & Polyn (2016), simulating end-of-list distraction\n",
    "        and some amount of pre-list context reinstatement. This context is used as a retrieval cue (probe) to\n",
    "        attempt retrieval of a studied item, generating an associated memory echo.\n",
    "\n",
    "        At each recall attempt, we also calculate a probability of stopping recall as a function of output\n",
    "        position according to eq. 18 of Morton & Polyn (2016). The probability of recalling a given item\n",
    "        conditioned on not stopping recall is defined on the basis of the item's similarity to the current\n",
    "        contextual representation according to a formula similar to eq 19 of Morton and Polyn (2016).\n",
    "        \"\"\"\n",
    "        # some amount of the pre-list context is reinstated before initiating recall\n",
    "        if self.state == 'encoding':\n",
    "            self.recall = []\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.start_drift_rate)\n",
    "            self.state = 'retrieving'\n",
    "\n",
    "        # number of items to retrieve is infinite if steps is unspecified\n",
    "        if steps is None:\n",
    "            steps = math.inf\n",
    "        steps = len(self.recall) + steps\n",
    "\n",
    "        # at each recall attempt\n",
    "        while len(self.recall) < steps:\n",
    "\n",
    "            # the current state of context is used as a retrieval cue to attempt recall of a studied item\n",
    "            activations = self.activations(np.hstack((np.zeros(self.item_count + 1), self.context)))\n",
    "\n",
    "            # compute outcome probabilities and make choice based on distribution\n",
    "            outcome_probabilities = self.outcome_probabilities(activations)\n",
    "            choice = np.random.choice(len(outcome_probabilities), p=outcome_probabilities)\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made\n",
    "            if not choice:\n",
    "                self.state = 'encoding'\n",
    "                self.context = self.preretrieval_context\n",
    "                break\n",
    "            self.recall.append(choice - 1)\n",
    "            self.update_context(self.recall_drift_rate,\n",
    "                                np.hstack((self.items[choice - 1], np.zeros(self.item_count + 1))))\n",
    "\n",
    "        return self.recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-advertising",
   "metadata": {},
   "source": [
    "## Miscellaneous Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-rider",
   "metadata": {},
   "source": [
    "### Missing Details\n",
    "Some aspects that are not faithful to CMR as specified by Morton and Polyn (2016):\n",
    "- We COULD set a minimal activation for each item to 10^-7 here but we don't yet.\n",
    "- We could go ahead and add support for semantic associations, but we don't yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-tackle",
   "metadata": {},
   "source": [
    "### How Should the DualStorePrototype Choose Responses Under Ambiguously Retrieved Traces?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-vienna",
   "metadata": {},
   "source": [
    "I missed something when brainstorming this model. The traces I lay down for new items don't always contain an\n",
    "exact matching feature representation for the item. For example, at model initialization, gamma modulates\n",
    "item to context associations a bit (1-gamma instead of 1).\n",
    "\n",
    "It would be highly irregular if I had a separate representation labelling each trace by its associated item.\n",
    "Though I guess CMR does the same thing.\n",
    "\n",
    "I could definitely modify the model to enforce stable feature representations. For example, I could take the\n",
    "gamma modulation of pre-experimental activations out of the memory array like I've already done for\n",
    "experimental items. But the problem still remains in a subtle way: I don't get to \"mess\" with feature\n",
    "representations later, for example.\n",
    "\n",
    "A nearest neighbor approach is possible, but which is the one I can best justify in the context of CMR and\n",
    "what I've read of instance models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-plasma",
   "metadata": {},
   "source": [
    "#### Which Policies are Possible?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-basketball",
   "metadata": {},
   "source": [
    "We can just apply a classification rule to choose when the recovered trace is ambiguous. We can have a\n",
    "separate store of the decision associated with an item (e.g. a perfect representation of the item or just an\n",
    "index stored for each trace). However, this feels like cheating, and when we start thinking about memory\n",
    "failure/bias, this gets weird, too.\n",
    "\n",
    "These might be our only options! \n",
    "\n",
    "I definitely like making selection happen for particular traces. I want my decision rule to depend on\n",
    "particular traces. \n",
    "\n",
    "Why should the content of my Mfc vector be what decides what's stored though? The Mfc and Mcf are supposed to\n",
    "be realized on the basis of co-occurrence of feature and contextual information in the same trace. Our two\n",
    "store model isn't a combination of Mfc and Mcf information; it's a combination of feature and contextual\n",
    "information; Mcf and Mfc mechanisms just emerge from their combination. So I do want my F store to be a\n",
    "faithful store of encoded feature information.\n",
    "\n",
    "I resolved in this model to go with a classification strategy: the nearest applicable item is selected for\n",
    "retrieval. Further exploration of retrieval mechanisms might be worthwhile. Some further discussion in past\n",
    "relevant papers below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-romance",
   "metadata": {},
   "source": [
    "#### Hintzman, D. L. (1984). MINERVA 2: A simulation model of human memory. Behavior Research Methods, Instruments, & Computers, 16(2), 96-101."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-drain",
   "metadata": {},
   "source": [
    "\"The ambiguous recall problem is that information retrieved from memory is sometimes only vaguely similar to\n",
    "what was originally stored, or to any acceptable response. One way of getting around this difficulty is to\n",
    "assume that there is a pattern-recognition system that knows the set of acceptable responses and that takes\n",
    "the memory echo as input to be classified (e.g., Eich, 1982). But MINERVA 2 lends itself to a more elegant\n",
    "solution. If the echo content is \"normalized\" into the -1 to +1 range and turned into a secondary probe, the\n",
    "subsequent echo is more like an acceptable response than the original echo was. And if this process is\n",
    "repeated, there is further improvement. Typically, only a few iterations of this procedure are necessary to\n",
    "produce a virtually perfect copy of the information that was originally stored. In this way, MINERVA 2\n",
    "appears able to \"bootstrap\" its way out of the ambiguous recall problem with no help from a memory system on\n",
    "the outside.\"\n",
    "\n",
    "There's never a perfect equality here, here, even after repeated probing. I can set some sort of threshold\n",
    "for selecting a match after enough iterations, but if I'm doing that, why not pull a nearest-neighbors\n",
    "selection approach? Classification is required if I'm doing decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-jacksonville",
   "metadata": {},
   "source": [
    "#### Morton, N. W., & Polyn, S. M. (2016). A predictive framework for evaluating models of semantic organization in free recall. Journal of Memory and Language, 86, 119-140."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-italic",
   "metadata": {},
   "source": [
    "\"At each recall attempt, the current state of context is used as a retrieval cue to attempt retrieval of a\n",
    "studied item. First, the activation of each item a is determined according to... In order to avoid the\n",
    "possibility of the model assigning a probability of 0 to any possible recall, we set a minimal activation for\n",
    "each item of 10^-7.\n",
    "\n",
    "At each recall attempt, we calculated the probability of stopping recall (in which case no item was recalled,\n",
    "and search terminated). Probability of stopping recall varies as a function of output position j (where j = 0\n",
    "for the first attempt), according to: P(stop, j) = ... where hs and hr are free parameters that determine the\n",
    "scaling and rate of increase, respectively, of the exponential function. The stopping mechanism does not\n",
    "interact with any model mechanism, and is simply intended to capture the average probability of stopping as a\n",
    "function of output position. The probability P(i) of recalling a given item i is defined conditional on\n",
    "recall not stopping at that position, and it varies with activation strength, according to P(i) = ... where s\n",
    "is a sensitivity parameter that determines the contrast between well-supported and poorly supported items.\n",
    "High values of s will cause a greater influence of differences in support, while low values will cause\n",
    "relatively uniform probabilities of recalling each item.\n",
    "\"\n",
    "\n",
    "So this is a classification scheme. We want to follow this, so we want the probability of recalling an item\n",
    "to be a linear combination of the probability of recalling each relevant trace. There are tons of ways to\n",
    "potentially realize this. The important thing is just picking one! In my mind, a nearest neighbor approach is\n",
    "reasonably solid. It represents the likely outcome of more complex selection processes we can think of, but\n",
    "it still makes room for behavior to depend on the content of the stored trace, which can be messed with in\n",
    "lots of conceivable ways."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
