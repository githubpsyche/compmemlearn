{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supposed-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp models\n",
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-assembly",
   "metadata": {},
   "source": [
    "# PrototypeCMR\n",
    "> The Classic Prototype-Based Account of Context Maintenance and Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-electricity",
   "metadata": {},
   "source": [
    "The Context Maintenance and Retrieval (CMR) as specified by Morton and Polyn (2016) takes the form of a simplified neural network with two interacting representations, a feature-based representation of the studied item and a contextual representation (the context layer, $C$). The two layers communicate with one another through two sets of associative connections represented by matrices $M^{FC}$ and $M^{CF}$. Each of these weight matrices contains both pre-experimental associations and new associations learned during the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "neural-graham",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from numba import float64, int32, boolean\n",
    "from numba.experimental import jitclass\n",
    "\n",
    "cmr_spec = [\n",
    "    ('item_count', int32), \n",
    "    ('encoding_drift_rate', float64),\n",
    "    ('start_drift_rate', float64),\n",
    "    ('recall_drift_rate', float64),\n",
    "    ('shared_support', float64),\n",
    "    ('item_support', float64),\n",
    "    ('learning_rate', float64),\n",
    "    ('primacy_scale', float64),\n",
    "    ('primacy_decay', float64),\n",
    "    ('stop_probability_scale', float64),\n",
    "    ('stop_probability_growth', float64),\n",
    "    ('choice_sensitivity', float64),\n",
    "    ('context', float64[::1]),\n",
    "    ('preretrieval_context', float64[::1]),\n",
    "    ('recall', float64[::1]),\n",
    "    ('retrieving', boolean),\n",
    "    ('recall_total', int32),\n",
    "    ('primacy_weighting', float64[::1]),\n",
    "    ('probabilities', float64[::1]),\n",
    "    ('mfc', float64[:,::1]),\n",
    "    ('mcf', float64[:,::1]),\n",
    "    ('encoding_index', int32),\n",
    "    ('items', float64[:,::1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amber-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "@jitclass(cmr_spec)\n",
    "class CMR:\n",
    "\n",
    "    def __init__(self, item_count, presentation_count, encoding_drift_rate, start_drift_rate, recall_drift_rate, shared_support,\n",
    "                 item_support, learning_rate, primacy_scale, primacy_decay, stop_probability_scale,\n",
    "                 stop_probability_growth, choice_sensitivity):\n",
    "        \n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = encoding_drift_rate\n",
    "        self.start_drift_rate = start_drift_rate\n",
    "        self.recall_drift_rate = recall_drift_rate\n",
    "        self.shared_support = shared_support\n",
    "        self.item_support = item_support\n",
    "        self.learning_rate = learning_rate\n",
    "        self.primacy_scale = primacy_scale\n",
    "        self.primacy_decay = primacy_decay\n",
    "        self.stop_probability_scale = stop_probability_scale\n",
    "        self.stop_probability_growth = stop_probability_growth\n",
    "        self.choice_sensitivity = choice_sensitivity\n",
    "        \n",
    "        # at the start of the list context is initialized with a state orthogonal to the pre-experimental context\n",
    "        # associated with the set of items\n",
    "        self.context = np.zeros(item_count + 1)\n",
    "        self.context[0] = 1\n",
    "        self.preretrieval_context = self.context\n",
    "        self.recall = np.zeros(item_count) # recalls has at most `item_count` entries\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "\n",
    "        # predefine primacy weighting vectors\n",
    "        self.primacy_weighting = primacy_scale * np.exp(-primacy_decay * np.arange(presentation_count)) + 1\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((item_count + 1))\n",
    "\n",
    "        # The two layers communicate with one another through two sets of associative connections represented by\n",
    "        # matrices Mfc and Mcf. Pre-experimental Mfc is 1-learning_rate and pre-experimental Mcf is item_support for \n",
    "        # i=j. For i!=j, Mcf is shared_support.\n",
    "        self.mfc = np.eye(item_count, item_count+1, 1) * (1 - learning_rate)\n",
    "        self.mcf = np.ones((item_count, item_count)) * shared_support\n",
    "        for i in range(item_count):\n",
    "            self.mcf[i, i] = item_support\n",
    "        self.mcf =  np.vstack((np.zeros((1, item_count)), self.mcf))\n",
    "        self.encoding_index = 0\n",
    "        self.items = np.eye(item_count, item_count)\n",
    "\n",
    "    def experience(self, experiences):\n",
    "        \n",
    "        for i in range(len(experiences)):\n",
    "            self.update_context(self.encoding_drift_rate, experiences[i])\n",
    "            self.mfc += self.learning_rate * np.outer(self.context, experiences[i]).T\n",
    "            self.mcf += self.primacy_weighting[self.encoding_index] * np.outer(self.context, experiences[i])\n",
    "            self.encoding_index += 1\n",
    "\n",
    "    def update_context(self, drift_rate, experience=None):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if experience is not None:\n",
    "            context_input = np.dot(experience, self.mfc)\n",
    "            context_input = context_input / np.sqrt(np.sum(np.square(context_input))) # norm to length 1\n",
    "        else:\n",
    "            context_input = np.zeros((self.item_count+1))\n",
    "            context_input[0] = 1\n",
    "\n",
    "        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)) - (\n",
    "            drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "\n",
    "    def activations(self, probe, use_mfc=False):\n",
    "\n",
    "        if use_mfc:\n",
    "            return np.dot(probe, self.mfc) + 10e-7\n",
    "        else:\n",
    "            return np.dot(probe, self.mcf) + 10e-7\n",
    "        \n",
    "    def outcome_probabilities(self, activation_cue):\n",
    "\n",
    "        activation = self.activations(activation_cue)\n",
    "        activation = np.power(activation, self.choice_sensitivity)\n",
    "\n",
    "        self.probabilities = np.zeros((self.item_count + 1))\n",
    "        self.probabilities[0] = min(self.stop_probability_scale * np.exp(\n",
    "            self.recall_total * self.stop_probability_growth), 1.0)\n",
    "\n",
    "        if self.probabilities[0] < 1:\n",
    "            for already_recalled_item in self.recall[:self.recall_total]:\n",
    "                activation[int(already_recalled_item)] = 0\n",
    "        self.probabilities[1:] = (1-self.probabilities[0]) * activation / np.sum(activation)\n",
    "\n",
    "        return self.probabilities\n",
    "\n",
    "    def free_recall(self, steps=None):\n",
    "\n",
    "        # some amount of the pre-list context is reinstated before initiating recall\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.start_drift_rate)\n",
    "            self.retrieving = True\n",
    "\n",
    "        # number of items to retrieve is # of items left to recall if steps is unspecified\n",
    "        if steps is None:\n",
    "            steps = self.item_count - self.recall_total\n",
    "        steps = self.recall_total + steps\n",
    "        \n",
    "        # at each recall attempt\n",
    "        while self.recall_total < steps:\n",
    "\n",
    "            # the current state of context is used as a retrieval cue to attempt recall of a studied item\n",
    "            # compute outcome probabilities and make choice based on distribution\n",
    "            outcome_probabilities = self.outcome_probabilities(self.context)\n",
    "            if np.any(outcome_probabilities[1:]):\n",
    "                choice = np.sum(np.cumsum(outcome_probabilities) < np.random.rand())\n",
    "            else:\n",
    "                choice = 0\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made (0)\n",
    "            if choice == 0:\n",
    "                self.retrieving = False\n",
    "                self.context = self.preretrieval_context\n",
    "                break\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "        return self.recall[:self.recall_total]\n",
    "\n",
    "    def force_recall(self, choice=None):\n",
    "\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.start_drift_rate)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        elif choice > 0:\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "        else:\n",
    "            self.retrieving = False\n",
    "            self.context = self.preretrieval_context\n",
    "        return self.recall[:self.recall_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabulous-lexington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"CMR\" class=\"doc_header\"><code>class</code> <code>CMR</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>CMR</code>(**\\*`args`**, **\\*\\*`kwargs`**) :: [`CMR`](/instance_cmr/Classic_CMR.html#CMR)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    show_doc(CMR)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unable-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(CMR.experience)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "criminal-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(CMR.update_context)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "overall-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(CMR.activations)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "recent-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(CMR.outcome_probabilities)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faced-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(CMR.activations)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "universal-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(CMR.free_recall)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sensitive-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(CMR.force_recall)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-render",
   "metadata": {},
   "source": [
    "We reserve exploration of model behavior to later project notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
