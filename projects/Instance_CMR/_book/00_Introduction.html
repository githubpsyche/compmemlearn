<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang=""><head>
  <meta charset="utf-8">
  <meta name="generator" content="quarto-0.2.281">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>An Instance-Based Account of Context Maintenance and Retrieval - 2&nbsp; Instance and Prototype Accounts of Abstraction</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>

  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <script src="site_libs/quarto-nav/quarto-nav.js"></script>
  <script src="site_libs/quarto-nav/headroom.min.js"></script>
  <script src="site_libs/clipboard/clipboard.min.js"></script>
  <meta name="quarto:offset" content="./">
  <script src="site_libs/quarto-search/autocomplete.umd.js"></script>
  <script src="site_libs/quarto-search/fuse.min.js"></script>
  <script src="site_libs/quarto-search/quarto-search.js"></script>
  <link href="./01_Classic_CMR.html" rel="next">
  <link href="./index.html" rel="prev">
  <script src="site_libs/quarto-html/quarto.js"></script>
  <script src="site_libs/quarto-html/popper.min.js"></script>
  <script src="site_libs/quarto-html/tippy.umd.min.js"></script>
  <script src="site_libs/quarto-html/anchor.min.js"></script>
  <link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
  <link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
  <script src="site_libs/bootstrap/bootstrap.min.js"></script>
  <link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
  <link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
  <script id="quarto-search-options" type="application/json">{
    "location": "sidebar",
    "copy-button": false,
    "collapse-after": 2,
    "panel-placement": "start",
    "type": "textbox",
    "limit": 20,
    "language": {
      "search-no-results-text": "No results",
      "search-matching-documents-text": "matching documents",
      "search-copy-link-title": "Copy link to search",
      "search-hide-matches-text": "Hide additional matches",
      "search-more-match-text": "more match in this document",
      "search-more-matches-text": "more matches in this document",
      "search-clear-button-title": "Clear",
      "search-detached-cancel-button-title": "Cancel",
      "search-submit-button-title": "Submit"
    }
  }</script>
</head>
<body class="floating">
<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Instance and Prototype Accounts of Abstraction</span></h1>
      <button type="button" class="quarto-btn-toggle btn">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
  <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">An Instance-Based Account of Context Maintenance and Retrieval</a> 
        <div class="sidebar-tools-main">
</div>
    </div>
  </div>
    <div class="px-3 mt-2 flex-shrink-0 align-items-center">
      <div class="sidebar-search">
      <div id="quarto-search" class="" title="Search"></div>
      </div>
    </div>
  <div class="sidebar-menu-container"> 
  <ul class="list-unstyled mt-1">
      <li class="sidebar-item">
  <a href="./index.html" class=""><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">index.html</span></a>
</li>
      <li class="sidebar-item">
  <a href="./00_Introduction.html" class="active"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Instance and Prototype Accounts of Abstraction</span></a>
</li>
      <li class="sidebar-item">
  <a href="./01_Classic_CMR.html" class=""><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Prototype-Based Account of Context Maintenance and Retrieval</span></a>
</li>
      <li class="sidebar-item">
  <a href="./02_Instance_CMR.html" class=""><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Context Maintenance and Retrieval within an Instance-Based Architecture</span></a>
</li>
      <li class="sidebar-item">
  <a href="./03_Methods.html" class=""><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Analysis Approach</span></a>
</li>
      <li class="sidebar-item">
  <a href="./04_Baseline_Comparison.html" class=""><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Simulation of Murdock and Okada (1970)</span></a>
</li>
      <li class="sidebar-item">
  <a href="./05_Variable_List_Lengths.html" class=""><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Simulation of Murdock Jr (1962)</span></a>
</li>
      <li class="sidebar-item">
  <a href="./06_Item_Repetitions.html" class=""><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Repetition Effects</span></a>
</li>
      <li class="sidebar-item">
  <a href="./07_Discussion.html" class=""><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Discussion</span></a>
</li>
      <li class="sidebar-item">
  <a href="./references.html" class=""><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">References</span></a>
</li>
  </ul>
  </div>
</nav>
<!-- toc -->
    <nav id="TOC" role="doc-toc" class="sidebar sidebar-toc">
<h2 id="toc-title">On this page</h2>
<ul>
<li><a href="#models-of-free-recall-are-traditionally-prototype-based" class="nav-link active" data-scroll-target="#models-of-free-recall-are-traditionally-prototype-based"> <span class="header-section-number">2.0.1</span> Models of Free Recall are Traditionally Prototype-Based</a></li>
<li><a href="#research-approach" class="nav-link" data-scroll-target="#research-approach"> <span class="header-section-number">2.0.2</span> Research Approach</a></li>
</ul>
</nav>
<!-- main -->
<main class="content">
<header id="title-block-header">
<h1 class="title d-none d-lg-block display-7"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Instance and Prototype Accounts of Abstraction</span></h1>
</header>

<p>A central task of memory is to relate features of current experience with relevant and useful information from past experience; however, stored information relevant to a probe is often distributed across multiple learning episodes. To account for our ability to retrieve this information, models of memory search often specify some mechanism for abstraction – selective generalization across recurrent features of past experience <span class="citation" data-cites="yee2019abstraction">(<a href="references.html#ref-yee2019abstraction" role="doc-biblioref">Yee 2019</a>)</span>. Abstraction involves identifying and highlighting features common across experiential episodes while disregarding or suppressing reinstatement more idiosyncratic properties. Since this capacity is central to how memory systems retrieve relevant information from stored experience, much work has explored how humans carry it out.</p>
<p>Depending on how they characterize the process of abstraction, memory models can often be categorized as prototype- or instance-based. Prototype-based models conceptualize abstraction as a process enacted during encoding; new experiences are conceived as updating memory representations to reflect prototypical features that are common across past experiences. Connectionist models such as the multilayer perceptron are typically examples of prototype-based models <span class="citation" data-cites="jamieson2018instance">(<a href="references.html#ref-jamieson2018instance" role="doc-biblioref">Jamieson et al. 2018</a>)</span>. Instead of being stored as separate records in memory, learning examples presented to a connectionist model each update a prototypical pattern of weights that eventually map memory probes to responses.</p>
<p>Instance-based models do store learning exampls as separate records in memory. The model architecture was originally identified to help understand how category learning might be possible without explicit storage of so-called abstract ideas <span class="citation" data-cites="hintzman1984minerva hintzman1986schema hintzman1988judgments">(<a href="references.html#ref-hintzman1984minerva" role="doc-biblioref">Hintzman 1984</a>, <a href="references.html#ref-hintzman1986schema" role="doc-biblioref">1986</a>, <a href="references.html#ref-hintzman1988judgments" role="doc-biblioref">1988</a>)</span>. Instance-based models posit that memory encoding primarily involves accumulating a record of every experience as separate traces in memory. Abstraction over stored instances later occurs at retrieval rather than during encoding, and unfolds through comparison of a memory cue with each instance stored in memory. The abstractive representation finally retrieved is a blend of the content in each stored instance, weighted such that information in the instances most similar to the probe is substantially more prominent than information in instances that are dissimilar to the probe. Because instance-based models preserve a discrete record of all relevant events in memory, they can often selectively retrieve information about even rare past events with high flexibility. <!--
Instance-based architecture might predate minerva 2??
--></p>
<p>Instance-based accounts of memory have faced scrutiny for implying that the number of stored instances in memory can increase without limit and are all contacted upon retrieval, respectively placing extraordinary capacity and processing demands on the human nervous system <span class="citation" data-cites="kahana2020computational">(e.g., <a href="references.html#ref-kahana2020computational" role="doc-biblioref">Kahana 2020</a>)</span>. However, at the same time as instance-based models have been critiqued for their architectural lack of data compression at storage, the way abstractive representations exclude idiosyncratic features of individual learning episodes to reflect a center of tendency across them is similarly recurrently cited as a limitation of prototype-based models. In research on categorization for example, ‘exemplar-similarity’ models <span class="citation" data-cites="nosofsky2002exemplar stanton2002comparisons">(<a href="references.html#ref-nosofsky2002exemplar" role="doc-biblioref">Nosofsky and Zaki 2002</a>; <a href="references.html#ref-stanton2002comparisons" role="doc-biblioref">Stanton, Nosofsky, and Zaki 2002</a>)</span> outperform comparable prototype-based models by representing categories as sets of stored instances paired with a process for comparison against probes. A related analysis extends these findings to also critique prototype-based accounts of semantic memory. <span class="citation" data-cites="jamieson2018instance">Jamieson et al. (<a href="references.html#ref-jamieson2018instance" role="doc-biblioref">2018</a>)</span> found that because prototype-based distributional semantic models such as latent semantic analysis <span class="citation" data-cites="dumais2004latent">(<a href="references.html#ref-dumais2004latent" role="doc-biblioref">Dumais 2004</a>)</span> and Word2Vec <span class="citation" data-cites="church2017word2vec">(<a href="references.html#ref-church2017word2vec" role="doc-biblioref">Church 2017</a>)</span> “collapse the many contexts in which a word occurs to a single best-fitting representation”, they lose the ability to represent rare senses of homonymous and polymsemous words. Consequently, prototype-based models exhibited measureably worse performance accounting for word similarity patterns in various natural language simulations compared to an instance-based account of semantic memory based on the MINERVA 2 multiple traces memory model <span class="citation" data-cites="hintzman1984minerva">(<a href="references.html#ref-hintzman1984minerva" role="doc-biblioref">Hintzman 1984</a>)</span>. In the context of successes like these across diverse research conditions, instance-based accounts of memory have become increasingly prominent.</p>
<section id="models-of-free-recall-are-traditionally-prototype-based" class="level3" data-number="2.0.1">
<h3 data-number="2.0.1" class="anchored" data-anchor-id="models-of-free-recall-are-traditionally-prototype-based"><span class="header-section-number">2.0.1</span> Models of Free Recall are Traditionally Prototype-Based</h3>
<p>While instance-based models have organized formal work in a variety of research subfields, models of memory search primarily focused on accounting for performance on the free recall task largely countervail this pattern. In the free recall task paradigm, research participants are presented a sequence of items — usually a word list — to memorize during a study phase. Later, after a delay or perhaps some distraction task, participants are prompted to recall as many items from the list as possible, in whatever order they come to mind. Since participants largely organize the course of retrieval themselves in the response phase of a free recall task, work by researchers to characterize the organization of responses measured under the paradigm <span class="citation" data-cites="postman1971organization puff1979memory">(<a href="references.html#ref-postman1971organization" role="doc-biblioref">Postman 1971</a>; <a href="references.html#ref-puff1979memory" role="doc-biblioref">Puff 1979</a>)</span> have provided important constraints on accounts of the representations and mechanisms underlying search through memory to retrieve information.</p>
<p>In particular, three consistent regularities across experiments have received especial emphasis in accounts of performance on the free recall task <span class="citation" data-cites="kahana2020computational">(<a href="references.html#ref-kahana2020computational" role="doc-biblioref">Kahana 2020</a>)</span>. The serial position effect identifies a nonlinear, U-shaped relationship between the position of an item within a study list — its serial position — and its probability of retrieval after encoding <span class="citation" data-cites="murdock1962serial">(<a href="references.html#ref-murdock1962serial" role="doc-biblioref">Murdock Jr 1962</a>)</span>. Researchers typically distinguish between the enhanced retrieval probabilities for early and terminal items; the advantage for the initially presented items is called the primacy effect, while the normally larger advantage for the few presented items is called the recency effect.</p>
<p>A similar but distinct pattern constraining accounts of memory search is found in analyses relating an item’s serial position with the probability that it will be recalled first in the retrieval phase of experiments. Pivotally, in list-based free recall tasks, participants tend to initiate recall with the most recently studied items from the list; however, in a <em>serial</em> recall task where participants are instructed to recall items in the order in which they were presented rather than freely, participants tend to successfully recall the earliest presented items first <span class="citation" data-cites="golomb2008effects">(for example in <a href="references.html#ref-golomb2008effects" role="doc-biblioref">Golomb et al. 2008</a>)</span>. This difference implies that while participants maintain and can access memories of item positions to perform a serial recall task, memory search and retrieval is organized by other features of experience.</p>
<p>Primacy and recency effects demonstrate that the temporal structure of the list affects the memorability of the items within it. This temporal structure can also be seen in the organization of responses throughout the response sequence, not just for initial and terminal items or recall positions. Free recall task data exhibits a pattern called <em>temporal contiguity</em> where items studied at nearby serial positions tend to be recalled near one another at the retrieval phase of an experiment. To quantify this pattern, researchers measure across trials the conditional probability of retrieving items given increasing inter-item lags between the serial positions of considered items and the serial position of the item last recalled. These lag-based condition response probability (lag-CRP) analyses find that subjects reliably tend to make transitions between temporally contiguous items (that is, items presented near one another) during free recall. Furthermore, they exhibit a forward bias, recalling contiguous items presented after the last recalled item more frequently than items presented before <span class="citation" data-cites="kahana1996associative">(<a href="references.html#ref-kahana1996associative" role="doc-biblioref">Kahana 1996</a>)</span>.</p>
<p>To account for these phenomena, the formal literature has largely converged on retrieved context theories of memory search <span class="citation" data-cites="howard2002distributed polyn2009context morton2016predictive">(for example, <a href="references.html#ref-howard2002distributed" role="doc-biblioref">Howard and Kahana 2002</a>; <a href="references.html#ref-polyn2009context" role="doc-biblioref">Polyn, Norman, and Kahana 2009</a>; <a href="references.html#ref-morton2016predictive" role="doc-biblioref">Morton and Polyn 2016</a>)</span>. Generally, according to these theories, as items are encoded into a memory system, an internal representational of temporal context is also maintained that dynamically updates itself to reflect a weighted summary of recent experience. As each item is studied, a Hebbian learning mechanism associates the item’s features to the current state of the context representation. Once associated, item features can cue retrieval of associated contextual features, and vice versa. When the retrieval phase comes, the current contextual representation can drive memory search by activating a blend of associated item features. This prompts a retrieval competition in which a particular item is selected and retrieved. Correspondingly, retrieving an item reactivates its associated contextual features, updating context before the next recall attempt. The retrieved context supports the neighbors of the just-recalled item, which gives rise to temporal organization.</p>
<p>With these basic mechanisms, retrieved-context models have been used to explain many phenomena, including serial and temporal organizational effects in list-learning tasks <span class="citation" data-cites="polyn2009context siegel2014retrieved schwartz2005shadows">(<a href="references.html#ref-polyn2009context" role="doc-biblioref">Polyn, Norman, and Kahana 2009</a>; <a href="references.html#ref-siegel2014retrieved" role="doc-biblioref">Siegel and Kahana 2014</a>; <a href="references.html#ref-schwartz2005shadows" role="doc-biblioref">Schwartz et al. 2005</a>)</span>, and broader domains such as financial decision making <span class="citation" data-cites="wachter2019retrieved">(<a href="references.html#ref-wachter2019retrieved" role="doc-biblioref">Wachter and Kahana 2019</a>)</span>, emotion regulation <span class="citation" data-cites="talmi2019retrieved">(<a href="references.html#ref-talmi2019retrieved" role="doc-biblioref">Talmi, Lohnas, and Daw 2019</a>)</span>, and neural signal dynamics within the medial temporal lobe <span class="citation" data-cites="kragel2015neural">(<a href="references.html#ref-kragel2015neural" role="doc-biblioref">Kragel, Morton, and Polyn 2015</a>)</span>. Further model development has integrated retrieved context accounts of memory search with theories of semantic knowledge <span class="citation" data-cites="morton2016predictive">(<a href="references.html#ref-morton2016predictive" role="doc-biblioref">Morton and Polyn 2016</a>)</span> and changes related to healthy aging <span class="citation" data-cites="healey2016four">(<a href="references.html#ref-healey2016four" role="doc-biblioref">Healey and Kahana 2016</a>)</span>.</p>
<p>The framework used to implement most retrieved context models of memory search acts like a prototype model. These models typically encode memories associating contextual states and item features by updating connection weights within a simplified neural network. Through Hebbian learning, where co-activation of item and contextual features increase weights associating those features, the network accumulates a collapsed average representation reflecting the history of context and item interactions across experience. During retrieval, the network can be probed with a contextual cue to retrieve an item feature representation (or vice versa) based on a linear function of the cue’s content and stored context-to-item weights.</p>
<p>In contrast, an instance-based alternative would track this history by storing a discrete record of each experience with its unique temporal context in memory to perform abstraction over only at the point of retrieval. Previous instance-based accounts of performance on various tasks have emphasized a role of some sort of temporal contextual representation in organizing performance. Indeed, the original presentation of MINERVA 2, the first major instance-based memory modeling architecture, included a representation of list context as a feature in stored memory instances to model source-specific frequency judgments from memory <span class="citation" data-cites="hintzman1984minerva">(<a href="references.html#ref-hintzman1984minerva" role="doc-biblioref">Hintzman 1984</a>)</span>. <span class="citation" data-cites="lehman2013buffer">(<a href="references.html#ref-lehman2013buffer" role="doc-biblioref">Lehman and Malmberg 2013</a>)</span> proposed an instance-based buffer model that accounts for patterns like recency and the position position effect in terms of storage and retrieval of traces containing information about item and contextual co-occurrences. Most recently, <span class="citation" data-cites="logan2021serial">Logan (<a href="references.html#ref-logan2021serial" role="doc-biblioref">2021</a>)</span> introduced the Context Retrieval and Updating (CRU) model, which extends retrieved context theories’ conceptualization of context as a recency-weighted history of previously presented items to account for performance on whole report, serial recall, and copy typing tasks. Nonetheless, it remains unclear whether differences reported in related memory literatures between the performance of prototype- and instance-based memory models might similarly distinguish models of memory search.</p>
</section>
<section id="research-approach" class="level3" data-number="2.0.2">
<h3 data-number="2.0.2" class="anchored" data-anchor-id="research-approach"><span class="header-section-number">2.0.2</span> Research Approach</h3>
<p>In this paper, I show that the mechanisms proposed by the influential Context Maintanence and Retrieval (CMR) model of memory search <span class="citation" data-cites="morton2016predictive">(<a href="references.html#ref-morton2016predictive" role="doc-biblioref">Morton and Polyn 2016</a>)</span> can be realized within either a prototypical or instance-based model architecture without substantially impacting performance across various experimental conditions. This instance-based CMR (InstanceCMR) extends the established MINERVA 2 multiple traces model <span class="citation" data-cites="hintzman1984minerva hintzman1986schema hintzman1988judgments">(<a href="references.html#ref-hintzman1984minerva" role="doc-biblioref">Hintzman 1984</a>, <a href="references.html#ref-hintzman1986schema" role="doc-biblioref">1986</a>, <a href="references.html#ref-hintzman1988judgments" role="doc-biblioref">1988</a>)</span> to support context-based memory search and simulate performance on the free recall task. I fit InstanceCMR and its original prototype-based counterpart (prototypeCMR) to the sequences of individual responses made by participants in three distinct free recall task datasets.I find that the models account for retrieval performance with similar effectiveness despite architectural differences, including over data manipulating the lengths of study lists between trials and other data manipulating the number of times particular items are studied within trials.</p>
<p>Analyses of the two specifications for CMR suggest that these outcomes can be largely explained by the model’s assumption that feature representations corresponding to studied items in free recall experiments are orthogonal — activation of each unit on an item feature layer corresponds to one item. This ensures that context-to-feature associations built via experience of one item do not overlap with associations built through experience of some other distinct item. Correspondingly, the influence of relevant experiences on the content of abstractive representations retrieved via these associations can be selectively enhanced while simultaneously suppressing the influence of less relevant experiences, without any interference. This capacity to nonlinearly modulate the influence of selected learning episodes on recall based on the content of a probe approximates trace-based activation functions realized within instance-based models, sidestepping issues reported about prototype-based memory models in other literatures.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-church2017word2vec" class="csl-entry" role="doc-biblioentry">
Church, Kenneth Ward. 2017. <span>“Word2Vec.”</span> <em>Natural Language Engineering</em> 23 (1): 155–62.
</div>
<div id="ref-dumais2004latent" class="csl-entry" role="doc-biblioentry">
Dumais, Susan T. 2004. <span>“Latent Semantic Analysis.”</span> <em>Annual Review of Information Science and Technology</em> 38 (1): 188–230.
</div>
<div id="ref-golomb2008effects" class="csl-entry" role="doc-biblioentry">
Golomb, Julie D, Jonathan E Peelle, Kelly M Addis, Michael J Kahana, and Arthur Wingfield. 2008. <span>“Effects of Adult Aging on Utilization of Temporal and Semantic Associations During Free and Serial Recall.”</span> <em>Memory &amp; Cognition</em> 36 (5): 947–56.
</div>
<div id="ref-healey2016four" class="csl-entry" role="doc-biblioentry">
Healey, M Karl, and Michael J Kahana. 2016. <span>“A Four-Component Model of Age-Related Memory Change.”</span> <em>Psychological Review</em> 123 (1): 23.
</div>
<div id="ref-hintzman1984minerva" class="csl-entry" role="doc-biblioentry">
Hintzman, Douglas L. 1984. <span>“MINERVA 2: A Simulation Model of Human Memory.”</span> <em>Behavior Research Methods, Instruments, &amp; Computers</em> 16 (2): 96–101.
</div>
<div id="ref-hintzman1986schema" class="csl-entry" role="doc-biblioentry">
———. 1986. <span>“"Schema Abstraction" in a Multiple-Trace Memory Model.”</span> <em>Psychological Review</em> 93 (4): 411.
</div>
<div id="ref-hintzman1988judgments" class="csl-entry" role="doc-biblioentry">
———. 1988. <span>“Judgments of Frequency and Recognition Memory in a Multiple-Trace Memory Model.”</span> <em>Psychological Review</em> 95 (4): 528.
</div>
<div id="ref-howard2002distributed" class="csl-entry" role="doc-biblioentry">
Howard, Marc W, and Michael J Kahana. 2002. <span>“A Distributed Representation of Temporal Context.”</span> <em>Journal of Mathematical Psychology</em> 46 (3): 269–99.
</div>
<div id="ref-jamieson2018instance" class="csl-entry" role="doc-biblioentry">
Jamieson, Randall K, Johnathan E Avery, Brendan T Johns, and Michael N Jones. 2018. <span>“An Instance Theory of Semantic Memory.”</span> <em>Computational Brain &amp; Behavior</em> 1 (2): 119–36.
</div>
<div id="ref-kahana1996associative" class="csl-entry" role="doc-biblioentry">
Kahana, Michael J. 1996. <span>“Associative Retrieval Processes in Free Recall.”</span> <em>Memory &amp; Cognition</em> 24 (1): 103–9.
</div>
<div id="ref-kahana2020computational" class="csl-entry" role="doc-biblioentry">
———. 2020. <span>“Computational Models of Memory Search.”</span> <em>Annual Review of Psychology</em> 71: 107–38.
</div>
<div id="ref-kragel2015neural" class="csl-entry" role="doc-biblioentry">
Kragel, James E, Neal W Morton, and Sean M Polyn. 2015. <span>“Neural Activity in the Medial Temporal Lobe Reveals the Fidelity of Mental Time Travel.”</span> <em>Journal of Neuroscience</em> 35 (7): 2914–26.
</div>
<div id="ref-lehman2013buffer" class="csl-entry" role="doc-biblioentry">
Lehman, Melissa, and Kenneth J Malmberg. 2013. <span>“A Buffer Model of Memory Encoding and Temporal Correlations in Retrieval.”</span> <em>Psychological Review</em> 120 (1): 155.
</div>
<div id="ref-logan2021serial" class="csl-entry" role="doc-biblioentry">
Logan, Gordon D. 2021. <span>“Serial Order in Perception, Memory, and Action.”</span> <em>Psychological Review</em> 128 (1): 1.
</div>
<div id="ref-morton2016predictive" class="csl-entry" role="doc-biblioentry">
Morton, Neal W, and Sean M Polyn. 2016. <span>“A Predictive Framework for Evaluating Models of Semantic Organization in Free Recall.”</span> <em>Journal of Memory and Language</em> 86: 119–40.
</div>
<div id="ref-murdock1962serial" class="csl-entry" role="doc-biblioentry">
Murdock Jr, Bennet B. 1962. <span>“The Serial Position Effect of Free Recall.”</span> <em>Journal of Experimental Psychology</em> 64 (5): 482.
</div>
<div id="ref-nosofsky2002exemplar" class="csl-entry" role="doc-biblioentry">
Nosofsky, Robert M, and Safa R Zaki. 2002. <span>“Exemplar and Prototype Models Revisited: Response Strategies, Selective Attention, and Stimulus Generalization.”</span> <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em> 28 (5): 924.
</div>
<div id="ref-polyn2009context" class="csl-entry" role="doc-biblioentry">
Polyn, Sean M, Kenneth A Norman, and Michael J Kahana. 2009. <span>“A Context Maintenance and Retrieval Model of Organizational Processes in Free Recall.”</span> <em>Psychological Review</em> 116 (1): 129.
</div>
<div id="ref-postman1971organization" class="csl-entry" role="doc-biblioentry">
Postman, Leo. 1971. <span>“Organization and Interference.”</span> <em>Psychological Review</em> 78 (4): 290.
</div>
<div id="ref-puff1979memory" class="csl-entry" role="doc-biblioentry">
Puff, C Richard. 1979. <em>Memory Organization and Structure</em>. Academic Press.
</div>
<div id="ref-schwartz2005shadows" class="csl-entry" role="doc-biblioentry">
Schwartz, Greg, Marc W Howard, Bing Jing, and Michael J Kahana. 2005. <span>“Shadows of the Past: Temporal Retrieval Effects in Recognition Memory.”</span> <em>Psychological Science</em> 16 (11): 898–904.
</div>
<div id="ref-siegel2014retrieved" class="csl-entry" role="doc-biblioentry">
Siegel, Lynn L, and Michael J Kahana. 2014. <span>“A Retrieved Context Account of Spacing and Repetition Effects in Free Recall.”</span> <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em> 40 (3): 755.
</div>
<div id="ref-stanton2002comparisons" class="csl-entry" role="doc-biblioentry">
Stanton, Roger D, Robert M Nosofsky, and Safa R Zaki. 2002. <span>“Comparisons Between Exemplar Similarity and Mixed Prototype Models Using a Linearly Separable Category Structure.”</span> <em>Memory &amp; Cognition</em> 30 (6): 934–44.
</div>
<div id="ref-talmi2019retrieved" class="csl-entry" role="doc-biblioentry">
Talmi, Deborah, Lynn J Lohnas, and Nathaniel D Daw. 2019. <span>“A Retrieved Context Model of the Emotional Modulation of Memory.”</span> <em>Psychological Review</em> 126 (4): 455.
</div>
<div id="ref-wachter2019retrieved" class="csl-entry" role="doc-biblioentry">
Wachter, Jessica A, and Michael Jacob Kahana. 2019. <span>“A Retrieved-Context Theory of Financial Decisions.”</span> National Bureau of Economic Research.
</div>
<div id="ref-yee2019abstraction" class="csl-entry" role="doc-biblioentry">
Yee, Eiling. 2019. <span>“Abstraction and Concepts: When, How, Where, What and Why?”</span> Taylor &amp; Francis.
</div>
</div>
</section>
<script type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    setTimeout(function() {
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</main> <!-- /main -->
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">index.html</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./01_Classic_CMR.html">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Prototype-Based Account of Context Maintenance and Retrieval</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->


</body></html>