{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "integrated-antique",
   "metadata": {},
   "source": [
    "# CMR Bulk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-legend",
   "metadata": {},
   "source": [
    "#### The Idea\n",
    "By basically just adding an extra dimension to the arrays that CMR or InstanceCMR use to simulate encoding and retrieval, we can compute trial likelihoods across trials using just a single model instance. For example, currently CMR's context representation is a vector. We can add another dimension to that array with length T where T is the number of trials you're interested in performing simulations with. Same goes for representations like Mfc and Mcf. Where relevant during encoding (such as when item presentation scheme varies as in the Lohnas spacing dataset) or retrieval (recall order varies across trials), we can pass vectors of events instead of single events to track model performance using a single sequence of array operations. Before in my likelihood functions I reset or (worse) instantiated a totally new model instance for each trial I wanted to run my model on; with this approach, we can avoid that bottleneck completely while still having a codebase can can run single-trial simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-radio",
   "metadata": {},
   "source": [
    "#### Testing Requirements\n",
    "We need a version of CMR that can maintain and update representations of multiple model states simultaneously.\n",
    "Our testing function should use this model to encode multiple sequences of experiences simultaneously, then to perform free recall each instance as well, using a single array operation across instances each time.\n",
    "\n",
    "This still applies a for-loop: each new model state is generated sequentially.This is necessary as far as we can tell because succeeding states depend on prior states. But we may be able to move some operations outside that loop. \n",
    "\n",
    "If a record of relevant aspects of each model state is tracked across transitions within a cross-transition representation, for example, then computation of outcome_probabilities and similar operations can be performed across all states using a single set of operations as well. But we'll save that modification for later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-adrian",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "controlled-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from numba import float64, int32, boolean\n",
    "from numba.experimental import jitclass\n",
    "\n",
    "cmr_spec = [\n",
    "    ('item_count', int32), \n",
    "    ('encoding_drift_rate', float64),\n",
    "    ('start_drift_rate', float64),\n",
    "    ('recall_drift_rate', float64),\n",
    "    ('shared_support', float64),\n",
    "    ('item_support', float64),\n",
    "    ('learning_rate', float64),\n",
    "    ('primacy_scale', float64),\n",
    "    ('primacy_decay', float64),\n",
    "    ('stop_probability_scale', float64),\n",
    "    ('stop_probability_growth', float64),\n",
    "    ('choice_sensitivity', float64),\n",
    "    ('context', float64[:, ::1]),\n",
    "    ('recall', int32[:, ::1]),\n",
    "    ('retrieving', boolean),\n",
    "    ('recall_total', int32),\n",
    "    ('primacy_weighting', float64[::1]),\n",
    "    ('probabilities', float64[:, ::1]),\n",
    "    ('mfc', float64[:, :, ::1]),\n",
    "    ('mcf', float64[:, :, ::1]),\n",
    "    ('encoding_index', int32),\n",
    "    ('items', float64[:,::1]),\n",
    "    ('trial_count', int32),\n",
    "    ('context_input', float64[:,::1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loving-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "@jitclass(cmr_spec)\n",
    "class CMR:\n",
    "\n",
    "    def __init__(self, item_count, presentation_count, trial_count, \n",
    "                 encoding_drift_rate, start_drift_rate, recall_drift_rate, \n",
    "                 shared_support, item_support, learning_rate, primacy_scale, \n",
    "                 primacy_decay, stop_probability_scale, \n",
    "                 stop_probability_growth, choice_sensitivity):\n",
    "        \n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = encoding_drift_rate\n",
    "        self.start_drift_rate = start_drift_rate\n",
    "        self.recall_drift_rate = recall_drift_rate\n",
    "        self.shared_support = shared_support\n",
    "        self.item_support = item_support\n",
    "        self.learning_rate = learning_rate\n",
    "        self.primacy_scale = primacy_scale\n",
    "        self.primacy_decay = primacy_decay\n",
    "        self.stop_probability_scale = stop_probability_scale\n",
    "        self.stop_probability_growth = stop_probability_growth\n",
    "        self.choice_sensitivity = choice_sensitivity\n",
    "        \n",
    "        # at the start of the list context is initialized with a state \n",
    "        # orthogonal to the pre-experimental context associated with the items\n",
    "        self.context = np.zeros((trial_count, item_count+1))\n",
    "        self.context[:, 0] = 1\n",
    "        self.recall = np.zeros((trial_count, item_count), dtype='int32') # preallocation\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "        \n",
    "        # predefine primacy weighting vectors\n",
    "        self.primacy_weighting = primacy_scale * np.exp(\n",
    "            -primacy_decay * np.arange(presentation_count)) + 1\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((trial_count, item_count+1))\n",
    "        \n",
    "        # The two layers communicate with one another through two sets of \n",
    "        # associative connections represented by matrices Mfc and Mcf. Pre-\n",
    "        # experimental Mfc is 1-learning_rate and pre-experimental Mcf is \n",
    "        # item_support for i=j. For i!=j, Mcf is shared_support.\n",
    "        self.mfc = np.zeros((trial_count, item_count, item_count+1))\n",
    "        self.mfc[:,] = np.eye(item_count, item_count+1, 1) * (1-learning_rate)\n",
    "        self.mcf = np.zeros((trial_count, item_count+1, item_count))\n",
    "        self.mcf[:,] = np.ones((item_count+1, item_count)) * shared_support\n",
    "        for i in range(item_count):\n",
    "            self.mcf[:, i+1, i] = item_support\n",
    "        self.mcf[:,1,:] = 0\n",
    "        self.encoding_index = 0\n",
    "        self.items = np.eye(item_count, item_count)\n",
    "        self.trial_count = trial_count\n",
    "        self.context_input = np.zeros((trial_count, self.item_count+1))\n",
    "        \n",
    "    def experience(self, experiences):\n",
    "        \n",
    "        for i in range(len(experiences[0])):\n",
    "            self.update_context(self.encoding_drift_rate, experiences[:, i])\n",
    "            \n",
    "            for j in range(self.trial_count):\n",
    "                self.mfc[j] += self.learning_rate * np.outer(\n",
    "                    self.context[j], experiences[j, i]).T\n",
    "                self.mcf[j] += self.primacy_weighting[\n",
    "                    self.encoding_index] * np.outer(\n",
    "                    self.context[j], experiences[j, i])\n",
    "                \n",
    "            self.encoding_index += 1\n",
    "            \n",
    "    def update_context(self, drift_rate, experience=None):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        self.context_input[:] = 0\n",
    "        if experience is not None:\n",
    "            for i in range(self.trial_count):\n",
    "                self.context_input[i, :] = np.dot(experience[i], self.mfc[i])\n",
    "                self.context_input[i, :] = self.context_input[i, :] / np.sqrt(\n",
    "                    np.sum(np.square(self.context_input[i, :]))) # make len 1\n",
    "        else:\n",
    "            self.context_input[:, 0] = 1\n",
    "\n",
    "        # updated context is sum of context and input, modulated by rho to \n",
    "        # have len 1 and some drift_rate\n",
    "        rho = np.sqrt(1 + np.square(drift_rate) * (np.square(\n",
    "            self.context * self.context_input) - 1)) - (drift_rate * (\n",
    "            self.context * self.context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * self.context_input)\n",
    "        \n",
    "    def activations(self, probe, use_mfc=False):\n",
    "        \n",
    "        if use_mfc:\n",
    "            activation = np.zeros((self.trial_count, len(self.mfc[0, 0])))\n",
    "            for i in range(self.trial_count):\n",
    "                activation[i] = np.dot(probe[i], self.mfc[i]) + 10e-7\n",
    "        else:\n",
    "            activation = np.zeros((self.trial_count, len(self.mcf[0, 0])))\n",
    "            for i in range(self.trial_count):\n",
    "                activation[i] = np.dot(probe[i], self.mcf[i]) + 10e-7\n",
    "        return activation\n",
    "        \n",
    "    def outcome_probabilities(self, activation_cue):\n",
    "\n",
    "        activation = self.activations(activation_cue)\n",
    "        activation = np.power(activation, self.choice_sensitivity)\n",
    "\n",
    "        self.probabilities[:, 1:] = 0\n",
    "        self.probabilities[:, 0] = min(self.stop_probability_scale * np.exp(\n",
    "            self.recall_total * self.stop_probability_growth), 1.0  - (\n",
    "            self.item_count * 10e-7))\n",
    "        \n",
    "        # also set stop probability to 1 where recall has terminated\n",
    "        if self.recall_total > 0:\n",
    "            self.probabilities[self.recall[:, self.recall_total-1] == 0, 0] = 1\n",
    "        \n",
    "        # track for each trial whether recall termination is guaranteed or not\n",
    "        termination_not_guaranteed = self.probabilities[:, 0] < 1\n",
    "        \n",
    "        # suppress activation for already recalled items to 0\n",
    "        for trial_index in range(self.trial_count):\n",
    "            if termination_not_guaranteed[trial_index]:\n",
    "                for each in self.recall[trial_index, :self.recall_total]:\n",
    "                    activation[trial_index, each-1] = 0\n",
    "                self.probabilities[trial_index, 1:] = (\n",
    "                    1-self.probabilities[trial_index, 0]) * activation[trial_index] / np.sum(activation[trial_index])\n",
    "\n",
    "        return self.probabilities\n",
    "    \n",
    "    def force_recall(self, choice=None):\n",
    "        \n",
    "        if not self.retrieving:\n",
    "            self.update_context(self.start_drift_rate)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        else:\n",
    "            self.recall[:, self.recall_total] = choice\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "\n",
    "        return self.recall[:, :self.recall_total]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-association",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "polar-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "from numba.typed import List\n",
    "from numba.typed import List\n",
    "\n",
    "#@njit(fastmath=True, nogil=True)\n",
    "def cmr_murd_likelihood(\n",
    "    data_to_fit, item_counts, encoding_drift_rate, start_drift_rate, \n",
    "    recall_drift_rate, shared_support, item_support, learning_rate, \n",
    "    primacy_scale, primacy_decay, stop_probability_scale, \n",
    "    stop_probability_growth, choice_sensitivity):\n",
    "    \n",
    "    result = 0.0\n",
    "    for i in range(len(item_counts)):\n",
    "        item_count = item_counts[i]\n",
    "        trials = data_to_fit[i]\n",
    "        \n",
    "        model = CMR(item_count, item_count, len(trials), encoding_drift_rate, \n",
    "                    start_drift_rate, recall_drift_rate, shared_support,\n",
    "                    item_support, learning_rate, primacy_scale, \n",
    "                    primacy_decay, stop_probability_scale, \n",
    "                    stop_probability_growth, choice_sensitivity)\n",
    "\n",
    "        # same sequence of experiences across trials\n",
    "        experiences = np.zeros((len(trials), item_count, item_count))\n",
    "        experiences[:,] = np.eye(item_count, item_count)\n",
    "        model.experience(experiences)\n",
    "\n",
    "        likelihood = np.ones((len(trials), item_count), dtype='float64')\n",
    "\n",
    "        model.force_recall()\n",
    "        for recall_index in range(len(trials[0]) + 1):\n",
    "\n",
    "            # identify index of item recalled; if zero then recall is over\n",
    "            if recall_index == len(trials[0]) and len(trials[0]) < item_count:\n",
    "                recall = np.zeros(len(trials), dtype='int64')\n",
    "            else:\n",
    "                recall = trials[:, recall_index]\n",
    "\n",
    "            # store probability of and simulate recalling item with this index\n",
    "            probs = model.outcome_probabilities(model.context)\n",
    "            for j in range(len(trials)):\n",
    "                likelihood[j, recall_index] = probs[j, recall]\n",
    "\n",
    "            if np.all(recall == 0):\n",
    "                break\n",
    "            model.force_recall(recall)\n",
    "        \n",
    "        result -= np.sum(np.log(likelihood))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "specialized-soldier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 (1200, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>item</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>study</th>\n",
       "      <th>recall</th>\n",
       "      <th>repeat</th>\n",
       "      <th>intrusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  list  item  input  output  study  recall  repeat  intrusion\n",
       "0        1     1     1      1     5.0   True    True       0      False\n",
       "1        1     1     2      2     7.0   True    True       0      False\n",
       "2        1     1     3      3     NaN   True   False       0      False\n",
       "3        1     1     4      4     NaN   True   False       0      False\n",
       "4        1     1     5      5     NaN   True   False       0      False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from instance_cmr.datasets import *\n",
    "\n",
    "murd_trials0, murd_events0, murd_length0 = prepare_murddata(\n",
    "    '../data/MurdData_clean.mat', 0)\n",
    "print(murd_length0, np.shape(murd_trials0))\n",
    "\n",
    "murd_events0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "nonprofit-chaos",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-fe6c54fbba2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;34m'choice_sensitivity'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m }\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mcmr_murd_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmurd_trials0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhand_fit_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-7f46747d6715>\u001b[0m in \u001b[0;36mcmr_murd_likelihood\u001b[1;34m(data_to_fit, item_counts, encoding_drift_rate, start_drift_rate, recall_drift_rate, shared_support, item_support, learning_rate, primacy_scale, primacy_decay, stop_probability_scale, stop_probability_growth, choice_sensitivity)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutcome_probabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0mlikelihood\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "lb = np.finfo(float).eps\n",
    "hand_fit_parameters = {\n",
    "    'item_counts': List([murd_length0]),\n",
    "    'encoding_drift_rate': .8,\n",
    "    'start_drift_rate': .7,\n",
    "    'recall_drift_rate': .8,\n",
    "    'shared_support': 0.01,\n",
    "    'item_support': 1.0,\n",
    "    'learning_rate': .3,\n",
    "    'primacy_scale': 1,\n",
    "    'primacy_decay': 1,\n",
    "    'stop_probability_scale': 0.01,\n",
    "    'stop_probability_growth': 0.3,\n",
    "    'choice_sensitivity': 2\n",
    "}\n",
    "cmr_murd_likelihood(List([murd_trials0[:80]]), **hand_fit_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blessed-preparation",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5f29a215b4d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cmr_murd_likelihood(List([murd_trials0[:80]]), **hand_fit_parameters)\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2397\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2398\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2399\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2400\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-54>\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1167\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                 \u001b[0mtime_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-ca5b880243c1>\u001b[0m in \u001b[0;36mcmr_murd_likelihood\u001b[1;34m(data_to_fit, item_counts, encoding_drift_rate, start_drift_rate, recall_drift_rate, shared_support, item_support, learning_rate, primacy_scale, primacy_decay, stop_probability_scale, stop_probability_growth, choice_sensitivity)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutcome_probabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0mlikelihood\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cmr_murd_likelihood(List([murd_trials0[:80]]), **hand_fit_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-brand",
   "metadata": {},
   "source": [
    "## Dot Product Explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "remarkable-pollution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10, 11],\n",
       "       [12, 13, 14, 15, 16, 17],\n",
       "       [18, 19, 20, 21, 22, 23],\n",
       "       [24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35],\n",
       "       [36, 37, 38, 39, 40, 41],\n",
       "       [42, 43, 44, 45, 46, 47]])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(48).reshape(8, 6)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "premier-trading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  2,  3,  4,  5],\n",
       "       [ 0,  2,  4,  6,  8, 10],\n",
       "       [ 0,  3,  6,  9, 12, 15],\n",
       "       [ 0,  4,  8, 12, 16, 20],\n",
       "       [ 0,  5, 10, 15, 20, 25]])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.outer(a[0], a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "cordless-trace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  2,  3,  4,  5],\n",
       "       [ 0,  2,  4,  6,  8, 10],\n",
       "       [ 0,  3,  6,  9, 12, 15],\n",
       "       [ 0,  4,  8, 12, 16, 20],\n",
       "       [ 0,  5, 10, 15, 20, 25]])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(np.outer(a, a)))\n",
    "np.outer(a, a)[0:6,0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "suburban-davis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.outer(a, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "dress-petersburg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6],\n",
       "       [ 7,  8,  9, 10, 11, 12, 13],\n",
       "       [14, 15, 16, 17, 18, 19, 20],\n",
       "       [21, 22, 23, 24, 25, 26, 27],\n",
       "       [28, 29, 30, 31, 32, 33, 34],\n",
       "       [35, 36, 37, 38, 39, 40, 41]])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(336).reshape((8, 6, 7))\n",
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "deluxe-techno",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n",
      "[49 50 51 52 53 54 55]\n",
      "[ 98  99 100 101 102 103 104]\n",
      "[147 148 149 150 151 152 153]\n",
      "[196 197 198 199 200 201 202]\n",
      "[245 246 247 248 249 250 251]\n",
      "[0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(a[i] @ b[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "hollow-rwanda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3,   4,   5,   6],\n",
       "       [ 49,  50,  51,  52,  53,  54,  55],\n",
       "       [ 98,  99, 100, 101, 102, 103, 104],\n",
       "       [147, 148, 149, 150, 151, 152, 153],\n",
       "       [196, 197, 198, 199, 200, 201, 202],\n",
       "       [245, 246, 247, 248, 249, 250, 251],\n",
       "       [  0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(np.dot(a, b)))\n",
    "result = np.dot(a, b)\n",
    "\n",
    "result[np.eye(8, dtype='bool')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "correct-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(8, dtype='bool')[0] +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "above-suspension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    1,    4,    9,   16,   25,   36,   49],\n",
       "       [  64,   81,  100,  121,  144,  169,  196,  225],\n",
       "       [ 256,  289,  324,  361,  400,  441,  484,  529],\n",
       "       [ 576,  625,  676,  729,  784,  841,  900,  961],\n",
       "       [1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521],\n",
       "       [1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209]])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(48).reshape(6, 8) * np.arange(48).reshape(6, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "fifth-andrews",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  4,  9, 16, 25, 36, 49], dtype=int32)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(48).reshape(6, 8)[0] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-overview",
   "metadata": {},
   "source": [
    "## Development Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-textbook",
   "metadata": {},
   "source": [
    "During initialization, the main change is just setting `trial_count` as the first dimension of whatever was previously a vector or 2D array.\n",
    "\n",
    "`self.primacy_weighting` seems to be an exception; this changes if we decide the model should be able to accept vectors of parameter values to vary across trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "governmental-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_count = 100\n",
    "item_count = 20\n",
    "learning_rate = .8\n",
    "shared_support = .02\n",
    "item_support = .7\n",
    "\n",
    "context = np.zeros((trial_count, item_count + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "manual-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "context[:, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "radio-skating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-jewel",
   "metadata": {},
   "source": [
    "As for Mfc and Mcf, `np.eye` doesn't support higher than two dimensions. I have limited options for repeating the operation over a dimension, too, thanks to numba limitations. Maybe the approach is to stay with a zero array with the right size, and assign the eye array across trials simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "certain-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfc = np.zeros((trial_count, item_count, item_count + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "russian-regular",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfc[:,] = np.eye(item_count, item_count+1, 1) * (1 - learning_rate)\n",
    "np.all(mfc[1] == np.eye(item_count, item_count+1, 1) * (1 - learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "viral-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcf = np.zeros((trial_count, item_count, item_count))\n",
    "mcf[:, ] = np.ones((item_count, item_count)) * shared_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "parliamentary-novel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.38 µs ± 131 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for i in range(item_count):\n",
    "    mcf[:, i, i] = shared_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "intended-workstation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.63 µs ± 263 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ref = np.eye(item_count) * shared_support\n",
    "mcf[:, ] = ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "reasonable-wrong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [1, 3]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((np.array([1, 2]), np.array([1, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfc = np.zeros((trial_count, item_count, item_count + 1))\n",
    "mfc[:,] = np.eye(item_count, item_count+1, 1) * (1 - learning_rate)\n",
    "mcf = np.zeros((trial_count, item_count+1, item_count))\n",
    "mcf[:,] = np.ones((item_count+1, item_count)) * shared_support\n",
    "for i in range(item_count):\n",
    "    mcf[:, i+1, i] = item_support\n",
    "mcf[:,0,:] = 0\n",
    "\n",
    "mcf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "numerical-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'item_count': 20,\n",
    "    'presentation_count': 20,\n",
    "    'trial_count': 100,\n",
    "    'encoding_drift_rate': .8,\n",
    "    'start_drift_rate': .7,\n",
    "    'recall_drift_rate': .8,\n",
    "    'shared_support': 0.01,\n",
    "    'item_support': 1.0,\n",
    "    'learning_rate': .3,\n",
    "    'primacy_scale': 1,\n",
    "    'primacy_decay': 1,\n",
    "    'stop_probability_scale': 0.01,\n",
    "    'stop_probability_growth': 0.3,\n",
    "    'choice_sensitivity': 2\n",
    "}\n",
    "\n",
    "model = CMR(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "tracked-carolina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.7, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0.7, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0.7, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.7, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0.7, 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0.7, 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.7, 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.7, 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.7, 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.7, 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.7, 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.7,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0.7, 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0.7, 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0.7, 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0.7, 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0.7, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0.7, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0.7, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.7]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mfc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-accreditation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
