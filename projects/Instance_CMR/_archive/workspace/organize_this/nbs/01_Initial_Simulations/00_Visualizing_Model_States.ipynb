{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp model_analysis\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-audit",
   "metadata": {},
   "source": [
    "# Visualizing Model States"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-placement",
   "metadata": {},
   "source": [
    "We often simulate a simple free recall experiment and visualize model states throughout to explore their capacity to\n",
    "exhibit classical patterns of primacy, recency, and temporal contiguity. Any arbitrary configuration of parameters can\n",
    "be specified for the model, including an `experiment_count`, determining the number of simulations with the given\n",
    "parameters.\n",
    "\n",
    "In each experiment:\n",
    "1. A specified number of unique items are each experienced once,\n",
    "2. Context is momentarily drifted toward its pre-experimental state, and\n",
    "3. The model freely recalls items until it stops, with retrieval of previously experienced items disallowed.\n",
    "\n",
    "To visualize model state, we add to our `model_analysis` submodule three basic categories of visualizations. To\n",
    "visualize model state throughout encoding, we track the state of `context` and the amount of `support` for recall of\n",
    "each item based on contextual state. We also prepare a visualization of the final state of `memory` once encoding is\n",
    "finished. To visualize model state throughout retrieval, we similarly track `context` and `support` at each step of\n",
    "recall. An additional visualization makes clearer the distribution of outcome probabilities at a particular index of\n",
    "recall (e.g. after a second item has been recalled). While the previous sets of analyses focus on behavior of a\n",
    "particular instantiation of the model, a final set of analysis focuses on model behavior across many simulations. We\n",
    "track recall probability as a function of serial position, probability of starting recall with each serial position,\n",
    "and conditional response probability as a function of lag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-flood",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "First we create simulations and visualizations to track model state throughout encoding of new memories. To do this,\n",
    "we produce two parallel functions, `encoding_states` and `plot_states` that collect and visualize encoding states,\n",
    "respectively. An additional wrapper function called `encoding_visualizations` plots these states in addition to the\n",
    "final overall state of model memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "#export\n",
    "import numpy as np\n",
    "\n",
    "def encoding_states(model):\n",
    "    \"\"\"\n",
    "    Tracks state of context, and item supports across encoding. Model is also advanced to a state of fully encoded\n",
    "    memories.\n",
    "\n",
    "    **Required model attributes**:  \n",
    "    - item_count: specifies number of items encoded into memory  \n",
    "    - context: vector representing an internal contextual state  \n",
    "    - experience: adding a new trace to the memory model  \n",
    "    - activations: function returning item activations given a vector probe  \n",
    "    - outcome_probabilities: function returning item supports given a set of activations\n",
    "\n",
    "    **Returns** array representations of context and support for retrieval of each item at each increment of item\n",
    "    encoding. Each has shape model.item_count by model.item_count + 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    experiences = np.eye(model.item_count, model.item_count + 1, 1)\n",
    "    cmr_experiences = np.eye(model.item_count, model.item_count)\n",
    "    encoding_contexts, encoding_supports = model.context, []\n",
    "\n",
    "    # track model state across experiences\n",
    "    for i in range(len(experiences)):\n",
    "        try:\n",
    "            model.experience(experiences[i].reshape((1, -1)))\n",
    "        except ValueError:\n",
    "            # special case for CMR\n",
    "            model.experience(cmr_experiences[i].reshape((1, -1)))\n",
    "\n",
    "        # track model contexts and item supports\n",
    "        encoding_contexts = np.vstack((encoding_contexts, model.context))\n",
    "\n",
    "        if model.__class__.__name__ == 'CMR':\n",
    "            activation_cue = lambda model: model.context\n",
    "        else:\n",
    "            activation_cue = lambda model: np.hstack((np.zeros(model.item_count + 1), model.context))\n",
    "\n",
    "        if len(encoding_supports) > 0:\n",
    "            encoding_supports = np.vstack((encoding_supports, model.outcome_probabilities(activation_cue(model))))\n",
    "        else:\n",
    "            encoding_supports = model.outcome_probabilities(activation_cue(model))\n",
    "    \n",
    "    return encoding_contexts, encoding_supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(encoding_states, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# export \n",
    "# collapse_input\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_states(matrix, title, figsize=(15, 15), savefig=False):\n",
    "    \"\"\"\n",
    "    Plots an array of model states as a value-annotated heatmap with an arbitrary title.\n",
    "\n",
    "    **Arguments**:  \n",
    "    - matrix: an array of model states, ideally with columns representing unique feature indices and rows\n",
    "        representing unique update indices  \n",
    "    - title: a title for the generated plot, ideally conveying what array values represent at each entry  \n",
    "    - savefig: boolean deciding whether generated figure is saved (True if Yes)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(matrix, annot=True, linewidths=.5)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Update Index')\n",
    "    if savefig:\n",
    "        plt.savefig('figures/{}.jpeg'.format(title).replace(' ', '_').lower(), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(plot_states, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# export\n",
    "def encoding_visualizations(model, savefig=True):\n",
    "    \"\"\"\n",
    "    Plots encoding contexts, encoding supports as heatmaps.\n",
    "\n",
    "    **Required model attributes**:  \n",
    "    - item_count: specifies number of items encoded into memory  \n",
    "    - context: vector representing an internal contextual state  \n",
    "    - experience: adding a new trace to the memory model  \n",
    "    - activations: function returning item activations given a vector probe  \n",
    "    - outcome_probabilities: function returning item supports given a set of activations\n",
    "    - memory: a unitary representation of the current state of memory\n",
    "\n",
    "    **Also** requires savefig:  boolean deciding if generated figure is saved\n",
    "    \"\"\"\n",
    "    \n",
    "    encoding_contexts, encoding_supports = encoding_states(model)\n",
    "    plot_states(encoding_contexts, 'Encoding Contexts', savefig=savefig)\n",
    "    plot_states(encoding_supports, 'Supports For Each Item At Each Increment of Encoding', savefig=savefig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(encoding_visualizations, title_level=3)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-plenty",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-baking",
   "metadata": {},
   "source": [
    "#### ICMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instance_cmr.models import InstanceCMR\n",
    "\n",
    "parameters = {\n",
    "    'item_count': 20,\n",
    "    'encoding_drift_rate': .8,\n",
    "    'start_drift_rate': .7,\n",
    "    'recall_drift_rate': .8,\n",
    "    'shared_support': 0.01,\n",
    "    'item_support': 1.0,\n",
    "    'learning_rate': .3,\n",
    "    'primacy_scale': 1,\n",
    "    'primacy_decay': 1,\n",
    "    'stop_probability_scale': 0.01,\n",
    "    'stop_probability_growth': 0.3,\n",
    "    'choice_sensitivity': 2\n",
    "}\n",
    "\n",
    "model = InstanceCMR(**parameters)\n",
    "encoding_visualizations(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-riverside",
   "metadata": {},
   "source": [
    "![](figures/icmr_encoding_contexts.jpeg)\n",
    "![](figures/icmr_supports_for_each_item_at_each_increment_of_encoding.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-magnet",
   "metadata": {},
   "source": [
    "#### CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instance_cmr.models import CMR\n",
    "\n",
    "parameters = {\n",
    "    'item_count': 20,\n",
    "    'encoding_drift_rate': .8,\n",
    "    'start_drift_rate': .7,\n",
    "    'recall_drift_rate': .8,\n",
    "    'shared_support': 0.01,\n",
    "    'item_support': 1.0,\n",
    "    'learning_rate': .3,\n",
    "    'primacy_scale': 1,\n",
    "    'primacy_decay': 1,\n",
    "    'stop_probability_scale': 0.01,\n",
    "    'stop_probability_growth': 0.3,\n",
    "    'choice_sensitivity': 2\n",
    "}\n",
    "\n",
    "model = CMR(**parameters)\n",
    "encoding_visualizations(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-binding",
   "metadata": {},
   "source": [
    "![](figures/cmr_encoding_contexts.jpeg)\n",
    "![](figures/cmr_supports_for_each_item_at_each_increment_of_encoding.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-pakistan",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "Tracking model state across each step of retrieval. Since it's stochastic, these values change with each\n",
    "random seed. An additional optional parameter `first_recall_item` can control which item is recalled first by\n",
    "the model (`0` denotes termination of recall while actual items are 1-indexed); it is useful for testing\n",
    "hypotheses about model dynamics during recall. We leave the parameter set at `None`, for now, indicating no\n",
    "controlled first recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "#collapse_input\n",
    "import numpy as np\n",
    "\n",
    "def retrieval_states(model, first_recall_item=None):\n",
    "    \"\"\"\n",
    "    Tracks state of context, and item supports across retrieval. Model is also advanced into a state of\n",
    "    completed free recall.\n",
    "\n",
    "    **Required model attributes**:\n",
    "    - item_count: specifies number of items encoded into memory\n",
    "    - context: vector representing an internal contextual state\n",
    "    - experience: adding a new trace to the memory model\n",
    "    - activations: function returning item activations given a vector probe\n",
    "    - outcome_probabilities: function returning item supports given a set of activations\n",
    "    - free_recall: function that freely recalls a given number of items or until recall stops\n",
    "    - state: indicates whether model is encoding or engaged in recall with a string\n",
    "\n",
    "    **Also** optionally uses first_recall_item: can specify an item for first recall\n",
    "\n",
    "    **Returns** array representations of context and support for retrieval of each item at each increment of item\n",
    "    retrieval. Also returns recall train associated with simulation.\n",
    "    \"\"\"\n",
    "\n",
    "    if model.__class__.__name__ == 'CMR':\n",
    "        activation_cue = lambda model: model.context\n",
    "    else:\n",
    "        activation_cue = lambda model: np.hstack((np.zeros(model.item_count + 1), model.context))\n",
    "\n",
    "    # encoding items, presuming model is freshly initialized\n",
    "    encoding_states(model)\n",
    "    retrieval_contexts, retrieval_supports = model.context, model.outcome_probabilities(activation_cue(model))\n",
    "\n",
    "    # pre-retrieval distraction\n",
    "    model.free_recall(0)\n",
    "    retrieval_contexts = np.vstack((retrieval_contexts, model.context))\n",
    "    retrieval_supports = np.vstack((retrieval_supports, model.outcome_probabilities(activation_cue(model))))\n",
    "\n",
    "    # optional forced first item recall\n",
    "    if first_recall_item is not None:\n",
    "        model.force_recall(first_recall_item)\n",
    "        retrieval_contexts = np.vstack((retrieval_contexts, model.context))\n",
    "        retrieval_supports = np.vstack((retrieval_supports, model.outcome_probabilities(activation_cue(model))))\n",
    "\n",
    "    # actual recall\n",
    "    while model.retrieving:\n",
    "        model.free_recall(1)\n",
    "        retrieval_contexts = np.vstack((retrieval_contexts, model.context))\n",
    "        retrieval_supports = np.vstack((retrieval_supports, model.outcome_probabilities(activation_cue(model))))\n",
    "\n",
    "    return retrieval_contexts, retrieval_supports, model.recall[:model.recall_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(retrieval_states, title_level=3)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#collapse_input\n",
    "def outcome_probs_at_index(model, support_index_to_plot=1, savefig=True):\n",
    "    \"\"\"\n",
    "    Plots outcome probability distribution at a specific index of free recall.\n",
    "\n",
    "    **Required model attributes**:\n",
    "    - item_count: specifies number of items encoded into memory  \n",
    "    - context: vector representing an internal contextual state  \n",
    "    - experience: adding a new trace to the memory model  \n",
    "    - activations: function returning item activations given a vector probe  \n",
    "    - outcome_probabilities: function returning item supports given a set of activations  \n",
    "    - free_recall: function that freely recalls a given number of items or until recall stops  \n",
    "    - state: indicates whether model is encoding or engaged in recall with a string\n",
    "\n",
    "    **Other arguments**:  \n",
    "    - support_index_to_plot: index of retrieval to plot  \n",
    "    - savefig: whether to save or display the figure of interest\n",
    "\n",
    "    **Generates** a plot of outcome probabilities as a line graph. Also returns vector representation of the\n",
    "    generated probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    retrieval_supports = retrieval_states(model)[1]\n",
    "    plt.plot(np.arange(model.item_count + 1), retrieval_supports[support_index_to_plot])\n",
    "    plt.xlabel('Choice Index')\n",
    "    plt.ylabel('Outcome Probability')\n",
    "    plt.title('Outcome Probabilities At Recall Index {}'.format(support_index_to_plot))\n",
    "    plt.show()\n",
    "    return retrieval_supports[support_index_to_plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(outcome_probs_at_index, title_level=3)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#collapse_input\n",
    "def retrieval_visualizations(model, savefig=True):\n",
    "    \"\"\"\n",
    "    Plots incremental retrieval contexts and supports, as heatmaps, and prints recalled items.\n",
    "\n",
    "    **Required model attributes**:\n",
    "    - item_count: specifies number of items encoded into memory\n",
    "    - context: vector representing an internal contextual state\n",
    "    - experience: adding a new trace to the memory model\n",
    "    - activations: function returning item activations given a vector probe\n",
    "    - outcome_probabilities: function returning item supports given a set of activations\n",
    "\n",
    "    **Also** uses savefig: boolean deciding whether figures are saved (True) or displayed\n",
    "    \"\"\"\n",
    "    \n",
    "    retrieval_contexts, retrieval_supports, recall = retrieval_states(model)\n",
    "    plot_states(retrieval_contexts, 'Retrieval Contexts', savefig=savefig)\n",
    "    plot_states(retrieval_supports, 'Supports For Each Item At Each Increment of Retrieval', \n",
    "                savefig=savefig)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(retrieval_visualizations, title_level=3)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-reflection",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-selection",
   "metadata": {},
   "source": [
    "#### ICMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InstanceCMR(**parameters)\n",
    "retrieval_visualizations(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-shield",
   "metadata": {},
   "source": [
    "Outputs can look like...\n",
    "\n",
    "![](figures/retrieval_contexts.jpeg)\n",
    "![](figures/supports_for_each_item_at_each_increment_of_retrieval.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-appliance",
   "metadata": {},
   "source": [
    "#### CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CMR(**parameters)\n",
    "retrieval_visualizations(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-dating",
   "metadata": {},
   "source": [
    "![](figures/retrieval_contexts.jpeg)\n",
    "![](figures/supports_for_each_item_at_each_increment_of_retrieval.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-serial",
   "metadata": {},
   "source": [
    "## Organizational Analyses\n",
    "Upon completion,  the `psifr` toolbox is used to generate three plots corresponding to the contents of Figure\n",
    "4 in Morton & Polyn, 2016:\n",
    "1. Recall probability as a function of serial position\n",
    "2. Probability of starting recall with each serial position\n",
    "3. Conditional response probability as a function of lag\n",
    "\n",
    "Whereas previous visualizations were based on an arbitrary model simulation, the current figures are based on\n",
    "averages over a simulation of the model some specified amount of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#collapse_input\n",
    "import pandas as pd\n",
    "from psifr import fr\n",
    "\n",
    "def temporal_organization_analyses(model, experiment_count, savefig=False, figsize=(15, 15), first_recall_item=None):\n",
    "    \"\"\"\n",
    "    Visualization of the outcomes of a trio of organizational analyses of model performance on a free recall\n",
    "    task.\n",
    "\n",
    "    **Required model attributes**:\n",
    "    - item_count: specifies number of items encoded into memory  \n",
    "    - context: vector representing an internal contextual state  \n",
    "    - experience: adding a new trace to the memory model  \n",
    "    - free_recall: function that freely recalls a given number of items or until recall stops  \n",
    "\n",
    "    **Other arguments**:  \n",
    "    - experiment_count: number of simulations to compute curves over  \n",
    "    - savefig: whether to save or display the figure of interest\n",
    "\n",
    "    **Returns** three plots corresponding to the contents of Figure 4 in Morton & Polyn, 2016:  \n",
    "    1. Recall probability as a function of serial position  \n",
    "    2. Probability of starting recall with each serial position  \n",
    "    3. Conditional response probability as a function of lag  \n",
    "    \"\"\"\n",
    "    \n",
    "    # encode items\n",
    "    try:\n",
    "        model.experience(np.eye(model.item_count, model.item_count + 1, 1))\n",
    "    except ValueError:\n",
    "        # so we can apply to CMR\n",
    "        model.experience(np.eye(model.item_count, model.item_count))\n",
    "    \n",
    "    # simulate retrieval for the specified number of times, tracking results in df\n",
    "    data = []\n",
    "    for experiment in range(experiment_count):\n",
    "        data += [[experiment, 0, 'study', i + 1, i] for i in range(model.item_count)]\n",
    "    for experiment in range(experiment_count):\n",
    "        if first_recall_item is not None:\n",
    "            model.force_recall(first_recall_item)\n",
    "        data += [[experiment, 0, 'recall', i + 1, o] for i, o in enumerate(model.free_recall())]\n",
    "    data = pd.DataFrame(data, columns=['subject', 'list', 'trial_type', 'position', 'item'])\n",
    "    merged = fr.merge_free_recall(data)\n",
    "    \n",
    "    # visualizations\n",
    "    # spc\n",
    "    recall = fr.spc(merged)\n",
    "    g = fr.plot_spc(recall)\n",
    "    plt.title('Serial Position Curve')\n",
    "    if savefig:\n",
    "        plt.savefig('figures/spc.jpeg', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    # P(Start Recall) For Each Serial Position\n",
    "    prob = fr.pnr(merged)\n",
    "    pfr = prob.query('output <= 1')\n",
    "    g = fr.plot_spc(pfr).add_legend()\n",
    "    plt.title('Probability of Starting Recall With Each Serial Position')\n",
    "    if savefig:\n",
    "        plt.savefig('figures/pfr.jpeg', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    # Conditional response probability as a function of lag\n",
    "    crp = fr.lag_crp(merged)\n",
    "    g = fr.plot_lag_crp(crp)\n",
    "    plt.title('Conditional Response Probability')\n",
    "    if savefig:\n",
    "        plt.savefig('figures/crp.jpeg', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(temporal_organization_analyses, title_level=3)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-million",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instance_cmr.models import InstanceCMR\n",
    "\n",
    "model = InstanceCMR(**parameters)\n",
    "temporal_organization_analyses(model, 100, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-socket",
   "metadata": {},
   "source": [
    "![](figures/spc.jpeg)\n",
    "\n",
    "![](figures/pfr.jpeg)\n",
    "\n",
    "![](figures/crp.jpeg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
