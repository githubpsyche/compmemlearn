{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp models\n",
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-criticism",
   "metadata": {},
   "source": [
    "# InstanceCMR\n",
    "> Context Maintenance and Retrieval within an Instance-Based Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-method",
   "metadata": {},
   "source": [
    "| Structure Type        | Symbol            | Name                    | Description                                                 |\n",
    "|:----------------------|:------------------|:------------------------|:------------------------------------------------------------|\n",
    "| Architecture          |                   |                         |                                                             |\n",
    "|                       | $M$               | memory                  | Array of accumulated memory traces                          |\n",
    "|                       | $C$               | temporal context        | A recency-weighted average of encoded items                 |\n",
    "|                       | $F$               | item features           | Current pattern of item feature unit activations            |\n",
    "| Context Updating      |                   |                         |                                                             |\n",
    "|                       | ${\\beta}_{enc}$   | encoding drift rate     | Rate of context drift during item encoding                  |\n",
    "|                       | ${\\beta}_{start}$ | start drift rate        | Amount of start-list context retrieved at start of recall   |\n",
    "|                       | ${\\beta}_{rec}$   | recall drift rate       | Rate of context drift during recall                         |\n",
    "| Associative Structure |                   |                         |                                                             |\n",
    "|                       | ${\\alpha}$        | shared support          | Amount of support items initially have for one another      |\n",
    "|                       | ${\\delta}$        | item support            | Initial pre-experimental contextual self-associations       |\n",
    "|                       | ${\\gamma}$        | learning rate           | Amount of experimental context retrieved by a recalled item |\n",
    "|                       | ${\\phi}_{s}$      | primacy scale           | Scaling of primacy gradient on trace activations            |\n",
    "|                       | ${\\phi}_{d}$      | primacy decay           | Rate of decay of primacy gradient                           |\n",
    "| Retrieval Dynamics    |                   |                         |                                                             |\n",
    "|                       | ${\\tau}$          | choice sensitivity      | Exponential weighting of similarity-driven activation       |\n",
    "|                       | ${\\theta}_{s}$    | stop probability scale  | Scaling of the stop probability over output position        |\n",
    "|                       | ${\\theta}_{r}$    | stop probability growth | Rate of increase in stop probability over output position   |\n",
    "|                       |                   |                         |                                                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from numba import float64, int32, boolean\n",
    "from numba.experimental import jitclass\n",
    "\n",
    "spec = [\n",
    "    ('item_count', int32), \n",
    "    ('encoding_drift_rate', float64),\n",
    "    ('start_drift_rate', float64),\n",
    "    ('recall_drift_rate', float64),\n",
    "    ('shared_support', float64),\n",
    "    ('item_support', float64),\n",
    "    ('learning_rate', float64),\n",
    "    ('primacy_scale', float64),\n",
    "    ('primacy_decay', float64),\n",
    "    ('stop_probability_scale', float64),\n",
    "    ('stop_probability_growth', float64),\n",
    "    ('choice_sensitivity', float64),\n",
    "    ('context_sensitivity', float64),\n",
    "    ('feature_sensitivity', float64),\n",
    "    ('context', float64[::1]),\n",
    "    ('preretrieval_context', float64[::1]),\n",
    "    ('recall', float64[::1]),\n",
    "    ('retrieving', boolean),\n",
    "    ('recall_total', int32),\n",
    "    ('item_weighting', float64[::1]),\n",
    "    ('context_weighting', float64[::1]),\n",
    "    ('all_weighting', float64[::1]),\n",
    "    ('probabilities', float64[::1]),\n",
    "    ('memory', float64[:,::1]),\n",
    "    ('encoding_index', int32),\n",
    "    ('items', float64[:,::1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "\n",
    "@jitclass(spec)\n",
    "class InstanceCMR:\n",
    "\n",
    "    def __init__(\n",
    "        self, item_count, presentation_count, encoding_drift_rate, \n",
    "        start_drift_rate, recall_drift_rate, shared_support,\n",
    "        item_support, learning_rate, primacy_scale, primacy_decay, \n",
    "        stop_probability_scale, stop_probability_growth, choice_sensitivity, \n",
    "        context_sensitivity, feature_sensitivity):\n",
    "\n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = encoding_drift_rate\n",
    "        self.start_drift_rate = start_drift_rate\n",
    "        self.recall_drift_rate = recall_drift_rate\n",
    "        self.shared_support = shared_support\n",
    "        self.item_support = item_support\n",
    "        self.learning_rate = learning_rate\n",
    "        self.primacy_scale = primacy_scale\n",
    "        self.primacy_decay = primacy_decay\n",
    "        self.stop_probability_scale = stop_probability_scale\n",
    "        self.stop_probability_growth = stop_probability_growth\n",
    "        self.choice_sensitivity = choice_sensitivity\n",
    "        self.context_sensitivity = context_sensitivity\n",
    "        self.feature_sensitivity = feature_sensitivity\n",
    "        \n",
    "        # at the start of the list context is initialized with a state \n",
    "        # orthogonal to the pre-experimental context associated with the set of items\n",
    "        self.context = np.zeros(item_count + 1)\n",
    "        self.context[0] = 1\n",
    "        self.preretrieval_context = self.context\n",
    "        self.recall = np.zeros(item_count) # recalls has at most `item_count` entries\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "\n",
    "        # predefine activation weighting vectors\n",
    "        self.item_weighting = np.ones(item_count+presentation_count)\n",
    "        self.context_weighting = np.ones(item_count+presentation_count)\n",
    "        self.item_weighting[item_count:] = learning_rate\n",
    "        self.context_weighting[item_count:] = \\\n",
    "            primacy_scale * np.exp(-primacy_decay * np.arange(presentation_count)) + 1\n",
    "        self.all_weighting = self.item_weighting * self.context_weighting\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((item_count + 1))\n",
    "\n",
    "        # initialize memory\n",
    "        # we now conceptualize it as a pairing of two stores Mfc and Mcf respectively\n",
    "        # representing feature-to-context and context-to-feature associations\n",
    "        mfc = np.eye(item_count, item_count + 1, 1) * (1 - learning_rate)\n",
    "        mcf = np.ones((item_count, item_count)) * shared_support\n",
    "        for i in range(item_count):\n",
    "            mcf[i, i] = item_support\n",
    "        mcf = np.hstack((np.zeros((item_count, 1)), mcf))\n",
    "        self.memory = np.zeros((item_count + presentation_count, item_count * 2 + 2))\n",
    "        self.memory[:item_count,] = np.hstack((mfc, mcf))\n",
    "        self.encoding_index = item_count\n",
    "        self.items = np.eye(item_count, item_count + 1, 1)\n",
    "\n",
    "    def experience(self, experiences):\n",
    "\n",
    "        for i in range(len(experiences)):\n",
    "            self.memory[self.encoding_index, :self.item_count+1] = experiences[i]\n",
    "            self.update_context(self.encoding_drift_rate, self.memory[self.encoding_index])\n",
    "            self.memory[self.encoding_index, self.item_count+1:] = self.context\n",
    "            self.encoding_index += 1\n",
    "\n",
    "    def update_context(self, drift_rate, experience=None):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if experience is not None:\n",
    "            context_input = self.echo(experience)[self.item_count + 1:]\n",
    "            context_input = context_input / np.sqrt(np.sum(np.square(context_input))) # norm to length 1\n",
    "        else:\n",
    "            context_input = np.zeros((self.item_count+1))\n",
    "            context_input[0] = 1\n",
    "\n",
    "        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)) - (\n",
    "                drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "\n",
    "    def echo(self, probe):\n",
    "\n",
    "        return np.dot(self.activations(probe), self.memory[:self.encoding_index])\n",
    "\n",
    "    def activations(self, probe):\n",
    "\n",
    "        # computes and cubes similarity value to find activation for each trace in memory\n",
    "        activation = np.dot(self.memory[:self.encoding_index], probe) / (\n",
    "            np.sqrt(np.sum(np.square(self.memory[:self.encoding_index]), axis=1)) * np.sqrt(\n",
    "                np.sum(np.square(probe))))\n",
    "\n",
    "        # weight activations based on whether probe contains item or contextual features or both\n",
    "        if np.any(probe[:self.item_count + 1]):\n",
    "            if np.any(probe[self.item_count + 1:]):\n",
    "                # both mfc and mcf weightings, see below\n",
    "                activation *= self.all_weighting[:self.encoding_index]\n",
    "            else:\n",
    "                # mfc weightings - scale by gamma for each experimental trace\n",
    "                activation *= self.item_weighting[:self.encoding_index]\n",
    "            activation = np.power(activation, self.context_sensitivity)\n",
    "        else:\n",
    "            # mcf weightings - scale by primacy/attention function based on experience position\n",
    "            activation *= self.context_weighting[:self.encoding_index]\n",
    "            if self.feature_sensitivity != 1.0:\n",
    "                activation = np.power(activation, self.feature_sensitivity)\n",
    "            else:\n",
    "                activation = np.power(activation, self.context_sensitivity)\n",
    "            \n",
    "        return activation + 10e-7\n",
    "\n",
    "    def outcome_probabilities(self, activation_cue):\n",
    "\n",
    "        echo = self.echo(activation_cue)[1:self.item_count+1]\n",
    "        echo = np.power(echo, self.choice_sensitivity)\n",
    "        \n",
    "        self.probabilities = np.zeros((self.item_count + 1))\n",
    "        self.probabilities[0] = min(self.stop_probability_scale * np.exp(\n",
    "            self.recall_total * self.stop_probability_growth), 1.0 - (self.item_count * 10e-7))\n",
    "\n",
    "        if self.probabilities[0] < 1:\n",
    "            for already_recalled_item in self.recall[:self.recall_total]:\n",
    "                echo[int(already_recalled_item)] = 0\n",
    "        self.probabilities[1:] = (1-self.probabilities[0]) * echo / np.sum(echo)\n",
    "        \n",
    "        return self.probabilities\n",
    "\n",
    "    def free_recall(self, steps=None):\n",
    "\n",
    "        # some pre-list context is reinstated before initiating recall\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.start_drift_rate)\n",
    "            self.retrieving = True\n",
    "            \n",
    "        # number of items to retrieve is infinite if steps is unspecified\n",
    "        if steps is None:\n",
    "            steps = self.item_count - self.recall_total\n",
    "        steps = self.recall_total + steps\n",
    "\n",
    "        # at each recall attempt\n",
    "        while self.recall_total < steps:\n",
    "\n",
    "            # the current state of context is used as a retrieval cue to \n",
    "            # attempt recall of a studied item compute outcome probabilities \n",
    "            # and make choice based on distribution\n",
    "            outcome_probabilities = self.outcome_probabilities(\n",
    "                np.hstack((np.zeros(self.item_count + 1), self.context)))\n",
    "            if np.any(outcome_probabilities[1:]):\n",
    "                choice = np.sum(\n",
    "                    np.cumsum(outcome_probabilities) < np.random.rand())\n",
    "            else:\n",
    "                choice = 0\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made (0)\n",
    "            if choice == 0:\n",
    "                self.retrieving = False\n",
    "                self.context = self.preretrieval_context\n",
    "                break\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate,\n",
    "                                np.hstack((self.items[choice - 1], \n",
    "                                           np.zeros(self.item_count + 1))))\n",
    "        return self.recall[:self.recall_total]\n",
    "    \n",
    "    def force_recall(self, choice=None):\n",
    "\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.start_drift_rate)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        elif choice > 0:\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(\n",
    "                self.recall_drift_rate, \n",
    "                np.hstack((self.items[choice - 1], \n",
    "                           np.zeros(self.item_count + 1))))\n",
    "        else:\n",
    "            self.retrieving = False\n",
    "            self.context = self.preretrieval_context\n",
    "        return self.recall[:self.recall_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(InstanceCMR, doc_string=False)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "political-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(InstanceCMR.__init__, doc_string=False)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "discrete-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(InstanceCMR.experience, doc_string=False)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stable-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(InstanceCMR.update_context, doc_string=False)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "excessive-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(InstanceCMR.activations, doc_string=False)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(InstanceCMR.echo, doc_string=False)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accredited-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(InstanceCMR.outcome_probabilities, doc_string=False)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "valuable-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(InstanceCMR.free_recall, doc_string=False)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caroline-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_doc(InstanceCMR.force_recall, doc_string=False)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-summary",
   "metadata": {},
   "source": [
    "We reserve exploration of model behavior to later project notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
