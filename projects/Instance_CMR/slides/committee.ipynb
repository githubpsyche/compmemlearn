{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"An Instance-Based Account of Context Maintenance and Retrieval\"\n",
    "author: \"Jordan Gunn\"\n",
    "format: revaljs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's At Stake When You Choose a Model Architecture?\n",
    "\n",
    "<!--\n",
    "\n",
    "\n",
    "Main ideas to highlight:\n",
    "- Question: What's at stake when you're choosing between instance- and prototype-based architectures to model how humans do memory search\n",
    "- To help find out, I developed an instance-based variant of an established prototype-based account of memory search called the context maintenance and retrieval model.\n",
    "-->\n",
    "\n",
    "What's at stake when you're choosing between instance- and prototype-based architectures to model how humans do memory search? To help find out, I developed an instance-based variant of an established prototype-based account of memory search called the context maintenance and retrieval model. I compared the variant and the original's capacity to account for human performance across various datasets using prediction-based model fitting and simulation of benchmark behavioral phenomena. Both variants performed similarly in my comparisons, demonstrating the architectural independence of the models' theoretical commitments and laying the groundwork for deeper integration between instance- and prototype-based modeling traditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory *associates* information based on a history of experiences\n",
    "\n",
    "<!--\n",
    "Slide visuals: \n",
    "- black box memory model\n",
    "\n",
    "Main ideas to highlight:\n",
    "- Memory *associates* information based on feature co-occurrence over a history of experiences\n",
    "- Can be modeled with instance- or prototype-based frameworks\n",
    "-->\n",
    "\n",
    "We can imagine memory as a system that associates cues with responses based on co-occurence of features over some history of experiences. Seeing a flower can remind you of details from other times you've seen that flower, such as in a vase or while walking outside. Being in this meeting might remind you of similar meetings you've had, and so on.\n",
    "\n",
    "In the cognitive modeling literature, research often distinguishes between two basic frameworks summarizing how human memory systems pull this off -- between **instance** and **prototype** theories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance-Based Models\n",
    "\n",
    "<!--\n",
    "Slide visuals: \n",
    "- Each piece of an instance-based model (traces, probe, activations, echo)\n",
    "- The nonlinear similarity equation!\n",
    "\n",
    "Main ideas to highlight:\n",
    "- Representation. Discrete traces stored for each experience.\n",
    "- Probe. An activation generated for each stored trace based on similarity to the reminder.\n",
    "- Echo. A blend of coactivated traces, weighted based on relevance to the probe.\n",
    "-->\n",
    "\n",
    "Instance-based accounts of memory conceptualize learning as growing a collection of distinct memory traces, each a record of a unique event or experience. A reminder retrieves associations by activating each stored instance in parallel based on similarity. Traces highly similar to your reminder are especially activated, while very *dis*similar traces see their activations suppressed, thereby prioritizing relevant information. The weighted sum of representations retrieved from all these traces shouting at the same time is an \"echo\" your memory system replies with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype-based models\n",
    "\n",
    "<!--\n",
    "Slide visuals: \n",
    "- Each piece of an instance-based model (traces, probe, activations, echo)\n",
    "\n",
    "Main ideas to highlight:\n",
    "- Representations progressively update to reflect prototypical features common across past experience\n",
    "- Example: weights in a simple neural network\n",
    "-->\n",
    "\n",
    "Rather than assuming we store each experience separately, prototype-based models assume experience updates memory representations to reflect prototypical features that are common across past experience. A simple and frequent example of what I'm talking about are the weights in linear associator network. In a linear associator, experiences activate units in an input layer to represent an array of features. These in turn pass activation to units in an output layer to form the memory system's responses - which we'll keep calling echoes for consistency. Weighted connections control the extent to which activation in an input unit drives activation in a given output unit, and get updated through some learning process with each new experience. For example, through the Hebbian learning rule, units that fire together, wire together, strengthening the connection between input and output units coactivated in a learning episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architectures Trade Between Compression and Flexibility\n",
    "\n",
    "<!--\n",
    "Slide visuals: \n",
    "- Jamieson et al example + Homonym\n",
    "- \n",
    "\n",
    "Main ideas to highlight:\n",
    "- Flexible retrieval. Discrete traces keeps it easy to contact individuals without interference.\n",
    "- Data Compression. Aggregated representations minimizes the costs of storage and retrieval.\n",
    "\n",
    "-->\n",
    "\n",
    "Both architectures have underpinned models accounting for diverse suite of behaviors ranging from performance on simple cued recall tasks to complex financial decision-making. However, some fundamental differences between the frameworks though have brought them into conflict. For example, instance-based models have faced criticism for their lack of data compression. The multitrace account implies that the number of traces can increase without bound, and that they are all contacted simultaneously, and both ideas are difficult to accept given the biological constraints that face cognition.\n",
    "\n",
    "Prototype-based models on the other hand have been criticized for collapsing the many contexts in which a item occurs to a single best-fitting representation. A comparison by Jamieson and colleages in 2018 compared the architectures' capacity to retrieve homonyms -- words that carry multiple meanings, like the way \"break\" can describe stopping a car, reporting a story in the news, or smashing a plate, depending on the context you use it in. They found that instance-based models can flexibly retrieve the rare senses of homonyms when paired with different disambiguating cues, but that prototype-based models struggled to suppress the words' dominant sense under parallel conditions. Since instance models alternatively store and can flexibly retrieve individual memory traces based on relevance to a probe, they've been compared favorably against prototype models in several domains, like in category learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Focus: Memory Search\n",
    "<!--\n",
    "Slide visuals: \n",
    "- Memory search schematic\n",
    "- Free recall task\n",
    "\n",
    "Main ideas to highlight:\n",
    "- Flexible retrieval. Discrete traces keeps it easy to contact individuals without interference.\n",
    "- Data Compression. Aggregated representations minimizes the costs of storage and retrieval.\n",
    "\n",
    "-->\n",
    "\n",
    "The significance of these differences have been examined in domains like semantic memory and category learning, but not our present focus -- memory SEARCH, the iterative process where you might remember a piece of information using a probe, and then use the retrieved information to *update* your probe your memory so you can access more information. \n",
    "\n",
    "Much of what we know about memory search is based on performance on the free recall task, where participants are presented a sequence of items (usually words) and then prompted to recall as many list items as possible in whatever order they want. \n",
    "\n",
    "Temporal contiguity effect\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "To account for phenomena like this temporal contiguity effect, the formal literature has largely converged on retrieved context theories of memory search that centers a evolving representation of temporal context as the dynamic probe driving the process. The contexts retrieved from encoding or retrieving items update the current state of context, while the current state in context in turn is used to probe memory. The association of temporal features with item features and the use of a recency-weighted contextual representation to drive recall helps account for memory phenomena like the temporal contiguity effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch\n",
    "\n",
    "You can think of memory as a system that associates information based on a history of experiences. Seeing a flower can remind you of details from other times you've seen it, such as in a vase or while walking outside. Similarly, being in this meeting might remind you of other meetings you've had, and so on. \n",
    "\n",
    "- Can think of memory as a system that *associates* information based on a history of experiences\n",
    "- Memory search iteratively updates probe based on retrieved information to retrieve even more\n",
    "- Memory search generally studied under free recall paradigm\n",
    "\n",
    "::: {.notes}\n",
    "Models of memory in cognitive science are often distinguished between instance- and prototype-based theories. \n",
    "\n",
    "Two basic architectures - called the instance- and prototype- theories - dominate the memory modeling literature, and for this project\n",
    "\n",
    "So for this project, I was interested in clearing up the relationship between instance- and prototype-based model \n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
