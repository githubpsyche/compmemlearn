{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe182068-7a11-4ad9-bf76-197303104d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abba0af-43f5-4278-ac78-a7d274a61fe5",
   "metadata": {},
   "source": [
    "## Context Maintenance and Retrieval within an Instance-Based Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e0bcb9-973d-4314-899d-98689d79a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "import numpy as np\n",
    "from numba import float64, int32, boolean\n",
    "from numba.experimental import jitclass\n",
    "from numba import njit\n",
    "from compmemlearn.models import icmr_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07889527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "@jitclass(icmr_spec)\n",
    "class Exp_ICMR:\n",
    "    \"InstanceCMR Except MFC Exponent-Based Activation Scaling Only Applied To Experimental Traces\"\n",
    "\n",
    "    def __init__(self, item_count, presentation_count, parameters):\n",
    "\n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = parameters['encoding_drift_rate']\n",
    "        self.delay_drift_rate = parameters['delay_drift_rate']\n",
    "        self.start_drift_rate = parameters['start_drift_rate']\n",
    "        self.recall_drift_rate = parameters['recall_drift_rate']\n",
    "        self.shared_support = parameters['shared_support']\n",
    "        self.item_support = parameters['item_support']\n",
    "        self.learning_rate = parameters['learning_rate']\n",
    "        self.primacy_scale = parameters['primacy_scale']\n",
    "        self.primacy_decay = parameters['primacy_decay']\n",
    "        self.stop_probability_scale = parameters['stop_probability_scale']\n",
    "        self.stop_probability_growth = parameters['stop_probability_growth']\n",
    "        self.choice_sensitivity = parameters['choice_sensitivity']\n",
    "        self.drift_familiarity_scale = parameters['drift_familiarity_scale']\n",
    "        self.mfc_familiarity_scale = parameters['mfc_familiarity_scale']\n",
    "        self.mcf_familiarity_scale = parameters['mcf_familiarity_scale']\n",
    "        self.context_sensitivity = parameters['context_sensitivity']\n",
    "        self.feature_sensitivity = parameters['feature_sensitivity']\n",
    "        \n",
    "        # at the start of the list context is initialized with a state \n",
    "        # orthogonal to the pre-experimental context associated with the set of items\n",
    "        self.context = np.zeros(item_count + 2)\n",
    "        self.context[0] = 1\n",
    "        self.preretrieval_context = self.context\n",
    "        self.recall = np.zeros(item_count, np.int32) # recalls has at most `item_count` entries\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "\n",
    "        # predefine activation weighting vectors\n",
    "        self.item_weighting = np.ones(item_count+presentation_count)\n",
    "        self.context_weighting = np.ones(item_count+presentation_count)\n",
    "        self.item_weighting[item_count:] = self.learning_rate\n",
    "        self.context_weighting[item_count:] = \\\n",
    "            self.primacy_scale * np.exp(-self.primacy_decay * np.arange(presentation_count)) + 1\n",
    "        self.all_weighting = self.item_weighting * self.context_weighting\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((item_count + 1))\n",
    "\n",
    "        # predefine contextual input vectors relevant for delay_drift_rate and start_drift_rate parameters\n",
    "        self.start_context_input = np.zeros((self.item_count+2))\n",
    "        self.start_context_input[0] = 1\n",
    "        self.delay_context_input = np.zeros((self.item_count+2))\n",
    "        self.delay_context_input[-1] = 1\n",
    "\n",
    "        # initialize memory\n",
    "        # we now conceptualize it as a pairing of two stores Mfc and Mcf respectively\n",
    "        # representing feature-to-context and context-to-feature associations\n",
    "        mfc = np.eye(item_count, item_count + 2, 1) * (1 - self.learning_rate)\n",
    "        mcf = np.ones((item_count, item_count)) * self.shared_support\n",
    "        for i in range(item_count):\n",
    "            mcf[i, i] = self.item_support\n",
    "        mcf = np.hstack((np.zeros((item_count, 1)), mcf,  np.zeros((item_count, 1))))\n",
    "        self.memory = np.zeros((item_count + presentation_count, item_count * 2 + 4))\n",
    "        self.memory[:item_count,] = np.hstack((mfc, mcf))\n",
    "\n",
    "        self.norm = np.zeros(item_count + presentation_count)\n",
    "        self.norm[:item_count] = np.sqrt(np.sum(np.square(self.memory[0])))\n",
    "        self.norm[item_count:] = np.sqrt(2)\n",
    "        self.encoding_index = item_count\n",
    "        self.items = np.hstack((np.eye(item_count, item_count + 2, 1), np.zeros((item_count, item_count+2))))\n",
    "\n",
    "    def experience(self, experiences):\n",
    "\n",
    "        for i in range(len(experiences)):\n",
    "\n",
    "            drift_rate = self.encoding_drift_rate\n",
    "            if ((np.dot(experiences[i], np.sum(self.memory[:self.encoding_index], axis=0)[:len(experiences[i])]) > 1)\n",
    "                and ((self.mfc_familiarity_scale != 0) or (self.mcf_familiarity_scale != 0) or (\n",
    "                    self.drift_familiarity_scale != 0))):\n",
    "            \n",
    "                self.context_weighting[self.encoding_index] *= 1-self.mcf_familiarity_scale\n",
    "                self.item_weighting[self.encoding_index] *= 1-self.mfc_familiarity_scale\n",
    "                #drift_rate *= 1-self.drift_familiarity_scale\n",
    "            \n",
    "            self.memory[self.encoding_index] = experiences[i]\n",
    "            self.update_context(drift_rate, self.memory[self.encoding_index])\n",
    "            self.memory[self.encoding_index, self.item_count+2:] = self.context\n",
    "            self.encoding_index += 1\n",
    "\n",
    "    def update_context(self, drift_rate, experience):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if len(experience) == self.item_count * 2 + 4:\n",
    "            context_input = self.echo(experience)[self.item_count + 2:]\n",
    "            context_input = context_input / np.sqrt(np.sum(np.square(context_input))) # norm to length 1\n",
    "\n",
    "            if not self.retrieving and (np.dot(experience, np.sum(self.memory[:self.encoding_index], axis=0)[:len(experience)]) > 1):\n",
    "                context_input = np.power(context_input, 1-self.drift_familiarity_scale)\n",
    "\n",
    "            context_input = context_input / np.sqrt(np.sum(np.square(context_input))) # norm to length 1\n",
    "\n",
    "        else:\n",
    "            context_input = experience\n",
    "\n",
    "        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)) - (\n",
    "                drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "        self.context = self.context / np.sqrt(np.sum(np.square(self.context)))\n",
    "\n",
    "    def echo(self, probe):\n",
    "\n",
    "        return np.dot(self.activations(probe), self.memory[:self.encoding_index])\n",
    "\n",
    "    def activations(self, probe, probe_norm=1.0):\n",
    "\n",
    "        activation = np.dot(self.memory[:self.encoding_index], probe) / (\n",
    "             self.norm[:self.encoding_index] * probe_norm)\n",
    "\n",
    "        # weight activations based on whether probe contains item or contextual features or both\n",
    "        if np.any(probe[:self.item_count + 2]): # if probe is an item feature cue as during contextual retrieval\n",
    "            if np.any(probe[self.item_count + 2:]): # if probe is (also) a contextual cue as during item retrieval\n",
    "                # both mfc and mcf weightings, see below\n",
    "                activation *= self.all_weighting[:self.encoding_index]\n",
    "            else:\n",
    "                # mfc weightings - scale by gamma for each experimental trace\n",
    "                activation *= self.item_weighting[:self.encoding_index]\n",
    "            activation[self.item_count:] = np.power(activation[self.item_count:], self.feature_sensitivity)\n",
    "        else:\n",
    "            # mcf weightings - scale by primacy/attention function based on experience position\n",
    "            activation *= self.context_weighting[:self.encoding_index]\n",
    "            activation = np.power(activation, self.context_sensitivity)\n",
    "            \n",
    "        return activation\n",
    "\n",
    "    def outcome_probabilities(self):\n",
    "        \n",
    "        self.probabilities[0] = min(self.stop_probability_scale * np.exp(\n",
    "            self.recall_total * self.stop_probability_growth), 1.0 - (\n",
    "                 (self.item_count-self.recall_total) * 10e-7))\n",
    "        self.probabilities[1:] = 10e-7\n",
    "\n",
    "        if self.probabilities[0] < (1.0 - ((self.item_count-self.recall_total) * 10e-7)):\n",
    "\n",
    "            # measure activation for each item\n",
    "            activation_cue = np.hstack((np.zeros(self.item_count + 2), self.context))\n",
    "            activation = self.echo(activation_cue)[1:self.item_count+1]\n",
    "\n",
    "            # already recalled items have zero activation\n",
    "            activation[self.recall[:self.recall_total]] = 0\n",
    "            \n",
    "            # recall probability is a function of activation\n",
    "            if np.sum(activation) > 0:\n",
    "                activation = np.power(activation, self.choice_sensitivity)\n",
    "                self.probabilities[1:] = (1-self.probabilities[0]) * activation / np.sum(activation)\n",
    "        \n",
    "        return self.probabilities\n",
    "\n",
    "    def free_recall(self, steps=None):\n",
    "\n",
    "        # some pre-list context is reinstated before initiating recall\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "            \n",
    "        # number of items to retrieve is infinite if steps is unspecified\n",
    "        if steps is None:\n",
    "            steps = self.item_count - self.recall_total\n",
    "        steps = self.recall_total + steps\n",
    "\n",
    "        # at each recall attempt\n",
    "        while self.recall_total < steps:\n",
    "\n",
    "            # the current state of context is used as a retrieval cue to \n",
    "            # attempt recall of a studied item compute outcome probabilities \n",
    "            # and make choice based on distribution\n",
    "            outcome_probabilities = self.outcome_probabilities()\n",
    "            if np.any(outcome_probabilities[1:]):\n",
    "                choice = np.sum(\n",
    "                    np.cumsum(outcome_probabilities) < np.random.rand(), dtype=np.int32)\n",
    "            else:\n",
    "                choice = 0\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made (0)\n",
    "            if choice == 0:\n",
    "                self.retrieving = False\n",
    "                self.context = self.preretrieval_context\n",
    "                break\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "        return self.recall[:self.recall_total]\n",
    "    \n",
    "    def force_recall(self, choice=None):\n",
    "\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        elif choice > 0:\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(\n",
    "                self.recall_drift_rate, self.items[choice - 1])\n",
    "        else:\n",
    "            self.retrieving = False\n",
    "            self.context = self.preretrieval_context\n",
    "        return self.recall[:self.recall_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5abea88-f13e-4091-8d7a-77c47e5cb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "@jitclass(icmr_spec)\n",
    "class Lrn_Instance_CMR:\n",
    "    \"InstanceCMR With Exponent-Based Activation Scaling Applied Before Learning Rate Modulation\"\n",
    "\n",
    "    def __init__(self, item_count, presentation_count, parameters):\n",
    "\n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = parameters['encoding_drift_rate']\n",
    "        self.delay_drift_rate = parameters['delay_drift_rate']\n",
    "        self.start_drift_rate = parameters['start_drift_rate']\n",
    "        self.recall_drift_rate = parameters['recall_drift_rate']\n",
    "        self.shared_support = parameters['shared_support']\n",
    "        self.item_support = parameters['item_support']\n",
    "        self.learning_rate = parameters['learning_rate']\n",
    "        self.primacy_scale = parameters['primacy_scale']\n",
    "        self.primacy_decay = parameters['primacy_decay']\n",
    "        self.stop_probability_scale = parameters['stop_probability_scale']\n",
    "        self.stop_probability_growth = parameters['stop_probability_growth']\n",
    "        self.choice_sensitivity = parameters['choice_sensitivity']\n",
    "        self.drift_familiarity_scale = parameters['drift_familiarity_scale']\n",
    "        self.mfc_familiarity_scale = parameters['mfc_familiarity_scale']\n",
    "        self.mcf_familiarity_scale = parameters['mcf_familiarity_scale']\n",
    "        self.context_sensitivity = parameters['context_sensitivity']\n",
    "        self.feature_sensitivity = parameters['feature_sensitivity']\n",
    "        \n",
    "        # at the start of the list context is initialized with a state \n",
    "        # orthogonal to the pre-experimental context associated with the set of items\n",
    "        self.context = np.zeros(item_count + 2)\n",
    "        self.context[0] = 1\n",
    "        self.preretrieval_context = self.context\n",
    "        self.recall = np.zeros(item_count, np.int32) # recalls has at most `item_count` entries\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "\n",
    "        # predefine activation weighting vectors\n",
    "        self.item_weighting = np.ones(item_count+presentation_count)\n",
    "        self.context_weighting = np.ones(item_count+presentation_count)\n",
    "        self.item_weighting[item_count:] = self.learning_rate\n",
    "        self.context_weighting[item_count:] = \\\n",
    "            self.primacy_scale * np.exp(-self.primacy_decay * np.arange(presentation_count)) + 1\n",
    "        self.all_weighting = self.item_weighting * self.context_weighting\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((item_count + 1))\n",
    "\n",
    "        # predefine contextual input vectors relevant for delay_drift_rate and start_drift_rate parameters\n",
    "        self.start_context_input = np.zeros((self.item_count+2))\n",
    "        self.start_context_input[0] = 1\n",
    "        self.delay_context_input = np.zeros((self.item_count+2))\n",
    "        self.delay_context_input[-1] = 1\n",
    "\n",
    "        # initialize memory\n",
    "        # we now conceptualize it as a pairing of two stores Mfc and Mcf respectively\n",
    "        # representing feature-to-context and context-to-feature associations\n",
    "        mfc = np.eye(item_count, item_count + 2, 1) * (1 - self.learning_rate)\n",
    "        mcf = np.ones((item_count, item_count)) * self.shared_support\n",
    "        for i in range(item_count):\n",
    "            mcf[i, i] = self.item_support\n",
    "        mcf = np.hstack((np.zeros((item_count, 1)), mcf,  np.zeros((item_count, 1))))\n",
    "        self.memory = np.zeros((item_count + presentation_count, item_count * 2 + 4))\n",
    "        self.memory[:item_count,] = np.hstack((mfc, mcf))\n",
    "\n",
    "        self.norm = np.zeros(item_count + presentation_count)\n",
    "        self.norm[:item_count] = np.sqrt(np.sum(np.square(self.memory[0])))\n",
    "        self.norm[item_count:] = np.sqrt(2)\n",
    "        self.encoding_index = item_count\n",
    "        self.items = np.hstack((np.eye(item_count, item_count + 2, 1), np.zeros((item_count, item_count+2))))\n",
    "\n",
    "    def experience(self, experiences):\n",
    "\n",
    "        for i in range(len(experiences)):\n",
    "\n",
    "            drift_rate = self.encoding_drift_rate\n",
    "            if ((np.dot(experiences[i], np.sum(self.memory[:self.encoding_index], axis=0)[:len(experiences[i])]) > 1)\n",
    "                and ((self.mfc_familiarity_scale != 0) or (self.mcf_familiarity_scale != 0) or (\n",
    "                    self.drift_familiarity_scale != 0))):\n",
    "            \n",
    "                self.context_weighting[self.encoding_index] *= 1-self.mcf_familiarity_scale\n",
    "                self.item_weighting[self.encoding_index] *= 1-self.mfc_familiarity_scale\n",
    "                #drift_rate *= 1-self.drift_familiarity_scale\n",
    "            \n",
    "            self.memory[self.encoding_index] = experiences[i]\n",
    "            self.update_context(drift_rate, self.memory[self.encoding_index])\n",
    "            self.memory[self.encoding_index, self.item_count+2:] = self.context\n",
    "            self.encoding_index += 1\n",
    "\n",
    "    def update_context(self, drift_rate, experience):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if len(experience) == self.item_count * 2 + 4:\n",
    "            context_input = self.echo(experience)[self.item_count + 2:]\n",
    "            context_input = context_input / np.sqrt(np.sum(np.square(context_input))) # norm to length 1\n",
    "\n",
    "            if not self.retrieving and (np.dot(experience, np.sum(self.memory[:self.encoding_index], axis=0)[:len(experience)]) > 1):\n",
    "                context_input = np.power(context_input, 1-self.drift_familiarity_scale)\n",
    "\n",
    "            context_input = context_input / np.sqrt(np.sum(np.square(context_input))) # norm to length 1\n",
    "\n",
    "        else:\n",
    "            context_input = experience\n",
    "\n",
    "        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)) - (\n",
    "                drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "        self.context = self.context / np.sqrt(np.sum(np.square(self.context)))\n",
    "\n",
    "    def echo(self, probe):\n",
    "\n",
    "        return np.dot(self.activations(probe), self.memory[:self.encoding_index])\n",
    "\n",
    "    def activations(self, probe, probe_norm=1.0):\n",
    "\n",
    "        activation = np.dot(self.memory[:self.encoding_index], probe) / (\n",
    "             self.norm[:self.encoding_index] * probe_norm)\n",
    "\n",
    "        # weight activations based on whether probe contains item or contextual features or both\n",
    "        if np.any(probe[:self.item_count + 2]): # if probe is an item feature cue as during contextual retrieval\n",
    "            activation = np.power(activation, self.feature_sensitivity)\n",
    "            if np.any(probe[self.item_count + 2:]): # if probe is (also) a contextual cue as during item retrieval\n",
    "                # both mfc and mcf weightings, see below\n",
    "                activation *= self.all_weighting[:self.encoding_index]\n",
    "            else:\n",
    "                # mfc weightings - scale by gamma for each experimental trace\n",
    "                activation *= self.item_weighting[:self.encoding_index]\n",
    "        else:\n",
    "            # mcf weightings - scale by primacy/attention function based on experience position\n",
    "            activation = np.power(activation, self.context_sensitivity)\n",
    "            activation *= self.context_weighting[:self.encoding_index]\n",
    "            \n",
    "        return activation\n",
    "\n",
    "    def outcome_probabilities(self):\n",
    "        \n",
    "        self.probabilities[0] = min(self.stop_probability_scale * np.exp(\n",
    "            self.recall_total * self.stop_probability_growth), 1.0 - (\n",
    "                 (self.item_count-self.recall_total) * 10e-7))\n",
    "        self.probabilities[1:] = 10e-7\n",
    "\n",
    "        if self.probabilities[0] < (1.0 - ((self.item_count-self.recall_total) * 10e-7)):\n",
    "\n",
    "            # measure activation for each item\n",
    "            activation_cue = np.hstack((np.zeros(self.item_count + 2), self.context))\n",
    "            activation = self.echo(activation_cue)[1:self.item_count+1]\n",
    "\n",
    "            # already recalled items have zero activation\n",
    "            activation[self.recall[:self.recall_total]] = 0\n",
    "            \n",
    "            # recall probability is a function of activation\n",
    "            if np.sum(activation) > 0:\n",
    "                activation = np.power(activation, self.choice_sensitivity)\n",
    "                self.probabilities[1:] = (1-self.probabilities[0]) * activation / np.sum(activation)\n",
    "        \n",
    "        return self.probabilities\n",
    "\n",
    "    def free_recall(self, steps=None):\n",
    "\n",
    "        # some pre-list context is reinstated before initiating recall\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "            \n",
    "        # number of items to retrieve is infinite if steps is unspecified\n",
    "        if steps is None:\n",
    "            steps = self.item_count - self.recall_total\n",
    "        steps = self.recall_total + steps\n",
    "\n",
    "        # at each recall attempt\n",
    "        while self.recall_total < steps:\n",
    "\n",
    "            # the current state of context is used as a retrieval cue to \n",
    "            # attempt recall of a studied item compute outcome probabilities \n",
    "            # and make choice based on distribution\n",
    "            outcome_probabilities = self.outcome_probabilities()\n",
    "            if np.any(outcome_probabilities[1:]):\n",
    "                choice = np.sum(\n",
    "                    np.cumsum(outcome_probabilities) < np.random.rand(), dtype=np.int32)\n",
    "            else:\n",
    "                choice = 0\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made (0)\n",
    "            if choice == 0:\n",
    "                self.retrieving = False\n",
    "                self.context = self.preretrieval_context\n",
    "                break\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "        return self.recall[:self.recall_total]\n",
    "    \n",
    "    def force_recall(self, choice=None):\n",
    "\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        elif choice > 0:\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(\n",
    "                self.recall_drift_rate, self.items[choice - 1])\n",
    "        else:\n",
    "            self.retrieving = False\n",
    "            self.context = self.preretrieval_context\n",
    "        return self.recall[:self.recall_total]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
