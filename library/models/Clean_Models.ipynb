{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual ICMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "from numba import float64, int32, boolean\n",
    "from numba.experimental import jitclass\n",
    "lb = 10e-7 #np.finfo(float).eps\n",
    "\n",
    "dual_icmr_spec = [\n",
    "    (\"item_count\", int32),\n",
    "    (\"encoding_drift_rate\", float64),\n",
    "    (\"start_drift_rate\", float64),\n",
    "    (\"recall_drift_rate\", float64),\n",
    "    (\"delay_drift_rate\", float64),\n",
    "    (\"shared_support\", float64),\n",
    "    (\"item_support\", float64),\n",
    "    (\"learning_rate\", float64),\n",
    "    (\"primacy_scale\", float64),\n",
    "    (\"primacy_decay\", float64),\n",
    "    (\"stop_probability_scale\", float64),\n",
    "    (\"stop_probability_growth\", float64),\n",
    "    (\"choice_sensitivity\", float64),\n",
    "    (\"context_sensitivity\", float64),\n",
    "    (\"feature_sensitivity\", float64),\n",
    "    (\"context\", float64[::1]),\n",
    "    (\"start_context_input\", float64[::1]),\n",
    "    (\"delay_context_input\", float64[::1]),\n",
    "    (\"preretrieval_context\", float64[::1]),\n",
    "    (\"recall\", int32[::1]),\n",
    "    (\"retrieving\", boolean),\n",
    "    (\"recall_total\", int32),\n",
    "    (\"item_weighting\", float64[::1]),\n",
    "    (\"context_weighting\", float64[::1]),\n",
    "    (\"all_weighting\", float64[::1]),\n",
    "    (\"probabilities\", float64[::1]),\n",
    "    (\"mfc\", float64[:, ::1]),\n",
    "    (\"mcf\", float64[:, ::1]),\n",
    "    (\"encoding_index\", int32),\n",
    "    (\"items\", float64[:, ::1]),\n",
    "    (\"norm_mfc\", float64[::1]),\n",
    "    (\"norm_mcf\", float64[::1]),\n",
    "    (\"learn_first\", boolean),\n",
    "]\n",
    "\n",
    "\n",
    "@jitclass(dual_icmr_spec)\n",
    "class Dual_ICMR:\n",
    "    def __init__(self, item_count, presentation_count, parameters):\n",
    "\n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = parameters[\"encoding_drift_rate\"]\n",
    "        self.delay_drift_rate = parameters[\"delay_drift_rate\"]\n",
    "        self.start_drift_rate = parameters[\"start_drift_rate\"]\n",
    "        self.recall_drift_rate = parameters[\"recall_drift_rate\"]\n",
    "        self.shared_support = parameters[\"shared_support\"]\n",
    "        self.item_support = parameters[\"item_support\"]\n",
    "        self.learning_rate = parameters[\"learning_rate\"]\n",
    "        self.primacy_scale = parameters[\"primacy_scale\"]\n",
    "        self.primacy_decay = parameters[\"primacy_decay\"]\n",
    "        self.stop_probability_scale = parameters[\"stop_probability_scale\"]\n",
    "        self.stop_probability_growth = parameters[\"stop_probability_growth\"]\n",
    "        self.choice_sensitivity = parameters[\"choice_sensitivity\"]\n",
    "        self.context_sensitivity = parameters[\"context_sensitivity\"]\n",
    "        self.feature_sensitivity = parameters[\"feature_sensitivity\"]\n",
    "        self.learn_first = parameters[\"learn_first\"]\n",
    "\n",
    "        # at the start of the list context is initialized with a state\n",
    "        # orthogonal to the pre-experimental context associated with the set of items\n",
    "        self.context = np.zeros(item_count + 2)\n",
    "        self.context[0] = 1\n",
    "        self.preretrieval_context = self.context\n",
    "        self.recall = np.zeros(item_count, np.int32)\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "\n",
    "        # predefine activation weighting vectors\n",
    "        self.item_weighting = np.ones(item_count + presentation_count)\n",
    "        self.context_weighting = np.ones(item_count + presentation_count)\n",
    "        self.item_weighting[item_count:] = self.learning_rate\n",
    "        self.context_weighting[item_count:] = (\n",
    "            self.primacy_scale\n",
    "            * np.exp(-self.primacy_decay * np.arange(presentation_count))\n",
    "            + 1\n",
    "        )\n",
    "        self.all_weighting = self.item_weighting * self.context_weighting\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((item_count + 1))\n",
    "\n",
    "        # predefine contextual input vectors relevant for delay_drift_rate and start_drift_rate parameters\n",
    "        self.start_context_input = np.zeros((self.item_count + 2))\n",
    "        self.start_context_input[0] = 1\n",
    "        self.delay_context_input = np.zeros((self.item_count + 2))\n",
    "        self.delay_context_input[-1] = 1\n",
    "\n",
    "        # initialize memory\n",
    "        # we now conceptualize it as a pairing of two stores Mfc and Mcf respectively\n",
    "        # representing feature-to-context and context-to-feature associations\n",
    "        mfc_pre = np.eye(item_count, item_count + 2, 1) * (1 - self.learning_rate)\n",
    "        mcf_pre1 = np.eye(item_count, item_count) * self.item_support\n",
    "        mcf_pre2 = np.ones((item_count, item_count)) * self.shared_support\n",
    "        for i in range(item_count):\n",
    "            mcf_pre2[i, i] = self.item_support\n",
    "        mcf_pre1 = np.hstack((np.zeros((item_count, 1)), mcf_pre1,  np.zeros((item_count, 1))))\n",
    "        mcf_pre2 = np.hstack((np.zeros((item_count, 1)), mcf_pre2,  np.zeros((item_count, 1))))\n",
    "        self.mfc = np.zeros((item_count + presentation_count, item_count * 2 + 4))\n",
    "        self.mfc[:item_count,] = np.hstack((mfc_pre, mcf_pre1))\n",
    "        self.mcf = np.zeros((item_count + presentation_count, item_count * 2 + 4))\n",
    "        self.mcf[:item_count,] = np.hstack((mfc_pre, mcf_pre2))\n",
    "\n",
    "        self.norm_mfc = np.zeros(item_count + presentation_count)\n",
    "        self.norm_mcf = np.zeros(item_count + presentation_count)\n",
    "        self.norm_mfc[:item_count] = np.sqrt(np.sum(np.square(self.mfc[0])))\n",
    "        self.norm_mfc[item_count:] = np.sqrt(2)\n",
    "        self.norm_mcf[:item_count] = np.sqrt(np.sum(np.square(self.mcf[0])))\n",
    "        self.norm_mcf[item_count:] = np.sqrt(2)\n",
    "        self.encoding_index = item_count\n",
    "        self.items = np.hstack(\n",
    "            (np.eye(item_count, item_count + 2, 1), np.zeros((item_count, item_count + 2)),)\n",
    "        )\n",
    "\n",
    "    def experience(self, experiences):\n",
    "\n",
    "        for i in range(len(experiences)):\n",
    "            self.mfc[self.encoding_index] = experiences[i]\n",
    "            self.mcf[self.encoding_index] = experiences[i]\n",
    "            self.update_context(self.encoding_drift_rate, self.mfc[self.encoding_index])\n",
    "            self.mfc[self.encoding_index, self.item_count + 2 :] = self.context\n",
    "            self.mcf[self.encoding_index, self.item_count + 2 :] = self.context\n",
    "            self.encoding_index += 1\n",
    "\n",
    "    def update_context(self, drift_rate, experience):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if len(experience) == self.item_count * 2 + 4:\n",
    "            context_input = self.echo_mfc(experience)[self.item_count + 2 :]\n",
    "            context_input = context_input / np.sqrt(\n",
    "                np.sum(np.square(context_input))\n",
    "            )  # norm to length 1\n",
    "        else:\n",
    "            # but sometimes we specify contextual input directly\n",
    "            context_input = experience\n",
    "\n",
    "        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(\n",
    "            1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)\n",
    "        ) - (drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "        self.context = self.context / np.sqrt(np.sum(np.square(self.context)))\n",
    "\n",
    "    def echo_mfc(self, probe):\n",
    "        return np.dot(self.activations_mfc(probe), self.mfc[: self.encoding_index])\n",
    "\n",
    "    def echo_mcf(self, probe):\n",
    "        return np.dot(self.activations_mcf(probe), self.mcf[: self.encoding_index])\n",
    "\n",
    "    def activations_mfc(self, probe, probe_norm=1.0):\n",
    "\n",
    "        activation = np.dot(self.mfc[: self.encoding_index], probe) / (\n",
    "            self.norm_mfc[: self.encoding_index] * probe_norm\n",
    "        )\n",
    "\n",
    "        # weight activations based on whether probe contains item or contextual features or both\n",
    "        if np.any(probe[: self.item_count + 2]):  # if probe is an item feature cue as during contextual retrieval\n",
    "            if not self.learn_first:\n",
    "                activation = np.power(activation, self.feature_sensitivity)\n",
    "            if np.any(\n",
    "                probe[self.item_count + 2 :]\n",
    "            ):  # if probe is (also) a contextual cue as during item retrieval\n",
    "                # both mfc and mcf weightings, see below\n",
    "                activation *= self.all_weighting[: self.encoding_index]\n",
    "            else:\n",
    "                # mfc weightings - scale by gamma for each experimental trace\n",
    "                activation *= self.item_weighting[: self.encoding_index]\n",
    "            if not self.learn_first:\n",
    "                activation = np.power(activation, self.feature_sensitivity)\n",
    "        else:\n",
    "            # mcf weightings - scale by primacy/attention function based on experience position\n",
    "            if self.learn_first:\n",
    "                activation = np.power(activation, self.context_sensitivity)\n",
    "                activation *= self.context_weighting[: self.encoding_index]\n",
    "            else:\n",
    "                activation *= self.context_weighting[: self.encoding_index]\n",
    "                activation = np.power(activation, self.context_sensitivity)\n",
    "\n",
    "        return activation\n",
    "\n",
    "    def activations_mcf(self, probe, probe_norm=1.0):\n",
    "\n",
    "        activation = np.dot(self.mcf[: self.encoding_index], probe) / (\n",
    "            self.norm_mcf[: self.encoding_index] * probe_norm\n",
    "        )\n",
    "\n",
    "        # weight activations based on whether probe contains item or contextual features or both\n",
    "        if np.any(probe[: self.item_count + 2]):  # if probe is an item feature cue as during contextual retrieval\n",
    "            if self.learn_first:\n",
    "                activation = np.power(activation, self.feature_sensitivity)\n",
    "            if np.any(\n",
    "                probe[self.item_count + 2 :]\n",
    "            ):  # if probe is (also) a contextual cue as during item retrieval\n",
    "                # both mfc and mcf weightings, see below\n",
    "                activation *= self.all_weighting[: self.encoding_index]\n",
    "            else:\n",
    "                # mfc weightings - scale by gamma for each experimental trace\n",
    "                activation *= self.item_weighting[: self.encoding_index]\n",
    "            if not self.learn_first:\n",
    "                activation = np.power(activation, self.feature_sensitivity)\n",
    "        else:\n",
    "            # mcf weightings - scale by primacy/attention function based on experience position\n",
    "            if self.learn_first:\n",
    "                activation = np.power(activation, self.context_sensitivity)\n",
    "                activation *= self.context_weighting[: self.encoding_index]\n",
    "            else:\n",
    "                activation *= self.context_weighting[: self.encoding_index]\n",
    "                activation = np.power(activation, self.context_sensitivity)\n",
    "\n",
    "        return activation\n",
    "\n",
    "    def outcome_probabilities(self):\n",
    "\n",
    "        self.probabilities[0] = min(\n",
    "            self.stop_probability_scale * np.exp(self.recall_total * self.stop_probability_growth),\n",
    "            1.0 - ((self.item_count - self.recall_total) * lb),\n",
    "        )\n",
    "        self.probabilities[1:] = lb\n",
    "        self.probabilities[self.recall[: self.recall_total] + 1] = 0\n",
    "\n",
    "        if self.probabilities[0] < (1.0 - ((self.item_count - self.recall_total) * lb)):\n",
    "\n",
    "            # measure the support in echo for each item; already recalled items have zero activation\n",
    "            activation_cue = np.hstack((np.zeros(self.item_count + 2), self.context))\n",
    "            echo = self.echo_mcf(activation_cue)[1:self.item_count + 1]\n",
    "\n",
    "            # recall probability is a function of support within echo\n",
    "            if np.sum(echo) > 0:\n",
    "                echo = np.power(echo, self.choice_sensitivity)\n",
    "                echo[echo==0] = lb\n",
    "                echo[self.recall[:self.recall_total]] = 0\n",
    "                self.probabilities[1:] = (1 - self.probabilities[0]) * echo / np.sum(echo)\n",
    "\n",
    "        return self.probabilities\n",
    "\n",
    "    def free_recall(self, steps=None):\n",
    "\n",
    "        # some pre-list context is reinstated before initiating recall\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        # number of items to retrieve is infinite if steps is unspecified\n",
    "        if steps is None:\n",
    "            steps = self.item_count - self.recall_total\n",
    "        steps = self.recall_total + steps\n",
    "\n",
    "        # at each recall attempt\n",
    "        while self.recall_total < steps:\n",
    "\n",
    "            # the current state of context is used as a retrieval cue to\n",
    "            # attempt recall of a studied item compute outcome probabilities\n",
    "            # and make choice based on distribution\n",
    "            self.outcome_probabilities()\n",
    "            if np.any(self.probabilities[1:]):\n",
    "                choice = np.sum(np.cumsum(self.probabilities) < np.random.rand(), dtype=np.int32)\n",
    "            else:\n",
    "                choice = 0\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made (0)\n",
    "            if choice == 0:\n",
    "                self.retrieving = False\n",
    "                self.context = self.preretrieval_context\n",
    "                break\n",
    "\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "            \n",
    "        return self.recall[: self.recall_total]\n",
    "\n",
    "    def force_recall(self, choice=None):\n",
    "\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        elif choice > 0:\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "        else:\n",
    "            self.retrieving = False\n",
    "            self.context = self.preretrieval_context\n",
    "        return self.recall[: self.recall_total]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logsumexp CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "from numba import float64, int32, boolean\n",
    "from numba.experimental import jitclass\n",
    "from numba import njit\n",
    "lb = 10e-7 #np.finfo(float).eps\n",
    "\n",
    "@njit\n",
    "def logsumexp(x):\n",
    "    c = x.max()\n",
    "    return c + np.log(np.sum(np.exp(x - c)))\n",
    "\n",
    "@jitclass(dual_icmr_spec)\n",
    "class Logsumexp_ICMR:\n",
    "    def __init__(self, item_count, presentation_count, parameters):\n",
    "\n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = parameters[\"encoding_drift_rate\"]\n",
    "        self.delay_drift_rate = parameters[\"delay_drift_rate\"]\n",
    "        self.start_drift_rate = parameters[\"start_drift_rate\"]\n",
    "        self.recall_drift_rate = parameters[\"recall_drift_rate\"]\n",
    "        self.shared_support = parameters[\"shared_support\"]\n",
    "        self.item_support = parameters[\"item_support\"]\n",
    "        self.learning_rate = parameters[\"learning_rate\"]\n",
    "        self.primacy_scale = parameters[\"primacy_scale\"]\n",
    "        self.primacy_decay = parameters[\"primacy_decay\"]\n",
    "        self.stop_probability_scale = parameters[\"stop_probability_scale\"]\n",
    "        self.stop_probability_growth = parameters[\"stop_probability_growth\"]\n",
    "        self.choice_sensitivity = parameters[\"choice_sensitivity\"]\n",
    "        self.context_sensitivity = parameters[\"context_sensitivity\"]\n",
    "        self.feature_sensitivity = parameters[\"feature_sensitivity\"]\n",
    "        self.learn_first = parameters[\"learn_first\"]\n",
    "\n",
    "        # at the start of the list context is initialized with a state\n",
    "        # orthogonal to the pre-experimental context associated with the set of items\n",
    "        self.context = np.zeros(item_count + 2)\n",
    "        self.context[0] = 1\n",
    "        self.preretrieval_context = self.context\n",
    "        self.recall = np.zeros(item_count, np.int32)\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "\n",
    "        # predefine activation weighting vectors\n",
    "        self.item_weighting = np.ones(item_count + presentation_count)\n",
    "        self.context_weighting = np.ones(item_count + presentation_count)\n",
    "        self.item_weighting[item_count:] = self.learning_rate\n",
    "        self.context_weighting[item_count:] = (\n",
    "            self.primacy_scale\n",
    "            * np.exp(-self.primacy_decay * np.arange(presentation_count))\n",
    "            + 1\n",
    "        )\n",
    "        self.item_weighting = np.log(self.item_weighting)\n",
    "        self.context_weighting = np.log(self.context_weighting)\n",
    "        self.all_weighting = np.log(self.item_weighting * self.context_weighting)\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((item_count + 1))\n",
    "\n",
    "        # predefine contextual input vectors relevant for delay_drift_rate and start_drift_rate parameters\n",
    "        self.start_context_input = np.zeros((self.item_count + 2))\n",
    "        self.start_context_input[0] = 1\n",
    "        self.delay_context_input = np.zeros((self.item_count + 2))\n",
    "        self.delay_context_input[-1] = 1\n",
    "\n",
    "        # initialize memory\n",
    "        # we now conceptualize it as a pairing of two stores Mfc and Mcf respectively\n",
    "        # representing feature-to-context and context-to-feature associations\n",
    "        mfc_pre = np.eye(item_count, item_count + 2, 1) * (1 - self.learning_rate)\n",
    "        mcf_pre1 = np.eye(item_count, item_count) * self.item_support\n",
    "        mcf_pre2 = np.ones((item_count, item_count)) * self.shared_support\n",
    "        for i in range(item_count):\n",
    "            mcf_pre2[i, i] = self.item_support\n",
    "        mcf_pre1 = np.hstack((np.zeros((item_count, 1)), mcf_pre1,  np.zeros((item_count, 1))))\n",
    "        mcf_pre2 = np.hstack((np.zeros((item_count, 1)), mcf_pre2,  np.zeros((item_count, 1))))\n",
    "        self.mfc = np.zeros((item_count + presentation_count, item_count * 2 + 4))\n",
    "        self.mfc[:item_count,] = np.hstack((mfc_pre, mcf_pre1))\n",
    "        self.mcf = np.zeros((item_count + presentation_count, item_count * 2 + 4))\n",
    "        self.mcf[:item_count,] = np.hstack((mfc_pre, mcf_pre2))\n",
    "\n",
    "        self.norm_mfc = np.zeros(item_count + presentation_count)\n",
    "        self.norm_mcf = np.zeros(item_count + presentation_count)\n",
    "        self.norm_mfc[:item_count] = np.sqrt(np.sum(np.square(self.mfc[0])))\n",
    "        self.norm_mfc[item_count:] = np.sqrt(2)\n",
    "        self.norm_mcf[:item_count] = np.sqrt(np.sum(np.square(self.mcf[0])))\n",
    "        self.norm_mcf[item_count:] = np.sqrt(2)\n",
    "        self.encoding_index = item_count\n",
    "        self.items = np.hstack(\n",
    "            (np.eye(item_count, item_count + 2, 1), np.zeros((item_count, item_count + 2)),)\n",
    "        )\n",
    "\n",
    "    def experience(self, experiences):\n",
    "\n",
    "        for i in range(len(experiences)):\n",
    "            self.mfc[self.encoding_index] = experiences[i]\n",
    "            self.mcf[self.encoding_index] = experiences[i]\n",
    "            self.update_context(self.encoding_drift_rate, self.mfc[self.encoding_index])\n",
    "            self.mfc[self.encoding_index, self.item_count + 2 :] = self.context\n",
    "            self.mcf[self.encoding_index, self.item_count + 2 :] = self.context\n",
    "            self.encoding_index += 1\n",
    "\n",
    "    def update_context(self, drift_rate, experience):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if len(experience) == self.item_count * 2 + 4:\n",
    "            context_input = self.echo_mfc(experience)[self.item_count + 2 :]\n",
    "            context_input = context_input / np.sqrt(\n",
    "                np.sum(np.square(context_input))\n",
    "            )  # norm to length 1\n",
    "        else:\n",
    "            # but sometimes we specify contextual input directly\n",
    "            context_input = experience\n",
    "\n",
    "        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(\n",
    "            1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)\n",
    "        ) - (drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "        self.context = self.context / np.sqrt(np.sum(np.square(self.context)))\n",
    "\n",
    "    def echo_mfc(self, probe):\n",
    "        return np.dot(self.activations_mfc(probe), self.mfc[: self.encoding_index])\n",
    "\n",
    "    def echo_mcf(self, probe):\n",
    "        return np.dot(self.activations_mcf(probe), self.mcf[: self.encoding_index])\n",
    "\n",
    "    def activations_mfc(self, probe, probe_norm=1.0):\n",
    "\n",
    "        activation = np.dot(self.mfc[: self.encoding_index], probe) / (\n",
    "            self.norm_mfc[: self.encoding_index] * probe_norm\n",
    "        )\n",
    "        activation = np.log(activation)\n",
    "\n",
    "        # weight activations based on whether probe contains item or contextual features or both\n",
    "        if np.any(probe[: self.item_count + 2]):  # if probe is an item feature cue as during contextual retrieval\n",
    "            if not self.learn_first:\n",
    "                activation = activation * self.feature_sensitivity\n",
    "            if np.any(\n",
    "                probe[self.item_count + 2 :]\n",
    "            ):  # if probe is (also) a contextual cue as during item retrieval\n",
    "                # both mfc and mcf weightings, see below\n",
    "                activation += self.all_weighting[: self.encoding_index]\n",
    "            else:\n",
    "                # mfc weightings - scale by gamma for each experimental trace\n",
    "                activation += self.item_weighting[: self.encoding_index]\n",
    "            if not self.learn_first:\n",
    "                activation = activation * self.feature_sensitivity\n",
    "        else:\n",
    "            # mcf weightings - scale by primacy/attention function based on experience position\n",
    "            if self.learn_first:\n",
    "                activation = activation * self.context_sensitivity\n",
    "                activation += self.context_weighting[: self.encoding_index]\n",
    "            else:\n",
    "                activation += self.context_weighting[: self.encoding_index]\n",
    "                activation =activation * self.context_sensitivity\n",
    "\n",
    "        return np.exp(activation - logsumexp(activation))\n",
    "\n",
    "    def activations_mcf(self, probe, probe_norm=1.0):\n",
    "\n",
    "        activation = np.dot(self.mcf[: self.encoding_index], probe) / (\n",
    "            self.norm_mcf[: self.encoding_index] * probe_norm\n",
    "        )\n",
    "        activation = np.log(activation)\n",
    "\n",
    "        # weight activations based on whether probe contains item or contextual features or both\n",
    "        if np.any(probe[: self.item_count + 2]):  # if probe is an item feature cue as during contextual retrieval\n",
    "            if not self.learn_first:\n",
    "                activation = activation * self.feature_sensitivity\n",
    "            if np.any(\n",
    "                probe[self.item_count + 2 :]\n",
    "            ):  # if probe is (also) a contextual cue as during item retrieval\n",
    "                # both mfc and mcf weightings, see below\n",
    "                activation += self.all_weighting[: self.encoding_index]\n",
    "            else:\n",
    "                # mfc weightings - scale by gamma for each experimental trace\n",
    "                activation += self.item_weighting[: self.encoding_index]\n",
    "            if not self.learn_first:\n",
    "                activation = activation * self.feature_sensitivity\n",
    "        else:\n",
    "            # mcf weightings - scale by primacy/attention function based on experience position\n",
    "            if self.learn_first:\n",
    "                activation = activation * self.context_sensitivity\n",
    "                activation += self.context_weighting[: self.encoding_index]\n",
    "            else:\n",
    "                activation += self.context_weighting[: self.encoding_index]\n",
    "                activation =activation * self.context_sensitivity\n",
    "\n",
    "        return activation\n",
    "\n",
    "    def outcome_probabilities(self):\n",
    "\n",
    "        self.probabilities[0] = min(\n",
    "            self.stop_probability_scale * np.exp(self.recall_total * self.stop_probability_growth),\n",
    "            1.0 - ((self.item_count - self.recall_total) * lb),\n",
    "        )\n",
    "        self.probabilities[1:] = lb\n",
    "        self.probabilities[self.recall[: self.recall_total] + 1] = 0\n",
    "\n",
    "        if self.probabilities[0] < (1.0 - ((self.item_count - self.recall_total) * lb)):\n",
    "\n",
    "            # measure the support in echo for each item; already recalled items have zero activation\n",
    "            activation_cue = np.hstack((np.zeros(self.item_count + 2), self.context))\n",
    "            echo = self.echo_mcf(activation_cue)[1:self.item_count + 1]\n",
    "\n",
    "            # recall probability is a function of support within echo\n",
    "            if np.sum(echo) > 0:\n",
    "                echo = np.power(echo, self.choice_sensitivity)\n",
    "                echo[echo==0] = lb\n",
    "                echo[self.recall[:self.recall_total]] = 0\n",
    "                self.probabilities[1:] = (1 - self.probabilities[0]) * echo / np.sum(echo)\n",
    "\n",
    "        return self.probabilities\n",
    "\n",
    "    def free_recall(self, steps=None):\n",
    "\n",
    "        # some pre-list context is reinstated before initiating recall\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        # number of items to retrieve is infinite if steps is unspecified\n",
    "        if steps is None:\n",
    "            steps = self.item_count - self.recall_total\n",
    "        steps = self.recall_total + steps\n",
    "\n",
    "        # at each recall attempt\n",
    "        while self.recall_total < steps:\n",
    "\n",
    "            # the current state of context is used as a retrieval cue to\n",
    "            # attempt recall of a studied item compute outcome probabilities\n",
    "            # and make choice based on distribution\n",
    "            self.outcome_probabilities()\n",
    "            if np.any(self.probabilities[1:]):\n",
    "                choice = np.sum(np.cumsum(self.probabilities) < np.random.rand(), dtype=np.int32)\n",
    "            else:\n",
    "                choice = 0\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made (0)\n",
    "            if choice == 0:\n",
    "                self.retrieving = False\n",
    "                self.context = self.preretrieval_context\n",
    "                break\n",
    "\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "            \n",
    "        return self.recall[: self.recall_total]\n",
    "\n",
    "    def force_recall(self, choice=None):\n",
    "\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        elif choice > 0:\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "        else:\n",
    "            self.retrieving = False\n",
    "            self.context = self.preretrieval_context\n",
    "        return self.recall[: self.recall_total]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "from numba import float64, int32, boolean\n",
    "from numba.experimental import jitclass\n",
    "lb = 10e-7 #np.finfo(float).eps\n",
    "\n",
    "\n",
    "base_cmr_spec = [\n",
    "    (\"item_count\", int32),\n",
    "    (\"encoding_drift_rate\", float64),\n",
    "    (\"delay_drift_rate\", float64),\n",
    "    (\"start_drift_rate\", float64),\n",
    "    (\"recall_drift_rate\", float64),\n",
    "    (\"shared_support\", float64),\n",
    "    (\"item_support\", float64),\n",
    "    (\"learning_rate\", float64),\n",
    "    (\"primacy_scale\", float64),\n",
    "    (\"primacy_decay\", float64),\n",
    "    (\"stop_probability_scale\", float64),\n",
    "    (\"stop_probability_growth\", float64),\n",
    "    (\"choice_sensitivity\", float64),\n",
    "    (\"context\", float64[::1]),\n",
    "    (\"start_context_input\", float64[::1]),\n",
    "    (\"delay_context_input\", float64[::1]),\n",
    "    (\"preretrieval_context\", float64[::1]),\n",
    "    (\"recall\", int32[::1]),\n",
    "    (\"retrieving\", boolean),\n",
    "    (\"recall_total\", int32),\n",
    "    (\"primacy_weighting\", float64[::1]),\n",
    "    (\"probabilities\", float64[::1]),\n",
    "    (\"mfc\", float64[:, ::1]),\n",
    "    (\"mcf\", float64[:, ::1]),\n",
    "    (\"encoding_index\", int32),\n",
    "    (\"items\", float64[:, ::1]),\n",
    "]\n",
    "\n",
    "@jitclass(base_cmr_spec)\n",
    "class Base_CMR:\n",
    "    def __init__(self, item_count, presentation_count, parameters):\n",
    "\n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = parameters[\"encoding_drift_rate\"]\n",
    "        self.delay_drift_rate = parameters[\"delay_drift_rate\"]\n",
    "        self.start_drift_rate = parameters[\"start_drift_rate\"]\n",
    "        self.recall_drift_rate = parameters[\"recall_drift_rate\"]\n",
    "        self.shared_support = parameters[\"shared_support\"]\n",
    "        self.item_support = parameters[\"item_support\"]\n",
    "        self.learning_rate = parameters[\"learning_rate\"]\n",
    "        self.primacy_scale = parameters[\"primacy_scale\"]\n",
    "        self.primacy_decay = parameters[\"primacy_decay\"]\n",
    "        self.stop_probability_scale = parameters[\"stop_probability_scale\"]\n",
    "        self.stop_probability_growth = parameters[\"stop_probability_growth\"]\n",
    "        self.choice_sensitivity = parameters[\"choice_sensitivity\"]\n",
    "\n",
    "        # at the start of the list context is initialized with a state\n",
    "        # orthogonal to the pre-experimental context\n",
    "        # associated with the set of items\n",
    "        self.context = np.zeros(item_count + 2)\n",
    "        self.context[0] = 1\n",
    "        self.preretrieval_context = self.context\n",
    "        self.recall = np.zeros(item_count, np.int32)\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "\n",
    "        # predefine primacy weighting vectors\n",
    "        self.primacy_weighting = (\n",
    "            self.primacy_scale\n",
    "            * np.exp(-self.primacy_decay * np.arange(presentation_count))\n",
    "            + 1\n",
    "        )\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((item_count + 1))\n",
    "\n",
    "        # predefine contextual input vectors relevant for delay_drift_rate and start_drift_rate parameters\n",
    "        self.start_context_input = np.zeros((self.item_count + 2))\n",
    "        self.start_context_input[0] = 1\n",
    "        self.delay_context_input = np.zeros((self.item_count + 2))\n",
    "        self.delay_context_input[-1] = 1\n",
    "\n",
    "        # The two layers communicate with one another through two sets of\n",
    "        # associative connections represented by matrices Mfc and Mcf.\n",
    "        # Pre-experimental Mfc is 1-learning_rate and pre-experimental Mcf is\n",
    "        # item_support for i=j. For i!=j, Mcf is shared_support.\n",
    "        self.mfc = np.eye(item_count, item_count + 2, 1) * (1 - self.learning_rate)\n",
    "        self.mcf = np.ones((item_count, item_count)) * self.shared_support\n",
    "        for i in range(item_count):\n",
    "            self.mcf[i, i] = self.item_support\n",
    "        self.mcf = np.vstack(\n",
    "            (np.zeros((1, item_count)), self.mcf, np.zeros((1, item_count)))\n",
    "        )\n",
    "        self.encoding_index = 0\n",
    "        self.items = np.eye(item_count, item_count)\n",
    "\n",
    "    def experience(self, experiences):\n",
    "\n",
    "        for i in range(len(experiences)):\n",
    "            self.update_context(self.encoding_drift_rate, experiences[i])\n",
    "            self.mfc += self.learning_rate * np.outer(self.context, experiences[i]).T\n",
    "            self.mcf += self.primacy_weighting[self.encoding_index] * np.outer(\n",
    "                self.context, experiences[i])\n",
    "            self.encoding_index += 1\n",
    "\n",
    "    def update_context(self, drift_rate, experience):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if len(experience) == len(self.mfc):\n",
    "            context_input = self.activations(experience, use_mfc=True)\n",
    "            context_input /= np.sqrt(\n",
    "                np.sum(np.square(context_input))\n",
    "            )  # norm to length 1\n",
    "        else:\n",
    "            # but sometimes we specify contextual input directly\n",
    "            context_input = experience\n",
    "\n",
    "        # new context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(\n",
    "            1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)\n",
    "        ) - (drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "\n",
    "    def activations(self, probe, use_mfc=False):\n",
    "        if use_mfc:\n",
    "            return np.dot(probe, self.mfc)\n",
    "        else:\n",
    "            return np.dot(probe, self.mcf)\n",
    "\n",
    "    def outcome_probabilities(self):\n",
    "\n",
    "        self.probabilities[0] = min(\n",
    "            self.stop_probability_scale * np.exp(self.recall_total * self.stop_probability_growth),\n",
    "            1.0 - ((self.item_count - self.recall_total) * lb),\n",
    "        )\n",
    "        self.probabilities[1:] = lb\n",
    "        self.probabilities[self.recall[: self.recall_total] + 1] = 0\n",
    "\n",
    "        if self.probabilities[0] < (1.0 - ((self.item_count - self.recall_total) * lb)):\n",
    "\n",
    "            activation = self.activations(self.context)\n",
    "            if np.sum(activation) > 0:\n",
    "                activation = np.power(activation, self.choice_sensitivity)\n",
    "                activation[activation==0] = lb\n",
    "                activation[self.recall[:self.recall_total]] = 0\n",
    "                self.probabilities[1:] = (1 - self.probabilities[0]) * activation / np.sum(activation)\n",
    "\n",
    "        return self.probabilities\n",
    "\n",
    "    def free_recall(self, steps=None):\n",
    "\n",
    "        # some amount of the pre-list context is reinstated before initiating the recall\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        # number of items to retrieve is # of items left to recall if steps is unspecified\n",
    "        if steps is None:\n",
    "            steps = self.item_count - self.recall_total\n",
    "        steps = self.recall_total + steps\n",
    "\n",
    "        # at each recall attempt,\n",
    "        while self.recall_total < steps:\n",
    "\n",
    "            # the current state of context is used as a retrieval cue\n",
    "            # we compute outcome probabilities and make choice based on distribution\n",
    "            self.outcome_probabilities()\n",
    "            if np.any(self.probabilities[1:]):\n",
    "                choice = np.sum(np.cumsum(self.probabilities) < np.random.rand(), dtype=np.int32)\n",
    "            else:\n",
    "                choice = 0\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made (0)\n",
    "            if choice == 0:\n",
    "                self.retrieving = False\n",
    "                self.context = self.preretrieval_context\n",
    "                break\n",
    "\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "\n",
    "        return self.recall[: self.recall_total]\n",
    "\n",
    "    def force_recall(self, choice=None):\n",
    "\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        elif choice > 0:\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "        else:\n",
    "            self.retrieving = False\n",
    "            self.context = self.preretrieval_context\n",
    "\n",
    "        return self.recall[: self.recall_total]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single ICMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "from numba import float64, int32, boolean\n",
    "from numba.experimental import jitclass\n",
    "lb = 10e-7 #np.finfo(float).eps\n",
    "\n",
    "single_icmr_spec = [\n",
    "    (\"item_count\", int32),\n",
    "    (\"encoding_drift_rate\", float64),\n",
    "    (\"start_drift_rate\", float64),\n",
    "    (\"recall_drift_rate\", float64),\n",
    "    (\"delay_drift_rate\", float64),\n",
    "    (\"shared_support\", float64),\n",
    "    (\"item_support\", float64),\n",
    "    (\"learning_rate\", float64),\n",
    "    (\"primacy_scale\", float64),\n",
    "    (\"primacy_decay\", float64),\n",
    "    (\"stop_probability_scale\", float64),\n",
    "    (\"stop_probability_growth\", float64),\n",
    "    (\"choice_sensitivity\", float64),\n",
    "    (\"context_sensitivity\", float64),\n",
    "    (\"feature_sensitivity\", float64),\n",
    "    (\"context\", float64[::1]),\n",
    "    (\"start_context_input\", float64[::1]),\n",
    "    (\"delay_context_input\", float64[::1]),\n",
    "    (\"preretrieval_context\", float64[::1]),\n",
    "    (\"recall\", int32[::1]),\n",
    "    (\"retrieving\", boolean),\n",
    "    (\"recall_total\", int32),\n",
    "    (\"item_weighting\", float64[::1]),\n",
    "    (\"context_weighting\", float64[::1]),\n",
    "    (\"all_weighting\", float64[::1]),\n",
    "    (\"probabilities\", float64[::1]),\n",
    "    (\"memory\", float64[:, ::1]),\n",
    "    (\"encoding_index\", int32),\n",
    "    (\"items\", float64[:, ::1]),\n",
    "    (\"norm\", float64[::1]),\n",
    "    (\"learn_first\", boolean)\n",
    "]\n",
    "\n",
    "@jitclass(single_icmr_spec)\n",
    "class Single_ICMR:\n",
    "    def __init__(self, item_count, presentation_count, parameters):\n",
    "\n",
    "        # store initial parameters\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = parameters[\"encoding_drift_rate\"]\n",
    "        self.delay_drift_rate = parameters[\"delay_drift_rate\"]\n",
    "        self.start_drift_rate = parameters[\"start_drift_rate\"]\n",
    "        self.recall_drift_rate = parameters[\"recall_drift_rate\"]\n",
    "        self.shared_support = parameters[\"shared_support\"]\n",
    "        self.item_support = parameters[\"item_support\"]\n",
    "        self.learning_rate = parameters[\"learning_rate\"]\n",
    "        self.primacy_scale = parameters[\"primacy_scale\"]\n",
    "        self.primacy_decay = parameters[\"primacy_decay\"]\n",
    "        self.stop_probability_scale = parameters[\"stop_probability_scale\"]\n",
    "        self.stop_probability_growth = parameters[\"stop_probability_growth\"]\n",
    "        self.choice_sensitivity = parameters[\"choice_sensitivity\"]\n",
    "        self.context_sensitivity = parameters[\"context_sensitivity\"]\n",
    "        self.feature_sensitivity = parameters[\"feature_sensitivity\"]\n",
    "        self.learn_first = parameters[\"learn_first\"]\n",
    "\n",
    "        # at the start of the list context is initialized with a state\n",
    "        # orthogonal to the pre-experimental context associated with the set of items\n",
    "        self.context = np.zeros(item_count + 2)\n",
    "        self.context[0] = 1\n",
    "        self.preretrieval_context = self.context\n",
    "        self.recall = np.zeros(item_count, np.int32)\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "\n",
    "        # predefine activation weighting vectors\n",
    "        self.item_weighting = np.ones(item_count + presentation_count)\n",
    "        self.context_weighting = np.ones(item_count + presentation_count)\n",
    "        self.item_weighting[item_count:] = self.learning_rate\n",
    "        self.context_weighting[item_count:] = (\n",
    "            self.primacy_scale\n",
    "            * np.exp(-self.primacy_decay * np.arange(presentation_count))\n",
    "            + 1\n",
    "        )\n",
    "        self.all_weighting = self.item_weighting * self.context_weighting\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((item_count + 1))\n",
    "\n",
    "        # predefine contextual input vectors relevant for delay_drift_rate and start_drift_rate parameters\n",
    "        self.start_context_input = np.zeros((self.item_count + 2))\n",
    "        self.start_context_input[0] = 1\n",
    "        self.delay_context_input = np.zeros((self.item_count + 2))\n",
    "        self.delay_context_input[-1] = 1\n",
    "\n",
    "        # initialize memory\n",
    "        # we now conceptualize it as a pairing of two stores Mfc and Mcf respectivelysee\n",
    "        # representing feature-to-context and context-to-feature associations\n",
    "        mfc = np.eye(item_count, item_count + 2, 1) * (1 - self.learning_rate)\n",
    "        mcf = np.ones((item_count, item_count)) * self.shared_support\n",
    "        for i in range(item_count):\n",
    "            mcf[i, i] = self.item_support\n",
    "        mcf = np.hstack((np.zeros((item_count, 1)), mcf,  np.zeros((item_count, 1))))\n",
    "        self.memory = np.zeros((item_count + presentation_count, item_count * 2 + 4))\n",
    "        self.memory[:item_count,] = np.hstack((mfc, mcf))\n",
    "\n",
    "        self.norm = np.zeros(item_count + presentation_count)\n",
    "        self.norm[:item_count] = np.sqrt(np.sum(np.square(self.memory[0])))\n",
    "        self.norm[item_count:] = np.sqrt(2)\n",
    "        self.encoding_index = item_count\n",
    "        self.items = np.hstack((np.eye(item_count, item_count + 2, 1), np.zeros((item_count, item_count+2))))\n",
    "\n",
    "    def experience(self, experiences):\n",
    "\n",
    "        for i in range(len(experiences)):\n",
    "            self.memory[self.encoding_index] = experiences[i]\n",
    "            self.update_context(self.encoding_drift_rate, self.memory[self.encoding_index])\n",
    "            self.memory[self.encoding_index, self.item_count+2:] = self.context\n",
    "            self.encoding_index += 1\n",
    "\n",
    "    def update_context(self, drift_rate, experience):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if len(experience) == self.item_count * 2 + 4:\n",
    "            context_input = self.echo(experience)[self.item_count + 2 :]\n",
    "            context_input = context_input / np.sqrt(\n",
    "                np.sum(np.square(context_input))\n",
    "            )  # norm to length 1\n",
    "        else:\n",
    "            # but sometimes we specify contextual input directly\n",
    "            context_input = experience\n",
    "\n",
    "        # updated context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(\n",
    "            1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)\n",
    "        ) - (drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "        self.context = self.context / np.sqrt(np.sum(np.square(self.context)))\n",
    "\n",
    "    def echo(self, probe):\n",
    "\n",
    "        return np.dot(self.activations(probe), self.memory[:self.encoding_index])\n",
    "\n",
    "    def activations(self, probe, probe_norm=1.0):\n",
    "\n",
    "        activation = np.dot(self.memory[: self.encoding_index], probe) / (\n",
    "            self.norm[: self.encoding_index] * probe_norm)\n",
    "\n",
    "        # weight activations based on whether probe contains item or contextual features or both\n",
    "        if np.any(probe[: self.item_count + 2]):  # if probe is an item feature cue as during contextual retrieval\n",
    "            if self.learn_first:\n",
    "                activation = np.power(activation, self.feature_sensitivity)\n",
    "            if np.any(probe[self.item_count + 2:]):  # if probe is (also) a contextual cue as during item retrieval\n",
    "                # both mfc and mcf weightings, see below\n",
    "                activation *= self.all_weighting[: self.encoding_index]\n",
    "            else:\n",
    "                # mfc weightings - scale by gamma for each experimental trace\n",
    "                activation *= self.item_weighting[: self.encoding_index]\n",
    "            if not self.learn_first:\n",
    "                activation = np.power(activation, self.feature_sensitivity)\n",
    "        else:\n",
    "            # mcf weightings - scale by primacy/attention function based on experience position\n",
    "            if not self.learn_first:\n",
    "                activation *= self.context_weighting[: self.encoding_index]\n",
    "                activation = np.power(activation, self.context_sensitivity)\n",
    "            else:\n",
    "                activation = np.power(activation, self.context_sensitivity)\n",
    "                activation *= self.context_weighting[: self.encoding_index]\n",
    "\n",
    "        return activation\n",
    "        \n",
    "    def outcome_probabilities(self):\n",
    "\n",
    "        self.probabilities[0] = min(\n",
    "            self.stop_probability_scale * np.exp(self.recall_total * self.stop_probability_growth),\n",
    "            1.0 - ((self.item_count - self.recall_total) * lb))\n",
    "        self.probabilities[1:] = lb\n",
    "        self.probabilities[self.recall[: self.recall_total] + 1] = 0\n",
    "\n",
    "        if self.probabilities[0] < (1.0 - ((self.item_count - self.recall_total) * lb)):\n",
    "\n",
    "            # measure the activation for each item; already recalled items have zero activation\n",
    "            activation_cue = np.hstack((np.zeros(self.item_count + 2), self.context))\n",
    "            activation = self.echo(activation_cue)[1:self.item_count + 1]\n",
    "\n",
    "            # recall probability is a function of activation\n",
    "            if np.sum(activation) > 0:\n",
    "                activation = np.power(activation, self.choice_sensitivity)\n",
    "                activation[activation==0] = lb\n",
    "                activation[self.recall[:self.recall_total]] = 0\n",
    "                self.probabilities[1:] = (1 - self.probabilities[0]) * activation / np.sum(activation)\n",
    "\n",
    "        return self.probabilities\n",
    "\n",
    "    def free_recall(self, steps=None):\n",
    "\n",
    "        # some pre-list context is reinstated before initiating recall\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        # number of items to retrieve is infinite if steps is unspecified\n",
    "        if steps is None:\n",
    "            steps = self.item_count - self.recall_total\n",
    "        steps = self.recall_total + steps\n",
    "\n",
    "        # at each recall attempt\n",
    "        while self.recall_total < steps:\n",
    "\n",
    "            # the current state of context is used as a retrieval cue to\n",
    "            # attempt recall of a studied item compute outcome probabilities\n",
    "            # and make choice based on distribution\n",
    "            self.outcome_probabilities()\n",
    "            if np.any(self.probabilities[1:]):\n",
    "                choice = np.sum(np.cumsum(self.probabilities) < np.random.rand(), dtype=np.int32)\n",
    "            else:\n",
    "                choice = 0\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made (0)\n",
    "            if choice == 0:\n",
    "                self.retrieving = False\n",
    "                self.context = self.preretrieval_context\n",
    "                break\n",
    "\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "            \n",
    "        return self.recall[: self.recall_total]\n",
    "\n",
    "    def force_recall(self, choice=None):\n",
    "\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        elif choice > 0:\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "        else:\n",
    "            self.retrieving = False\n",
    "            self.context = self.preretrieval_context\n",
    "        return self.recall[: self.recall_total]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Semantic CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "from numba import float64, int32, boolean\n",
    "from numba.experimental import jitclass\n",
    "lb = 10e-7 #np.finfo(float).eps\n",
    "\n",
    "context_semantic_cmr_spec = [\n",
    "    (\"item_count\", int32),\n",
    "    (\"encoding_drift_rate\", float64),\n",
    "    (\"delay_drift_rate\", float64),\n",
    "    (\"start_drift_rate\", float64),\n",
    "    (\"recall_drift_rate\", float64),\n",
    "    (\"shared_support\", float64),\n",
    "    (\"item_support\", float64),\n",
    "    (\"learning_rate\", float64),\n",
    "    (\"primacy_scale\", float64),\n",
    "    (\"primacy_decay\", float64),\n",
    "    (\"stop_probability_scale\", float64),\n",
    "    (\"stop_probability_growth\", float64),\n",
    "    (\"choice_sensitivity\", float64),\n",
    "    (\"context\", float64[::1]),\n",
    "    (\"start_context_input\", float64[::1]),\n",
    "    (\"delay_context_input\", float64[::1]),\n",
    "    (\"preretrieval_context\", float64[::1]),\n",
    "    (\"recall\", int32[::1]),\n",
    "    (\"retrieving\", boolean),\n",
    "    (\"recall_total\", int32),\n",
    "    (\"primacy_weighting\", float64[::1]),\n",
    "    (\"probabilities\", float64[::1]),\n",
    "    (\"mfc\", float64[:, ::1]),\n",
    "    (\"mcf\", float64[:, ::1]),\n",
    "    (\"encoding_index\", int32),\n",
    "    (\"items\", float64[:, ::1]),\n",
    "    ('semantic_scale', float64),\n",
    "    ('similarities', float64[:,::1])\n",
    "]\n",
    "\n",
    "@jitclass(context_semantic_cmr_spec)\n",
    "class Context_Semantic_CMR:\n",
    "    def __init__(self, similarities, presentation_count, parameters):\n",
    "\n",
    "        # store initial parameters\n",
    "        item_count = len(similarities)\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = parameters[\"encoding_drift_rate\"]\n",
    "        self.delay_drift_rate = parameters[\"delay_drift_rate\"]\n",
    "        self.start_drift_rate = parameters[\"start_drift_rate\"]\n",
    "        self.recall_drift_rate = parameters[\"recall_drift_rate\"]\n",
    "        self.shared_support = parameters[\"shared_support\"]\n",
    "        self.item_support = parameters[\"item_support\"]\n",
    "        self.learning_rate = parameters[\"learning_rate\"]\n",
    "        self.primacy_scale = parameters[\"primacy_scale\"]\n",
    "        self.primacy_decay = parameters[\"primacy_decay\"]\n",
    "        self.stop_probability_scale = parameters[\"stop_probability_scale\"]\n",
    "        self.stop_probability_growth = parameters[\"stop_probability_growth\"]\n",
    "        self.choice_sensitivity = parameters[\"choice_sensitivity\"]\n",
    "\n",
    "        # specialized support for semantic connections when MCF is the cue\n",
    "        self.semantic_scale = parameters['semantic_scale']\n",
    "        self.similarities = np.vstack((np.zeros((1, item_count)), similarities, np.zeros((1, item_count))))\n",
    "\n",
    "        # at the start of the list context is initialized with a state\n",
    "        # orthogonal to the pre-experimental context\n",
    "        # associated with the set of items\n",
    "        self.context = np.zeros(item_count + 2)\n",
    "        self.context[0] = 1\n",
    "        self.preretrieval_context = self.context\n",
    "        self.recall = np.zeros(item_count, np.int32)\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "\n",
    "        # predefine primacy weighting vectors\n",
    "        self.primacy_weighting = (\n",
    "            self.primacy_scale * np.exp(-self.primacy_decay * np.arange(presentation_count)) + 1\n",
    "        )\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((item_count + 1))\n",
    "\n",
    "        # predefine contextual input vectors relevant for delay_drift_rate and start_drift_rate parameters\n",
    "        self.start_context_input = np.zeros((self.item_count + 2))\n",
    "        self.start_context_input[0] = 1\n",
    "        self.delay_context_input = np.random.rand((self.item_count + 2))\n",
    "        self.delay_context_input /= np.sqrt(\n",
    "                np.sum(np.square(self.delay_context_input)))\n",
    "        #self.delay_context_input[-1] = 1\n",
    "\n",
    "        # The two layers communicate with one another through two sets of\n",
    "        # associative connections represented by matrices Mfc and Mcf.\n",
    "        # Pre-experimental Mfc is 1-learning_rate and pre-experimental Mcf is\n",
    "        # item_support for i=j. For i!=j, Mcf is shared_support.\n",
    "        self.mfc = np.eye(item_count, item_count + 2, 1) * (1 - self.learning_rate)\n",
    "        self.mcf = np.ones((item_count, item_count)) * self.shared_support\n",
    "        for i in range(item_count):\n",
    "            self.mcf[i, i] = self.item_support\n",
    "        self.mcf = np.vstack(\n",
    "            (np.zeros((1, item_count)), self.mcf, np.zeros((1, item_count)))\n",
    "        )\n",
    "        self.encoding_index = 0\n",
    "        self.items = np.eye(item_count, item_count)\n",
    "\n",
    "    def experience(self, experiences):\n",
    "\n",
    "        for i in range(len(experiences)):\n",
    "            self.update_context(self.encoding_drift_rate, experiences[i])\n",
    "            self.mfc += self.learning_rate * np.outer(self.context, experiences[i]).T\n",
    "            self.mcf += self.primacy_weighting[self.encoding_index] * np.outer(\n",
    "                self.context, experiences[i])\n",
    "            self.encoding_index += 1\n",
    "\n",
    "    def update_context(self, drift_rate, experience):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if len(experience) == len(self.mfc):\n",
    "            context_input = self.activations(experience, use_mfc=True)\n",
    "            context_input /= np.sqrt(\n",
    "                np.sum(np.square(context_input))\n",
    "            )  # norm to length 1\n",
    "        else:\n",
    "            # but sometimes we specify contextual input directly\n",
    "            context_input = experience\n",
    "\n",
    "        # new context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(\n",
    "            1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)\n",
    "        ) - (drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "\n",
    "    def activations(self, probe, use_mfc=False):\n",
    "        if use_mfc:\n",
    "            return np.dot(probe, self.mfc)\n",
    "        elif self.semantic_scale == 0.0:\n",
    "            return np.dot(probe, self.mcf)\n",
    "        else:\n",
    "            return (self.semantic_scale * np.dot(probe, self.similarities)) + np.dot(probe, self.mcf)\n",
    "\n",
    "    def outcome_probabilities(self):\n",
    "\n",
    "        self.probabilities[0] = min(\n",
    "            self.stop_probability_scale * np.exp(self.recall_total * self.stop_probability_growth),\n",
    "            1.0 - ((self.item_count - self.recall_total) * lb),\n",
    "        )\n",
    "        self.probabilities[1:] = lb\n",
    "        self.probabilities[self.recall[: self.recall_total] + 1] = 0\n",
    "\n",
    "        if self.probabilities[0] < (1.0 - ((self.item_count - self.recall_total) * lb)):\n",
    "\n",
    "            activation = self.activations(self.context)\n",
    "            if np.sum(activation) > 0:\n",
    "                activation = np.power(activation, self.choice_sensitivity)\n",
    "                activation[activation==0] = lb\n",
    "                activation[self.recall[:self.recall_total]] = 0\n",
    "                self.probabilities[1:] = (1 - self.probabilities[0]) * activation / np.sum(activation)\n",
    "\n",
    "        return self.probabilities\n",
    "\n",
    "    def free_recall(self, steps=None):\n",
    "\n",
    "        # some amount of the pre-list context is reinstated before initiating the recall\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        # number of items to retrieve is # of items left to recall if steps is unspecified\n",
    "        if steps is None:\n",
    "            steps = self.item_count - self.recall_total\n",
    "        steps = self.recall_total + steps\n",
    "\n",
    "        # at each recall attempt,\n",
    "        while self.recall_total < steps:\n",
    "\n",
    "            # the current state of context is used as a retrieval cue\n",
    "            # we compute outcome probabilities and make choice based on distribution\n",
    "            self.outcome_probabilities()\n",
    "            if np.any(self.probabilities[1:]):\n",
    "                choice = np.sum(np.cumsum(self.probabilities) < np.random.rand(), dtype=np.int32)\n",
    "            else:\n",
    "                choice = 0\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made (0)\n",
    "            if choice == 0:\n",
    "                self.retrieving = False\n",
    "                self.context = self.preretrieval_context\n",
    "                break\n",
    "\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "\n",
    "        return self.recall[: self.recall_total]\n",
    "\n",
    "    def force_recall(self, choice=None):\n",
    "\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        elif choice > 0:\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "        else:\n",
    "            self.retrieving = False\n",
    "            self.context = self.preretrieval_context\n",
    "\n",
    "        return self.recall[: self.recall_total]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "from numba import float64, int32, boolean\n",
    "from numba.experimental import jitclass\n",
    "lb = 10e-7 #np.finfo(float).eps\n",
    "\n",
    "semantic_cmr_spec = [\n",
    "    (\"item_count\", int32),\n",
    "    (\"encoding_drift_rate\", float64),\n",
    "    (\"delay_drift_rate\", float64),\n",
    "    (\"start_drift_rate\", float64),\n",
    "    (\"recall_drift_rate\", float64),\n",
    "    (\"shared_support\", float64),\n",
    "    (\"item_support\", float64),\n",
    "    (\"learning_rate\", float64),\n",
    "    (\"primacy_scale\", float64),\n",
    "    (\"primacy_decay\", float64),\n",
    "    (\"stop_probability_scale\", float64),\n",
    "    (\"stop_probability_growth\", float64),\n",
    "    (\"choice_sensitivity\", float64),\n",
    "    (\"context\", float64[::1]),\n",
    "    (\"start_context_input\", float64[::1]),\n",
    "    (\"delay_context_input\", float64[::1]),\n",
    "    (\"preretrieval_context\", float64[::1]),\n",
    "    (\"recall\", int32[::1]),\n",
    "    (\"retrieving\", boolean),\n",
    "    (\"recall_total\", int32),\n",
    "    (\"primacy_weighting\", float64[::1]),\n",
    "    (\"probabilities\", float64[::1]),\n",
    "    (\"mfc\", float64[:, ::1]),\n",
    "    (\"mcf\", float64[:, ::1]),\n",
    "    (\"encoding_index\", int32),\n",
    "    (\"items\", float64[:, ::1]),\n",
    "    ('semantic_scale', float64),\n",
    "    ('similarities', float64[:,::1])\n",
    "]\n",
    "\n",
    "@jitclass(semantic_cmr_spec)\n",
    "class Semantic_CMR:\n",
    "    def __init__(self, similarities, presentation_count, parameters):\n",
    "\n",
    "        # store initial parameters\n",
    "        item_count = len(similarities)\n",
    "        self.item_count = item_count\n",
    "        self.encoding_drift_rate = parameters[\"encoding_drift_rate\"]\n",
    "        self.delay_drift_rate = parameters[\"delay_drift_rate\"]\n",
    "        self.start_drift_rate = parameters[\"start_drift_rate\"]\n",
    "        self.recall_drift_rate = parameters[\"recall_drift_rate\"]\n",
    "        self.shared_support = parameters[\"shared_support\"]\n",
    "        self.item_support = parameters[\"item_support\"]\n",
    "        self.learning_rate = parameters[\"learning_rate\"]\n",
    "        self.primacy_scale = parameters[\"primacy_scale\"]\n",
    "        self.primacy_decay = parameters[\"primacy_decay\"]\n",
    "        self.stop_probability_scale = parameters[\"stop_probability_scale\"]\n",
    "        self.stop_probability_growth = parameters[\"stop_probability_growth\"]\n",
    "        self.choice_sensitivity = parameters[\"choice_sensitivity\"]\n",
    "\n",
    "        # specialized support for semantic connections when MCF is the cue\n",
    "        self.semantic_scale = parameters['semantic_scale']\n",
    "        self.similarities = similarities\n",
    "\n",
    "        # at the start of the list context is initialized with a state\n",
    "        # orthogonal to the pre-experimental context\n",
    "        # associated with the set of items\n",
    "        self.context = np.zeros(item_count + 2)\n",
    "        self.context[0] = 1\n",
    "        self.preretrieval_context = self.context\n",
    "        self.recall = np.zeros(item_count, np.int32)\n",
    "        self.retrieving = False\n",
    "        self.recall_total = 0\n",
    "\n",
    "        # predefine primacy weighting vectors\n",
    "        self.primacy_weighting = (\n",
    "            self.primacy_scale * np.exp(-self.primacy_decay * np.arange(presentation_count)) + 1\n",
    "        )\n",
    "\n",
    "        # preallocate for outcome_probabilities\n",
    "        self.probabilities = np.zeros((item_count + 1))\n",
    "\n",
    "        # predefine contextual input vectors relevant for delay_drift_rate and start_drift_rate parameters\n",
    "        self.start_context_input = np.zeros((self.item_count + 2))\n",
    "        self.start_context_input[0] = 1\n",
    "        self.delay_context_input = np.random.rand((self.item_count + 2))\n",
    "        self.delay_context_input /= np.sqrt(\n",
    "                np.sum(np.square(self.delay_context_input)))\n",
    "        #self.delay_context_input[-1] = 1\n",
    "\n",
    "        # The two layers communicate with one another through two sets of\n",
    "        # associative connections represented by matrices Mfc and Mcf.\n",
    "        # Pre-experimental Mfc is 1-learning_rate and pre-experimental Mcf is\n",
    "        # item_support for i=j. For i!=j, Mcf is shared_support.\n",
    "        self.mfc = np.eye(item_count, item_count + 2, 1) * (1 - self.learning_rate)\n",
    "        self.mcf = np.ones((item_count, item_count)) * self.shared_support\n",
    "        for i in range(item_count):\n",
    "            self.mcf[i, i] = self.item_support\n",
    "        self.mcf = np.vstack(\n",
    "            (np.zeros((1, item_count)), self.mcf, np.zeros((1, item_count)))\n",
    "        )\n",
    "        self.encoding_index = 0\n",
    "        self.items = np.eye(item_count, item_count)\n",
    "\n",
    "    def experience(self, experiences):\n",
    "\n",
    "        for i in range(len(experiences)):\n",
    "            self.update_context(self.encoding_drift_rate, experiences[i])\n",
    "            self.mfc += self.learning_rate * np.outer(self.context, experiences[i]).T\n",
    "            self.mcf += self.primacy_weighting[self.encoding_index] * np.outer(\n",
    "                self.context, experiences[i])\n",
    "            self.encoding_index += 1\n",
    "\n",
    "    def update_context(self, drift_rate, experience):\n",
    "\n",
    "        # first pre-experimental or initial context is retrieved\n",
    "        if len(experience) == len(self.mfc):\n",
    "            context_input = self.activations(experience, use_mfc=True)\n",
    "            context_input /= np.sqrt(\n",
    "                np.sum(np.square(context_input))\n",
    "            )  # norm to length 1\n",
    "        else:\n",
    "            # but sometimes we specify contextual input directly\n",
    "            context_input = experience\n",
    "\n",
    "        # new context is sum of context and input, modulated by rho to have len 1 and some drift_rate\n",
    "        rho = np.sqrt(\n",
    "            1 + np.square(drift_rate) * (np.square(self.context * context_input) - 1)\n",
    "        ) - (drift_rate * (self.context * context_input))\n",
    "        self.context = (rho * self.context) + (drift_rate * context_input)\n",
    "\n",
    "    def activations(self, probe, use_mfc=False):\n",
    "        if use_mfc:\n",
    "            return np.dot(probe, self.mfc)\n",
    "        elif self.semantic_scale == 0.0 or self.recall_total == 0:\n",
    "            return np.dot(probe, self.mcf)\n",
    "        else:\n",
    "            return (\n",
    "                self.semantic_scale * np.dot(\n",
    "                    self.items[self.recall[self.recall_total-1]], self.similarities)\n",
    "                    ) + np.dot(probe, self.mcf)\n",
    "\n",
    "    def outcome_probabilities(self):\n",
    "\n",
    "        self.probabilities[0] = min(\n",
    "            self.stop_probability_scale * np.exp(self.recall_total * self.stop_probability_growth),\n",
    "            1.0 - ((self.item_count - self.recall_total) * lb),\n",
    "        )\n",
    "        self.probabilities[1:] = lb\n",
    "        self.probabilities[self.recall[: self.recall_total] + 1] = 0\n",
    "\n",
    "        if self.probabilities[0] < (1.0 - ((self.item_count - self.recall_total) * lb)):\n",
    "\n",
    "            activation = self.activations(self.context)\n",
    "            if np.sum(activation) > 0:\n",
    "                activation = np.power(activation, self.choice_sensitivity)\n",
    "                activation[activation==0] = lb\n",
    "                activation[self.recall[:self.recall_total]] = 0\n",
    "                self.probabilities[1:] = (1 - self.probabilities[0]) * activation / np.sum(activation)\n",
    "\n",
    "        return self.probabilities\n",
    "\n",
    "    def free_recall(self, steps=None):\n",
    "\n",
    "        # some amount of the pre-list context is reinstated before initiating the recall\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        # number of items to retrieve is # of items left to recall if steps is unspecified\n",
    "        if steps is None:\n",
    "            steps = self.item_count - self.recall_total\n",
    "        steps = self.recall_total + steps\n",
    "\n",
    "        # at each recall attempt,\n",
    "        while self.recall_total < steps:\n",
    "\n",
    "            # the current state of context is used as a retrieval cue\n",
    "            # we compute outcome probabilities and make choice based on distribution\n",
    "            self.outcome_probabilities()\n",
    "            if np.any(self.probabilities[1:]):\n",
    "                choice = np.sum(np.cumsum(self.probabilities) < np.random.rand(), dtype=np.int32)\n",
    "            else:\n",
    "                choice = 0\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made (0)\n",
    "            if choice == 0:\n",
    "                self.retrieving = False\n",
    "                self.context = self.preretrieval_context\n",
    "                break\n",
    "\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "\n",
    "        return self.recall[: self.recall_total]\n",
    "\n",
    "    def force_recall(self, choice=None):\n",
    "\n",
    "        if not self.retrieving:\n",
    "            self.recall = np.zeros(self.item_count, np.int32)\n",
    "            self.recall_total = 0\n",
    "            self.preretrieval_context = self.context\n",
    "            self.update_context(self.delay_drift_rate, self.delay_context_input)\n",
    "            self.update_context(self.start_drift_rate, self.start_context_input)\n",
    "            self.retrieving = True\n",
    "\n",
    "        if choice is None:\n",
    "            pass\n",
    "        elif choice > 0:\n",
    "            self.recall[self.recall_total] = choice - 1\n",
    "            self.recall_total += 1\n",
    "            self.update_context(self.recall_drift_rate, self.items[choice - 1])\n",
    "        else:\n",
    "            self.retrieving = False\n",
    "            self.context = self.preretrieval_context\n",
    "\n",
    "        return self.recall[: self.recall_total]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
