# AUTOGENERATED! DO NOT EDIT! File to edit: library/model_analysis/Data_Likelihood_Under_Model.ipynb (unless otherwise specified).

__all__ = ['murdock_data_likelihood', 'murdock_objective_function', 'lohnas_data_likelihood',
           'lohnas_objective_function', 'generate_objective_function', 'apply_and_concatenate']

# Cell

import numpy as np
from numba import njit, prange
from numba.typed import Dict
from numba.core import types

@njit(nogil=True, parallel=True)
def murdock_data_likelihood(data_to_fit, item_counts, model_class, parameters):

    result = 0.0
    for i in prange(len(item_counts)):
        item_count = item_counts[i]
        trials = data_to_fit[i]
        likelihood = np.ones((len(trials), item_count))

        model = model_class(item_count, item_count, parameters)
        model.experience(model.items)

        for trial_index in range(len(trials)):
            trial = trials[trial_index]

            model.force_recall()
            for recall_index in range(len(trial) + 1):

                # identify index of item recalled; if zero then recall is over
                if recall_index == len(trial) and len(trial) < item_count:
                    recall = 0
                else:
                    recall = trial[recall_index]

                # store probability of and simulate recall of indexed item
                likelihood[trial_index, recall_index] = \
                    model.outcome_probabilities()[recall]
                if likelihood[trial_index, recall_index] <= 0:
                    print(trial_index, recall_index, recall, trial, model.outcome_probabilities())
                    raise ValueError('Likelihood is not greater than zero')

                if recall == 0 or recall_index+1 == item_count:
                    break
                model.force_recall(recall)

            # reset model to its pre-retrieval (but post-encoding) state
            model.force_recall(0)

        result -= np.sum(np.log(likelihood))

    return result

def murdock_objective_function(data_to_fit, item_counts, model_class, fixed_parameters, free_parameters):
    """
    Configures cmr_likelihood for search over specified free/fixed parameters.
    """

    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)
    for name, value in fixed_parameters.items():
        parameters[name] = value

    def objective_function(x):
        for i in range(len(free_parameters)):
            parameters[free_parameters[i]] = x[i]
        return murdock_data_likelihood(data_to_fit, item_counts, model_class, parameters)

    return objective_function

# Cell

import numpy as np
from numba import njit, prange
from .models import Classic_CMR
from numba.typed import Dict
from numba.core import types

@njit(fastmath=True, nogil=True, parallel=True)
def lohnas_data_likelihood(trials, presentations, model_class, parameters):

    list_length = len(presentations[0])
    likelihood = np.ones((len(trials), list_length))

    for trial_index in prange(len(trials)):

        item_count = np.max(presentations[trial_index])+1
        trial = trials[trial_index]
        model = model_class(item_count, list_length, parameters)
        model.experience(model.items[presentations[trial_index]])

        model.force_recall()
        for recall_index in range(min(len(trial) + 1, item_count)):

            # identify index of item recalled; if zero then recall is over
            if recall_index == len(trial) and len(trial) < item_count:
                recall = 0
            elif trial[recall_index] == 0:
                recall = 0
            else:
                recall = presentations[trial_index][trial[recall_index]-1] + 1

            # store probability of and simulate recalling item with this index
            likelihood[trial_index, recall_index] = \
                model.outcome_probabilities()[recall]
            if likelihood[trial_index, recall_index] <= 0:
                print(trial_index, recall_index, recall, trial, likelihood[trial_index, recall_index], model.outcome_probabilities())
                raise ValueError('Likelihood is not greater than zero')

            if recall == 0 or recall_index+1 == item_count:
                break
            model.force_recall(recall)

        # reset model to its pre-retrieval (but post-encoding) state
        model.force_recall(0)

    return -np.sum(np.log(likelihood))

def lohnas_objective_function(data_to_fit, presentations, model_class, fixed_parameters, free_parameters):

    """
    Generates and returns an objective function for input to support search
    through parameter space for model fit using an optimization function.

    Returns a function that accepts a vector x specifying arbitrary values for
    free parameters and returns evaluation of likelihood using the model
    class, all parameters, and provided data.
    """

    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)
    for name, value in fixed_parameters.items():
        parameters[name] = value

    def objective_function(x):
        for i in range(len(free_parameters)):
            parameters[free_parameters[i]] = x[i]
        return lohnas_data_likelihood(data_to_fit, presentations, model_class, parameters)

    return objective_function

# Cell

from numba.typed import List
from .datasets import events_metadata

def generate_objective_function(
    trials, presentations, list_lengths, model_class, fixed_parameters, free_parameters):

    list_lengths = [list_lengths[i] for i in range(len(list_lengths)) if len(trials[i]) > 0]
    trials = [t for t in trials if len(t) > 0]
    presentations = [p for p in presentations if len(p) > 0]

    # generate function based on whether list contains item repetitions or not
    if len(trials) == 1:
        if (presentations[0] == np.arange(list_lengths[0])).all():
            return murdock_objective_function(
                List(trials), List(list_lengths), model_class, fixed_parameters, free_parameters)
        else:
            return lohnas_objective_function(
                trials[0], presentations[0], model_class, fixed_parameters, free_parameters)
    elif len(trials) > 1:
        return murdock_objective_function(
            List(trials), List(list_lengths), model_class, fixed_parameters, free_parameters)
    else:
        raise ValueError("No trials provided.")

# Cell
import pandas as pd

def apply_and_concatenate(function, dfs, contrast_name='contrast', labels='AB'):
    """
    Concatenates the results of a function applied to two dataframes and creates a new column identifying the contrast.
    """
    return pd.concat([function(df) for df in dfs], keys=labels, names=[contrast_name]).reset_index()
