# AUTOGENERATED! DO NOT EDIT! File to edit: library/model_analysis/Data_Likelihood_Under_Model.ipynb (unless otherwise specified).

__all__ = ['murdock_data_likelihood', 'murdock_objective_function', 'lb', 'lohnas_data_likelihood',
           'lohnas_objective_function', 'lb', 'semantic_data_likelihood', 'semantic_objective_function',
           'bifurcated_semantic_objective_function', 'lb', 'generate_objective_function',
           'generate_bifurcated_objective_function', 'model_weights', 'apply_and_concatenate']

# Cell

import numpy as np
from numba import njit, prange
from numba.typed import Dict
from numba.core import types
lb = np.finfo(float).eps

@njit(nogil=True, parallel=True)
def murdock_data_likelihood(data_to_fit, item_counts, model_class, parameters):

    result = 0.0
    for i in prange(len(item_counts)):
        item_count = item_counts[i]
        trials = data_to_fit[i]
        likelihood = np.ones((len(trials), item_count))

        model = model_class(item_count, item_count, parameters)
        model.experience(model.items)

        for trial_index in range(len(trials)):
            trial = trials[trial_index]

            model.force_recall()
            for recall_index in range(len(trial) + 1):

                # identify index of item recalled; if zero then recall is over
                if recall_index == len(trial) and len(trial) < item_count:
                    recall = 0
                else:
                    recall = trial[recall_index]

                # store probability of and simulate recall of indexed item
                likelihood[trial_index, recall_index] = \
                    model.outcome_probabilities()[recall]
                if likelihood[trial_index, recall_index] <= 0:
                    print('Likelihood is not greater than zero', trial_index, recall_index, recall, trial, model.outcome_probabilities())
                    likelihood[trial_index, recall_index] = lb

                if recall == 0 or recall_index+1 == item_count:
                    break
                model.force_recall(recall)

            # reset model to its pre-retrieval (but post-encoding) state
            model.force_recall(0)

        result -= np.sum(np.log(likelihood))

    return result

def murdock_objective_function(data_to_fit, item_counts, model_class, fixed_parameters, free_parameters):
    """
    Configures cmr_likelihood for search over specified free/fixed parameters.
    """

    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)
    for name, value in fixed_parameters.items():
        parameters[name] = value

    def objective_function(x):
        for i in range(len(free_parameters)):
            parameters[free_parameters[i]] = x[i]
        return murdock_data_likelihood(data_to_fit, item_counts, model_class, parameters)

    return objective_function

# Cell

import numpy as np
from numba import njit, prange
from numba.typed import Dict
from numba.core import types
lb = np.finfo(float).eps

@njit(nogil=True, parallel=True)
def lohnas_data_likelihood(trials, presentations, model_class, parameters):

    list_length = len(presentations[0])
    likelihood = np.ones((len(trials), list_length))

    for trial_index in prange(len(trials)):

        item_count = np.max(presentations[trial_index])+1
        trial = trials[trial_index]
        model = model_class(item_count, list_length, parameters)
        model.experience(model.items[presentations[trial_index]])

        model.force_recall()
        for recall_index in range(min(len(trial) + 1, item_count)):

            # identify index of item recalled; if zero then recall is over
            if recall_index == len(trial) and len(trial) < item_count:
                recall = 0
            elif trial[recall_index] == 0:
                recall = 0
            else:
                recall = presentations[trial_index][trial[recall_index]-1] + 1

            # store probability of and simulate recalling item with this index
            likelihood[trial_index, recall_index] = \
                model.outcome_probabilities()[recall]
            if likelihood[trial_index, recall_index] <= 0:
                #print('Likelihood is not greater than zero', trial_index, recall_index, recall, trial, model.outcome_probabilities())
                likelihood[trial_index, recall_index] = lb

            if recall == 0 or recall_index+1 == item_count:
                break
            model.force_recall(recall)

        # reset model to its pre-retrieval (but post-encoding) state
        model.force_recall(0)

    return -np.sum(np.log(likelihood))

def lohnas_objective_function(data_to_fit, presentations, model_class, fixed_parameters, free_parameters):

    """
    Generates and returns an objective function for input to support search
    through parameter space for model fit using an optimization function.

    Returns a function that accepts a vector x specifying arbitrary values for
    free parameters and returns evaluation of likelihood using the model
    class, all parameters, and provided data.
    """

    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)
    for name, value in fixed_parameters.items():
        parameters[name] = value

    def objective_function(x):
        for i in range(len(free_parameters)):
            parameters[free_parameters[i]] = x[i]
        return lohnas_data_likelihood(data_to_fit, presentations, model_class, parameters)

    return objective_function

# Cell

import numpy as np
from numba import njit, prange
from numba.typed import Dict
from numba.core import types
lb = np.finfo(float).eps

@njit(nogil=True, parallel=True)
def semantic_data_likelihood(data_to_fit, item_counts, similarities, model_class, parameters):

    result = 0.0
    for i in prange(len(item_counts)):
        item_count = item_counts[i]
        trials = data_to_fit[i]
        similarity_matrix = similarities[i]
        likelihood = np.ones((len(trials), item_count))

        for trial_index in range(len(trials)):

            model = model_class(similarity_matrix[trial_index], item_count, parameters)
            model.experience(model.items)
            trial = trials[trial_index]

            model.force_recall()
            for recall_index in range(len(trial) + 1):

                # identify index of item recalled; if zero then recall is over
                if recall_index == len(trial) and len(trial) < item_count:
                    recall = 0
                else:
                    recall = trial[recall_index]

                # store probability of and simulate recall of indexed item
                likelihood[trial_index, recall_index] = \
                    model.outcome_probabilities()[recall]
                if likelihood[trial_index, recall_index] <= 0:
                    #print('Likelihood is not greater than zero', trial_index, recall_index, recall, trial, model.outcome_probabilities())
                    likelihood[trial_index, recall_index] = lb

                if recall == 0 or recall_index+1 == item_count:
                    break
                model.force_recall(recall)

            # reset model to its pre-retrieval (but post-encoding) state
            model.force_recall(0)

        result -= np.sum(np.log(likelihood))

    return result

def semantic_objective_function(
    data_to_fit, item_counts, similarities, model_class, fixed_parameters, free_parameters):
    """
    Configures cmr_likelihood for search over specified free/fixed parameters.
    """

    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)
    for name, value in fixed_parameters.items():
        parameters[name] = value

    def objective_function(x):
        for i in range(len(free_parameters)):
            parameters[free_parameters[i]] = x[i]
        return semantic_data_likelihood(data_to_fit, item_counts, similarities, model_class, parameters)

    return objective_function

def bifurcated_semantic_objective_function(
    data_to_fit, item_counts, similarities, model_class, fixed_parameters, free_parameters):
    """
    Configures cmr_likelihood for search over specified free/fixed parameters.
    """

    switch_options = [0.0, 1.0]
    parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)
    for name, value in fixed_parameters.items():
        parameters[name] = value

    def objective_function(x):
        for i in range(len(free_parameters)):
            parameters[free_parameters[i]] = x[i]

        total = 0.0
        for i in range(len(switch_options)):
            parameters['switch'] = switch_options[i]
            total += semantic_data_likelihood(
                data_to_fit[i], item_counts[i], similarities[i], model_class, parameters)

        return total

    return objective_function

# Cell

from numba.typed import List
from .datasets import events_metadata
from sentence_transformers import util

def generate_objective_function(
    trials, specific_presentations, list_lengths, model_class, fixed_parameters, free_parameters,
    string_embeddings=None, specific_string_ids=None, switch_mask=None):

    if switch_mask is not None:
        return generate_bifurcated_objective_function(
            trials, specific_presentations, list_lengths, model_class, fixed_parameters, free_parameters,
            string_embeddings, specific_string_ids, switch_mask)

    list_lengths = [list_lengths[i] for i in range(len(list_lengths)) if len(trials[i]) > 0]
    trials = [t for t in trials if len(t) > 0]
    specific_presentations = [p for p in specific_presentations if len(p) > 0]
    specific_string_ids = [i for i in specific_string_ids if len(i) > 0]

    # generate function based on whether list contains item repetitions or not and language model provided
    if string_embeddings is None:
        if len(trials) == 1:
            if (specific_presentations[0] == np.arange(list_lengths[0])).all():
                return murdock_objective_function(
                    List(trials), List(list_lengths), model_class, fixed_parameters, free_parameters)
            else:
                return lohnas_objective_function(
                    trials[0], specific_presentations[0], model_class, fixed_parameters, free_parameters)
        elif len(trials) > 1:
            return murdock_objective_function(
                List(trials), List(list_lengths), model_class, fixed_parameters, free_parameters)
        else:
            raise ValueError("No trials provided.")
    else:

        # we generate similiarity matrix for each trial in each list length
        specific_similarities = []
        for ll_index, list_length in enumerate(list_lengths):
            specific_similarities.append(np.zeros((len(trials[ll_index]), list_length, list_length)))

            for trial_index in range(len(trials[ll_index])):
                trial_embeddings = string_embeddings[specific_string_ids[ll_index][trial_index]]
                cosine_scores = util.pytorch_cos_sim(trial_embeddings, trial_embeddings).numpy() + 1
                np.fill_diagonal(cosine_scores, 0)
                specific_similarities[-1][trial_index] = cosine_scores

        return semantic_objective_function(
            List(trials), List(list_lengths), List(specific_similarities), model_class, fixed_parameters, free_parameters)

def generate_bifurcated_objective_function(
    trials, presentations, list_lengths, model_class, fixed_parameters, free_parameters,
    string_embeddings, string_ids, switch_mask):

    all_trials = []
    all_similarities = []
    all_list_lengths = []

    for flip_switch in [False, True]:

        specific_switch_mask = switch_mask if flip_switch else [
            np.logical_not(switch_mask[i]) for i in range(len(switch_mask))]

        specific_trials = [t[specific_switch_mask[i]] for i,t in enumerate(trials)]
        specific_presentations = [p[specific_switch_mask[i]] for i,p in enumerate(presentations)]
        specific_string_ids = [s[specific_switch_mask[i]] for i,s in enumerate(string_ids)]
        list_lengths = [list_lengths[i] for i in range(len(list_lengths)) if len(trials[i]) > 0]
        specific_trials = [t for t in specific_trials if len(t) > 0]
        specific_presentations = [p for p in specific_presentations if len(p) > 0]
        specific_string_ids = [i for i in specific_string_ids if len(i) > 0]

        # we generate similiarity matrix for each trial in each list length
        specific_similarities = []
        for ll_index, list_length in enumerate(list_lengths):
            specific_similarities.append(np.zeros((len(specific_trials[ll_index]), list_length, list_length)))

            for trial_index in range(len(specific_trials[ll_index])):
                trial_embeddings = string_embeddings[specific_string_ids[ll_index][trial_index]]
                cosine_scores = util.pytorch_cos_sim(trial_embeddings, trial_embeddings).numpy() + 1
                np.fill_diagonal(cosine_scores, 0)
                specific_similarities[-1][trial_index] = cosine_scores

        all_trials.append(List(specific_trials))
        all_similarities.append(List(specific_similarities))
        all_list_lengths.append(List(list_lengths))

    return bifurcated_semantic_objective_function(
        List(all_trials), List(all_list_lengths), List(all_similarities), model_class, fixed_parameters, free_parameters)

# Cell

import numpy as np

def model_weights(positive_log_likelihoods, number_parameters, N):
    AIC = 2 * positive_log_likelihoods + 2 * number_parameters
    AICc = AIC #+ (2*np.power(number_parameters, 2) + 2 * number_parameters) / (N - number_parameters - 2)
    AICd = AIC - np.min(AICc)
    #return AICd
    AICw = np.exp(-.5 * AICd) / np.sum(np.exp(-.5 * AICd))
    return AICw

# Cell
import pandas as pd

def apply_and_concatenate(function, dfs, contrast_name='contrast', labels='AB'):
    """
    Concatenates the results of a function applied to two dataframes and creates a new column identifying the contrast.
    """
    return pd.concat([function(df) for df in dfs], keys=labels, names=[contrast_name]).reset_index()
