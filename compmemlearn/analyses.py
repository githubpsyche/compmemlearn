# AUTOGENERATED! DO NOT EDIT! File to edit: library/analyses/Serial_Position_Effect_in_Repetition_Datasets.ipynb (unless otherwise specified).

__all__ = ['alternative_contiguity', 'fast_csp', 'plot_csp', 'fast_crp', 'plot_crp', 'fast_mixed_crp', 'flex_mixed_crp',
           'plot_flex_crp', 'randomize_dataset', 'indices_of_repeated_items', 'alternative_contiguity_test',
           'alternative_contiguity_control', 'sim_alternative_contiguity_test', 'fast_pfr', 'plot_pfr',
           'fast_mixed_pfr', 'flex_mixed_pfr', 'plot_flex_pfr', 'fast_rpl', 'plot_rpl', 'rpl', 'fast_spc', 'plot_spc',
           'recall_by_second_study_position', 'recall_by_all_study_positions', 'fast_mixed_spc', 'flex_mixed_spc',
           'plot_flex_spc']

# Cell

from numba import njit
from numba import int32
import numpy as np

@njit(nogil=True)
def alternative_contiguity(trials, presentations, lag_threshold = 3, max_repeats = 2):

    list_length = len(presentations[0])
    lag_range = list_length - 1
    total_actual_lags = np.zeros((max_repeats, lag_range * 2 + 1)) # extended dimension to split by pres positions
    total_possible_lags = np.zeros((max_repeats, lag_range * 2 + 1))
    terminus = np.sum(trials != 0, axis=1) # number of recalls per trial
    recall_by_study_position = recall_by_all_study_positions(trials, presentations, max_repeats)

    for trial_index in range(len(trials)):
        previous_item = 0
        item_count = np.max(presentations[trial_index]) + 1
        possible_items = np.arange(item_count) # initial pool of possible recalls, 1-indexed
        possible_positions = np.zeros((item_count, max_repeats), dtype=int32)

        # we track possible positions using presentations and alt_presentations
        for item in range(item_count):
            pos = np.nonzero(presentations[trial_index] == item)[0] + 1
            possible_positions[item, :len(pos)] = pos

        for recall_index in range(terminus[trial_index]):

            current_item = presentations[trial_index][trials[trial_index, recall_index]-1]

            # track possible and actual lags;
            # focus only on transitions from items with > 1 study positions
            # and only when those multiple study positions have lag over lag
            if recall_index > 0 and np.count_nonzero(
                possible_positions[previous_item]) > 1 and (
                possible_positions[previous_item][1] - possible_positions[previous_item][0] >= lag_threshold):

                # item indices don't help track lags anymore
                # so more complex calculation needed to identify possible lags given previous item
                current_index = np.nonzero(possible_items==current_item)[0]

                index = 0
                for x in range(len(recall_by_study_position)):
                    for y in range(len(recall_by_study_position)):
                        if possible_positions[previous_item, y] > 0:

                            possible_lags = possible_positions[
                                possible_items, x] - possible_positions[previous_item, y]

                            # if tracked position is 0, then we don't actually want to count it in our lags
                            possible_lags[possible_positions[possible_items, x] == 0] = 0

                            # we track actual lag at each iteration
                            actual_lag = possible_lags[current_index] + lag_range
                            total_actual_lags[y][actual_lag] += 1

                            # we track possible lag at each iteration
                            possible_lags += lag_range
                            total_possible_lags[y][possible_lags] += 1

                        index += 1

            # update pool to exclude recalled item (updated to still identify 1-indexed item)
            previous_item = current_item
            possible_items = possible_items[possible_items != previous_item]


    # small correction to avoid nans and commit to excluding multiply-tracked single presentations
    total_actual_lags[:, lag_range] = 0
    for i in range(max_repeats):
        total_possible_lags[i][total_actual_lags[i]==0] += 1

    return total_actual_lags/total_possible_lags

# Cell

from numba import njit
import numpy as np

@njit(fastmath=True, nogil=True)
def fast_csp(trials, item_count):

    # numerator is number of trials with zero in current column position
    numerator = np.zeros(item_count+1)

    # denominator is number of trials without zero in previous column positions
    denominator = np.zeros(item_count+1)

    stop_positions = trials == 0
    for i in range(len(trials)):

        # add 1 to index of final recall
        numerator[np.argmax(stop_positions[i])] += 1

        # add 1 to each index up through final recall
        denominator[:np.argmax(stop_positions[i])+1] += 1

    denominator[denominator==0] += 1
    return numerator/denominator

# Cell
import seaborn as sns
from psifr import fr

def plot_csp(data, **facet_kws):

    trials = pd.pivot_table(
        data, index=['subject', 'list'],
        columns=['output'], values='input',
        fill_value=0).to_numpy()

    sns.lineplot(
        data=csp(data, trials),
        x='output', y='prob', **facet_kws)

# Cell

from numba import njit
import numpy as np

@njit(fastmath=True, nogil=True)
def fast_crp(trials, item_count):

    lag_range = item_count - 1
    total_actual_lags = np.zeros(lag_range * 2 + 1)
    total_possible_lags = np.zeros(lag_range * 2 + 1)
    terminus = np.sum(trials != 0, axis=1)

    # compute actual serial lag b/t recalls
    actual_lags = trials[:, 1:] - trials[:, :-1]
    actual_lags += lag_range

    # tabulate bin totals for actual and possible lags
    for i in range(len(trials)):
        possible_items = np.arange(item_count) + 1
        previous_item = 0

        for recall_index in range(terminus[i]):

            # track possible and actual lags
            if recall_index > 0:
                total_actual_lags[actual_lags[i, recall_index-1]] += 1

                # exploit equivalence b/t item index and study position to track possible lags
                possible_lags = possible_items - previous_item
                possible_lags += lag_range
                total_possible_lags[possible_lags] += 1

            # update pool of possible items to exclude recalled item
            previous_item = trials[i, recall_index]
            possible_items = possible_items[possible_items != previous_item]

    # small correction to avoid nans
    total_possible_lags[total_actual_lags==0] += 1

    return total_actual_lags/total_possible_lags

# Cell

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from .datasets import events_metadata, generate_trial_mask


def plot_crp(data, trial_query, contrast_name='', labels=None, axis=None, max_lag=5):

    if axis is None:
        plt.figure()
        axis = plt.gca()

    if labels is None:
        labels = [''] * len(data)

    result = []
    for data_index, events in enumerate(data):

        # generate and subset trials array and list of list_lengths based on trial_query
        trials, list_lengths = events_metadata(events)[:2]
        trial_mask = generate_trial_mask(events, trial_query)
        chose = [i for i in range(len(trial_mask)) if np.sum(trial_mask[i]) != 0]
        assert(len(chose) == 1)
        chose = chose[0]
        trials = trials[chose]
        list_length = list_lengths[chose]
        trial_mask = trial_mask[chose]

        lag_interval = np.arange(-max_lag, max_lag+1)
        list_length = list_lengths[0]
        lag_range = list_length -1
        for subject in pd.unique(events.subject):
            subject_specific_trial_mask = np.logical_and(
                generate_trial_mask(events, f"subject == {subject}")[chose], trial_mask
            )

            #for i in range(len(subject_specific_trial_mask)):
            if np.sum(subject_specific_trial_mask) == 0:
                continue

            res = fast_crp(trials[subject_specific_trial_mask], list_length)
            res[lag_range] = np.nan
            result.append(pd.DataFrame.from_dict(
                {
                    "subject": subject,
                    "lag": lag_interval,
                    "prob": res[lag_range-max_lag:lag_range+max_lag+1],
                    contrast_name: labels[data_index],
                }
            ))

    result = pd.concat(result).reset_index()

    color = None if len(data) == 1 else 'blue'
    filt_neg = f'{-max_lag} <= lag < 0'
    filt_pos = f'0 < lag <= {max_lag}'

    sns.lineplot(ax=axis, data=result.query(filt_neg), x='lag', y='prob',
                err_style='bars', hue=contrast_name, legend=False, color=color)
    sns.lineplot(ax=axis, data=result.query(filt_pos), x='lag', y='prob',
                err_style='bars', hue=contrast_name, color=color)
    axis.set(xlabel='Item\'s Lag In Study List From Last Recalled Item', ylabel='Conditional Recall Rate')
    axis.set_xticks(np.arange(-max_lag, max_lag+1, 1))
    axis.set_ylim((0, 1))

    if contrast_name:
        axis.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)

    return axis

# Cell

from numba import njit
from numba import int32
import numpy as np
from .datasets import find_first


@njit(nogil=True)
def fast_mixed_crp(trials, presentations):

    list_length = len(presentations[0])
    lag_range = list_length - 1
    total_actual_lags = np.zeros(lag_range * 2 + 1)
    total_possible_lags = np.zeros(lag_range * 2 + 1)
    terminus = np.sum(trials != 0, axis=1) # number of recalls per trial

    # compute actual serial lag b/t recalls, considering all possible positions
    alt_presentations = np.fliplr(presentations)
    alt_trials = recall_by_second_study_position(trials, presentations)
    actual_lags = np.zeros((4, len(trials), len(trials[0])-1), dtype=int32)
    actual_lags[0] = trials[:, 1:] - trials[:, :-1]
    actual_lags[1] = trials[:, 1:] - alt_trials[:, :-1]
    actual_lags[2] = alt_trials[:, 1:] - trials[:, :-1]
    actual_lags[3] = alt_trials[:, 1:] - alt_trials[:, :-1]

    # if actual[0, x, y] == actual[2, x, y] (or 1, 3) then lagged-to item has 1 presentation
    # if actual[0, x, y] == actual[1, x, y] (or 2, 3 respectively) then lagged-from item has 1 pres
    # avoid counting single presentations twice by giving those lags a value of 0
    previous_item_equivalence = actual_lags[0] == actual_lags[2]
    current_item_equivalence = actual_lags[0] == actual_lags[1]
    either_item_equivalence = np.logical_or(previous_item_equivalence, current_item_equivalence)

    for i in range(len(actual_lags[0])):
        actual_lags[1, i][current_item_equivalence[i]] = 0
        actual_lags[2, i][previous_item_equivalence[i]] = 0
        actual_lags[3, i][either_item_equivalence[i]] = 0

    # we add lag_range to have result identify indices in total_ to bin counts
    actual_lags += lag_range

    for trial_index in range(len(trials)):

        previous_item = 0
        item_count = np.max(presentations[trial_index]) + 1
        possible_items = np.arange(item_count) # initial pool of possible recalls, 1-indexed
        possible_positions = np.zeros((item_count, 2))

        # we track possible positions using presentations and alt_presentations
        for item in range(item_count):
            possible_positions[item, 0] = find_first(item, presentations[trial_index])
            possible_positions[item, 1] = list_length - find_first(item, alt_presentations[trial_index]) -1

        for recall_index in range(terminus[trial_index]):

            # track possible and actual lags
            if recall_index > 0:

                # we add to actual_lags total for each lag transition made for this recall
                total_actual_lags[actual_lags[:, trial_index, recall_index-1]] += 1

                # item indices don't help track lags anymore
                # so more complex calculation needed to identify possible lags given previous item
                possible_lags = np.zeros((4, len(possible_items)), dtype=int32)
                possible_lags[0] = possible_positions[possible_items, 0] - possible_positions[previous_item, 0]
                possible_lags[1] = possible_positions[possible_items, 0] - possible_positions[previous_item, 1]
                possible_lags[2] = possible_positions[possible_items, 1] - possible_positions[previous_item, 0]
                possible_lags[3] = possible_positions[possible_items, 1] - possible_positions[previous_item, 1]

                # avoid redundant counting of single presentations
                previous_item_equivalence = possible_lags[0] == possible_lags[2]
                current_item_equivalence = possible_lags[0] == possible_lags[1]
                either_item_equivalence = np.logical_or(previous_item_equivalence, current_item_equivalence)
                possible_lags[1][current_item_equivalence] = 0
                possible_lags[2][previous_item_equivalence] = 0
                possible_lags[3][either_item_equivalence] = 0

                possible_lags += lag_range
                total_possible_lags[possible_lags.flatten()] += 1

            # update pool to exclude recalled item (updated to still identify 1-indexed item)
            previous_item = presentations[trial_index][trials[trial_index, recall_index]-1]
            possible_items = possible_items[possible_items != previous_item]

    # small correction to avoid nans and commit to excluding multiply-tracked single presentations
    total_actual_lags[lag_range] = 0
    total_possible_lags[total_actual_lags==0] += 1

    return total_actual_lags/total_possible_lags

# Cell

@njit(nogil=True)
def flex_mixed_crp(trials, presentations, max_repeats=2):

    list_length = len(presentations[0])
    lag_range = list_length - 1
    total_actual_lags = np.zeros(lag_range * 2 + 1)
    total_possible_lags = np.zeros(lag_range * 2 + 1)
    terminus = np.sum(trials != 0, axis=1) # number of recalls per trial
    recall_by_study_position = recall_by_all_study_positions(trials, presentations, max_repeats)

    for trial_index in range(len(trials)):

        previous_item = 0
        item_count = np.max(presentations[trial_index]) + 1
        possible_items = np.arange(item_count) # initial pool of possible recalls, 1-indexed
        possible_positions = np.zeros((item_count, max_repeats), dtype=int32)

        # we track possible positions using presentations and alt_presentations
        for item in range(item_count):
            pos = np.nonzero(presentations[trial_index] == item)[0] + 1
            possible_positions[item, :len(pos)] = pos

        for recall_index in range(terminus[trial_index]):

            current_item = presentations[trial_index][trials[trial_index, recall_index]-1]

            # track possible and actual lags
            if recall_index > 0:

                # item indices don't help track lags anymore
                # so more complex calculation needed to identify possible lags given previous item
                current_index = np.nonzero(possible_items==current_item)[0]
                possible_lags = np.zeros((len(recall_by_study_position) ** 2, len(possible_items)), dtype=int32)

                index = 0
                for x in range(len(recall_by_study_position)):
                    for y in range(len(recall_by_study_position)):
                        if possible_positions[previous_item, y] > 0:

                            possible_lags[index] = possible_positions[
                                possible_items, x] - possible_positions[previous_item, y]

                            # if tracked position is 0, then we don't actually want to count it in our lags
                            possible_lags[index][possible_positions[possible_items, x] == 0] = 0

                        index += 1

                possible_lags += lag_range
                total_actual_lags[possible_lags[:, current_index].flatten()] += 1
                total_possible_lags[possible_lags.flatten()] += 1


            # update pool to exclude recalled item (updated to still identify 1-indexed item)
            previous_item = current_item
            possible_items = possible_items[possible_items != previous_item]

    # small correction to avoid nans and commit to excluding multiply-tracked single presentations
    total_actual_lags[lag_range] = 0
    total_possible_lags[total_actual_lags==0] += 1

    return total_actual_lags/total_possible_lags

# Cell

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from .datasets import events_metadata, generate_trial_mask


def plot_flex_crp(data, trial_query, contrast_name='', labels=None, axis=None, max_lag=5):

    if axis is None:
        plt.figure()
        axis = plt.gca()

    if labels is None:
        labels = [''] * len(data)

    result = []
    for data_index, events in enumerate(data):

        # generate and subset trials array and list of list_lengths based on trial_query
        trials, list_lengths, presentations = events_metadata(events)
        trial_mask = generate_trial_mask(events, trial_query)
        chose = [i for i in range(len(trial_mask)) if np.sum(trial_mask[i]) != 0]
        assert(len(chose) == 1)
        chose = chose[0]
        trials = trials[chose]
        list_length = list_lengths[chose]
        presentations = presentations[chose]
        trial_mask = trial_mask[chose]

        lag_interval = np.arange(-max_lag, max_lag+1)
        list_length = list_lengths[0]
        lag_range = list_length -1
        for subject in pd.unique(events.subject):
            subject_specific_trial_mask = np.logical_and(
                generate_trial_mask(events, f"subject == {subject}")[chose], trial_mask
            )

            #for i in range(len(subject_specific_trial_mask)):
            if np.sum(subject_specific_trial_mask) == 0:
                continue

            res = flex_mixed_crp(trials[subject_specific_trial_mask], presentations[subject_specific_trial_mask])
            res[lag_range] = np.nan
            result.append(pd.DataFrame.from_dict(
                {
                    "subject": subject,
                    "lag": lag_interval,
                    "prob": res[lag_range-max_lag:lag_range+max_lag+1],
                    contrast_name: labels[data_index],
                }
            ))

    result = pd.concat(result).reset_index()

    color = None if len(data) == 1 else 'blue'
    filt_neg = f'{-max_lag} <= lag < 0'
    filt_pos = f'0 < lag <= {max_lag}'

    sns.lineplot(ax=axis, data=result.query(filt_neg), x='lag', y='prob',
                err_style='bars', hue=contrast_name, legend=False, color=color)
    sns.lineplot(ax=axis, data=result.query(filt_pos), x='lag', y='prob',
                err_style='bars', hue=contrast_name, color=color)
    axis.set(xlabel='Item\'s Lag In Study List From Last Recalled Item', ylabel='Conditional Recall Rate')
    axis.set_xticks(np.arange(-max_lag, max_lag+1, 1))
    axis.set_ylim((0, 1))

    if contrast_name:
        axis.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)

    return axis

# Cell

from numba import njit, prange
import numpy as np

@njit(parallel=True)
def randomize_dataset(recall_rate_by_serial_position, sample_size):
    """
    To control for serial position effects of repeated items,
    analyses are often performed on randomized recall sequences with recall probabilities
    matched to the serial position curve of controls lists. Recall of each item is then
    calculated randomly and independently across trials.
    """

    samples = np.random.rand(sample_size, len(recall_rate_by_serial_position)) < recall_rate_by_serial_position
    result = np.zeros((sample_size, len(recall_rate_by_serial_position)))

    for i in prange(sample_size):
        sample = samples[i].nonzero()[0] + 1
        np.random.shuffle(sample)
        result[i, :len(sample)] = sample

    return result


# Cell

import pandas as pd
import numpy as np

def indices_of_repeated_items(presentation_sequence):

    values, counts = np.unique(presentation_sequence, return_counts=True)
    repeated_items = {v: np.where(presentation_sequence == v)[0] for v in values if counts[v] > 1}

    return {key:repeated_items[key] for key in repeated_items}


def alternative_contiguity_test(mixed_presentations, mixed_recalls, lag_threshold, repetition_count):
    relevant_lags = list(range(-int(lag_threshold/2), int(lag_threshold/2+1)))
    del relevant_lags[int(lag_threshold/2)]

    actual_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]
    possible_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]

    for trial_index in range(len(mixed_presentations)):

        # sequence of item indices ordered as they were studied
        presentation = mixed_presentations[trial_index]

        # sequence of initial study positions ordered as they were recalled
        trial_by_study_position = mixed_recalls[trial_index]

        # sequence of item indices ordered as they were recalled
        trial_by_item_index = presentation[trial_by_study_position-1][:np.size(np.nonzero(trial_by_study_position))]

        # {item_index: [presentation indices]} for each repeated item in presentation sequence spaced by >4 items
        i_and_j = indices_of_repeated_items(presentation)

        # then for each unique repeated item in the study list,
        for repeated_item in i_and_j:

            # search for relevant item(s) in recall sequence and skip if not found
            look_for = trial_by_item_index == presentation[i_and_j[repeated_item][0]]
            for k in range(1, repetition_count):
                look_for = np.logical_or(
                    look_for, trial_by_item_index == presentation[i_and_j[repeated_item][k]])
            recall_positions = np.where(look_for)[0]

            if np.size(recall_positions) == 0:
                continue

            # check each position the item was observed (always just 1 position; we loop for parallelism w control)
            for recall_position in recall_positions:

                # also skip if no successive recall was made,
                if np.size(trial_by_item_index) == recall_position + 1:
                    continue

                # build list of study positions for items recalled up to repeated item
                prior_lags = [[] for each in range(repetition_count)]
                for i in range(recall_position):

                    # if considered item is also repeated, we track lags wrt to all presentations
                    if trial_by_item_index[i] in i_and_j:
                        for considered in range(len(i_and_j[trial_by_item_index[i]])):
                            for focal in range(repetition_count):
                                prior_lags[focal].append(
                                    int(i_and_j[trial_by_item_index[i]][considered] - i_and_j[repeated_item][focal]))
                    else:
                        for k in range(repetition_count):
                            prior_lags[k].append(int(trial_by_study_position[i] - i_and_j[repeated_item][k]))

                # transition of a given lag is possible if lag not present in prior_lags
                for lag in relevant_lags:
                    for k in range(repetition_count):

                        # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][-1] < lag_threshold
                        if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):
                            continue

                        if lag not in prior_lags[k]:
                            possible_lags[k][relevant_lags.index(lag)] += 1

                # track each serial lag of actually transitioned-to item
                if trial_by_item_index[recall_position+1] in i_and_j:
                    positions = i_and_j[trial_by_item_index[recall_position+1]]
                    for transition_study_position in positions:
                        for k in range(repetition_count):

                            # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold
                            if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):
                                continue

                            lag = int(transition_study_position - i_and_j[repeated_item][k])
                            if lag in relevant_lags:
                                actual_lags[k][relevant_lags.index(lag)] += 1
                else:
                    transition_study_position = trial_by_study_position[recall_position+1]-1
                    for k in range(repetition_count):

                        # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold
                        if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):
                            continue

                        lag = int(transition_study_position-i_and_j[repeated_item][k])
                        if lag in relevant_lags:
                            actual_lags[k][relevant_lags.index(lag)] += 1

    result = []
    for k in range(repetition_count):

        for i in range(len(possible_lags[k])):
            if possible_lags[k][i] == 0:
                possible_lags[k][i] += 1

        result.append(pd.DataFrame(
            {'lag': relevant_lags, 'prob': np.divide(actual_lags[k], possible_lags[k]),
            'actual': actual_lags[k], 'possible': possible_lags[k]}))

    return pd.concat(result, keys=['From Position {}'.format(i+1) for i in range(repetition_count)], names=['locus'])


def alternative_contiguity_control(
    mixed_presentations, control_presentations, control_recalls, lag_threshold, repetition_count):
    relevant_lags = list(range(-int(lag_threshold/2), int(lag_threshold/2+1)))
    del relevant_lags[int(lag_threshold/2)]

    actual_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]
    possible_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]

    for trial_index in range(len(mixed_presentations)):

        # sequence of item indices ordered as they were studied
        presentation = mixed_presentations[trial_index]
        control_presentation = control_presentations[trial_index]

        # sequence of initial study positions ordered as they were recalled
        trial_by_study_position = control_recalls[trial_index]

        # sequence of item indices ordered as they were recalled
        trial_by_item_index = control_presentation[trial_by_study_position-1][:np.size(np.nonzero(trial_by_study_position))]

        # {item_index: [presentation indices]} for each repeated item in presentation sequence spaced by >4 items
        i_and_j = indices_of_repeated_items(presentation)

        # then for each unique repeated item in the study list,
        for repeated_item in i_and_j:

            # search for relevant item(s) in recall sequence and skip if not found
            look_for = trial_by_item_index == control_presentation[i_and_j[repeated_item][0]]
            for k in range(1, repetition_count):
                look_for = np.logical_or(
                    look_for, trial_by_item_index == control_presentation[i_and_j[repeated_item][k]])
            recall_positions = np.where(look_for)[0]

            for recall_position in recall_positions:

                # also skip if no successive recall was made,
                if np.size(trial_by_item_index) == recall_position + 1:
                    continue

                # build list of study positions for items recalled up to repeated item
                prior_lags = [[] for each in range(repetition_count)]
                for i in range(recall_position):
                    if trial_by_item_index[i] in i_and_j:
                        for considered in range(len(i_and_j[trial_by_item_index[i]])):
                            for focal in range(repetition_count):
                                prior_lags[focal].append(
                                    int(i_and_j[trial_by_item_index[i]][considered] - i_and_j[repeated_item][focal]))
                    else:
                        for k in range(repetition_count):
                            prior_lags[k].append(int(trial_by_study_position[i] - i_and_j[repeated_item][k]))

                # transition of a given lag is possible if lag not present in prior_lags
                for lag in relevant_lags:
                    for k in range(repetition_count):
                        if lag not in prior_lags[k]:
                            possible_lags[k][relevant_lags.index(lag)] += 1

                # track each serial lag of actually transitioned-to item
                if trial_by_item_index[recall_position+1] in i_and_j:
                    positions = i_and_j[trial_by_item_index[recall_position+1]]
                    for transition_study_position in positions:
                        for k in range(repetition_count):
                            lag = int(transition_study_position - i_and_j[repeated_item][k])
                            if lag in relevant_lags:
                                actual_lags[k][relevant_lags.index(lag)] += 1
                else:
                    transition_study_position = trial_by_study_position[recall_position+1]-1
                    for k in range(repetition_count):
                        lag = int(transition_study_position-i_and_j[repeated_item][k])
                        if lag in relevant_lags:
                            actual_lags[k][relevant_lags.index(lag)] += 1

    result = []
    for k in range(repetition_count):
        result.append(pd.DataFrame(
            {'lag': relevant_lags, 'prob': np.divide(actual_lags[k], possible_lags[k]),
            'actual': actual_lags[k], 'possible': possible_lags[k]}))

    return pd.concat(result, keys=['From Position {}'.format(i+1) for i in range(repetition_count)], names=['locus'])

def sim_alternative_contiguity_test(presentations, experiment_count, lag_threshold, repetition_count, encoding_drift_rate,
    start_drift_rate, recall_drift_rate, shared_support, item_support, learning_rate,
    primacy_scale, primacy_decay, stop_probability_scale,
    stop_probability_growth, choice_sensitivity, delay_drift_rate,
    drift_familiarity_scale, mfc_familiarity_scale, mcf_familiarity_scale, sampling_rule):
    """
    Apply organizational analyses to visually compare the behavior of the model
    with these parameters against specified dataset.
    """

    results = []
    # generate simulation data from model
    for experiment in range(experiment_count):

        sim = np.zeros(np.shape(presentations), dtype=int)
        for trial_index in range(len(presentations)):
            presentation = presentations[trial_index]

            item_count = np.max(presentation)+1
            model = Classic_CMR( item_count, len(presentations),  encoding_drift_rate,
                start_drift_rate, recall_drift_rate, shared_support, item_support, learning_rate,
                primacy_scale, primacy_decay, stop_probability_scale,
                stop_probability_growth, choice_sensitivity, delay_drift_rate, drift_familiarity_scale,
                 mfc_familiarity_scale, mcf_familiarity_scale, sampling_rule)

            # simulate study events
            model.experience(np.eye(model.item_count, model.item_count)[presentation])

            # simulate and add recall events to trials array
            recalled = model.free_recall()
            xsorted = np.argsort(presentation)
            ypos = np.searchsorted(presentation[xsorted], recalled)
            sim[trial_index, :len(recalled)] = xsorted[ypos]+1

        # apply contiguity test
        results.append(alternative_contiguity_test(presentations, sim, lag_threshold, repetition_count))

    return pd.concat(results, keys=list(range(experiment_count)), names=['experiment']).reset_index()

# Cell

from numba import njit
import numpy as np


@njit(fastmath=True, nogil=True)
def fast_pfr(trials, item_count):
    return np.bincount(trials[:, 0], minlength=item_count + 1)[1:] / len(trials)


# Cell

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from .datasets import events_metadata, generate_trial_mask


def plot_pfr(data, trial_query, contrast_name='', labels=None, axis=None):

    if axis is None:
        plt.figure()
        axis = plt.gca()

    if labels is None:
        labels = [''] * len(data)

    result = []
    for data_index, events in enumerate(data):

        # generate and subset trials array and list of list_lengths based on trial_query
        trials, list_lengths = events_metadata(events)[:2]
        trial_mask = generate_trial_mask(events, trial_query)
        chose = [i for i in range(len(trial_mask)) if np.sum(trial_mask[i]) != 0]
        assert(len(chose) == 1)
        chose = chose[0]
        trials = trials[chose]
        list_length = list_lengths[chose]
        trial_mask = trial_mask[chose]

        for subject in pd.unique(events.subject):
            subject_specific_trial_mask = np.logical_and(
                generate_trial_mask(events, f"subject == {subject}")[chose], trial_mask
            )

            if np.sum(subject_specific_trial_mask) == 0:
                continue

            result.append(pd.DataFrame.from_dict(
                {
                    "subject": subject,
                    "input": np.arange(1, list_length + 1),
                    "recall": fast_pfr(trials[subject_specific_trial_mask], list_length),
                    contrast_name: labels[data_index],
                }
            ))

    result = pd.concat(result).reset_index()

    sns.lineplot(ax=axis, data=result, x='input', y='recall', err_style='bars', hue=contrast_name)
    axis.set(xlabel='Study Position', ylabel='Recall Rate')
    axis.set_xticks(np.arange(1, list_length+int(list_length/10), int(list_length/10)))
    axis.set_ylim((0, 1))

    if contrast_name:
        axis.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)

    return axis

# Cell

from numba import njit
import numpy as np
from numba import int32

@njit(nogil=True)
def fast_mixed_pfr(trials, presentations):

    list_length = len(presentations[0])
    result = np.zeros(list_length, dtype=int32)
    alt_trials = recall_by_second_study_position(trials, presentations)
    first_recalls = np.hstack((trials[:, :1], alt_trials[:, :1]))

    for trial_index in range(len(trials)):
        for i in range(list_length):
            result[i] += i+1 in first_recalls[trial_index]

    return result/len(trials)

@njit(nogil=True)
def flex_mixed_pfr(trials, presentations):

    list_length = len(presentations[0])
    result = np.zeros(list_length, dtype=int32)
    all_study_positions = recall_by_all_study_positions(trials, presentations)
    first_recalls = all_study_positions[:, :, :1]

    for trial_index in range(len(trials)):
        for i in range(list_length):
            result[i] += i+1 in first_recalls[:, trial_index]

    return result/len(trials)


# Cell

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from .datasets import events_metadata, generate_trial_mask


def plot_flex_pfr(data, trial_query, contrast_name='', labels=None, axis=None):

    if axis is None:
        plt.figure()
        axis = plt.gca()

    if labels is None:
        labels = [''] * len(data)

    result = []
    for data_index, events in enumerate(data):

        # generate and subset trials array and list of list_lengths based on trial_query
        trials, list_lengths, presentations = events_metadata(events)
        trial_mask = generate_trial_mask(events, trial_query)
        chose = [i for i in range(len(trial_mask)) if np.sum(trial_mask[i]) != 0]
        assert(len(chose) == 1)
        chose = chose[0]
        trials = trials[chose]
        list_length = list_lengths[chose]
        presentations = presentations[chose]
        trial_mask = trial_mask[chose]

        for subject in pd.unique(events.subject):
            subject_specific_trial_mask = np.logical_and(
                generate_trial_mask(events, f"subject == {subject}")[chose], trial_mask
            )

            if np.sum(subject_specific_trial_mask) == 0:
                continue

            pfr = flex_mixed_pfr(trials[subject_specific_trial_mask], presentations[subject_specific_trial_mask])
            result.append(pd.DataFrame.from_dict(
                {
                    "subject": subject,
                    "input": np.arange(1, list_length + 1),
                    "recall": pfr,
                    contrast_name: labels[data_index],
                }
            ))

    result = pd.concat(result).reset_index()

    sns.lineplot(ax=axis, data=result, x='input', y='recall', err_style='bars', hue=contrast_name)
    axis.set(xlabel='Study Position', ylabel='Recall Rate')
    axis.set_xticks(np.arange(1, list_length+int(list_length/10), int(list_length/10)))
    axis.set_ylim((0, 1))

    if contrast_name:
        axis.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)

    return axis

# Cell

from numba import njit, prange
import numpy as np

@njit(nogil=True, parallel=True)
def fast_rpl(study_positions_in_recall_order, presentations, max_lag=8):

    assert(len(presentations) == len(study_positions_in_recall_order))

    total_presented, total_retrieved = np.zeros(max_lag+2), np.zeros(max_lag+2)

    for trial_index in prange(len(presentations)):
        presented, retrieved = np.zeros(max_lag+2), np.zeros(max_lag+2)
        trial = study_positions_in_recall_order[trial_index]
        trial = trial[trial > 0]-1

        for item in np.unique(presentations[trial_index]):
            for idx, val in np.ndenumerate(presentations[trial_index]):
                if val == item:
                    locationA = idx[0]
                    break

            lag = 0
            if locationA < len(presentations[trial_index]):
                for idx, val in np.ndenumerate(presentations[trial_index][locationA+1:]):
                    if val == item:
                        lag = 1 + idx[0]
                        break

            presented[lag] += 1
            retrieved[lag] += locationA in trial

        total_presented += presented
        total_retrieved += retrieved

    return total_retrieved/total_presented

# Cell

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from .datasets import events_metadata, generate_trial_mask


def plot_rpl(data, trial_query, contrast_name='', labels=None, axis=None):

    lags = ['N/A', '0', '1-2', '3-5', '6-8']

    if axis is None:
        plt.figure()
        axis = plt.gca()

    if labels is None:
        labels = [''] * len(data)

    result = []
    for data_index, events in enumerate(data):

        # generate and subset trials array and list of list_lengths based on trial_query
        trials, list_lengths, presentations = events_metadata(events)
        trial_mask = generate_trial_mask(events, trial_query)
        chose = [i for i in range(len(trial_mask)) if np.sum(trial_mask[i]) != 0]
        assert(len(chose) == 1)
        chose = chose[0]
        trials = trials[chose]
        presentations = presentations[chose]
        trial_mask = trial_mask[chose]

        for subject in pd.unique(events.subject):
            subject_specific_trial_mask = np.logical_and(
                generate_trial_mask(events, f"subject == {subject}")[chose], trial_mask
            )

            if np.sum(subject_specific_trial_mask) == 0:
                continue

            subject_result = fast_rpl(trials[subject_specific_trial_mask], presentations[subject_specific_trial_mask])
            binned = np.zeros(5)
            binned[0] = subject_result[0]
            binned[1] = subject_result[1]
            binned[2] = (subject_result[2] + subject_result[3])/2
            binned[3] = (subject_result[4] + subject_result[5] + subject_result[6])/3
            binned[4] = (subject_result[7] + subject_result[8] + subject_result[9])/3

            result.append(pd.DataFrame.from_dict(
                {
                    "subject": subject,
                    "lag": lags,
                    "recall": binned,
                    contrast_name: labels[data_index],
                }
            ))

    result = pd.concat(result).reset_index()

    if contrast_name:
        sns.pointplot(ax=axis, data=result, x='lag', y='recall',  join=False, hue=contrast_name)
        axis.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
    else:
        sns.pointplot(ax=axis, data=result, x='lag', y='recall',  join=False)
    axis.set(xlabel='Study Position', ylabel='Recall Rate')

    return axis

# Cell

import pandas as pd

def rpl(presentations, trials, subjects, trial_count, list_length, max_lag=8):
    #subjects = len(np.unique(events.subject))
    #trial_count = np.max(events.list)
    #list_length = np.max(events.input)
    #lags = ['N/A'] + list(range(max_lag+1))
    lags = ['N/A', '0', '1-2', '3-5', '6-8']

    result = {'subject': [], 'lag': [], 'prob': []}

    for subject in range(subjects):

        subject_result = fast_rpl(
            trials[subject*trial_count:(subject+1)*trial_count], presentations[subject*trial_count:(subject+1)*trial_count], max_lag)

        binned = np.zeros(5)
        binned[0] = subject_result[0]
        binned[1] = subject_result[1]
        binned[2] = (subject_result[2] + subject_result[3])/2
        binned[3] = (subject_result[4] + subject_result[5] + subject_result[6])/3
        binned[4] = (subject_result[7] + subject_result[8] + subject_result[9])/3

        result['subject'] += [subject+1]*len(lags)
        result['lag'] += lags
        result['prob'] += binned.tolist()

    return pd.DataFrame(result)

# Cell

from numba import njit
import numpy as np

@njit(nogil=True)
def fast_spc(trials, item_count):
    return np.bincount(trials.flatten(), minlength=item_count+1)[1:]/len(trials)

# Cell

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from .datasets import events_metadata, generate_trial_mask


def plot_spc(data, trial_query, contrast_name='', labels=None, axis=None):

    if axis is None:
        plt.figure()
        axis = plt.gca()

    if labels is None:
        labels = [''] * len(data)

    result = []
    for data_index, events in enumerate(data):

        # generate and subset trials array and list of list_lengths based on trial_query
        trials, list_lengths, presentations = events_metadata(events)
        trial_mask = generate_trial_mask(events, trial_query)
        chose = [i for i in range(len(trial_mask)) if np.sum(trial_mask[i]) != 0]
        assert(len(chose) == 1)
        chose = chose[0]
        trials = trials[chose]
        list_length = list_lengths[chose]
        trial_mask = trial_mask[chose]

        for subject in pd.unique(events.subject):
            subject_specific_trial_mask = np.logical_and(
                generate_trial_mask(events, f"subject == {subject}")[chose], trial_mask
            )

            if np.sum(subject_specific_trial_mask) == 0:
                continue

            spc = fast_spc(trials[subject_specific_trial_mask], list_length)
            result.append(pd.DataFrame.from_dict(
                {
                    "subject": subject,
                    "input": np.arange(1, list_length + 1),
                    "recall": spc,
                    contrast_name: labels[data_index],
                }
            ))

    result = pd.concat(result).reset_index()

    sns.lineplot(ax=axis, data=result, x='input', y='recall', err_style='bars', hue=contrast_name)
    axis.set(xlabel='Study Position', ylabel='Recall Rate')
    axis.set_xticks(np.arange(1, list_length+int(list_length/10), int(list_length/10)))
    axis.set_ylim((0, 1))

    if contrast_name:
        axis.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)

    return axis

# Cell

from numba import njit, prange
import numpy as np
from numba import int32
from .datasets import find_first

@njit(nogil=True)
def recall_by_second_study_position(trials, presentations):

    flipped_presentations = np.fliplr(presentations)
    list_length = len(presentations[0])
    result = np.zeros(np.shape(trials), dtype=int32)

    for trial_index in range(len(trials)):

        trial = trials[trial_index]
        presentation = presentations[trial_index]
        flipped_presentation = flipped_presentations[trial_index]

        for recall_index in range(len(trial)):

            if trial[recall_index] == 0:
                continue

            item_index = presentation[trial[recall_index]-1]
            result[trial_index, recall_index] = list_length - find_first(
                item_index, flipped_presentation)

    return result

@njit(nogil=True)
def recall_by_all_study_positions(recall_by_first_study_position, presentations, max_repeats=3):

    trials_shape = np.shape(recall_by_first_study_position)
    result = np.zeros(
            (max_repeats, trials_shape[0], trials_shape[1]), dtype=int32)

    for trial_index in range(len(recall_by_first_study_position)):

        trial = recall_by_first_study_position[trial_index]
        presentation = presentations[trial_index]

        for recall_index in range(len(trial)):

            if trial[recall_index] == 0:
                continue

            presentation_positions = np.nonzero(
                presentation[trial[recall_index] - 1] == presentation)[0] + 1

            result[:len(presentation_positions), trial_index, recall_index] = presentation_positions

    return result

# Cell

@njit(nogil=True)
def fast_mixed_spc(trials, presentations):

    list_length = len(presentations[0])
    result = np.zeros(list_length, dtype=int32)
    alt_trials = recall_by_second_study_position(trials, presentations)
    trials = np.hstack((trials, alt_trials))

    for trial_index in range(len(trials)):
        for study_position in range(list_length):
            result[study_position] += study_position+1 in trials[trial_index]

    return result/len(trials)


@njit(nogil=True)
def flex_mixed_spc(trials, presentations):

    list_length = len(presentations[0])
    result = np.zeros(list_length, dtype=int32)
    all_study_positions = recall_by_all_study_positions(trials, presentations)

    for trial_index in range(len(trials)):
        for study_position in range(list_length):
            result[study_position] += study_position+1 in all_study_positions[:,trial_index]

    return result/len(trials)

# Cell

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from .datasets import events_metadata, generate_trial_mask


def plot_flex_spc(data, trial_query, contrast_name='', labels=None, axis=None):

    if axis is None:
        plt.figure()
        axis = plt.gca()

    if labels is None:
        labels = [''] * len(data)

    result = []
    for data_index, events in enumerate(data):

        # generate and subset trials array and list of list_lengths based on trial_query
        trials, list_lengths, presentations = events_metadata(events)
        trial_mask = generate_trial_mask(events, trial_query)
        chose = [i for i in range(len(trial_mask)) if np.sum(trial_mask[i]) != 0]
        assert(len(chose) == 1)
        chose = chose[0]
        trials = trials[chose]
        list_length = list_lengths[chose]
        presentations = presentations[chose]
        trial_mask = trial_mask[chose]

        for subject in pd.unique(events.subject):
            subject_specific_trial_mask = np.logical_and(
                generate_trial_mask(events, f"subject == {subject}")[chose], trial_mask
            )

            if np.sum(subject_specific_trial_mask) == 0:
                continue

            spc = flex_mixed_spc(trials[subject_specific_trial_mask], presentations[subject_specific_trial_mask])
            result.append(pd.DataFrame.from_dict(
                {
                    "subject": subject,
                    "input": np.arange(1, list_length + 1),
                    "recall": spc,
                    contrast_name: labels[data_index],
                }
            ))

    result = pd.concat(result).reset_index()

    sns.lineplot(ax=axis, data=result, x='input', y='recall', err_style='bars', hue=contrast_name)
    axis.set(xlabel='Study Position', ylabel='Recall Rate')
    axis.set_xticks(np.arange(1, list_length+int(list_length/10), int(list_length/10)))
    axis.set_ylim((0, 1))

    if contrast_name:
        axis.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)

    return axis