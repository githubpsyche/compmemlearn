# AUTOGENERATED! DO NOT EDIT! File to edit: library/analyses/Serial_Position_Effect_in_Repetition_Datasets.ipynb (unless otherwise specified).

__all__ = ['fast_crp', 'plot_lag_crp', 'fast_mixed_pfr', 'fast_csp', 'plot_csp', 'fast_crp', 'plot_lag_crp',
           'randomize_dataset', 'indices_of_repeated_items', 'alternative_contiguity_test',
           'alternative_contiguity_control', 'sim_alternative_contiguity_test', 'fast_pfr', 'plot_pfr',
           'fast_mixed_pfr', 'fast_rpl', 'rpl', 'fast_spc', 'plot_spc', 'recall_by_second_study_position',
           'fast_mixed_spc']

# Cell

from numba import njit
import numpy as np

@njit(fastmath=True, nogil=True)
def fast_crp(trials, item_count):

    transition_range = (item_count - 1)
    total_actual = np.zeros(transition_range * 2 + 1)
    total_possible = np.zeros(transition_range * 2 + 1)
    terminus = np.sum(trials != 0, axis=1)
    actual = trials[:, 1:] - trials[:, :-1]
    actual += transition_range

    # tabulate
    for i in range(len(trials)):
        pool = np.arange(20) + 1
        previous_recall = 0

        for j in range(terminus[i]):

            current_recall = trials[i, j]

            # track possible and actual transitions
            if j > 0:
                total_actual[actual[i, j-1]] += 1
                possible = pool - previous_recall
                possible += transition_range
                total_possible[possible] += 1

            # update pool to exclude recalled item
            previous_recall = trials[i, j]
            pool = pool[pool != previous_recall]

    # small correction to avoid nans
    total_possible[total_actual==0] += 1

    return total_actual/total_possible

# Cell
import seaborn as sns
from psifr import fr

def plot_lag_crp(data, max_lag=5, **facet_kws):

    filt_neg = f'{-max_lag} <= lag < 0'
    filt_pos = f'0 < lag <= {max_lag}'

    crp_data = fr.lag_crp(data)

    sns.lineplot(
        data=crp_data.query(filt_neg),
        x='lag', y='prob', **facet_kws)
    sns.lineplot(
        data=crp_data.query(filt_pos),
        x='lag', y='prob', **facet_kws)

# Cell

from numba import njit
import numpy as np
from numba import int32

@njit(nogil=True)
def fast_mixed_pfr(trials, presentations, item_count):

    result = np.zeros(item_count, dtype=int32)
    alt_trials = recall_by_second_study_position(trials, presentations)
    first_recalls = np.hstack((trials[:, :1], alt_trials[:, :1]))

    for trial_index in range(len(trials)):
        for i in range(item_count):
            result[i] += i+1 in first_recalls[trial_index]

    return result/len(trials)

# Cell

from numba import njit
import numpy as np

@njit(fastmath=True, nogil=True)
def fast_csp(trials, item_count):

    # numerator is number of trials with zero in current column position
    numerator = np.zeros(item_count+1)

    # denominator is number of trials without zero in previous column positions
    denominator = np.zeros(item_count+1)

    stop_positions = trials == 0
    for i in range(len(trials)):

        # add 1 to index of final recall
        numerator[np.argmax(stop_positions[i])] += 1

        # add 1 to each index up through final recall
        denominator[:np.argmax(stop_positions[i])+1] += 1

    denominator[denominator==0] += 1
    return numerator/denominator

# Cell
import seaborn as sns
from psifr import fr

def plot_csp(data, **facet_kws):

    trials = pd.pivot_table(
        data, index=['subject', 'list'],
        columns=['output'], values='input',
        fill_value=0).to_numpy()

    sns.lineplot(
        data=csp(data, trials),
        x='output', y='prob', **facet_kws)

# Cell

from numba import njit
import numpy as np

@njit(fastmath=True, nogil=True)
def fast_crp(trials, item_count):

    transition_range = (item_count - 1)
    total_actual = np.zeros(transition_range * 2 + 1)
    total_possible = np.zeros(transition_range * 2 + 1)
    terminus = np.sum(trials != 0, axis=1)
    actual = trials[:, 1:] - trials[:, :-1]
    actual += transition_range

    # tabulate
    for i in range(len(trials)):
        pool = np.arange(20) + 1
        previous_recall = 0

        for j in range(terminus[i]):

            current_recall = trials[i, j]

            # track possible and actual transitions
            if j > 0:
                total_actual[actual[i, j-1]] += 1
                possible = pool - previous_recall
                possible += transition_range
                total_possible[possible] += 1

            # update pool to exclude recalled item
            previous_recall = trials[i, j]
            pool = pool[pool != previous_recall]

    # small correction to avoid nans
    total_possible[total_actual==0] += 1

    return total_actual/total_possible

# Cell
import seaborn as sns
from psifr import fr

def plot_lag_crp(data, max_lag=5, **facet_kws):

    filt_neg = f'{-max_lag} <= lag < 0'
    filt_pos = f'0 < lag <= {max_lag}'

    crp_data = fr.lag_crp(data)

    sns.lineplot(
        data=crp_data.query(filt_neg),
        x='lag', y='prob', **facet_kws)
    sns.lineplot(
        data=crp_data.query(filt_pos),
        x='lag', y='prob', **facet_kws)

# Cell

from numba import njit, prange
import numpy as np

@njit(parallel=True)
def randomize_dataset(recall_rate_by_serial_position, sample_size):
    """
    To control for serial position effects of repeated items,
    analyses are often performed on randomized recall sequences with recall probabilities
    matched to the serial position curve of controls lists. Recall of each item is then
    calculated randomly and independently across trials.
    """

    samples = np.random.rand(sample_size, len(recall_rate_by_serial_position)) < recall_rate_by_serial_position
    result = np.zeros((sample_size, len(recall_rate_by_serial_position)))

    for i in prange(sample_size):
        sample = samples[i].nonzero()[0] + 1
        np.random.shuffle(sample)
        result[i, :len(sample)] = sample

    return result


# Cell

import pandas as pd
import numpy as np

def indices_of_repeated_items(presentation_sequence):

    values, counts = np.unique(presentation_sequence, return_counts=True)
    repeated_items = {v: np.where(presentation_sequence == v)[0] for v in values if counts[v] > 1}

    return {key:repeated_items[key] for key in repeated_items}


def alternative_contiguity_test(mixed_presentations, mixed_recalls, lag_threshold, repetition_count):
    relevant_lags = list(range(-int(lag_threshold/2), int(lag_threshold/2+1)))
    del relevant_lags[int(lag_threshold/2)]

    actual_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]
    possible_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]

    for trial_index in range(len(mixed_presentations)):

        # sequence of item indices ordered as they were studied
        presentation = mixed_presentations[trial_index]

        # sequence of initial study positions ordered as they were recalled
        trial_by_study_position = mixed_recalls[trial_index]

        # sequence of item indices ordered as they were recalled
        trial_by_item_index = presentation[trial_by_study_position-1][:np.size(np.nonzero(trial_by_study_position))]

        # {item_index: [presentation indices]} for each repeated item in presentation sequence spaced by >4 items
        i_and_j = indices_of_repeated_items(presentation)

        # then for each unique repeated item in the study list,
        for repeated_item in i_and_j:

            # search for relevant item(s) in recall sequence and skip if not found
            look_for = trial_by_item_index == presentation[i_and_j[repeated_item][0]]
            for k in range(1, repetition_count):
                look_for = np.logical_or(
                    look_for, trial_by_item_index == presentation[i_and_j[repeated_item][k]])
            recall_positions = np.where(look_for)[0]

            if np.size(recall_positions) == 0:
                continue

            # check each position the item was observed (always just 1 position; we loop for parallelism w control)
            for recall_position in recall_positions:

                # also skip if no successive recall was made,
                if np.size(trial_by_item_index) == recall_position + 1:
                    continue

                # build list of study positions for items recalled up to repeated item
                prior_lags = [[] for each in range(repetition_count)]
                for i in range(recall_position):

                    # if considered item is also repeated, we track lags wrt to all presentations
                    if trial_by_item_index[i] in i_and_j:
                        for considered in range(len(i_and_j[trial_by_item_index[i]])):
                            for focal in range(repetition_count):
                                prior_lags[focal].append(
                                    int(i_and_j[trial_by_item_index[i]][considered] - i_and_j[repeated_item][focal]))
                    else:
                        for k in range(repetition_count):
                            prior_lags[k].append(int(trial_by_study_position[i] - i_and_j[repeated_item][k]))

                # transition of a given lag is possible if lag not present in prior_lags
                for lag in relevant_lags:
                    for k in range(repetition_count):

                        # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][-1] < lag_threshold
                        if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):
                            continue

                        if lag not in prior_lags[k]:
                            possible_lags[k][relevant_lags.index(lag)] += 1

                # track each serial lag of actually transitioned-to item
                if trial_by_item_index[recall_position+1] in i_and_j:
                    positions = i_and_j[trial_by_item_index[recall_position+1]]
                    for transition_study_position in positions:
                        for k in range(repetition_count):

                            # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold
                            if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):
                                continue

                            lag = int(transition_study_position - i_and_j[repeated_item][k])
                            if lag in relevant_lags:
                                actual_lags[k][relevant_lags.index(lag)] += 1
                else:
                    transition_study_position = trial_by_study_position[recall_position+1]-1
                    for k in range(repetition_count):

                        # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold
                        if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):
                            continue

                        lag = int(transition_study_position-i_and_j[repeated_item][k])
                        if lag in relevant_lags:
                            actual_lags[k][relevant_lags.index(lag)] += 1

    result = []
    for k in range(repetition_count):

        for i in range(len(possible_lags[k])):
            if possible_lags[k][i] == 0:
                possible_lags[k][i] += 1

        result.append(pd.DataFrame(
            {'lag': relevant_lags, 'prob': np.divide(actual_lags[k], possible_lags[k]),
            'actual': actual_lags[k], 'possible': possible_lags[k]}))

    return pd.concat(result, keys=['From Position {}'.format(i+1) for i in range(repetition_count)], names=['locus'])


def alternative_contiguity_control(
    mixed_presentations, control_presentations, control_recalls, lag_threshold, repetition_count):
    relevant_lags = list(range(-int(lag_threshold/2), int(lag_threshold/2+1)))
    del relevant_lags[int(lag_threshold/2)]

    actual_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]
    possible_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]

    for trial_index in range(len(mixed_presentations)):

        # sequence of item indices ordered as they were studied
        presentation = mixed_presentations[trial_index]
        control_presentation = control_presentations[trial_index]

        # sequence of initial study positions ordered as they were recalled
        trial_by_study_position = control_recalls[trial_index]

        # sequence of item indices ordered as they were recalled
        trial_by_item_index = control_presentation[trial_by_study_position-1][:np.size(np.nonzero(trial_by_study_position))]

        # {item_index: [presentation indices]} for each repeated item in presentation sequence spaced by >4 items
        i_and_j = indices_of_repeated_items(presentation)

        # then for each unique repeated item in the study list,
        for repeated_item in i_and_j:

            # search for relevant item(s) in recall sequence and skip if not found
            look_for = trial_by_item_index == control_presentation[i_and_j[repeated_item][0]]
            for k in range(1, repetition_count):
                look_for = np.logical_or(
                    look_for, trial_by_item_index == control_presentation[i_and_j[repeated_item][k]])
            recall_positions = np.where(look_for)[0]

            for recall_position in recall_positions:

                # also skip if no successive recall was made,
                if np.size(trial_by_item_index) == recall_position + 1:
                    continue

                # build list of study positions for items recalled up to repeated item
                prior_lags = [[] for each in range(repetition_count)]
                for i in range(recall_position):
                    if trial_by_item_index[i] in i_and_j:
                        for considered in range(len(i_and_j[trial_by_item_index[i]])):
                            for focal in range(repetition_count):
                                prior_lags[focal].append(
                                    int(i_and_j[trial_by_item_index[i]][considered] - i_and_j[repeated_item][focal]))
                    else:
                        for k in range(repetition_count):
                            prior_lags[k].append(int(trial_by_study_position[i] - i_and_j[repeated_item][k]))

                # transition of a given lag is possible if lag not present in prior_lags
                for lag in relevant_lags:
                    for k in range(repetition_count):
                        if lag not in prior_lags[k]:
                            possible_lags[k][relevant_lags.index(lag)] += 1

                # track each serial lag of actually transitioned-to item
                if trial_by_item_index[recall_position+1] in i_and_j:
                    positions = i_and_j[trial_by_item_index[recall_position+1]]
                    for transition_study_position in positions:
                        for k in range(repetition_count):
                            lag = int(transition_study_position - i_and_j[repeated_item][k])
                            if lag in relevant_lags:
                                actual_lags[k][relevant_lags.index(lag)] += 1
                else:
                    transition_study_position = trial_by_study_position[recall_position+1]-1
                    for k in range(repetition_count):
                        lag = int(transition_study_position-i_and_j[repeated_item][k])
                        if lag in relevant_lags:
                            actual_lags[k][relevant_lags.index(lag)] += 1

    result = []
    for k in range(repetition_count):
        result.append(pd.DataFrame(
            {'lag': relevant_lags, 'prob': np.divide(actual_lags[k], possible_lags[k]),
            'actual': actual_lags[k], 'possible': possible_lags[k]}))

    return pd.concat(result, keys=['From Position {}'.format(i+1) for i in range(repetition_count)], names=['locus'])

def sim_alternative_contiguity_test(presentations, experiment_count, lag_threshold, repetition_count, encoding_drift_rate,
    start_drift_rate, recall_drift_rate, shared_support, item_support, learning_rate,
    primacy_scale, primacy_decay, stop_probability_scale,
    stop_probability_growth, choice_sensitivity, delay_drift_rate,
    drift_familiarity_scale, mfc_familiarity_scale, mcf_familiarity_scale, sampling_rule):
    """
    Apply organizational analyses to visually compare the behavior of the model
    with these parameters against specified dataset.
    """

    results = []
    # generate simulation data from model
    for experiment in range(experiment_count):

        sim = np.zeros(np.shape(presentations), dtype=int)
        for trial_index in range(len(presentations)):
            presentation = presentations[trial_index]

            item_count = np.max(presentation)+1
            model = Classic_CMR( item_count, len(presentations),  encoding_drift_rate,
                start_drift_rate, recall_drift_rate, shared_support, item_support, learning_rate,
                primacy_scale, primacy_decay, stop_probability_scale,
                stop_probability_growth, choice_sensitivity, delay_drift_rate, drift_familiarity_scale,
                 mfc_familiarity_scale, mcf_familiarity_scale, sampling_rule)

            # simulate study events
            model.experience(np.eye(model.item_count, model.item_count)[presentation])

            # simulate and add recall events to trials array
            recalled = model.free_recall()
            xsorted = np.argsort(presentation)
            ypos = np.searchsorted(presentation[xsorted], recalled)
            sim[trial_index, :len(recalled)] = xsorted[ypos]+1

        # apply contiguity test
        results.append(alternative_contiguity_test(presentations, sim, lag_threshold, repetition_count))

    return pd.concat(results, keys=list(range(experiment_count)), names=['experiment']).reset_index()

# Cell

from numba import njit
import numpy as np

@njit(fastmath=True, nogil=True)
def fast_pfr(trials, item_count):
    return np.bincount(trials[:, 0], minlength=item_count+1)[1:]/len(trials)

# Cell
import seaborn as sns
from psifr import fr

def plot_pfr(data, max_lag=5, **facet_kws):

    filt_neg = f'{-max_lag} <= lag < 0'
    filt_pos = f'0 < lag <= {max_lag}'

    pfr_data = fr.pnr(data).query('output <= 1')

    sns.lineplot(
        data=pfr_data, x='input', y='prob', **facet_kws)
    sns.lineplot(
        data=pfr_data, x='input', y='prob', **facet_kws)

# Cell

from numba import njit
import numpy as np
from numba import int32

@njit(nogil=True)
def fast_mixed_pfr(trials, presentations, item_count):

    result = np.zeros(item_count, dtype=int32)
    alt_trials = recall_by_second_study_position(trials, presentations)
    first_recalls = np.hstack((trials[:, :1], alt_trials[:, :1]))

    for trial_index in range(len(trials)):
        for i in range(item_count):
            result[i] += i+1 in first_recalls[trial_index]

    return result/len(trials)

# Cell

from numba import njit, prange
import numpy as np

@njit(nogil=True, parallel=True)
def fast_rpl(presentations, study_positions_in_recall_order, max_lag=8):

    assert(len(presentations) == len(study_positions_in_recall_order))

    total_presented, total_retrieved = np.zeros(max_lag+2), np.zeros(max_lag+2)

    for trial_index in prange(len(presentations)):
        presented, retrieved = np.zeros(max_lag+2), np.zeros(max_lag+2)
        trial = study_positions_in_recall_order[trial_index]
        trial = trial[trial > 0]-1

        for item in np.unique(presentations[trial_index]):
            for idx, val in np.ndenumerate(presentations[trial_index]):
                if val == item:
                    locationA = idx[0]
                    break

            lag = 0
            if locationA < len(presentations[trial_index]):
                for idx, val in np.ndenumerate(presentations[trial_index][locationA+1:]):
                    if val == item:
                        lag = 1 + idx[0]
                        break

            presented[lag] += 1
            retrieved[lag] += locationA in trial

        total_presented += presented
        total_retrieved += retrieved

    return total_retrieved/total_presented

# Cell

import pandas as pd

def rpl(presentations, trials, subjects, trial_count, list_length, max_lag=8):
    #subjects = len(np.unique(events.subject))
    #trial_count = np.max(events.list)
    #list_length = np.max(events.input)
    #lags = ['N/A'] + list(range(max_lag+1))
    lags = ['N/A', '0', '1-2', '3-5', '6-8']

    result = {'subject': [], 'lag': [], 'prob': []}

    for subject in range(subjects):

        subject_result = fast_rpl(
            presentations[subject*trial_count:(subject+1)*trial_count],
            trials[subject*trial_count:(subject+1)*trial_count], max_lag)

        binned = np.zeros(5)
        binned[0] = subject_result[0]
        binned[1] = subject_result[1]
        binned[2] = (subject_result[2] + subject_result[3])/2
        binned[3] = (subject_result[4] + subject_result[5] + subject_result[6])/3
        binned[4] = (subject_result[7] + subject_result[8] + subject_result[9])/3

        result['subject'] += [subject+1]*len(lags)
        result['lag'] += lags
        result['prob'] += binned.tolist()

    return pd.DataFrame(result)

# Cell

from numba import njit
import numpy as np

@njit(nogil=True)
def fast_spc(trials, item_count):
    return np.bincount(trials.flatten(), minlength=item_count+1)[1:]/len(trials)

# Cell
from psifr import fr
import seaborn as sns

def plot_spc(data, **facet_kws):

    sns.lineplot(
        data=fr.spc(data), x='input', y='recall', **facet_kws)

# Cell

from numba import njit
import numpy as np
from numba import int32
from .datasets import find_first

@njit(nogil=True)
def recall_by_second_study_position(trials, presentations):

    flipped_presentations = np.fliplr(presentations)
    list_length = len(presentations[0])
    result = np.zeros(np.shape(trials), dtype=int32)

    for trial_index in range(len(trials)):

        trial = trials[trial_index]
        presentation = presentations[trial_index]
        flipped_presentation = flipped_presentations[trial_index]

        for recall_index in range(len(trial)):

            if trial[recall_index] == 0:
                continue

            item_index = presentation[trial[recall_index]-1]
            result[trial_index, recall_index] = list_length - find_first(
                item_index, flipped_presentation)

    return result

@njit(nogil=True)
def fast_mixed_spc(trials, presentations, item_count):
    result = np.zeros(item_count, dtype=int32)
    alt_trials = recall_by_second_study_position(trials, presentations)
    trials = np.hstack((trials, alt_trials))

    for trial_index in range(len(trials)):
        for i in range(item_count):
            result[i] += i+1 in trials[trial_index]

    return result/len(trials)