# AUTOGENERATED! DO NOT EDIT! File to edit: library/analyses/Recall_Probability_by_Spacing.ipynb (unless otherwise specified).

__all__ = ['plot_spc', 'fast_spc', 'plot_lag_crp', 'fast_crp', 'plot_pfr', 'fast_pfr', 'randomize_dataset',
           'sim_recall_probability_by_lag', 'indices_of_repeated_items', 'alternative_contiguity_test',
           'alternative_contiguity_control', 'sim_alternative_contiguity_test', 'recall_probability_by_lag', 'plot_spc',
           'fast_spc', 'plot_lag_crp', 'fast_crp', 'plot_pfr', 'fast_pfr', 'randomize_dataset',
           'sim_recall_probability_by_lag', 'indices_of_repeated_items', 'alternative_contiguity_test',
           'alternative_contiguity_control', 'sim_alternative_contiguity_test', 'recall_probability_by_lag']

# Cell
from psifr import fr
import seaborn as sns

def plot_spc(data, **facet_kws):

    sns.lineplot(
        data=fr.spc(data), x='input', y='recall', **facet_kws)

# Cell

from numba import njit
import numpy as np

@njit(fastmath=True, nogil=True, parallel=True)
def fast_spc(trials, item_count):
    return np.bincount(trials.flatten(), minlength=item_count+1)[1:]/len(trials)

# Cell

def plot_lag_crp(data, max_lag=5, **facet_kws):

    filt_neg = f'{-max_lag} <= lag < 0'
    filt_pos = f'0 < lag <= {max_lag}'

    crp_data = fr.lag_crp(data)

    sns.lineplot(
        data=crp_data.query(filt_neg),
        x='lag', y='prob', **facet_kws)
    sns.lineplot(
        data=crp_data.query(filt_pos),
        x='lag', y='prob', **facet_kws)

# Cell
from numba import njit
import numpy as np

@njit(fastmath=True, nogil=True)
def fast_crp(trials, item_count):

    transition_range = (item_count - 1)
    total_actual = np.zeros(transition_range * 2 + 1)
    total_possible = np.zeros(transition_range * 2 + 1)
    terminus = np.sum(trials != 0, axis=1)
    actual = trials[:, 1:] - trials[:, :-1]
    actual += transition_range

    # tabulate
    for i in range(len(trials)):
        pool = np.arange(20) + 1
        previous_recall = 0

        for j in range(terminus[i]):

            current_recall = trials[i, j]

            # track possible and actual transitions
            if j > 0:
                total_actual[actual[i, j-1]] += 1
                possible = pool - previous_recall
                possible += transition_range
                total_possible[possible] += 1

            # update pool to exclude recalled item
            previous_recall = trials[i, j]
            pool = pool[pool != previous_recall]

    total_possible[total_actual==0] += 1
    return total_actual/total_possible

# Cell

def plot_pfr(data, max_lag=5, **facet_kws):

    filt_neg = f'{-max_lag} <= lag < 0'
    filt_pos = f'0 < lag <= {max_lag}'

    pfr_data = fr.pnr(data).query('output <= 1')

    sns.lineplot(
        data=pfr_data, x='input', y='prob', **facet_kws)
    sns.lineplot(
        data=pfr_data, x='input', y='prob', **facet_kws)

# Cell

from numba import njit
import numpy as np

@njit(fastmath=True, nogil=True)
def fast_pfr(trials, item_count):
    return np.bincount(trials[:, 0], minlength=item_count+1)[1:]/len(trials)

# Cell

from numba import njit, prange
import numpy as np

@njit(parallel=True)
def randomize_dataset(recall_rate_by_serial_position, sample_size):
    """
    To control for serial position effects of repeated items, analyses are often performed on randomized recall sequences with recall probabilities matched to the serial position curve of controls lists. Recall of each item is then calculated randomly and independently across trials.
    """

    samples = np.random.rand(sample_size, len(recall_rate_by_serial_position)) < recall_rate_by_serial_position
    result = np.zeros((sample_size, len(recall_rate_by_serial_position)))

    for i in prange(sample_size):
        sample = samples[i].nonzero()[0] + 1
        np.random.shuffle(sample)
        result[i, :len(sample)] = sample

    return result


# Cell
from .models import Classic_CMR
from numba import int64

@njit(fastmath=True, nogil=True)
def sim_recall_probability_by_lag(presentations, experiment_count, model_class, parameters):
    """
    Apply organizational analyses to visually compare the behavior of the model
    with these parameters against specified dataset.
    """

    max_lag = 8
    total_ratio = np.zeros(max_lag+2)
    total = 0

    # generate simulation data from model
    for experiment in range(experiment_count):

        sim = np.zeros(np.shape(presentations), dtype=int64) # set as int64 when using numba, int otherwise
        for trial_index in range(len(presentations)):
            presentation = presentations[trial_index]

            item_count = np.max(presentation)+1
            model = model_class(item_count, len(presentation), parameters)

            # simulate study events
            model.experience(model.items[presentation])

            # simulate and collect sequence of recalled item indices
            recalled = model.free_recall()
            xsorted = np.argsort(presentation)
            ypos = np.searchsorted(presentation[xsorted], recalled)
            sim[trial_index, :len(recalled)] = xsorted[ypos]+1

        total_ratio += recall_probability_by_lag(presentations, sim)
        total += 1

    return total_ratio/total

# Cell

import pandas as pd
import numpy as np

def indices_of_repeated_items(presentation_sequence):

    values, counts = np.unique(presentation_sequence, return_counts=True)
    repeated_items = {v: np.where(presentation_sequence == v)[0] for v in values if counts[v] > 1}

    return {key:repeated_items[key] for key in repeated_items}


def alternative_contiguity_test(mixed_presentations, mixed_recalls, lag_threshold, repetition_count):
    relevant_lags = list(range(-int(lag_threshold/2), int(lag_threshold/2+1)))
    del relevant_lags[int(lag_threshold/2)]

    actual_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]
    possible_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]

    for trial_index in range(len(mixed_presentations)):

        # sequence of item indices ordered as they were studied
        presentation = mixed_presentations[trial_index]

        # sequence of initial study positions ordered as they were recalled
        trial_by_study_position = mixed_recalls[trial_index]

        # sequence of item indices ordered as they were recalled
        trial_by_item_index = presentation[trial_by_study_position-1][:np.size(np.nonzero(trial_by_study_position))]

        # {item_index: [presentation indices]} for each repeated item in presentation sequence spaced by >4 items
        i_and_j = indices_of_repeated_items(presentation)

        # then for each unique repeated item in the study list,
        for repeated_item in i_and_j:

            # search for relevant item(s) in recall sequence and skip if not found
            look_for = trial_by_item_index == presentation[i_and_j[repeated_item][0]]
            for k in range(1, repetition_count):
                look_for = np.logical_or(
                    look_for, trial_by_item_index == presentation[i_and_j[repeated_item][k]])
            recall_positions = np.where(look_for)[0]

            if np.size(recall_positions) == 0:
                continue

            # check each position the item was observed (always just 1 position; we loop for parallelism w control)
            for recall_position in recall_positions:

                # also skip if no successive recall was made,
                if np.size(trial_by_item_index) == recall_position + 1:
                    continue

                # build list of study positions for items recalled up to repeated item
                prior_lags = [[] for each in range(repetition_count)]
                for i in range(recall_position):

                    # if considered item is also repeated, we track lags wrt to all presentations
                    if trial_by_item_index[i] in i_and_j:
                        for considered in range(len(i_and_j[trial_by_item_index[i]])):
                            for focal in range(repetition_count):
                                prior_lags[focal].append(
                                    int(i_and_j[trial_by_item_index[i]][considered] - i_and_j[repeated_item][focal]))
                    else:
                        for k in range(repetition_count):
                            prior_lags[k].append(int(trial_by_study_position[i] - i_and_j[repeated_item][k]))

                # transition of a given lag is possible if lag not present in prior_lags
                for lag in relevant_lags:
                    for k in range(repetition_count):

                        # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][-1] < lag_threshold
                        if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):
                            continue

                        if lag not in prior_lags[k]:
                            possible_lags[k][relevant_lags.index(lag)] += 1

                # track each serial lag of actually transitioned-to item
                if trial_by_item_index[recall_position+1] in i_and_j:
                    positions = i_and_j[trial_by_item_index[recall_position+1]]
                    for transition_study_position in positions:
                        for k in range(repetition_count):

                            # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold
                            if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):
                                continue

                            lag = int(transition_study_position - i_and_j[repeated_item][k])
                            if lag in relevant_lags:
                                actual_lags[k][relevant_lags.index(lag)] += 1
                else:
                    transition_study_position = trial_by_study_position[recall_position+1]-1
                    for k in range(repetition_count):

                        # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold
                        if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):
                            continue

                        lag = int(transition_study_position-i_and_j[repeated_item][k])
                        if lag in relevant_lags:
                            actual_lags[k][relevant_lags.index(lag)] += 1

    result = []
    for k in range(repetition_count):

        for i in range(len(possible_lags[k])):
            if possible_lags[k][i] == 0:
                possible_lags[k][i] += 1

        result.append(pd.DataFrame(
            {'lag': relevant_lags, 'prob': np.divide(actual_lags[k], possible_lags[k]),
            'actual': actual_lags[k], 'possible': possible_lags[k]}))

    return pd.concat(result, keys=['From Position {}'.format(i+1) for i in range(repetition_count)], names=['locus'])


def alternative_contiguity_control(
    mixed_presentations, control_presentations, control_recalls, lag_threshold, repetition_count):
    relevant_lags = list(range(-int(lag_threshold/2), int(lag_threshold/2+1)))
    del relevant_lags[int(lag_threshold/2)]

    actual_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]
    possible_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]

    for trial_index in range(len(mixed_presentations)):

        # sequence of item indices ordered as they were studied
        presentation = mixed_presentations[trial_index]
        control_presentation = control_presentations[trial_index]

        # sequence of initial study positions ordered as they were recalled
        trial_by_study_position = control_recalls[trial_index]

        # sequence of item indices ordered as they were recalled
        trial_by_item_index = control_presentation[trial_by_study_position-1][:np.size(np.nonzero(trial_by_study_position))]

        # {item_index: [presentation indices]} for each repeated item in presentation sequence spaced by >4 items
        i_and_j = indices_of_repeated_items(presentation)

        # then for each unique repeated item in the study list,
        for repeated_item in i_and_j:

            # search for relevant item(s) in recall sequence and skip if not found
            look_for = trial_by_item_index == control_presentation[i_and_j[repeated_item][0]]
            for k in range(1, repetition_count):
                look_for = np.logical_or(
                    look_for, trial_by_item_index == control_presentation[i_and_j[repeated_item][k]])
            recall_positions = np.where(look_for)[0]

            for recall_position in recall_positions:

                # also skip if no successive recall was made,
                if np.size(trial_by_item_index) == recall_position + 1:
                    continue

                # build list of study positions for items recalled up to repeated item
                prior_lags = [[] for each in range(repetition_count)]
                for i in range(recall_position):
                    if trial_by_item_index[i] in i_and_j:
                        for considered in range(len(i_and_j[trial_by_item_index[i]])):
                            for focal in range(repetition_count):
                                prior_lags[focal].append(
                                    int(i_and_j[trial_by_item_index[i]][considered] - i_and_j[repeated_item][focal]))
                    else:
                        for k in range(repetition_count):
                            prior_lags[k].append(int(trial_by_study_position[i] - i_and_j[repeated_item][k]))

                # transition of a given lag is possible if lag not present in prior_lags
                for lag in relevant_lags:
                    for k in range(repetition_count):
                        if lag not in prior_lags[k]:
                            possible_lags[k][relevant_lags.index(lag)] += 1

                # track each serial lag of actually transitioned-to item
                if trial_by_item_index[recall_position+1] in i_and_j:
                    positions = i_and_j[trial_by_item_index[recall_position+1]]
                    for transition_study_position in positions:
                        for k in range(repetition_count):
                            lag = int(transition_study_position - i_and_j[repeated_item][k])
                            if lag in relevant_lags:
                                actual_lags[k][relevant_lags.index(lag)] += 1
                else:
                    transition_study_position = trial_by_study_position[recall_position+1]-1
                    for k in range(repetition_count):
                        lag = int(transition_study_position-i_and_j[repeated_item][k])
                        if lag in relevant_lags:
                            actual_lags[k][relevant_lags.index(lag)] += 1

    result = []
    for k in range(repetition_count):
        result.append(pd.DataFrame(
            {'lag': relevant_lags, 'prob': np.divide(actual_lags[k], possible_lags[k]),
            'actual': actual_lags[k], 'possible': possible_lags[k]}))

    return pd.concat(result, keys=['From Position {}'.format(i+1) for i in range(repetition_count)], names=['locus'])

def sim_alternative_contiguity_test(presentations, experiment_count, lag_threshold, repetition_count, encoding_drift_rate,
    start_drift_rate, recall_drift_rate, shared_support, item_support, learning_rate,
    primacy_scale, primacy_decay, stop_probability_scale,
    stop_probability_growth, choice_sensitivity, delay_drift_rate,
    drift_familiarity_scale, mfc_familiarity_scale, mcf_familiarity_scale, sampling_rule):
    """
    Apply organizational analyses to visually compare the behavior of the model
    with these parameters against specified dataset.
    """

    results = []
    # generate simulation data from model
    for experiment in range(experiment_count):

        sim = np.zeros(np.shape(presentations), dtype=int)
        for trial_index in range(len(presentations)):
            presentation = presentations[trial_index]

            item_count = np.max(presentation)+1
            model = Classic_CMR( item_count, len(presentations),  encoding_drift_rate,
                start_drift_rate, recall_drift_rate, shared_support, item_support, learning_rate,
                primacy_scale, primacy_decay, stop_probability_scale,
                stop_probability_growth, choice_sensitivity, delay_drift_rate, drift_familiarity_scale,
                 mfc_familiarity_scale, mcf_familiarity_scale, sampling_rule)

            # simulate study events
            model.experience(np.eye(model.item_count, model.item_count)[presentation])

            # simulate and add recall events to trials array
            recalled = model.free_recall()
            xsorted = np.argsort(presentation)
            ypos = np.searchsorted(presentation[xsorted], recalled)
            sim[trial_index, :len(recalled)] = xsorted[ypos]+1

        # apply contiguity test
        results.append(alternative_contiguity_test(presentations, sim, lag_threshold, repetition_count))

    return pd.concat(results, keys=list(range(experiment_count)), names=['experiment']).reset_index()

# Cell

from numba import njit, prange
import numpy as np

@njit(fastmath=True, nogil=True, parallel=True)
def recall_probability_by_lag(presentations, study_positions_in_recall_order, max_lag=8):

    total_presented, total_retrieved = np.zeros(max_lag+2), np.zeros(max_lag+2)

    for trial_index in prange(len(presentations)):
        presented, retrieved = np.zeros(max_lag+2), np.zeros(max_lag+2)
        trial = study_positions_in_recall_order[trial_index]
        trial = trial[trial > 0]-1

        for item in np.unique(presentations[trial_index]):
            for idx, val in np.ndenumerate(presentations[trial_index]):
                if val == item:
                    locationA = idx[0]
                    break

            lag = 0
            if locationA < len(presentations[trial_index]):
                for idx, val in np.ndenumerate(presentations[trial_index][locationA+1:]):
                    if val == item:
                        lag = 1 + idx[0]
                        break

            presented[lag] += 1
            retrieved[lag] += locationA in trial

        total_presented += presented
        total_retrieved += retrieved

    return total_retrieved/total_presented

# Cell
from psifr import fr
import seaborn as sns

def plot_spc(data, **facet_kws):

    sns.lineplot(
        data=fr.spc(data), x='input', y='recall', **facet_kws)

# Cell

from numba import njit
import numpy as np

@njit(fastmath=True, nogil=True, parallel=True)
def fast_spc(trials, item_count):
    return np.bincount(trials.flatten(), minlength=item_count+1)[1:]/len(trials)

# Cell

def plot_lag_crp(data, max_lag=5, **facet_kws):

    filt_neg = f'{-max_lag} <= lag < 0'
    filt_pos = f'0 < lag <= {max_lag}'

    crp_data = fr.lag_crp(data)

    sns.lineplot(
        data=crp_data.query(filt_neg),
        x='lag', y='prob', **facet_kws)
    sns.lineplot(
        data=crp_data.query(filt_pos),
        x='lag', y='prob', **facet_kws)

# Cell
from numba import njit
import numpy as np

@njit(fastmath=True, nogil=True)
def fast_crp(trials, item_count):

    transition_range = (item_count - 1)
    total_actual = np.zeros(transition_range * 2 + 1)
    total_possible = np.zeros(transition_range * 2 + 1)
    terminus = np.sum(trials != 0, axis=1)
    actual = trials[:, 1:] - trials[:, :-1]
    actual += transition_range

    # tabulate
    for i in range(len(trials)):
        pool = np.arange(20) + 1
        previous_recall = 0

        for j in range(terminus[i]):

            current_recall = trials[i, j]

            # track possible and actual transitions
            if j > 0:
                total_actual[actual[i, j-1]] += 1
                possible = pool - previous_recall
                possible += transition_range
                total_possible[possible] += 1

            # update pool to exclude recalled item
            previous_recall = trials[i, j]
            pool = pool[pool != previous_recall]

    total_possible[total_actual==0] += 1
    return total_actual/total_possible

# Cell

def plot_pfr(data, max_lag=5, **facet_kws):

    filt_neg = f'{-max_lag} <= lag < 0'
    filt_pos = f'0 < lag <= {max_lag}'

    pfr_data = fr.pnr(data).query('output <= 1')

    sns.lineplot(
        data=pfr_data, x='input', y='prob', **facet_kws)
    sns.lineplot(
        data=pfr_data, x='input', y='prob', **facet_kws)

# Cell

from numba import njit
import numpy as np

@njit(fastmath=True, nogil=True)
def fast_pfr(trials, item_count):
    return np.bincount(trials[:, 0], minlength=item_count+1)[1:]/len(trials)

# Cell

from numba import njit, prange
import numpy as np

@njit(parallel=True)
def randomize_dataset(recall_rate_by_serial_position, sample_size):
    """
    To control for serial position effects of repeated items, analyses are often performed on randomized recall sequences with recall probabilities matched to the serial position curve of controls lists. Recall of each item is then calculated randomly and independently across trials.
    """

    samples = np.random.rand(sample_size, len(recall_rate_by_serial_position)) < recall_rate_by_serial_position
    result = np.zeros((sample_size, len(recall_rate_by_serial_position)))

    for i in prange(sample_size):
        sample = samples[i].nonzero()[0] + 1
        np.random.shuffle(sample)
        result[i, :len(sample)] = sample

    return result


# Cell
from .models import Classic_CMR
from numba import int64

@njit(fastmath=True, nogil=True)
def sim_recall_probability_by_lag(presentations, experiment_count, model_class, parameters):
    """
    Apply organizational analyses to visually compare the behavior of the model
    with these parameters against specified dataset.
    """

    max_lag = 8
    total_ratio = np.zeros(max_lag+2)
    total = 0

    # generate simulation data from model
    for experiment in range(experiment_count):

        sim = np.zeros(np.shape(presentations), dtype=int64) # set as int64 when using numba, int otherwise
        for trial_index in range(len(presentations)):
            presentation = presentations[trial_index]

            item_count = np.max(presentation)+1
            model = model_class(item_count, len(presentation), parameters)

            # simulate study events
            model.experience(model.items[presentation])

            # simulate and collect sequence of recalled item indices
            recalled = model.free_recall()
            xsorted = np.argsort(presentation)
            ypos = np.searchsorted(presentation[xsorted], recalled)
            sim[trial_index, :len(recalled)] = xsorted[ypos]+1

        total_ratio += recall_probability_by_lag(presentations, sim)
        total += 1

    return total_ratio/total

# Cell

import pandas as pd
import numpy as np

def indices_of_repeated_items(presentation_sequence):

    values, counts = np.unique(presentation_sequence, return_counts=True)
    repeated_items = {v: np.where(presentation_sequence == v)[0] for v in values if counts[v] > 1}

    return {key:repeated_items[key] for key in repeated_items}


def alternative_contiguity_test(mixed_presentations, mixed_recalls, lag_threshold, repetition_count):
    relevant_lags = list(range(-int(lag_threshold/2), int(lag_threshold/2+1)))
    del relevant_lags[int(lag_threshold/2)]

    actual_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]
    possible_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]

    for trial_index in range(len(mixed_presentations)):

        # sequence of item indices ordered as they were studied
        presentation = mixed_presentations[trial_index]

        # sequence of initial study positions ordered as they were recalled
        trial_by_study_position = mixed_recalls[trial_index]

        # sequence of item indices ordered as they were recalled
        trial_by_item_index = presentation[trial_by_study_position-1][:np.size(np.nonzero(trial_by_study_position))]

        # {item_index: [presentation indices]} for each repeated item in presentation sequence spaced by >4 items
        i_and_j = indices_of_repeated_items(presentation)

        # then for each unique repeated item in the study list,
        for repeated_item in i_and_j:

            # search for relevant item(s) in recall sequence and skip if not found
            look_for = trial_by_item_index == presentation[i_and_j[repeated_item][0]]
            for k in range(1, repetition_count):
                look_for = np.logical_or(
                    look_for, trial_by_item_index == presentation[i_and_j[repeated_item][k]])
            recall_positions = np.where(look_for)[0]

            if np.size(recall_positions) == 0:
                continue

            # check each position the item was observed (always just 1 position; we loop for parallelism w control)
            for recall_position in recall_positions:

                # also skip if no successive recall was made,
                if np.size(trial_by_item_index) == recall_position + 1:
                    continue

                # build list of study positions for items recalled up to repeated item
                prior_lags = [[] for each in range(repetition_count)]
                for i in range(recall_position):

                    # if considered item is also repeated, we track lags wrt to all presentations
                    if trial_by_item_index[i] in i_and_j:
                        for considered in range(len(i_and_j[trial_by_item_index[i]])):
                            for focal in range(repetition_count):
                                prior_lags[focal].append(
                                    int(i_and_j[trial_by_item_index[i]][considered] - i_and_j[repeated_item][focal]))
                    else:
                        for k in range(repetition_count):
                            prior_lags[k].append(int(trial_by_study_position[i] - i_and_j[repeated_item][k]))

                # transition of a given lag is possible if lag not present in prior_lags
                for lag in relevant_lags:
                    for k in range(repetition_count):

                        # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][-1] < lag_threshold
                        if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):
                            continue

                        if lag not in prior_lags[k]:
                            possible_lags[k][relevant_lags.index(lag)] += 1

                # track each serial lag of actually transitioned-to item
                if trial_by_item_index[recall_position+1] in i_and_j:
                    positions = i_and_j[trial_by_item_index[recall_position+1]]
                    for transition_study_position in positions:
                        for k in range(repetition_count):

                            # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold
                            if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):
                                continue

                            lag = int(transition_study_position - i_and_j[repeated_item][k])
                            if lag in relevant_lags:
                                actual_lags[k][relevant_lags.index(lag)] += 1
                else:
                    transition_study_position = trial_by_study_position[recall_position+1]-1
                    for k in range(repetition_count):

                        # skip increment if i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold
                        if (k > 0) and (i_and_j[repeated_item][k] - i_and_j[repeated_item][k-1] < lag_threshold):
                            continue

                        lag = int(transition_study_position-i_and_j[repeated_item][k])
                        if lag in relevant_lags:
                            actual_lags[k][relevant_lags.index(lag)] += 1

    result = []
    for k in range(repetition_count):

        for i in range(len(possible_lags[k])):
            if possible_lags[k][i] == 0:
                possible_lags[k][i] += 1

        result.append(pd.DataFrame(
            {'lag': relevant_lags, 'prob': np.divide(actual_lags[k], possible_lags[k]),
            'actual': actual_lags[k], 'possible': possible_lags[k]}))

    return pd.concat(result, keys=['From Position {}'.format(i+1) for i in range(repetition_count)], names=['locus'])


def alternative_contiguity_control(
    mixed_presentations, control_presentations, control_recalls, lag_threshold, repetition_count):
    relevant_lags = list(range(-int(lag_threshold/2), int(lag_threshold/2+1)))
    del relevant_lags[int(lag_threshold/2)]

    actual_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]
    possible_lags = [[0 for each in relevant_lags] for i in range(repetition_count)]

    for trial_index in range(len(mixed_presentations)):

        # sequence of item indices ordered as they were studied
        presentation = mixed_presentations[trial_index]
        control_presentation = control_presentations[trial_index]

        # sequence of initial study positions ordered as they were recalled
        trial_by_study_position = control_recalls[trial_index]

        # sequence of item indices ordered as they were recalled
        trial_by_item_index = control_presentation[trial_by_study_position-1][:np.size(np.nonzero(trial_by_study_position))]

        # {item_index: [presentation indices]} for each repeated item in presentation sequence spaced by >4 items
        i_and_j = indices_of_repeated_items(presentation)

        # then for each unique repeated item in the study list,
        for repeated_item in i_and_j:

            # search for relevant item(s) in recall sequence and skip if not found
            look_for = trial_by_item_index == control_presentation[i_and_j[repeated_item][0]]
            for k in range(1, repetition_count):
                look_for = np.logical_or(
                    look_for, trial_by_item_index == control_presentation[i_and_j[repeated_item][k]])
            recall_positions = np.where(look_for)[0]

            for recall_position in recall_positions:

                # also skip if no successive recall was made,
                if np.size(trial_by_item_index) == recall_position + 1:
                    continue

                # build list of study positions for items recalled up to repeated item
                prior_lags = [[] for each in range(repetition_count)]
                for i in range(recall_position):
                    if trial_by_item_index[i] in i_and_j:
                        for considered in range(len(i_and_j[trial_by_item_index[i]])):
                            for focal in range(repetition_count):
                                prior_lags[focal].append(
                                    int(i_and_j[trial_by_item_index[i]][considered] - i_and_j[repeated_item][focal]))
                    else:
                        for k in range(repetition_count):
                            prior_lags[k].append(int(trial_by_study_position[i] - i_and_j[repeated_item][k]))

                # transition of a given lag is possible if lag not present in prior_lags
                for lag in relevant_lags:
                    for k in range(repetition_count):
                        if lag not in prior_lags[k]:
                            possible_lags[k][relevant_lags.index(lag)] += 1

                # track each serial lag of actually transitioned-to item
                if trial_by_item_index[recall_position+1] in i_and_j:
                    positions = i_and_j[trial_by_item_index[recall_position+1]]
                    for transition_study_position in positions:
                        for k in range(repetition_count):
                            lag = int(transition_study_position - i_and_j[repeated_item][k])
                            if lag in relevant_lags:
                                actual_lags[k][relevant_lags.index(lag)] += 1
                else:
                    transition_study_position = trial_by_study_position[recall_position+1]-1
                    for k in range(repetition_count):
                        lag = int(transition_study_position-i_and_j[repeated_item][k])
                        if lag in relevant_lags:
                            actual_lags[k][relevant_lags.index(lag)] += 1

    result = []
    for k in range(repetition_count):
        result.append(pd.DataFrame(
            {'lag': relevant_lags, 'prob': np.divide(actual_lags[k], possible_lags[k]),
            'actual': actual_lags[k], 'possible': possible_lags[k]}))

    return pd.concat(result, keys=['From Position {}'.format(i+1) for i in range(repetition_count)], names=['locus'])

def sim_alternative_contiguity_test(presentations, experiment_count, lag_threshold, repetition_count, encoding_drift_rate,
    start_drift_rate, recall_drift_rate, shared_support, item_support, learning_rate,
    primacy_scale, primacy_decay, stop_probability_scale,
    stop_probability_growth, choice_sensitivity, delay_drift_rate,
    drift_familiarity_scale, mfc_familiarity_scale, mcf_familiarity_scale, sampling_rule):
    """
    Apply organizational analyses to visually compare the behavior of the model
    with these parameters against specified dataset.
    """

    results = []
    # generate simulation data from model
    for experiment in range(experiment_count):

        sim = np.zeros(np.shape(presentations), dtype=int)
        for trial_index in range(len(presentations)):
            presentation = presentations[trial_index]

            item_count = np.max(presentation)+1
            model = Classic_CMR( item_count, len(presentations),  encoding_drift_rate,
                start_drift_rate, recall_drift_rate, shared_support, item_support, learning_rate,
                primacy_scale, primacy_decay, stop_probability_scale,
                stop_probability_growth, choice_sensitivity, delay_drift_rate, drift_familiarity_scale,
                 mfc_familiarity_scale, mcf_familiarity_scale, sampling_rule)

            # simulate study events
            model.experience(np.eye(model.item_count, model.item_count)[presentation])

            # simulate and add recall events to trials array
            recalled = model.free_recall()
            xsorted = np.argsort(presentation)
            ypos = np.searchsorted(presentation[xsorted], recalled)
            sim[trial_index, :len(recalled)] = xsorted[ypos]+1

        # apply contiguity test
        results.append(alternative_contiguity_test(presentations, sim, lag_threshold, repetition_count))

    return pd.concat(results, keys=list(range(experiment_count)), names=['experiment']).reset_index()

# Cell

from numba import njit, prange
import numpy as np

@njit(fastmath=True, nogil=True, parallel=True)
def recall_probability_by_lag(presentations, study_positions_in_recall_order, max_lag=8):

    total_presented, total_retrieved = np.zeros(max_lag+2), np.zeros(max_lag+2)

    for trial_index in prange(len(presentations)):
        presented, retrieved = np.zeros(max_lag+2), np.zeros(max_lag+2)
        trial = study_positions_in_recall_order[trial_index]
        trial = trial[trial > 0]-1

        for item in np.unique(presentations[trial_index]):
            for idx, val in np.ndenumerate(presentations[trial_index]):
                if val == item:
                    locationA = idx[0]
                    break

            lag = 0
            if locationA < len(presentations[trial_index]):
                for idx, val in np.ndenumerate(presentations[trial_index][locationA+1:]):
                    if val == item:
                        lag = 1 + idx[0]
                        break

            presented[lag] += 1
            retrieved[lag] += locationA in trial

        total_presented += presented
        total_retrieved += retrieved

    return total_retrieved/total_presented